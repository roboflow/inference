# Welcome to Inference

![](https://github.com/roboflow/inference/raw/main/banner.png?raw=true)

Roboflow Inference is a fast, on-device computer vision inference server. With Inference, you can build multi-step "Workflows" that use state-of-the-art models. These Workflows can transform images, run and chain models, ask questions to VLMs, connect to external APIs, and more. Workflows can run on your own hardware, or in the cloud.

Inference supports essential video features, including object tracking, outlier frame detection (powered by embeddings), and tracking the time an object spends in a zone.

Inference runs both on the edge (i.e. on an NVIDIA Jetson) and in the cloud (i.e. AWS, GCP, Roboflow).

Inference is licensed under an [Apache 2.0 license](https://github.com/roboflow/inference/). Models supported by Inference are subject to their own licenses.

Ready to get started? [Let's build your first vision application with Inference](/start/getting-started/).

Need inspiration? Check out these guides:

- [Fine-tune and deploy SmolVLM2 for document understanding](https://www.youtube.com/watch?v=qLPInUmH9xE)
- [Deploy the Qwen2.5-VL VLM](https://www.youtube.com/watch?v=3PIDMhvwZd8)
- [Detect people in danger zones](https://www.youtube.com/watch?v=1N8JKCqR5Xg)
- [Measure the dimensions of objects](https://www.youtube.com/watch?v=FQY7TSHfZeI)
- [Build a vision app in 10 minutes with Roboflow Instant and a Workflow](https://www.youtube.com/watch?v=aPxlImNxj5A)
- [Deploy Florence-2 for object detection](https://www.youtube.com/watch?v=_u53TxShLsk)