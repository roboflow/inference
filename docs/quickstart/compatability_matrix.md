# Model Compatability

The table below shows on what devices you can deploy models supported by Inference.

| Model | CPU | GPU | TensorRT | Jetson 4.5.x | Jetson 4.6.x | Jetson 5.x | Roboflow Hosted Inference |
| --- | --- | --- | --- | --- | --- | --- | --- |
| YOLOv8 Object Detection | âœ… | âœ… | âœ… | ðŸš« | ðŸš« | âœ… | âœ… |
| YOLOv8 Classification | âœ… | âœ… | âœ… | ðŸš« | ðŸš« | âœ… | âœ… |
| YOLOv8 Segmentation | âœ… | âœ… | âœ… | ðŸš« | ðŸš« | âœ… | âœ… |
| YOLOv5 Object Detection | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… |
| YOLOv5 Classification | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… |
| YOLOv5 Segmentation | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… |
| DocTR | âœ… | âœ… | ðŸŸ¡ | âœ… | âœ… | âœ… | ðŸš§ |
| CLIP | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… |
| SAM | âœ… | âœ… | ðŸŸ¡ | ðŸš« | ðŸš« | ðŸš« | ðŸš« |
| ViT Classification | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… |
| YOLACT | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… |
| âœ… Fully supported |
| ðŸŸ¡ Not TRT accelerated |
| ðŸš« Not supported |
| ðŸš§ On roadmap |

See our [Docker Getting Started](/docs/quickstart/docker) guide for more information on how to deploy Inference on your device.