name: INTEGRATION TESTS - inference models
permissions:
  contents: read
on:
  push:
    branches: [main]
  workflow_dispatch:
    inputs:
      use_inference_models:
        type: boolean
        description: "Use inference_models"
        default: false

jobs:
  call_is_mergeable:
    uses: ./.github/workflows/check_if_branch_is_mergeable.yml
    secrets: inherit
  build-dev-test:
    needs: call_is_mergeable
    if: ${{ github.event_name != 'pull_request' || needs.call_is_mergeable.outputs.mergeable_state != 'not_clean' }}
    runs-on:
      labels: depot-ubuntu-22.04-8
      group: public-depot
    timeout-minutes: 45
    strategy:
      matrix:
        python-version: ["3.9", "3.10", "3.11", "3.12"]
    steps:
      - name: ğŸ›ï¸ Checkout
        uses: actions/checkout@v4
      - name: ğŸ Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
          check-latest: true
      - name: ğŸ“¦ Cache Python packages
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ matrix.python-version }}-${{ hashFiles('requirements/**') }}
          restore-keys: |
            ${{ runner.os }}-pip-${{ matrix.python-version }}-
      - name: ğŸš§ Install GDAL OS library
        run: sudo apt-get update && sudo apt-get install libgdal-dev
      - name: ğŸ“¦ Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install --upgrade setuptools
          pip install --extra-index-url https://download.pytorch.org/whl/cpu -r requirements/_requirements.txt -r requirements/requirements.cpu.txt -r requirements/requirements.sdk.http.txt -r requirements/requirements.test.unit.txt -r requirements/requirements.http.txt -r requirements/requirements.yolo_world.txt -r requirements/requirements.sam.txt -r requirements/requirements.transformers.txt
      - name: ğŸ§ª Integration Tests of Inference models
        timeout-minutes: 45
        env:
          USE_INFERENCE_MODELS: ${{ github.event.inputs.use_inference_models == 'true' }}
        run: MAX_BATCH_SIZE=6 python -m pytest tests/inference/models_predictions_tests
