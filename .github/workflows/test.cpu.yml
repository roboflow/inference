name: Code Quality & Regression Tests - CPU

on:
  pull_request:
    branches: [main]
  workflow_dispatch:

jobs:
  build:
    if: ${{ !github.event.act }}
    runs-on:
      group: group8core
      labels: ubuntu-latest

    steps:
      - name: Set up QEMU
        uses: docker/setup-qemu-action@v2
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v2
      - name: Login to Docker Hub
        uses: docker/login-action@v2
        with:
          username: ${{ secrets.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_TOKEN }}
      - name: ğŸ›ï¸ Checkout
        uses: actions/checkout@v3
        with:
          ref: ${{ github.head_ref }}
      
      - name: ğŸ¦¾ Install dependencies
        run: |
          python -m pip install --upgrade pip
          python -m pip install -r requirements/requirements.test.unit.txt -r requirements/requirements.test.integration.txt
      - name: ğŸ§¹ Lint with flake8
        run: |
          make check_code_quality
      - name: ğŸ§ª Unit Tests of Inference
        timeout-minutes: 30
        run: |
          pip install -r requirements/_requirements.txt -r requirements/requirements.cpu.txt -r requirements/requirements.hosted.txt
          python -m pytest tests/inference/unit_tests
      - name: ğŸ§ª Unit Tests of clients
        run: |
          python -m pip install -r requirements/requirements.sdk.http.txt
          python -m pytest tests/inference_sdk/unit_tests
      - name: ğŸ§ª Unit Tests of Inference CLI
        run: |
          python -m pip install -r requirements/requirements.cli.txt
          python -m pytest tests/inference_cli/unit_tests
      - name: ğŸ§ª Integration Tests of Inference CLI
        timeout-minutes: 30
        run: |
          python -m pip install -r requirements/requirements.cli.txt
          python -m pytest tests/inference_cli/integration_tests
      - name: ğŸ”¨ Build and Push Test Docker
        run: |
          docker pull roboflow/roboflow-inference-server-cpu:test
          docker build -t roboflow/roboflow-inference-server-cpu:test -f docker/dockerfiles/Dockerfile.onnx.cpu .
          docker push roboflow/roboflow-inference-server-cpu:test
      - name: ğŸ”‹ Start Test Docker
        run: |
          PORT=9101 INFERENCE_SERVER_REPO=roboflow-inference-server-cpu make start_test_docker_cpu
      - name: ğŸ§ª Regression Tests
        run: |
          PORT=9101 API_KEY=${{ secrets.API_KEY }} asl_instance_segmentation_API_KEY=${{ secrets.ASL_INSTANCE_SEGMENTATION_API_KEY }} asl_poly_instance_seg_API_KEY=${{ secrets.ASL_POLY_INSTANCE_SEG_API_KEY }} bccd_favz3_API_KEY=${{ secrets.BCCD_FAVZ3_API_KEY }} bccd_i4nym_API_KEY=${{ secrets.BCCD_I4NYM_API_KEY }} cats_and_dogs_smnpl_API_KEY=${{ secrets.CATS_AND_DOGS_SMNPL_API_KEY }} coins_xaz9i_API_KEY=${{ secrets.COINS_XAZ9I_API_KEY }} melee_API_KEY=${{ secrets.MELEE_API_KEY }} python -m pytest tests/inference/integration_tests
          make stop_test_docker