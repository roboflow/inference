
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Scalable, on-device computer vision deployment.">
      
      
        <meta name="author" content="Roboflow">
      
      
        <link rel="canonical" href="https://inference.roboflow.com/inference_helpers/cli_commands/reference/">
      
      
        <link rel="prev" href="../cloud/">
      
      
        <link rel="next" href="../../../api/">
      
      
        
      
      
      <link rel="icon" href="../../../favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.4+insiders-4.53.15">
    
    
      
        <title>Reference - Roboflow Inference</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.f15084e1.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.ab4e12ef.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Inter:300,300i,400,400i,700,700i%7Cui-monospace:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Inter";--md-code-font:"ui-monospace"}</style>
      
    
    
      <link rel="stylesheet" href="../../../assets/_mkdocstrings.css">
    
      <link rel="stylesheet" href="../../../styles/cookbooks.css">
    
      <link rel="stylesheet" href="../../../styles.css">
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      
  


  
  

<script id="__analytics">function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-T0CED2YY8K"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-T0CED2YY8K",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-T0CED2YY8K",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script>
  
    <script>"undefined"!=typeof __md_analytics&&__md_analytics()</script>
  

    
    
  
  

  
<meta property="og:type" content="website" />
<meta property="og:title" content="Reference - Roboflow Inference" />
<meta property="og:description" content="Scalable, on-device computer vision deployment." />
<meta property="og:image" content="https://inference.roboflow.com/assets/images/social/inference_helpers/cli_commands/reference.png" />
<meta property="og:image:type" content="image/png" />
<meta property="og:image:width" content="1200" />
<meta property="og:image:height" content="630" />
<meta property="og:url" content="https://inference.roboflow.com/inference_helpers/cli_commands/reference/" />
<meta property="twitter:card" content="summary_large_image" />
<meta property="twitter:title" content="Reference - Roboflow Inference" />
<meta property="twitter:description" content="Scalable, on-device computer vision deployment." />
<meta property="twitter:image" content="https://inference.roboflow.com/assets/images/social/inference_helpers/cli_commands/reference.png" />
</head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="custom" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#inference" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <div data-md-color-scheme="default" data-md-component="outdated" hidden>
        
      </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="Roboflow Inference" class="md-header__button md-logo" aria-label="Roboflow Inference" data-md-component="logo">
      
  <img src="../../../roboflow-logomark-white.svg" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Roboflow Inference
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Reference
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="custom" data-md-color-accent="indigo"  aria-hidden="true"  type="radio" name="__palette" id="__palette_0">
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="Share" aria-label="Share" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/roboflow/inference" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    roboflow/inference
  </div>
</a>
      </div>
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../start/overview/" class="md-tabs__link">
          
  
    
  
  Start

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../quickstart/run_a_model/" class="md-tabs__link">
          
  
    
  
  Models

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../workflows/about/" class="md-tabs__link">
          
  
    
  
  Workflows

        </a>
      </li>
    
  

      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../../../quickstart/roboflow_ecosystem/" class="md-tabs__link">
          
  
    
  
  Reference

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../workflows/gallery/basic_workflows/" class="md-tabs__link">
          
  
    
  
  Examples

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
  
        
      
  

      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="Roboflow Inference" class="md-nav__button md-logo" aria-label="Roboflow Inference" data-md-component="logo">
      
  <img src="../../../roboflow-logomark-white.svg" alt="logo">

    </a>
    Roboflow Inference
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/roboflow/inference" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    roboflow/inference
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../start/overview/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    
  
    Start
  

    
  </span>
  
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../quickstart/run_a_model/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    
  
    Models
  

    
  </span>
  
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../workflows/about/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    
  
    Workflows
  

    
  </span>
  
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
        
        
      
      
    
    
      
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" checked>
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="">
            
  
  <span class="md-ellipsis">
    
  
    Reference
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            
  
    Reference
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../quickstart/roboflow_ecosystem/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    
  
    Roboflow Ecosystem
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../using_inference/inference_pipeline/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    
  
    InferencePipeline
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
      
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../inference_sdk/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    
  
    Python SDK
  

    
  </span>
  
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
      
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_4" checked>
        
          
          <label class="md-nav__link" for="__nav_4_4" id="__nav_4_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    
  
    Command Line Interface
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_4_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_4_4">
            <span class="md-nav__icon md-icon"></span>
            
  
    Command Line Interface
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../inference_cli/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    
  
    About CLI
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../server/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    
  
    Control The Server
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../workflows/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    
  
    Run Workflows
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../benchmark/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    
  
    Benchmark Inference
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../infer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    
  
    Make Predictions
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../cloud/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    
  
    Deploy To Cloud
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    
  
    Reference
  

    
  </span>
  
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    
  
    Reference
  

    
  </span>
  
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#inference-infer" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference infer
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#inference-server" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference server
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="inference server">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#inference-server-start" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference server start
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference-server-status" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference server status
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference-server-stop" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference server stop
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#inference-cloud" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference cloud
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="inference cloud">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#inference-cloud-status" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference cloud status
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference-cloud-deploy" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference cloud deploy
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference-cloud-undeploy" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference cloud undeploy
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference-cloud-stop" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference cloud stop
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference-cloud-start" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference cloud start
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#inference-benchmark" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference benchmark
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="inference benchmark">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#inference-benchmark-api-speed" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference benchmark api-speed
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference-benchmark-python-package-speed" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference benchmark python-package-speed
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference-benchmark-inference-models-speed" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference benchmark inference-models-speed
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#inference-workflows" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference workflows
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="inference workflows">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#inference-workflows-process-video" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference workflows process-video
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference-workflows-process-image" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference workflows process-image
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference-workflows-process-images-directory" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference workflows process-images-directory
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#inference-rf-cloud" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference rf-cloud
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="inference rf-cloud">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#inference-rf-cloud-data-staging" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference rf-cloud data-staging
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="inference rf-cloud data-staging">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#inference-rf-cloud-data-staging-list-batches" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference rf-cloud data-staging list-batches
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference-rf-cloud-data-staging-list-batch-content" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference rf-cloud data-staging list-batch-content
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference-rf-cloud-data-staging-create-batch-of-images" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference rf-cloud data-staging create-batch-of-images
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference-rf-cloud-data-staging-create-batch-of-videos" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference rf-cloud data-staging create-batch-of-videos
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference-rf-cloud-data-staging-show-batch-details" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference rf-cloud data-staging show-batch-details
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference-rf-cloud-data-staging-export-batch" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference rf-cloud data-staging export-batch
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference-rf-cloud-data-staging-list-ingest-details" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference rf-cloud data-staging list-ingest-details
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference-rf-cloud-batch-processing" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference rf-cloud batch-processing
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="inference rf-cloud batch-processing">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#inference-rf-cloud-batch-processing-list-jobs" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference rf-cloud batch-processing list-jobs
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference-rf-cloud-batch-processing-show-job-details" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference rf-cloud batch-processing show-job-details
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference-rf-cloud-batch-processing-process-images-with-workflow" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference rf-cloud batch-processing process-images-with-workflow
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference-rf-cloud-batch-processing-process-videos-with-workflow" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference rf-cloud batch-processing process-videos-with-workflow
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference-rf-cloud-batch-processing-trt-compile" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference rf-cloud batch-processing trt-compile
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference-rf-cloud-batch-processing-abort-job" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference rf-cloud batch-processing abort-job
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference-rf-cloud-batch-processing-restart-job" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference rf-cloud batch-processing restart-job
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference-rf-cloud-batch-processing-fetch-logs" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference rf-cloud batch-processing fetch-logs
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
      
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../api/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    
  
    HTTP API
  

    
  </span>
  
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../reference/inference/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    
  
    inference Python Package
  

    
  </span>
  
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
      
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../enterprise/parallel_processing/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    
  
    Enterprise Features
  

    
  </span>
  
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../quickstart/docker/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    
  
    Server Configuration
  

    
  </span>
  
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../using_inference/offline_weights_download/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    
  
    Model Weights Download
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../contributing/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    
  
    Contribute to Inference
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://github.com/roboflow/inference/releases" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    
  
    Changelog
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../workflows/gallery/basic_workflows/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    
  
    Examples
  

    
  </span>
  
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#inference-infer" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference infer
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#inference-server" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference server
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="inference server">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#inference-server-start" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference server start
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference-server-status" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference server status
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference-server-stop" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference server stop
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#inference-cloud" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference cloud
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="inference cloud">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#inference-cloud-status" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference cloud status
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference-cloud-deploy" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference cloud deploy
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference-cloud-undeploy" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference cloud undeploy
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference-cloud-stop" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference cloud stop
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference-cloud-start" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference cloud start
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#inference-benchmark" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference benchmark
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="inference benchmark">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#inference-benchmark-api-speed" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference benchmark api-speed
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference-benchmark-python-package-speed" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference benchmark python-package-speed
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference-benchmark-inference-models-speed" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference benchmark inference-models-speed
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#inference-workflows" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference workflows
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="inference workflows">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#inference-workflows-process-video" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference workflows process-video
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference-workflows-process-image" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference workflows process-image
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference-workflows-process-images-directory" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference workflows process-images-directory
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#inference-rf-cloud" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference rf-cloud
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="inference rf-cloud">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#inference-rf-cloud-data-staging" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference rf-cloud data-staging
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="inference rf-cloud data-staging">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#inference-rf-cloud-data-staging-list-batches" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference rf-cloud data-staging list-batches
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference-rf-cloud-data-staging-list-batch-content" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference rf-cloud data-staging list-batch-content
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference-rf-cloud-data-staging-create-batch-of-images" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference rf-cloud data-staging create-batch-of-images
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference-rf-cloud-data-staging-create-batch-of-videos" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference rf-cloud data-staging create-batch-of-videos
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference-rf-cloud-data-staging-show-batch-details" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference rf-cloud data-staging show-batch-details
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference-rf-cloud-data-staging-export-batch" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference rf-cloud data-staging export-batch
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference-rf-cloud-data-staging-list-ingest-details" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference rf-cloud data-staging list-ingest-details
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference-rf-cloud-batch-processing" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference rf-cloud batch-processing
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="inference rf-cloud batch-processing">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#inference-rf-cloud-batch-processing-list-jobs" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference rf-cloud batch-processing list-jobs
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference-rf-cloud-batch-processing-show-job-details" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference rf-cloud batch-processing show-job-details
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference-rf-cloud-batch-processing-process-images-with-workflow" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference rf-cloud batch-processing process-images-with-workflow
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference-rf-cloud-batch-processing-process-videos-with-workflow" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference rf-cloud batch-processing process-videos-with-workflow
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference-rf-cloud-batch-processing-trt-compile" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference rf-cloud batch-processing trt-compile
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference-rf-cloud-batch-processing-abort-job" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference rf-cloud batch-processing abort-job
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference-rf-cloud-batch-processing-restart-job" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference rf-cloud batch-processing restart-job
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference-rf-cloud-batch-processing-fetch-logs" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference rf-cloud batch-processing fetch-logs
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
  
    
            <div class="md-content" data-md-component="content">
              
              <article class="md-content__inner md-typeset">
                
                  


  
    <a href="https://github.com/roboflow/inference/tree/main/docs/inference_helpers/cli_commands/reference.md" title="Edit this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"/></svg>
    </a>
  
  


<h1 id="inference"><code>inference</code><a class="headerlink" href="#inference" title="Permanent link">&para;</a></h1>
<p><strong>Usage</strong>:</p>
<div class="highlight"><pre><span></span><code><span class="gp">$ </span>inference<span class="w"> </span><span class="o">[</span>OPTIONS<span class="o">]</span><span class="w"> </span>COMMAND<span class="w"> </span><span class="o">[</span>ARGS<span class="o">]</span>...
</code></pre></div>
<p><strong>Options</strong>:</p>
<ul>
<li><code>--version</code></li>
<li><code>--install-completion</code>: Install completion for the current shell.</li>
<li><code>--show-completion</code>: Show completion for the current shell, to copy it or customize the installation.</li>
<li><code>--help</code>: Show this message and exit.</li>
</ul>
<p><strong>Commands</strong>:</p>
<ul>
<li><code>infer</code></li>
<li><code>server</code>: Commands for running the inference server...</li>
<li><code>cloud</code>: Commands for running the inference in...</li>
<li><code>benchmark</code>: Commands for running inference benchmarks.</li>
<li><code>workflows</code>: Commands for interacting with Roboflow...</li>
<li><code>rf-cloud</code>: Commands for interacting with Roboflow Cloud</li>
</ul>
<h2 id="inference-infer"><code>inference infer</code><a class="headerlink" href="#inference-infer" title="Permanent link">&para;</a></h2>
<p><strong>Usage</strong>:</p>
<div class="highlight"><pre><span></span><code><span class="gp">$ </span>inference<span class="w"> </span>infer<span class="w"> </span><span class="o">[</span>OPTIONS<span class="o">]</span>
</code></pre></div>
<p><strong>Options</strong>:</p>
<ul>
<li><code>-i, --input TEXT</code>: URL or local path of image / directory with images or video to run inference on.  [required]</li>
<li><code>-m, --model_id TEXT</code>: Model ID in format project/version.  [required]</li>
<li><code>-a, --api-key TEXT</code>: Roboflow API key for your workspace. If not given - env variable <code>ROBOFLOW_API_KEY</code> will be used</li>
<li><code>-h, --host TEXT</code>: Host to run inference on.  [default: http://localhost:9001]</li>
<li><code>-o, --output_location TEXT</code>: Location where to save the result (path to directory)</li>
<li><code>-D, --display / -d, --no-display</code>: Boolean flag to decide if visualisations should be displayed on the screen  [default: no-display]</li>
<li><code>-V, --visualise / -v, --no-visualise</code>: Boolean flag to decide if visualisations should be preserved  [default: visualise]</li>
<li><code>-c, --visualisation_config TEXT</code>: Location of yaml file with visualisation config</li>
<li><code>-mc, --model_config TEXT</code>: Location of yaml file with model config</li>
<li><code>--help</code>: Show this message and exit.</li>
</ul>
<h2 id="inference-server"><code>inference server</code><a class="headerlink" href="#inference-server" title="Permanent link">&para;</a></h2>
<p>Commands for running the inference server locally. </p>
<p>Supported devices targets are x86 CPU, ARM64 CPU, and NVIDIA GPU.</p>
<p><strong>Usage</strong>:</p>
<div class="highlight"><pre><span></span><code><span class="gp">$ </span>inference<span class="w"> </span>server<span class="w"> </span><span class="o">[</span>OPTIONS<span class="o">]</span><span class="w"> </span>COMMAND<span class="w"> </span><span class="o">[</span>ARGS<span class="o">]</span>...
</code></pre></div>
<p><strong>Options</strong>:</p>
<ul>
<li><code>--help</code>: Show this message and exit.</li>
</ul>
<p><strong>Commands</strong>:</p>
<ul>
<li><code>start</code></li>
<li><code>status</code></li>
<li><code>stop</code></li>
</ul>
<h3 id="inference-server-start"><code>inference server start</code><a class="headerlink" href="#inference-server-start" title="Permanent link">&para;</a></h3>
<p><strong>Usage</strong>:</p>
<div class="highlight"><pre><span></span><code><span class="gp">$ </span>inference<span class="w"> </span>server<span class="w"> </span>start<span class="w"> </span><span class="o">[</span>OPTIONS<span class="o">]</span>
</code></pre></div>
<p><strong>Options</strong>:</p>
<ul>
<li><code>-p, --port INTEGER</code>: Port to run the inference server on (default is 9001).  [default: 9001]</li>
<li><code>-rfe, --rf-env TEXT</code>: Roboflow environment to run the inference server with (default is roboflow-platform).  [default: roboflow-platform]</li>
<li><code>-e, --env-file TEXT</code>: Path to file with env variables (in each line KEY=VALUE). Optional. If given - values will be overriden by any explicit parameter of this command.</li>
<li><code>-d, --dev</code>: Run inference server in development mode (default is False).</li>
<li><code>-k, --roboflow-api-key TEXT</code>: Roboflow API key (default is None).</li>
<li><code>--tunnel</code>: Start a tunnel to expose inference to external requests on a TLS-enabled https://&lt;subdomain&gt;.roboflow.run endpoint</li>
<li><code>--image TEXT</code>: Point specific docker image you would like to run with command (useful for development of custom builds of inference server)</li>
<li><code>--use-local-images / --not-use-local-images</code>: Flag to allow using local images (if set False image is always attempted to be pulled)  [default: not-use-local-images]</li>
<li><code>--metrics-enabled / --metrics-disabled</code>: Flag controlling if metrics are enabled (default is True)  [default: metrics-enabled]</li>
<li><code>--help</code>: Show this message and exit.</li>
</ul>
<h3 id="inference-server-status"><code>inference server status</code><a class="headerlink" href="#inference-server-status" title="Permanent link">&para;</a></h3>
<p><strong>Usage</strong>:</p>
<div class="highlight"><pre><span></span><code><span class="gp">$ </span>inference<span class="w"> </span>server<span class="w"> </span>status<span class="w"> </span><span class="o">[</span>OPTIONS<span class="o">]</span>
</code></pre></div>
<p><strong>Options</strong>:</p>
<ul>
<li><code>--help</code>: Show this message and exit.</li>
</ul>
<h3 id="inference-server-stop"><code>inference server stop</code><a class="headerlink" href="#inference-server-stop" title="Permanent link">&para;</a></h3>
<p><strong>Usage</strong>:</p>
<div class="highlight"><pre><span></span><code><span class="gp">$ </span>inference<span class="w"> </span>server<span class="w"> </span>stop<span class="w"> </span><span class="o">[</span>OPTIONS<span class="o">]</span>
</code></pre></div>
<p><strong>Options</strong>:</p>
<ul>
<li><code>--help</code>: Show this message and exit.</li>
</ul>
<h2 id="inference-cloud"><code>inference cloud</code><a class="headerlink" href="#inference-cloud" title="Permanent link">&para;</a></h2>
<p>Commands for running the inference in cloud with skypilot. </p>
<p>Supported devices targets are x86 CPU and NVIDIA GPU VMs.</p>
<p><strong>Usage</strong>:</p>
<div class="highlight"><pre><span></span><code><span class="gp">$ </span>inference<span class="w"> </span>cloud<span class="w"> </span><span class="o">[</span>OPTIONS<span class="o">]</span><span class="w"> </span>COMMAND<span class="w"> </span><span class="o">[</span>ARGS<span class="o">]</span>...
</code></pre></div>
<p><strong>Options</strong>:</p>
<ul>
<li><code>--help</code>: Show this message and exit.</li>
</ul>
<p><strong>Commands</strong>:</p>
<ul>
<li><code>status</code></li>
<li><code>deploy</code></li>
<li><code>undeploy</code></li>
<li><code>stop</code></li>
<li><code>start</code></li>
</ul>
<h3 id="inference-cloud-status"><code>inference cloud status</code><a class="headerlink" href="#inference-cloud-status" title="Permanent link">&para;</a></h3>
<p><strong>Usage</strong>:</p>
<div class="highlight"><pre><span></span><code><span class="gp">$ </span>inference<span class="w"> </span>cloud<span class="w"> </span>status<span class="w"> </span><span class="o">[</span>OPTIONS<span class="o">]</span>
</code></pre></div>
<p><strong>Options</strong>:</p>
<ul>
<li><code>--help</code>: Show this message and exit.</li>
</ul>
<h3 id="inference-cloud-deploy"><code>inference cloud deploy</code><a class="headerlink" href="#inference-cloud-deploy" title="Permanent link">&para;</a></h3>
<p><strong>Usage</strong>:</p>
<div class="highlight"><pre><span></span><code><span class="gp">$ </span>inference<span class="w"> </span>cloud<span class="w"> </span>deploy<span class="w"> </span><span class="o">[</span>OPTIONS<span class="o">]</span>
</code></pre></div>
<p><strong>Options</strong>:</p>
<ul>
<li><code>-p, --provider TEXT</code>: Cloud provider to deploy to. Currently aws or gcp.  [required]</li>
<li><code>-t, --compute-type TEXT</code>: Execution environment to deploy to: cpu or gpu.  [required]</li>
<li><code>-d, --dry-run</code>: Print out deployment plan without executing.</li>
<li><code>-c, --custom TEXT</code>: Path to config file to override default config.</li>
<li><code>-r, --roboflow-api-key TEXT</code>: Roboflow API key for your workspace.</li>
<li><code>-h, --help</code>: Print out help text.</li>
</ul>
<h3 id="inference-cloud-undeploy"><code>inference cloud undeploy</code><a class="headerlink" href="#inference-cloud-undeploy" title="Permanent link">&para;</a></h3>
<p><strong>Usage</strong>:</p>
<div class="highlight"><pre><span></span><code><span class="gp">$ </span>inference<span class="w"> </span>cloud<span class="w"> </span>undeploy<span class="w"> </span><span class="o">[</span>OPTIONS<span class="o">]</span><span class="w"> </span>CLUSTER_NAME
</code></pre></div>
<p><strong>Arguments</strong>:</p>
<ul>
<li><code>CLUSTER_NAME</code>: Name of cluster to undeploy.  [required]</li>
</ul>
<p><strong>Options</strong>:</p>
<ul>
<li><code>--help</code>: Show this message and exit.</li>
</ul>
<h3 id="inference-cloud-stop"><code>inference cloud stop</code><a class="headerlink" href="#inference-cloud-stop" title="Permanent link">&para;</a></h3>
<p><strong>Usage</strong>:</p>
<div class="highlight"><pre><span></span><code><span class="gp">$ </span>inference<span class="w"> </span>cloud<span class="w"> </span>stop<span class="w"> </span><span class="o">[</span>OPTIONS<span class="o">]</span><span class="w"> </span>CLUSTER_NAME
</code></pre></div>
<p><strong>Arguments</strong>:</p>
<ul>
<li><code>CLUSTER_NAME</code>: Name of cluster to stop.  [required]</li>
</ul>
<p><strong>Options</strong>:</p>
<ul>
<li><code>--help</code>: Show this message and exit.</li>
</ul>
<h3 id="inference-cloud-start"><code>inference cloud start</code><a class="headerlink" href="#inference-cloud-start" title="Permanent link">&para;</a></h3>
<p><strong>Usage</strong>:</p>
<div class="highlight"><pre><span></span><code><span class="gp">$ </span>inference<span class="w"> </span>cloud<span class="w"> </span>start<span class="w"> </span><span class="o">[</span>OPTIONS<span class="o">]</span><span class="w"> </span>CLUSTER_NAME
</code></pre></div>
<p><strong>Arguments</strong>:</p>
<ul>
<li><code>CLUSTER_NAME</code>: Name of cluster to start.  [required]</li>
</ul>
<p><strong>Options</strong>:</p>
<ul>
<li><code>--help</code>: Show this message and exit.</li>
</ul>
<h2 id="inference-benchmark"><code>inference benchmark</code><a class="headerlink" href="#inference-benchmark" title="Permanent link">&para;</a></h2>
<p>Commands for running inference benchmarks.</p>
<p><strong>Usage</strong>:</p>
<div class="highlight"><pre><span></span><code><span class="gp">$ </span>inference<span class="w"> </span>benchmark<span class="w"> </span><span class="o">[</span>OPTIONS<span class="o">]</span><span class="w"> </span>COMMAND<span class="w"> </span><span class="o">[</span>ARGS<span class="o">]</span>...
</code></pre></div>
<p><strong>Options</strong>:</p>
<ul>
<li><code>--help</code>: Show this message and exit.</li>
</ul>
<p><strong>Commands</strong>:</p>
<ul>
<li><code>api-speed</code></li>
<li><code>python-package-speed</code></li>
<li><code>inference-models-speed</code>: This command provides a benchmark of...</li>
</ul>
<h3 id="inference-benchmark-api-speed"><code>inference benchmark api-speed</code><a class="headerlink" href="#inference-benchmark-api-speed" title="Permanent link">&para;</a></h3>
<p><strong>Usage</strong>:</p>
<div class="highlight"><pre><span></span><code><span class="gp">$ </span>inference<span class="w"> </span>benchmark<span class="w"> </span>api-speed<span class="w"> </span><span class="o">[</span>OPTIONS<span class="o">]</span>
</code></pre></div>
<p><strong>Options</strong>:</p>
<ul>
<li><code>-m, --model_id TEXT</code>: Model ID in format project/version.</li>
<li><code>-wid, --workflow-id TEXT</code>: Workflow ID.</li>
<li><code>-wn, --workspace-name TEXT</code>: Workspace Name.</li>
<li><code>-ws, --workflow-specification TEXT</code>: Workflow specification.</li>
<li><code>-wp, --workflow-parameters TEXT</code>: Model ID in format project/version.</li>
<li><code>-d, --dataset_reference TEXT</code>: Name of predefined dataset (one of [&#x27;coco&#x27;]) or path to directory with images  [default: coco]</li>
<li><code>-h, --host TEXT</code>: Host to run inference on.  [default: http://localhost:9001]</li>
<li><code>-wr, --warm_up_requests INTEGER</code>: Number of warm-up requests  [default: 10]</li>
<li><code>-br, --benchmark_requests INTEGER</code>: Number of benchmark requests  [default: 1000]</li>
<li><code>-bs, --batch_size INTEGER</code>: Batch size of single request  [default: 1]</li>
<li><code>-c, --clients INTEGER</code>: Meaningful if <code>rps</code> not specified - number of concurrent threads that will send requests one by one  [default: 1]</li>
<li><code>-rps, --rps INTEGER</code>: Number of requests per second to emit. If not specified - requests will be sent one-by-one by requested number of client threads</li>
<li><code>-a, --api-key TEXT</code>: Roboflow API key for your workspace. If not given - env variable <code>ROBOFLOW_API_KEY</code> will be used</li>
<li><code>-mc, --model_config TEXT</code>: Location of yaml file with model config</li>
<li><code>-o, --output_location TEXT</code>: Location where to save the result (path to file or directory)</li>
<li><code>-L, --legacy-endpoints / -l, --no-legacy-endpoints</code>: Boolean flag to decide if legacy endpoints should be used (applicable for self-hosted API benchmark)  [default: no-legacy-endpoints]</li>
<li><code>-y, --yes / -n, --no</code>: Boolean flag to decide on auto <code>yes</code> answer given on user input required.  [default: no]</li>
<li><code>--max_error_rate FLOAT</code>: Max error rate for API speed benchmark - if given and the error rate is higher - command will return non-success error code. Expected percentage values in range 0.0-100.0</li>
<li><code>--help</code>: Show this message and exit.</li>
</ul>
<h3 id="inference-benchmark-python-package-speed"><code>inference benchmark python-package-speed</code><a class="headerlink" href="#inference-benchmark-python-package-speed" title="Permanent link">&para;</a></h3>
<p><strong>Usage</strong>:</p>
<div class="highlight"><pre><span></span><code><span class="gp">$ </span>inference<span class="w"> </span>benchmark<span class="w"> </span>python-package-speed<span class="w"> </span><span class="o">[</span>OPTIONS<span class="o">]</span>
</code></pre></div>
<p><strong>Options</strong>:</p>
<ul>
<li><code>-m, --model_id TEXT</code>: Model ID in format project/version.  [required]</li>
<li><code>-d, --dataset_reference TEXT</code>: Name of predefined dataset (one of [&#x27;coco&#x27;]) or path to directory with images  [default: coco]</li>
<li><code>-wi, --warm_up_inferences INTEGER</code>: Number of warm-up requests  [default: 10]</li>
<li><code>-bi, --benchmark_requests INTEGER</code>: Number of benchmark requests  [default: 1000]</li>
<li><code>-bs, --batch_size INTEGER</code>: Batch size of single request  [default: 1]</li>
<li><code>-a, --api-key TEXT</code>: Roboflow API key for your workspace. If not given - env variable <code>ROBOFLOW_API_KEY</code> will be used</li>
<li><code>-mc, --model_config TEXT</code>: Location of yaml file with model config</li>
<li><code>-o, --output_location TEXT</code>: Location where to save the result (path to file or directory)</li>
<li><code>--help</code>: Show this message and exit.</li>
</ul>
<h3 id="inference-benchmark-inference-models-speed"><code>inference benchmark inference-models-speed</code><a class="headerlink" href="#inference-benchmark-inference-models-speed" title="Permanent link">&para;</a></h3>
<p>This command provides a benchmark of inference-models package. Currently, support for this feature is experimental.</p>
<p><strong>Usage</strong>:</p>
<div class="highlight"><pre><span></span><code><span class="gp">$ </span>inference<span class="w"> </span>benchmark<span class="w"> </span>inference-models-speed<span class="w"> </span><span class="o">[</span>OPTIONS<span class="o">]</span>
</code></pre></div>
<p><strong>Options</strong>:</p>
<ul>
<li><code>-m, --model_id TEXT</code>: Model ID in format project/version.  [required]</li>
<li><code>-d, --dataset_reference TEXT</code>: Name of predefined dataset (one of [&#x27;coco&#x27;]) or path to directory with images  [default: coco]</li>
<li><code>-wi, --warm_up_inferences INTEGER</code>: Number of warm-up requests  [default: 10]</li>
<li><code>-bi, --benchmark_requests INTEGER</code>: Number of benchmark requests  [default: 1000]</li>
<li><code>-bs, --batch_size INTEGER</code>: Batch size of single request  [default: 1]</li>
<li><code>-a, --api-key TEXT</code>: Roboflow API key for your workspace. If not given - env variable <code>ROBOFLOW_API_KEY</code> will be used</li>
<li><code>-mc, --model_config TEXT</code>: Location of yaml file with model config</li>
<li><code>-o, --output_location TEXT</code>: Location where to save the result (path to file or directory)</li>
<li><code>-mpi, --model_package_id TEXT</code>: Selected model package ID (leave blank to run auto-negotiation)</li>
<li><code>--images-as-tensors / --no-images-as-tensors</code>: Boolean flag to decide if input images are to be loaded as tensors on the device that model is running, or should be left as np.arrays.  [default: images-as-tensors]</li>
<li><code>--allow-untrusted-packages / --no-allow-untrusted-packages</code>: Boolean flag to decide if untrusted packages (for example the ones registered by clients) are allowed to be loaded.  [default: allow-untrusted-packages]</li>
<li><code>--help</code>: Show this message and exit.</li>
</ul>
<h2 id="inference-workflows"><code>inference workflows</code><a class="headerlink" href="#inference-workflows" title="Permanent link">&para;</a></h2>
<p>Commands for interacting with Roboflow Workflows</p>
<p><strong>Usage</strong>:</p>
<div class="highlight"><pre><span></span><code><span class="gp">$ </span>inference<span class="w"> </span>workflows<span class="w"> </span><span class="o">[</span>OPTIONS<span class="o">]</span><span class="w"> </span>COMMAND<span class="w"> </span><span class="o">[</span>ARGS<span class="o">]</span>...
</code></pre></div>
<p><strong>Options</strong>:</p>
<ul>
<li><code>--help</code>: Show this message and exit.</li>
</ul>
<p><strong>Commands</strong>:</p>
<ul>
<li><code>process-video</code>: Process video file with your Workflow...</li>
<li><code>process-image</code>: Process single image with Workflows...</li>
<li><code>process-images-directory</code>: Process whole images directory with...</li>
</ul>
<h3 id="inference-workflows-process-video"><code>inference workflows process-video</code><a class="headerlink" href="#inference-workflows-process-video" title="Permanent link">&para;</a></h3>
<p>Process video file with your Workflow locally (inference Python package required)</p>
<p><strong>Usage</strong>:</p>
<div class="highlight"><pre><span></span><code><span class="gp">$ </span>inference<span class="w"> </span>workflows<span class="w"> </span>process-video<span class="w"> </span><span class="o">[</span>OPTIONS<span class="o">]</span>
</code></pre></div>
<p><strong>Options</strong>:</p>
<ul>
<li><code>-v, --video_path TEXT</code>: Path to video to be processed  [required]</li>
<li><code>-o, --output_dir TEXT</code>: Path to output directory  [required]</li>
<li><code>-ft, --output_file_type [jsonl|csv]</code>: Type of the output file  [default: csv]</li>
<li><code>-ws, --workflow_spec TEXT</code>: Path to JSON file with Workflow definition (mutually exclusive with <code>workspace_name</code> and <code>workflow_id</code>)</li>
<li><code>-wn, --workspace_name TEXT</code>: Name of Roboflow workspace the that Workflow belongs to (mutually exclusive with <code>workflow_specification_path</code>)</li>
<li><code>-wid, --workflow_id TEXT</code>: Identifier of a Workflow on Roboflow platform (mutually exclusive with <code>workflow_specification_path</code>)</li>
<li><code>-wvid, --workflow_version_id TEXT</code>: Specific version of the Workflow to use. If not provided, the latest version is used.</li>
<li><code>--workflow_params TEXT</code>: Path to JSON document with Workflow parameters - helpful when Workflow is parametrized and passing the parameters in CLI is not handy / impossible due to typing conversion issues.</li>
<li><code>--image_input_name TEXT</code>: Name of the Workflow input that defines placeholder for image to be processed  [default: image]</li>
<li><code>--max_fps FLOAT</code>: Use the parameter to limit video FPS (additional frames will be skipped in processing).</li>
<li><code>--save_out_video / --no_save_out_video</code>: Flag deciding if image outputs of the workflow should be saved as video file  [default: save_out_video]</li>
<li><code>-a, --api-key TEXT</code>: Roboflow API key for your workspace. If not given - env variable <code>ROBOFLOW_API_KEY</code> will be used</li>
<li><code>--allow_override / --no_override</code>: Flag to decide if content of output directory can be overridden.  [default: no_override]</li>
<li><code>--debug_mode / --no_debug_mode</code>: Flag enabling errors stack traces to be displayed (helpful for debugging)  [default: no_debug_mode]</li>
<li><code>--help</code>: Show this message and exit.</li>
</ul>
<h3 id="inference-workflows-process-image"><code>inference workflows process-image</code><a class="headerlink" href="#inference-workflows-process-image" title="Permanent link">&para;</a></h3>
<p>Process single image with Workflows (inference Package may be needed dependent on mode)</p>
<p><strong>Usage</strong>:</p>
<div class="highlight"><pre><span></span><code><span class="gp">$ </span>inference<span class="w"> </span>workflows<span class="w"> </span>process-image<span class="w"> </span><span class="o">[</span>OPTIONS<span class="o">]</span>
</code></pre></div>
<p><strong>Options</strong>:</p>
<ul>
<li><code>-i, --image_path TEXT</code>: Path to image to be processed  [required]</li>
<li><code>-o, --output_dir TEXT</code>: Path to output directory  [required]</li>
<li><code>-pt, --processing_target [api|inference_package]</code>: Defines where the actual processing will be done, either in inference Python package running locally, or behind the API (which ensures greater throughput).  [default: api]</li>
<li><code>-ws, --workflow_spec TEXT</code>: Path to JSON file with Workflow definition (mutually exclusive with <code>workspace_name</code> and <code>workflow_id</code>)</li>
<li><code>-wn, --workspace_name TEXT</code>: Name of Roboflow workspace the that Workflow belongs to (mutually exclusive with <code>workflow_specification_path</code>)</li>
<li><code>-wid, --workflow_id TEXT</code>: Identifier of a Workflow on Roboflow platform (mutually exclusive with <code>workflow_specification_path</code>)</li>
<li><code>-wvid, --workflow_version_id TEXT</code>: Specific version of the Workflow to use. If not provided, the latest version is used.</li>
<li><code>--workflow_params TEXT</code>: Path to JSON document with Workflow parameters - helpful when Workflow is parametrized and passing the parameters in CLI is not handy / impossible due to typing conversion issues.</li>
<li><code>--image_input_name TEXT</code>: Name of the Workflow input that defines placeholder for image to be processed  [default: image]</li>
<li><code>-a, --api-key TEXT</code>: Roboflow API key for your workspace. If not given - env variable <code>ROBOFLOW_API_KEY</code> will be used</li>
<li><code>--api_url TEXT</code>: URL of the API that will be used for processing, when API processing target pointed.  [default: https://detect.roboflow.com]</li>
<li><code>--allow_override / --no_override</code>: Flag to decide if content of output directory can be overridden.  [default: no_override]</li>
<li><code>--save_image_outputs / --no_save_image_outputs</code>: Flag controlling persistence of Workflow outputs that are images  [default: save_image_outputs]</li>
<li><code>--force_reprocessing / --no_reprocessing</code>: Flag to enforce re-processing of specific images. Images are identified by file name.  [default: no_reprocessing]</li>
<li><code>--debug_mode / --no_debug_mode</code>: Flag enabling errors stack traces to be displayed (helpful for debugging)  [default: no_debug_mode]</li>
<li><code>--help</code>: Show this message and exit.</li>
</ul>
<h3 id="inference-workflows-process-images-directory"><code>inference workflows process-images-directory</code><a class="headerlink" href="#inference-workflows-process-images-directory" title="Permanent link">&para;</a></h3>
<p>Process whole images directory with Workflows (inference Package may be needed dependent on mode)</p>
<p><strong>Usage</strong>:</p>
<div class="highlight"><pre><span></span><code><span class="gp">$ </span>inference<span class="w"> </span>workflows<span class="w"> </span>process-images-directory<span class="w"> </span><span class="o">[</span>OPTIONS<span class="o">]</span>
</code></pre></div>
<p><strong>Options</strong>:</p>
<ul>
<li><code>-i, --input_directory TEXT</code>: Path to directory with images  [required]</li>
<li><code>-o, --output_dir TEXT</code>: Path to output directory  [required]</li>
<li><code>-pt, --processing_target [api|inference_package]</code>: Defines where the actual processing will be done, either in inference Python package running locally, or behind the API (which ensures greater throughput).  [default: api]</li>
<li><code>-ws, --workflow_spec TEXT</code>: Path to JSON file with Workflow definition (mutually exclusive with <code>workspace_name</code> and <code>workflow_id</code>)</li>
<li><code>-wn, --workspace_name TEXT</code>: Name of Roboflow workspace the that Workflow belongs to (mutually exclusive with <code>workflow_specification_path</code>)</li>
<li><code>-wid, --workflow_id TEXT</code>: Identifier of a Workflow on Roboflow platform (mutually exclusive with <code>workflow_specification_path</code>)</li>
<li><code>-wvid, --workflow_version_id TEXT</code>: Specific version of the Workflow to use. If not provided, the latest version is used.</li>
<li><code>--workflow_params TEXT</code>: Path to JSON document with Workflow parameters - helpful when Workflow is parametrized and passing the parameters in CLI is not handy / impossible due to typing conversion issues.</li>
<li><code>--image_input_name TEXT</code>: Name of the Workflow input that defines placeholder for image to be processed  [default: image]</li>
<li><code>-a, --api-key TEXT</code>: Roboflow API key for your workspace. If not given - env variable <code>ROBOFLOW_API_KEY</code> will be used</li>
<li><code>--api_url TEXT</code>: URL of the API that will be used for processing, when API processing target pointed.  [default: https://detect.roboflow.com]</li>
<li><code>--allow_override / --no_override</code>: Flag to decide if content of output directory can be overridden.  [default: no_override]</li>
<li><code>--save_image_outputs / --no_save_image_outputs</code>: Flag controlling persistence of Workflow outputs that are images  [default: save_image_outputs]</li>
<li><code>--force_reprocessing / --no_reprocessing</code>: Flag to enforce re-processing of specific images. Images are identified by file name.  [default: no_reprocessing]</li>
<li><code>--aggregate / --no_aggregate</code>: Flag to decide if processing results for a directory should be aggregated to a single file at the end of processing.  [default: aggregate]</li>
<li><code>-af, --aggregation_format [jsonl|csv]</code>: Defines the format of aggregated results - either CSV of JSONL  [default: csv]</li>
<li><code>--threads INTEGER</code>: Defines number of threads that will be used to send requests when processing target is API. Default for Roboflow Hosted API is 32, and for on-prem deployments: 1.</li>
<li><code>--debug_mode / --no_debug_mode</code>: Flag enabling errors stack traces to be displayed (helpful for debugging)  [default: no_debug_mode]</li>
<li><code>--max-failures INTEGER</code>: Maximum number of Workflow executions for directory images which will be tolerated before give up. If not set - unlimited.</li>
<li><code>--help</code>: Show this message and exit.</li>
</ul>
<h2 id="inference-rf-cloud"><code>inference rf-cloud</code><a class="headerlink" href="#inference-rf-cloud" title="Permanent link">&para;</a></h2>
<p>Commands for interacting with Roboflow Cloud</p>
<p><strong>Usage</strong>:</p>
<div class="highlight"><pre><span></span><code><span class="gp">$ </span>inference<span class="w"> </span>rf-cloud<span class="w"> </span><span class="o">[</span>OPTIONS<span class="o">]</span><span class="w"> </span>COMMAND<span class="w"> </span><span class="o">[</span>ARGS<span class="o">]</span>...
</code></pre></div>
<p><strong>Options</strong>:</p>
<ul>
<li><code>--help</code>: Show this message and exit.</li>
</ul>
<p><strong>Commands</strong>:</p>
<ul>
<li><code>data-staging</code>: Commands for interacting with Roboflow...</li>
<li><code>batch-processing</code>: Commands for interacting with Roboflow...</li>
</ul>
<h3 id="inference-rf-cloud-data-staging"><code>inference rf-cloud data-staging</code><a class="headerlink" href="#inference-rf-cloud-data-staging" title="Permanent link">&para;</a></h3>
<p>Commands for interacting with Roboflow Data Staging. THIS IS ALPHA PREVIEW OF THE FEATURE.</p>
<p><strong>Usage</strong>:</p>
<div class="highlight"><pre><span></span><code><span class="gp">$ </span>inference<span class="w"> </span>rf-cloud<span class="w"> </span>data-staging<span class="w"> </span><span class="o">[</span>OPTIONS<span class="o">]</span><span class="w"> </span>COMMAND<span class="w"> </span><span class="o">[</span>ARGS<span class="o">]</span>...
</code></pre></div>
<p><strong>Options</strong>:</p>
<ul>
<li><code>--help</code>: Show this message and exit.</li>
</ul>
<p><strong>Commands</strong>:</p>
<ul>
<li><code>list-batches</code>: List staging batches in your workspace.</li>
<li><code>list-batch-content</code>: List content of individual batch.</li>
<li><code>create-batch-of-images</code>: Create new batch with your images.</li>
<li><code>create-batch-of-videos</code>: Create new batch with your videos.</li>
<li><code>show-batch-details</code>: Show batch details</li>
<li><code>export-batch</code>: Export batch</li>
<li><code>list-ingest-details</code>: List details of your data ingest.</li>
</ul>
<h4 id="inference-rf-cloud-data-staging-list-batches"><code>inference rf-cloud data-staging list-batches</code><a class="headerlink" href="#inference-rf-cloud-data-staging-list-batches" title="Permanent link">&para;</a></h4>
<p>List staging batches in your workspace.</p>
<p><strong>Usage</strong>:</p>
<div class="highlight"><pre><span></span><code><span class="gp">$ </span>inference<span class="w"> </span>rf-cloud<span class="w"> </span>data-staging<span class="w"> </span>list-batches<span class="w"> </span><span class="o">[</span>OPTIONS<span class="o">]</span>
</code></pre></div>
<p><strong>Options</strong>:</p>
<ul>
<li><code>-a, --api-key TEXT</code>: Roboflow API key for your workspace. If not given - env variable <code>ROBOFLOW_API_KEY</code> will be used</li>
<li><code>-p, --pages INTEGER</code>: Number of pages to pull  [default: 1]</li>
<li><code>--page-size INTEGER</code>: Size of pagination page</li>
<li><code>--debug-mode / --no-debug-mode</code>: Flag enabling errors stack traces to be displayed (helpful for debugging)  [default: no-debug-mode]</li>
<li><code>--help</code>: Show this message and exit.</li>
</ul>
<h4 id="inference-rf-cloud-data-staging-list-batch-content"><code>inference rf-cloud data-staging list-batch-content</code><a class="headerlink" href="#inference-rf-cloud-data-staging-list-batch-content" title="Permanent link">&para;</a></h4>
<p>List content of individual batch.</p>
<p><strong>Usage</strong>:</p>
<div class="highlight"><pre><span></span><code><span class="gp">$ </span>inference<span class="w"> </span>rf-cloud<span class="w"> </span>data-staging<span class="w"> </span>list-batch-content<span class="w"> </span><span class="o">[</span>OPTIONS<span class="o">]</span>
</code></pre></div>
<p><strong>Options</strong>:</p>
<ul>
<li><code>-b, --batch-id TEXT</code>: Identifier of new batch (must be lower-cased letters with &#x27;-&#x27; and &#x27;_&#x27; allowed  [required]</li>
<li><code>-pn, --part-name TEXT</code>: Name of the part to be listed (if not given - all parts are presented). Invalid if batch is not multipart</li>
<li><code>-l, --limit INTEGER</code>: Number of entries to display / dump into th output files. If not given - whole content will be presented.</li>
<li><code>-o, --output-file TEXT</code>: Path to the output file - if not provided, command will dump result to the console. File type is JSONL.</li>
<li><code>-a, --api-key TEXT</code>: Roboflow API key for your workspace. If not given - env variable <code>ROBOFLOW_API_KEY</code> will be used</li>
<li><code>--debug-mode / --no-debug-mode</code>: Flag enabling errors stack traces to be displayed (helpful for debugging)  [default: no-debug-mode]</li>
<li><code>--help</code>: Show this message and exit.</li>
</ul>
<h4 id="inference-rf-cloud-data-staging-create-batch-of-images"><code>inference rf-cloud data-staging create-batch-of-images</code><a class="headerlink" href="#inference-rf-cloud-data-staging-create-batch-of-images" title="Permanent link">&para;</a></h4>
<p>Create new batch with your images.</p>
<p><strong>Usage</strong>:</p>
<div class="highlight"><pre><span></span><code><span class="gp">$ </span>inference<span class="w"> </span>rf-cloud<span class="w"> </span>data-staging<span class="w"> </span>create-batch-of-images<span class="w"> </span><span class="o">[</span>OPTIONS<span class="o">]</span>
</code></pre></div>
<p><strong>Options</strong>:</p>
<ul>
<li><code>-b, --batch-id TEXT</code>: Identifier of new batch (must be lower-cased letters with &#x27;-&#x27; and &#x27;_&#x27; allowed  [required]</li>
<li><code>-ds, --data-source [local-directory|references-file|cloud-storage]</code>: Source of the data - either local directory or JSON file with references.  [default: local-directory]</li>
<li><code>-i, --images-dir TEXT</code>: Path to your images directory to upload (required if data source is &#x27;local-directory&#x27;)</li>
<li><code>-r, --references TEXT</code>: Path to JSON file with URLs of files to be ingested (required if data source is &#x27;references-file&#x27;)</li>
<li><code>-bp, --bucket-path TEXT</code>: Cloud storage path with optional glob pattern (e.g., &#x27;s3://bucket/path/*<em>/</em>.jpg&#x27;, &#x27;gs://bucket/images/&#x27;). Required for cloud-storage source. Supports S3, GCS, and Azure.</li>
<li><code>-i, --ingest-id TEXT</code>: Identifier assigned for references ingest (if value not provided - system will auto-assign) - only relevant when <code>notifications-url</code> specified</li>
<li><code>--notifications-url TEXT</code>: Webhook URL where system should send notifications about ingest status</li>
<li><code>--notification-category TEXT</code>: Selecting specific notification categories (ingest-status / files-status) in combination with <code>--notifications-url</code> you may filter which notifications are going to be sent to your system. Please note that filtering of notifications do only work with ingests of files references via signed URLs and will not be applicable for ingests from local storage.</li>
<li><code>-bn, --batch-name TEXT</code>: Display name of your batch</li>
<li><code>-a, --api-key TEXT</code>: Roboflow API key for your workspace. If not given - env variable <code>ROBOFLOW_API_KEY</code> will be used</li>
<li><code>--debug-mode / --no-debug-mode</code>: Flag enabling errors stack traces to be displayed (helpful for debugging)  [default: no-debug-mode]</li>
<li><code>--help</code>: Show this message and exit.</li>
</ul>
<h4 id="inference-rf-cloud-data-staging-create-batch-of-videos"><code>inference rf-cloud data-staging create-batch-of-videos</code><a class="headerlink" href="#inference-rf-cloud-data-staging-create-batch-of-videos" title="Permanent link">&para;</a></h4>
<p>Create new batch with your videos.</p>
<p><strong>Usage</strong>:</p>
<div class="highlight"><pre><span></span><code><span class="gp">$ </span>inference<span class="w"> </span>rf-cloud<span class="w"> </span>data-staging<span class="w"> </span>create-batch-of-videos<span class="w"> </span><span class="o">[</span>OPTIONS<span class="o">]</span>
</code></pre></div>
<p><strong>Options</strong>:</p>
<ul>
<li><code>-b, --batch-id TEXT</code>: Identifier of new batch (must be lower-cased letters with &#x27;-&#x27; and &#x27;_&#x27; allowed  [required]</li>
<li><code>-ds, --data-source [local-directory|references-file|cloud-storage]</code>: Source of the data - either local directory or JSON file with references.  [default: local-directory]</li>
<li><code>-v, --videos-dir TEXT</code>: Path to your videos directory to upload</li>
<li><code>-r, --references TEXT</code>: Path to JSON file with URLs of files to be ingested (required if data source is &#x27;references-file&#x27;)</li>
<li><code>-bp, --bucket-path TEXT</code>: Cloud storage path with optional glob pattern (e.g., &#x27;s3://bucket/path/*<em>/</em>.mp4&#x27;, &#x27;gs://bucket/videos/&#x27;). Required for cloud-storage source. Supports S3, GCS, and Azure.</li>
<li><code>-i, --ingest-id TEXT</code>: Identifier assigned for references ingest (if value not provided - system will auto-assign) - only relevant if data source is &#x27;references-file&#x27;</li>
<li><code>--notifications-url TEXT</code>: Webhook URL where system should send notifications about ingest status - only relevant if data source is &#x27;references-file&#x27;</li>
<li><code>--notification-category TEXT</code>: Selecting specific notification categories (ingest-status / files-status) in combination with <code>--notifications-url</code> you may filter which notifications are going to be sent to your system. Please note that filtering of notifications do only work with ingests of files references via signed URLs and will not be applicable for ingests from local storage.</li>
<li><code>-a, --api-key TEXT</code>: Roboflow API key for your workspace. If not given - env variable <code>ROBOFLOW_API_KEY</code> will be used</li>
<li><code>-bn, --batch-name TEXT</code>: Display name of your batch</li>
<li><code>--debug-mode / --no-debug-mode</code>: Flag enabling errors stack traces to be displayed (helpful for debugging)  [default: no-debug-mode]</li>
<li><code>--help</code>: Show this message and exit.</li>
</ul>
<h4 id="inference-rf-cloud-data-staging-show-batch-details"><code>inference rf-cloud data-staging show-batch-details</code><a class="headerlink" href="#inference-rf-cloud-data-staging-show-batch-details" title="Permanent link">&para;</a></h4>
<p>Show batch details</p>
<p><strong>Usage</strong>:</p>
<div class="highlight"><pre><span></span><code><span class="gp">$ </span>inference<span class="w"> </span>rf-cloud<span class="w"> </span>data-staging<span class="w"> </span>show-batch-details<span class="w"> </span><span class="o">[</span>OPTIONS<span class="o">]</span>
</code></pre></div>
<p><strong>Options</strong>:</p>
<ul>
<li><code>-b, --batch-id TEXT</code>: Identifier of new batch (must be lower-cased letters with &#x27;-&#x27; and &#x27;_&#x27; allowed  [required]</li>
<li><code>-a, --api-key TEXT</code>: Roboflow API key for your workspace. If not given - env variable <code>ROBOFLOW_API_KEY</code> will be used</li>
<li><code>--debug-mode / --no-debug-mode</code>: Flag enabling errors stack traces to be displayed (helpful for debugging)  [default: no-debug-mode]</li>
<li><code>--help</code>: Show this message and exit.</li>
</ul>
<h4 id="inference-rf-cloud-data-staging-export-batch"><code>inference rf-cloud data-staging export-batch</code><a class="headerlink" href="#inference-rf-cloud-data-staging-export-batch" title="Permanent link">&para;</a></h4>
<p>Export batch</p>
<p><strong>Usage</strong>:</p>
<div class="highlight"><pre><span></span><code><span class="gp">$ </span>inference<span class="w"> </span>rf-cloud<span class="w"> </span>data-staging<span class="w"> </span>export-batch<span class="w"> </span><span class="o">[</span>OPTIONS<span class="o">]</span>
</code></pre></div>
<p><strong>Options</strong>:</p>
<ul>
<li><code>-b, --batch-id TEXT</code>: Identifier of new batch (must be lower-cased letters with &#x27;-&#x27; and &#x27;_&#x27; allowed  [required]</li>
<li><code>-t, --target-dir TEXT</code>: Path to export directory  [required]</li>
<li><code>-pn, --part-name TEXT</code>: Name of the part to be exported (if not given - all parts are presented). Invalid if batch is not multipart</li>
<li><code>-a, --api-key TEXT</code>: Roboflow API key for your workspace. If not given - env variable <code>ROBOFLOW_API_KEY</code> will be used</li>
<li><code>--override-existing / --no-override-existing</code>: Flag to enforce export even if partial content is already exported  [default: no-override-existing]</li>
<li><code>--debug-mode / --no-debug-mode</code>: Flag enabling errors stack traces to be displayed (helpful for debugging)  [default: no-debug-mode]</li>
<li><code>--help</code>: Show this message and exit.</li>
</ul>
<h4 id="inference-rf-cloud-data-staging-list-ingest-details"><code>inference rf-cloud data-staging list-ingest-details</code><a class="headerlink" href="#inference-rf-cloud-data-staging-list-ingest-details" title="Permanent link">&para;</a></h4>
<p>List details of your data ingest.</p>
<p><strong>Usage</strong>:</p>
<div class="highlight"><pre><span></span><code><span class="gp">$ </span>inference<span class="w"> </span>rf-cloud<span class="w"> </span>data-staging<span class="w"> </span>list-ingest-details<span class="w"> </span><span class="o">[</span>OPTIONS<span class="o">]</span>
</code></pre></div>
<p><strong>Options</strong>:</p>
<ul>
<li><code>-b, --batch-id TEXT</code>: Identifier of new batch (must be lower-cased letters with &#x27;-&#x27; and &#x27;_&#x27; allowed  [required]</li>
<li><code>-o, --output-file TEXT</code>: Path to the output file - if not provided, command will dump result to the console. File type is JSONL.</li>
<li><code>-a, --api-key TEXT</code>: Roboflow API key for your workspace. If not given - env variable <code>ROBOFLOW_API_KEY</code> will be used</li>
<li><code>--debug-mode / --no-debug-mode</code>: Flag enabling errors stack traces to be displayed (helpful for debugging)  [default: no-debug-mode]</li>
<li><code>--page-size INTEGER</code>: Size of pagination page</li>
<li><code>--help</code>: Show this message and exit.</li>
</ul>
<h3 id="inference-rf-cloud-batch-processing"><code>inference rf-cloud batch-processing</code><a class="headerlink" href="#inference-rf-cloud-batch-processing" title="Permanent link">&para;</a></h3>
<p>Commands for interacting with Roboflow Batch Processing. THIS IS ALPHA PREVIEW OF THE FEATURE.</p>
<p><strong>Usage</strong>:</p>
<div class="highlight"><pre><span></span><code><span class="gp">$ </span>inference<span class="w"> </span>rf-cloud<span class="w"> </span>batch-processing<span class="w"> </span><span class="o">[</span>OPTIONS<span class="o">]</span><span class="w"> </span>COMMAND<span class="w"> </span><span class="o">[</span>ARGS<span class="o">]</span>...
</code></pre></div>
<p><strong>Options</strong>:</p>
<ul>
<li><code>--help</code>: Show this message and exit.</li>
</ul>
<p><strong>Commands</strong>:</p>
<ul>
<li><code>list-jobs</code>: List batch jobs in your workspace.</li>
<li><code>show-job-details</code>: Get job details.</li>
<li><code>process-images-with-workflow</code>: Trigger batch job to process images with...</li>
<li><code>process-videos-with-workflow</code>: Trigger batch job to process videos with...</li>
<li><code>trt-compile</code>: Trigger TRT compilation of a model</li>
<li><code>abort-job</code>: Terminate running job</li>
<li><code>restart-job</code>: Restart failed job</li>
<li><code>fetch-logs</code>: Fetches job logs</li>
</ul>
<h4 id="inference-rf-cloud-batch-processing-list-jobs"><code>inference rf-cloud batch-processing list-jobs</code><a class="headerlink" href="#inference-rf-cloud-batch-processing-list-jobs" title="Permanent link">&para;</a></h4>
<p>List batch jobs in your workspace.</p>
<p><strong>Usage</strong>:</p>
<div class="highlight"><pre><span></span><code><span class="gp">$ </span>inference<span class="w"> </span>rf-cloud<span class="w"> </span>batch-processing<span class="w"> </span>list-jobs<span class="w"> </span><span class="o">[</span>OPTIONS<span class="o">]</span>
</code></pre></div>
<p><strong>Options</strong>:</p>
<ul>
<li><code>-a, --api-key TEXT</code>: Roboflow API key for your workspace. If not given - env variable <code>ROBOFLOW_API_KEY</code> will be used</li>
<li><code>-p, --max-pages INTEGER</code>: Number of pagination pages with batch jobs to display  [default: 1]</li>
<li><code>--debug-mode / --no-debug-mode</code>: Flag enabling errors stack traces to be displayed (helpful for debugging)  [default: no-debug-mode]</li>
<li><code>--help</code>: Show this message and exit.</li>
</ul>
<h4 id="inference-rf-cloud-batch-processing-show-job-details"><code>inference rf-cloud batch-processing show-job-details</code><a class="headerlink" href="#inference-rf-cloud-batch-processing-show-job-details" title="Permanent link">&para;</a></h4>
<p>Get job details.</p>
<p><strong>Usage</strong>:</p>
<div class="highlight"><pre><span></span><code><span class="gp">$ </span>inference<span class="w"> </span>rf-cloud<span class="w"> </span>batch-processing<span class="w"> </span>show-job-details<span class="w"> </span><span class="o">[</span>OPTIONS<span class="o">]</span>
</code></pre></div>
<p><strong>Options</strong>:</p>
<ul>
<li><code>-j, --job-id TEXT</code>: Identifier of job  [required]</li>
<li><code>-a, --api-key TEXT</code>: Roboflow API key for your workspace. If not given - env variable <code>ROBOFLOW_API_KEY</code> will be used</li>
<li><code>--debug-mode / --no-debug-mode</code>: Flag enabling errors stack traces to be displayed (helpful for debugging)  [default: no-debug-mode]</li>
<li><code>--help</code>: Show this message and exit.</li>
</ul>
<h4 id="inference-rf-cloud-batch-processing-process-images-with-workflow"><code>inference rf-cloud batch-processing process-images-with-workflow</code><a class="headerlink" href="#inference-rf-cloud-batch-processing-process-images-with-workflow" title="Permanent link">&para;</a></h4>
<p>Trigger batch job to process images with Workflow</p>
<p><strong>Usage</strong>:</p>
<div class="highlight"><pre><span></span><code><span class="gp">$ </span>inference<span class="w"> </span>rf-cloud<span class="w"> </span>batch-processing<span class="w"> </span>process-images-with-workflow<span class="w"> </span><span class="o">[</span>OPTIONS<span class="o">]</span>
</code></pre></div>
<p><strong>Options</strong>:</p>
<ul>
<li><code>-b, --batch-id TEXT</code>: Identifier of batch to be processed  [required]</li>
<li><code>-w, --workflow-id TEXT</code>: Identifier of the workflow  [required]</li>
<li><code>--workflow-params TEXT</code>: Path to JSON document with Workflow parameters - helpful when Workflow is parametrized and passing the parameters in CLI is not handy / impossible due to typing conversion issues.</li>
<li><code>--image-input-name TEXT</code>: Name of the Workflow input that defines placeholder for image to be processed</li>
<li><code>--save-image-outputs / --no-save-image-outputs</code>: Flag controlling persistence of Workflow outputs that are images  [default: no-save-image-outputs]</li>
<li><code>--image-outputs-to-save TEXT</code>: Use this option to filter out workflow image outputs you want to save</li>
<li><code>-p, --part-name TEXT</code>: Name of the batch part (relevant for multipart batches</li>
<li><code>-mt, --machine-type [cpu|gpu]</code>: Type of machine</li>
<li><code>--workers-per-machine INTEGER</code>: Number of workers to run on a single machine - more workers equals better resources utilisation, but may cause out of memory errors for bulky Workflows.</li>
<li><code>-ms, --machine-size [xs|s|m|l|xl]</code>: (Deprecated - use --workers-per-machine) Size of machine</li>
<li><code>--max-runtime-seconds INTEGER</code>: Max processing duration</li>
<li><code>--max-parallel-tasks INTEGER</code>: Max number of concurrent processing tasks</li>
<li><code>--aggregation-format [csv|jsonl]</code>: Format of results aggregation</li>
<li><code>-j, --job-id TEXT</code>: Identifier of job (if not given - will be generated)</li>
<li><code>-a, --api-key TEXT</code>: Roboflow API key for your workspace. If not given - env variable <code>ROBOFLOW_API_KEY</code> will be used</li>
<li><code>--debug-mode / --no-debug-mode</code>: Flag enabling errors stack traces to be displayed (helpful for debugging)  [default: no-debug-mode]</li>
<li><code>--notifications-url TEXT</code>: URL of the Webhook to be used for job state notifications.</li>
<li><code>--help</code>: Show this message and exit.</li>
</ul>
<h4 id="inference-rf-cloud-batch-processing-process-videos-with-workflow"><code>inference rf-cloud batch-processing process-videos-with-workflow</code><a class="headerlink" href="#inference-rf-cloud-batch-processing-process-videos-with-workflow" title="Permanent link">&para;</a></h4>
<p>Trigger batch job to process videos with Workflow</p>
<p><strong>Usage</strong>:</p>
<div class="highlight"><pre><span></span><code><span class="gp">$ </span>inference<span class="w"> </span>rf-cloud<span class="w"> </span>batch-processing<span class="w"> </span>process-videos-with-workflow<span class="w"> </span><span class="o">[</span>OPTIONS<span class="o">]</span>
</code></pre></div>
<p><strong>Options</strong>:</p>
<ul>
<li><code>-b, --batch-id TEXT</code>: Identifier of batch to be processed  [required]</li>
<li><code>-w, --workflow-id TEXT</code>: Identifier of the workflow  [required]</li>
<li><code>--workflow-params TEXT</code>: Path to JSON document with Workflow parameters - helpful when Workflow is parametrized and passing the parameters in CLI is not handy / impossible due to typing conversion issues.</li>
<li><code>--image-input-name TEXT</code>: Name of the Workflow input that defines placeholder for image to be processed</li>
<li><code>--save-image-outputs / --no-save-image-outputs</code>: Flag controlling persistence of Workflow outputs that are images  [default: no-save-image-outputs]</li>
<li><code>--image-outputs-to-save TEXT</code>: Use this option to filter out workflow image outputs you want to save</li>
<li><code>-p, --part-name TEXT</code>: Name of the batch part (relevant for multipart batches</li>
<li><code>-mt, --machine-type [cpu|gpu]</code>: Type of machine</li>
<li><code>--workers-per-machine INTEGER</code>: Number of workers to run on a single machine - more workers equals better resources utilisation, but may cause out of memory errors for bulky Workflows.</li>
<li><code>-ms, --machine-size [xs|s|m|l|xl]</code>: (Deprecated - use --workers-per-machine) Size of machine</li>
<li><code>--max-runtime-seconds INTEGER</code>: Max processing duration</li>
<li><code>--max-parallel-tasks INTEGER</code>: Max number of concurrent processing tasks</li>
<li><code>--aggregation-format [csv|jsonl]</code>: Format of results aggregation</li>
<li><code>--max-video-fps INTEGER</code>: Limit for FPS to process for video (subsampling predictions rate) - smaller FPS means faster processing and less accurate video analysis.</li>
<li><code>-j, --job-id TEXT</code>: Identifier of job (if not given - will be generated)</li>
<li><code>-a, --api-key TEXT</code>: Roboflow API key for your workspace. If not given - env variable <code>ROBOFLOW_API_KEY</code> will be used</li>
<li><code>--debug-mode / --no-debug-mode</code>: Flag enabling errors stack traces to be displayed (helpful for debugging)  [default: no-debug-mode]</li>
<li><code>--notifications-url TEXT</code>: URL of the Webhook to be used for job state notifications.</li>
<li><code>--help</code>: Show this message and exit.</li>
</ul>
<h4 id="inference-rf-cloud-batch-processing-trt-compile"><code>inference rf-cloud batch-processing trt-compile</code><a class="headerlink" href="#inference-rf-cloud-batch-processing-trt-compile" title="Permanent link">&para;</a></h4>
<p>Trigger TRT compilation of a model</p>
<p><strong>Usage</strong>:</p>
<div class="highlight"><pre><span></span><code><span class="gp">$ </span>inference<span class="w"> </span>rf-cloud<span class="w"> </span>batch-processing<span class="w"> </span>trt-compile<span class="w"> </span><span class="o">[</span>OPTIONS<span class="o">]</span>
</code></pre></div>
<p><strong>Options</strong>:</p>
<ul>
<li><code>-m, --model-id TEXT</code>: Model to be compiled  [required]</li>
<li><code>-d, --device [nvidia-l4|nvidia-t4]</code>: Target compilation devices  [required]</li>
<li><code>-j, --job-id TEXT</code>: Identifier of job (if not given - will be generated)</li>
<li><code>-a, --api-key TEXT</code>: Roboflow API key for your workspace. If not given - env variable <code>ROBOFLOW_API_KEY</code> will be used</li>
<li><code>--debug-mode / --no-debug-mode</code>: Flag enabling errors stack traces to be displayed (helpful for debugging)  [default: no-debug-mode]</li>
<li><code>--notifications-url TEXT</code>: URL of the Webhook to be used for job state notifications.</li>
<li><code>--help</code>: Show this message and exit.</li>
</ul>
<h4 id="inference-rf-cloud-batch-processing-abort-job"><code>inference rf-cloud batch-processing abort-job</code><a class="headerlink" href="#inference-rf-cloud-batch-processing-abort-job" title="Permanent link">&para;</a></h4>
<p>Terminate running job</p>
<p><strong>Usage</strong>:</p>
<div class="highlight"><pre><span></span><code><span class="gp">$ </span>inference<span class="w"> </span>rf-cloud<span class="w"> </span>batch-processing<span class="w"> </span>abort-job<span class="w"> </span><span class="o">[</span>OPTIONS<span class="o">]</span>
</code></pre></div>
<p><strong>Options</strong>:</p>
<ul>
<li><code>-j, --job-id TEXT</code>: Identifier of job  [required]</li>
<li><code>-a, --api-key TEXT</code>: Roboflow API key for your workspace. If not given - env variable <code>ROBOFLOW_API_KEY</code> will be used</li>
<li><code>--debug-mode / --no-debug-mode</code>: Flag enabling errors stack traces to be displayed (helpful for debugging)  [default: no-debug-mode]</li>
<li><code>--help</code>: Show this message and exit.</li>
</ul>
<h4 id="inference-rf-cloud-batch-processing-restart-job"><code>inference rf-cloud batch-processing restart-job</code><a class="headerlink" href="#inference-rf-cloud-batch-processing-restart-job" title="Permanent link">&para;</a></h4>
<p>Restart failed job</p>
<p><strong>Usage</strong>:</p>
<div class="highlight"><pre><span></span><code><span class="gp">$ </span>inference<span class="w"> </span>rf-cloud<span class="w"> </span>batch-processing<span class="w"> </span>restart-job<span class="w"> </span><span class="o">[</span>OPTIONS<span class="o">]</span>
</code></pre></div>
<p><strong>Options</strong>:</p>
<ul>
<li><code>-j, --job-id TEXT</code>: Identifier of job  [required]</li>
<li><code>-a, --api-key TEXT</code>: Roboflow API key for your workspace. If not given - env variable <code>ROBOFLOW_API_KEY</code> will be used</li>
<li><code>-mt, --machine-type [cpu|gpu]</code>: Type of machine</li>
<li><code>--workers-per-machine INTEGER</code>: Number of workers to run on a single machine - more workers equals better resources utilisation, but may cause out of memory errors for bulky Workflows.</li>
<li><code>--max-runtime-seconds INTEGER</code>: Max processing duration</li>
<li><code>--max-parallel-tasks INTEGER</code>: Max number of concurrent processing tasks</li>
<li><code>--debug-mode / --no-debug-mode</code>: Flag enabling errors stack traces to be displayed (helpful for debugging)  [default: no-debug-mode]</li>
<li><code>--help</code>: Show this message and exit.</li>
</ul>
<h4 id="inference-rf-cloud-batch-processing-fetch-logs"><code>inference rf-cloud batch-processing fetch-logs</code><a class="headerlink" href="#inference-rf-cloud-batch-processing-fetch-logs" title="Permanent link">&para;</a></h4>
<p>Fetches job logs</p>
<p><strong>Usage</strong>:</p>
<div class="highlight"><pre><span></span><code><span class="gp">$ </span>inference<span class="w"> </span>rf-cloud<span class="w"> </span>batch-processing<span class="w"> </span>fetch-logs<span class="w"> </span><span class="o">[</span>OPTIONS<span class="o">]</span>
</code></pre></div>
<p><strong>Options</strong>:</p>
<ul>
<li><code>-j, --job-id TEXT</code>: Identifier of job  [required]</li>
<li><code>-a, --api-key TEXT</code>: Roboflow API key for your workspace. If not given - env variable <code>ROBOFLOW_API_KEY</code> will be used</li>
<li><code>--log-severity [info|error|warning]</code>: Severity of logs to pick</li>
<li><code>-o, --output-file TEXT</code>: Path to the output file - if not provided, command will dump result to the console. File type is JSONL.</li>
<li><code>--debug-mode / --no-debug-mode</code>: Flag enabling errors stack traces to be displayed (helpful for debugging)  [default: no-debug-mode]</li>
<li><code>--help</code>: Show this message and exit.</li>
</ul>









  




                
              </article>
            </div>
          
  

          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Footer" >
        
          
          <a href="../cloud/" class="md-footer__link md-footer__link--prev" aria-label="Previous: Deploy To Cloud">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Previous
              </span>
              <div class="md-ellipsis">
                Deploy To Cloud
              </div>
            </div>
          </a>
        
        
          
          <a href="../../../api/" class="md-footer__link md-footer__link--next" aria-label="Next: OpenAPI Spec">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Next
              </span>
              <div class="md-ellipsis">
                OpenAPI Spec
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Roboflow 2025. All rights reserved.
    </div>
  
  
</div>
      
        <div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://github.com/roboflow" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://www.youtube.com/roboflow" target="_blank" rel="noopener" title="www.youtube.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78 0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305m-317.51 213.508V175.185l142.739 81.205z"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://www.linkedin.com/company/roboflow-ai/mycompany/" target="_blank" rel="noopener" title="www.linkedin.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3M135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5m282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9z"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://twitter.com/roboflow" target="_blank" rel="noopener" title="twitter.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
      <div class="md-progress" data-md-component="progress" role="progressbar"></div>
    
    
    <script id="__config" type="application/json">{"base": "../../..", "features": ["announce.dismiss", "content.action.edit", "content.code.copy", "content.tabs.link", "navigation.footer", "navigation.indexes", "navigation.instant", "navigation.instant.prefetch", "navigation.instant.preview", "navigation.instant.progress", "navigation.prune", "navigation.tabs", "navigation.tabs.sticky", "navigation.top", "navigation.tracking", "optimize", "search.share", "search.suggest", "toc.follow"], "search": "../../../assets/javascripts/workers/search.c7c1ca2c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": {"default": 1.0}}</script>
    
    
      <script src="../../../assets/javascripts/bundle.5a789024.min.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/dompurify/3.0.8/purify.min.js"></script>
      
        <script src="../../../javascript/init_kapa_widget.js"></script>
      
        <script src="../../../javascript/cookbooks.js"></script>
      
        <script src="../../../javascript/workflows.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/gsap/3.12.5/gsap.min.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/gsap/3.12.5/ScrollTrigger.min.js"></script>
      
        <script src="https://unpkg.com/@rive-app/canvas"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/swiper@11/swiper-bundle.min.js"></script>
      
        <script src="../../../assets/home.js"></script>
      
        <script src="../../../js/segment.js"></script>
      
    
  </body>
</html>