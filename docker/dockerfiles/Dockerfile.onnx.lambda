FROM public.ecr.aws/lambda/python:3.12

WORKDIR /app

ARG DEBIAN_FRONTEND=noninteractive
ARG TARGETPLATFORM

COPY requirements/requirements.clip.txt \
    requirements/requirements.cpu.txt \
    requirements/requirements.http.txt \
    requirements/requirements.hosted.txt \
    requirements/requirements.doctr.txt \
    requirements/requirements.groundingdino.txt \
    requirements/_requirements.txt \
    requirements/requirements.sdk.http.txt \
    requirements/requirements.yolo_world.txt \
    requirements/requirements.vino.txt \
    requirements/requirements.easyocr.txt \
    ./

RUN dnf makecache -y && dnf install -y \
    libSM \
    libXext  \
    python3-pip \
    git \
    zlib-devel \
    libjpeg-devel \
    gcc \
    mesa-libGL \
    pango \
    rustc \
    cargo \
    && dnf clean all \
  && if [ "${TARGETPLATFORM}" == "linux/amd64" ]; then mv requirements.vino.txt requirements.cpu.txt; fi \
  && /var/lang/bin/python3.12 -m pip install --upgrade pip && rm -rf ~/.cache/pip \
  && pip3 install \
    --extra-index-url https://download.pytorch.org/whl/cpu \
    certifi==2022.12.07 \
    -r _requirements.txt \
    -r requirements.clip.txt \
    -r requirements.cpu.txt \
    -r requirements.http.txt \
    -r requirements.hosted.txt \
    -r requirements.groundingdino.txt \
    -r requirements.doctr.txt \
    -r requirements.sdk.http.txt \
    -r requirements.yolo_world.txt \
    -r requirements.easyocr.txt \
    mangum \
    "setuptools<=75.5.0" \
    --upgrade \
    --target "${LAMBDA_TASK_ROOT}" \
  && rm -rf ~/.cache/pip \
  && rpm -e --nodeps \
    gcc \
    cargo \
    rust \
    zlib-devel \
    git \
    libjpeg-turbo-devel \
    perl-Git \
    annobin-plugin-gcc \
    rust-std-static \
  && dnf clean all \
  && rm -rf /var/cache/dnf /build

COPY inference ${LAMBDA_TASK_ROOT}/inference
COPY inference_sdk ${LAMBDA_TASK_ROOT}/inference_sdk
COPY docker/config/lambda.py ${LAMBDA_TASK_ROOT}/lambda.py

ENV LAMBDA=True \
  CORE_MODEL_SAM_ENABLED=False \
  CORE_MODEL_SAM2_ENABLED=False \
  ALLOW_NUMPY_INPUT=False \
  INFERENCE_SERVER_ID=HostedInferenceLambda \
  DISABLE_VERSION_CHECK=true \
  DOCTR_MULTIPROCESSING_DISABLE=TRUE \
  REDIS_SSL=true \
  WORKFLOWS_STEP_EXECUTION_MODE=remote \
  WORKFLOWS_REMOTE_API_TARGET=hosted \
  API_LOGGING_ENABLED=True \
  MODEL_VALIDATION_DISABLED=True \
  ALLOW_NON_HTTPS_URL_INPUT=False \
  ALLOW_URL_INPUT_WITHOUT_FQDN=False \
  ALLOW_CUSTOM_PYTHON_EXECUTION_IN_WORKFLOWS=False \
  CORE_MODEL_TROCR_ENABLED=false \
  USE_FILE_CACHE_FOR_WORKFLOWS_DEFINITIONS=False \
  ALLOW_WORKFLOW_BLOCKS_ACCESSING_LOCAL_STORAGE=False \
  ALLOW_WORKFLOW_BLOCKS_ACCESSING_ENVIRONMENTAL_VARIABLES=False \
  ALLOW_LOADING_IMAGES_FROM_LOCAL_FILESYSTEM=False \
  DEPTH_ESTIMATION_ENABLED=False \
  CORE_MODEL_PE_ENABLED=false \
  CORE_MODEL_SAM3_ENABLED=False

WORKDIR ${LAMBDA_TASK_ROOT}

CMD [ "lambda.handler" ]