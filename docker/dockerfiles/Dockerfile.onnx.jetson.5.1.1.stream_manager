FROM nvcr.io/nvidia/l4t-ml:r35.2.1-py3
#installs python 3.9

ARG DEBIAN_FRONTEND=noninteractive
ENV LANG en_US.UTF-8 

RUN apt-get update -y && apt-get install -y \
    lshw \
    git \
    python3.9 \
    python3.9-dev \
    python3-pip \
    python3-matplotlib \
    gfortran \
    ffmpeg \
    libavcodec58 \
    libavformat58 \
    libswscale5 \
    build-essential \
    libatlas-base-dev \
    libsm6 \
    libxext6 \
    wget \
    python3-shapely \
    gdal-bin \
    libgdal-dev \
    rustc \
    cargo \
    && rm -rf /var/lib/apt/lists/*

COPY requirements/requirements.clip.txt \
    requirements/requirements.http.txt \
    requirements/_requirements.txt \
    ./

RUN python3.9 -m pip install --ignore-installed PyYAML && rm -rf ~/.cache/pip

# We needed to take statically compiled library for last known stable build and put it into hosting
# That was due to faulty builds started 26.06.2024, probably due to release of new version
# of pybind11, which gets automatically pulled while build of zxing_cpp library making
# cmake to fail
RUN wget https://storage.googleapis.com/roboflow-tests-assets/zxing_cpp_library_compiled_for_inference_v0.12.1.tar.gz \
    && tar -xvzf zxing_cpp_library_compiled_for_inference_v0.12.1.tar.gz \
    && mv zxing_cpp-2.2.0.dist-info /usr/local/lib/python3.9/dist-packages/zxing_cpp-2.2.0.dist-info \
    && mv zxingcpp.cpython-39-aarch64-linux-gnu.so /usr/local/lib/python3.9/dist-packages/ \
    && rm zxing_cpp_library_compiled_for_inference_v0.12.1.tar.gz

RUN python3.9 -m pip install --upgrade pip  && python3.9 -m pip install \
    -r _requirements.txt \
    -r requirements.clip.txt \
    -r requirements.http.txt \
    "setuptools<=75.5.0" \
    --upgrade \
    && rm -rf ~/.cache/pip

WORKDIR /app/
COPY inference_cli/ ./inference_cli/
COPY inference_sdk/ ./inference_sdk/
COPY inference inference
COPY .release .release
COPY requirements requirements
COPY Makefile Makefile

RUN make create_inference_cli_whl PYTHON=python3.9
RUN python3.9 -m pip install dist/inference_cli*.whl

# BE CAREFUL, WE ENFORCE numpy 1.x for the sake of compatibility with onnxruntime
RUN python3.9 -m pip uninstall --yes onnxruntime numpy
RUN wget https://nvidia.box.com/shared/static/67zek28z497hs9aev7xg2c1wngdeyv4h.whl -O onnxruntime_gpu-1.16.0-cp39-cp39-linux_aarch64.whl
RUN python3.9 -m pip install "numpy<=1.26.4" onnxruntime_gpu-1.16.0-cp39-cp39-linux_aarch64.whl "opencv-python-headless>4,<=4.10.0.84" \
    && rm -rf ~/.cache/pip \
    && rm onnxruntime_gpu-1.16.0-cp39-cp39-linux_aarch64.whl

ENV ORT_TENSORRT_FP16_ENABLE=1 \
    ORT_TENSORRT_ENGINE_CACHE_ENABLE=1 \
    CORE_MODEL_SAM_ENABLED=False \
    OPENBLAS_CORETYPE=ARMV8 \
    LD_PRELOAD=/usr/lib/aarch64-linux-gnu/libgomp.so.1:/usr/local/lib/python3.8/dist-packages/torch.libs/libgomp-d22c30c5.so.1.0.0 \
    VERSION_CHECK_MODE=continuous \
    PROJECT=roboflow-platform \
    HOST=0.0.0.0 \
    PORT=7070 \
    WORKFLOWS_STEP_EXECUTION_MODE=local \
    WORKFLOWS_MAX_CONCURRENT_STEPS=1 \
    SUPERVISON_DEPRECATION_WARNING=0 \
    PYTHONPATH=/app:$PYTHONPATH

ENTRYPOINT ["python3.9", "-m", "inference.enterprise.stream_management.manager.app"]
