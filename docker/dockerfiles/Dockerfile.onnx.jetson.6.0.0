FROM roboflow/l4t-ml:r36.3.0

ARG DEBIAN_FRONTEND=noninteractive
ENV LANG=en_US.UTF-8

# Install dependencies
RUN apt-get update -y && \
    apt-get install -y --no-install-recommends \
    lshw \
    git \
    gfortran \
    build-essential \
    libatlas-base-dev \
    libsm6 \
    libxext6 \
    wget \
    gdal-bin \
    libgdal-dev && \
    rm -rf /var/lib/apt/lists/*

# Copy all requirements files
COPY requirements/ ./requirements/

# Remove specific packages from requirements files
RUN sed -i '/^opencv-python/d;/^onnxruntime/d;/^opencv-python-contrib/d' requirements/*.txt

# Upgrade pip and install Python packages
RUN python3 -m pip install --upgrade pip && \
    python3 -m pip install --upgrade \
    -r requirements/_requirements.txt \
    -r requirements/requirements.clip.txt \
    -r requirements/requirements.http.txt \
    -r requirements/requirements.doctr.txt \
    -r requirements/requirements.groundingdino.txt \
    -r requirements/requirements.sdk.http.txt \
    -r requirements/requirements.yolo_world.txt \
    -r requirements/requirements.jetson.txt \
    "setuptools<=75.5.0"

# Build the application
WORKDIR /build
COPY . .

RUN rm -f dist/* && \
    python3 .release/pypi/inference.core.setup.py bdist_wheel && \
    python3 .release/pypi/inference.gpu.setup.py bdist_wheel && \
    python3 .release/pypi/inference.sdk.setup.py bdist_wheel && \
    python3 .release/pypi/inference.cli.setup.py bdist_wheel && \
    python3 -m pip install dist/inference_cli*.whl dist/inference_core*.whl dist/inference_gpu*.whl dist/inference_sdk*.whl "setuptools<=75.5.0"

# Set up the application runtime
WORKDIR /app
COPY inference/ ./inference/
COPY inference_sdk/ ./inference_sdk/
COPY docker/config/gpu_http.py ./gpu_http.py

# Set environment variables
ENV VERSION_CHECK_MODE=continuous \
    PROJECT=roboflow-platform \
    ORT_TENSORRT_FP16_ENABLE=1 \
    ORT_TENSORRT_ENGINE_CACHE_ENABLE=1 \
    CORE_MODEL_SAM_ENABLED=False \
    NUM_WORKERS=1 \
    HOST=0.0.0.0 \
    PORT=9001 \
    OPENBLAS_CORETYPE=ARMV8 \
    LD_PRELOAD=/usr/lib/aarch64-linux-gnu/libgomp.so.1 \
    WORKFLOWS_STEP_EXECUTION_MODE=local \
    WORKFLOWS_MAX_CONCURRENT_STEPS=2 \
    API_LOGGING_ENABLED=True \
    CORE_MODEL_TROCR_ENABLED=false \
    RUNS_ON_JETSON=True \
    ENABLE_STREAM_API=True \
    ENABLE_WORKFLOWS_PROFILING=True \
    ENABLE_PROMETHEUS=True \
    ENV ENABLE_STREAM_API=True

# Expose the application port
EXPOSE 9001

# Set the entrypoint
ENTRYPOINT uvicorn gpu_http:app --workers $NUM_WORKERS --host $HOST --port $PORT
