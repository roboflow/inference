# Stage 1: Compile image - install build dependencies and create virtualenv
FROM nvcr.io/nvidia/cuda:12.4.1-cudnn-devel-ubuntu22.04 AS compile-image

WORKDIR /app

# Install build dependencies
RUN rm -rf /var/lib/apt/lists/* && apt-get clean && apt-get update -y && DEBIAN_FRONTEND=noninteractive apt-get install -y \
    python3-pip \
    python3-venv \
    git \
    wget \
    rustc \
    cargo \
    libxext6 \
    libopencv-dev \
    libgdal-dev \
    libvips-dev \
    && rm -rf /var/lib/apt/lists/*

# Create and use virtualenv
RUN python3 -m venv /opt/venv
ENV PATH="/opt/venv/bin:$PATH"

# Copy requirements files
COPY requirements/requirements.sam.txt \
    requirements/requirements.clip.txt \
    requirements/requirements.http.txt \
    requirements/requirements.gpu.txt \
    requirements/requirements.waf.txt \
    requirements/requirements.gaze.txt \
    requirements/requirements.doctr.txt \
    requirements/requirements.groundingdino.txt \
    requirements/requirements.yolo_world.txt \
    requirements/_requirements.txt \
    requirements/requirements.transformers.txt \
    requirements/requirements.pali.flash_attn.txt \
    ./

# Install Python packages into virtualenv
RUN python3 -m pip install -U pip
RUN python3 -m pip install \
    -r _requirements.txt \
    -r requirements.sam.txt \
    -r requirements.clip.txt \
    -r requirements.http.txt \
    -r requirements.gpu.txt \
    -r requirements.waf.txt \
    -r requirements.gaze.txt \
    -r requirements.groundingdino.txt \
    -r requirements.doctr.txt \
    -r requirements.yolo_world.txt \
    -r requirements.transformers.txt \
    jupyterlab \
    "setuptools<=75.5.0" \
    --upgrade \
    && rm -rf ~/.cache/pip

# Install setup.py requirements for flash_attn
RUN python3 -m pip install packaging==24.1 && rm -rf ~/.cache/pip

# Install flash_attn required for Paligemma and Florence2
RUN python3 -m pip install -r requirements.pali.flash_attn.txt --no-dependencies --no-build-isolation && rm -rf ~/.cache/pip

# Build application wheels
WORKDIR /build
COPY . .
RUN /bin/make create_wheels_for_gpu_notebook
RUN pip3 install --no-cache-dir dist/inference_cli*.whl dist/inference_core*.whl dist/inference_gpu*.whl dist/inference_sdk*.whl "setuptools<=75.5.0"

# Stage 2: Runtime image - minimal dependencies with virtualenv
FROM nvcr.io/nvidia/cuda:12.4.1-cudnn-runtime-ubuntu22.04 AS runtime-image

WORKDIR /app

# Install only runtime dependencies
RUN rm -rf /var/lib/apt/lists/* && apt-get clean && apt-get update -y && DEBIAN_FRONTEND=noninteractive apt-get install -y \
    uvicorn \
    libxext6 \
    libopencv-dev \
    libgdal-dev \
    libvips-dev \
    && rm -rf /var/lib/apt/lists/*

# Copy and use virtualenv from compile stage
COPY --from=compile-image /opt/venv /opt/venv
ENV PATH="/opt/venv/bin:$PATH"

# Copy notebooks
WORKDIR /notebooks
COPY examples/notebooks .

# Copy application code
WORKDIR /app/
COPY inference inference
COPY docker/config/gpu_http.py gpu_http.py

# Environment variables
ENV VERSION_CHECK_MODE=continuous
ENV PROJECT=roboflow-platform
ENV NUM_WORKERS=1
ENV HOST=0.0.0.0
ENV PORT=9001
ENV WORKFLOWS_STEP_EXECUTION_MODE=local
ENV WORKFLOWS_MAX_CONCURRENT_STEPS=4
ENV API_LOGGING_ENABLED=True
ENV LMM_ENABLED=True
ENV CORE_MODEL_SAM2_ENABLED=True
ENV CORE_MODEL_OWLV2_ENABLED=True
ENV ENABLE_STREAM_API=True
ENV ENABLE_PROMETHEUS=True
ENV STREAM_API_PRELOADED_PROCESSES=2

ENTRYPOINT uvicorn gpu_http:app --workers $NUM_WORKERS --host $HOST --port $PORT
