from typing import List, Literal, Optional, Type, Union

import supervision as sv
from pydantic import ConfigDict, Field

from inference.core.workflows.core_steps.visualizations.common.base import (
    OUTPUT_IMAGE_KEY,
)
from inference.core.workflows.core_steps.visualizations.common.base_colorable import (
    ColorableVisualizationBlock,
    ColorableVisualizationManifest,
)
from inference.core.workflows.execution_engine.entities.base import WorkflowImageData
from inference.core.workflows.execution_engine.entities.types import (
    FLOAT_ZERO_TO_ONE_KIND,
    FloatZeroToOne,
    Selector,
)
from inference.core.workflows.prototypes.block import BlockResult, WorkflowBlockManifest

TYPE: str = "roboflow_core/color_visualization@v1"
SHORT_DESCRIPTION = "Paint a solid color on detected objects in an image."
LONG_DESCRIPTION = """
Fill detected objects with solid colors using customizable color palettes, creating color-coded overlays that distinguish different objects or classes while preserving image details through opacity blending.

## How This Block Works

This block takes an image and detection predictions and fills the detected object regions with solid colors. The block:

1. Takes an image and predictions as input
2. Identifies detected regions from bounding boxes or segmentation masks
3. Applies color styling based on the selected color palette, with colors assigned by class, index, or track ID
4. Fills detected object regions with solid colors using Supervision's ColorAnnotator
5. Blends the colored overlay with the original image based on the opacity setting
6. Returns an annotated image where detected objects are filled with colors, while the rest of the image remains unchanged

The block works with both object detection predictions (using bounding boxes) and instance segmentation predictions (using masks). When masks are available, it fills the exact shape of detected objects; otherwise, it fills rectangular bounding box regions. Colors are assigned from the selected palette based on the color axis setting (class, index, or track ID), allowing different objects or classes to be distinguished by color. The opacity parameter controls how transparent the color overlay is, allowing you to create effects ranging from subtle color tinting (low opacity) where original image details remain visible, to solid color fills (high opacity) that completely replace object appearance.

## Common Use Cases

- **Color-Coded Object Classification**: Fill detected objects with different colors based on their class, category, or classification results to create intuitive color-coded visualizations for quick object identification and categorization
- **Multi-Object Tracking Visualization**: Color-code tracked objects with distinct colors based on their tracking IDs to visualize object trajectories, track persistence, or distinguish multiple tracked objects across frames
- **Visual Category Distinction**: Use different colors for different object categories or types (e.g., vehicles, people, products) to create clear visual distinctions in monitoring, surveillance, or inventory management workflows
- **Mask-Based Segmentation Display**: Fill segmented regions with colors to visualize instance segmentation results, highlight segmented objects, or create colored mask overlays for analysis or presentation
- **Interactive Visualization and UI**: Create color-coded visualizations for user interfaces, dashboards, or interactive applications where color-coding provides intuitive visual feedback or object grouping
- **Presentation and Reporting**: Generate color-filled visualizations for reports, documentation, or presentations where color-coding helps distinguish object types, highlight specific categories, or create visually appealing detection displays

## Connecting to Other Blocks

The annotated image from this block can be connected to:

- **Other visualization blocks** (e.g., Label Visualization, Bounding Box Visualization, Polygon Visualization) to combine color fills with additional annotations (labels, outlines) for comprehensive visualization
- **Data storage blocks** (e.g., Local File Sink, CSV Formatter, Roboflow Dataset Upload) to save color-coded images for documentation, reporting, or analysis
- **Webhook blocks** to send color-coded visualizations to external systems, APIs, or web applications for display in dashboards or monitoring tools
- **Notification blocks** (e.g., Email Notification, Slack Notification) to send color-coded images as visual evidence in alerts or reports
- **Video output blocks** to create color-coded video streams or recordings for live monitoring, tracking visualization, or post-processing analysis
"""


class ColorManifest(ColorableVisualizationManifest):
    type: Literal[f"{TYPE}", "ColorVisualization"]
    model_config = ConfigDict(
        json_schema_extra={
            "name": "Color Visualization",
            "version": "v1",
            "short_description": SHORT_DESCRIPTION,
            "long_description": LONG_DESCRIPTION,
            "license": "Apache-2.0",
            "block_type": "visualization",
            "search_keywords": ["annotator"],
            "ui_manifest": {
                "section": "visualization",
                "icon": "far fa-palette",
                "blockPriority": 6,
                "supervision": True,
                "warnings": [
                    {
                        "property": "copy_image",
                        "value": False,
                        "message": "This setting will mutate its input image. If the input is used by other blocks, it may cause unexpected behavior.",
                    }
                ],
            },
        }
    )

    opacity: Union[FloatZeroToOne, Selector(kind=[FLOAT_ZERO_TO_ONE_KIND])] = Field(  # type: ignore
        description="Opacity of the color overlay, ranging from 0.0 (fully transparent, original object appearance visible) to 1.0 (fully opaque, solid color fill). Values between 0.0 and 1.0 create a blend between the original image and the color overlay. Lower values create subtle color tinting where object details remain visible, while higher values create stronger color fills that obscure original object appearance.",
        default=0.5,
        examples=[0.5, "$inputs.opacity"],
    )

    @classmethod
    def get_execution_engine_compatibility(cls) -> Optional[str]:
        return ">=1.3.0,<2.0.0"


class ColorVisualizationBlockV1(ColorableVisualizationBlock):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.annotatorCache = {}

    @classmethod
    def get_manifest(cls) -> Type[WorkflowBlockManifest]:
        return ColorManifest

    def getAnnotator(
        self,
        color_palette: str,
        palette_size: int,
        custom_colors: List[str],
        color_axis: str,
        opacity: float,
    ) -> sv.annotators.base.BaseAnnotator:
        key = "_".join(
            map(
                str,
                [
                    color_palette,
                    palette_size,
                    color_axis,
                    opacity,
                ],
            )
        )

        if key not in self.annotatorCache:
            palette = self.getPalette(color_palette, palette_size, custom_colors)

            self.annotatorCache[key] = sv.ColorAnnotator(
                color=palette,
                color_lookup=getattr(sv.ColorLookup, color_axis),
                opacity=opacity,
            )

        return self.annotatorCache[key]

    def run(
        self,
        image: WorkflowImageData,
        predictions: sv.Detections,
        copy_image: bool,
        color_palette: Optional[str],
        palette_size: Optional[int],
        custom_colors: Optional[List[str]],
        color_axis: Optional[str],
        opacity: Optional[float],
    ) -> BlockResult:
        annotator = self.getAnnotator(
            color_palette,
            palette_size,
            custom_colors,
            color_axis,
            opacity,
        )
        annotated_image = annotator.annotate(
            scene=image.numpy_image.copy() if copy_image else image.numpy_image,
            detections=predictions,
        )
        return {
            OUTPUT_IMAGE_KEY: WorkflowImageData.copy_and_replace(
                origin_image_data=image, numpy_image=annotated_image
            )
        }
