_target_: lidra.data.dataset.tdfy.trellis.dataset.PreProcessor
img_transform:
  _target_: torchvision.transforms.Compose
  transforms:
    - _target_: lidra.data.dataset.tdfy.img_processing.pad_to_square_centered
      _partial_: true
    - _target_: torchvision.transforms.Resize
      size: 518
    - _target_: lidra.data.dataset.tdfy.img_processing.get_img_color_augmentation
mask_transform:
  _target_: torchvision.transforms.Compose
  transforms:
    - _target_: lidra.data.dataset.tdfy.img_processing.pad_to_square_centered
      _partial_: true
    - _target_: torchvision.transforms.Resize
      size: 518
      interpolation: 0 # nearest
pointmap_transform:
  _target_: torchvision.transforms.Compose
  transforms:
    - _target_: lidra.data.dataset.tdfy.img_processing.pad_to_square_centered
      _partial_: true
    - _target_: torchvision.transforms.Resize
      size: 518
      interpolation: 0 # nearest

# img_mask_joint_transform:
#   - _target_: lidra.data.dataset.tdfy.img_and_mask_transforms.crop_around_mask_with_random_box_size_factor
#     _partial_: true
#     random_box_size_factor: 2.0
# img_mask_pointmap_joint_transform: []


img_mask_joint_transform: []
img_mask_pointmap_joint_transform:
  # First resize all inputs to the same size (RGB image size)
  - _target_: lidra.data.dataset.tdfy.img_and_mask_transforms.resize_all_to_same_size
    _partial_: true
  # Then apply cropping
  - _target_: lidra.data.dataset.tdfy.img_and_mask_transforms.crop_around_mask_with_random_box_size_factor
    _partial_: true
    random_box_size_factor: 2.0
