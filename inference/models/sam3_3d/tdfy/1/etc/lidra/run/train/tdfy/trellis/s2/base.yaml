# @package _global_
defaults:
  - /run/train/tdfy/trellis@: base

  - /data/dataset/tdfy/trellis500k/preprocessor@tdfy.preprocessor: ???
  - /model/backbone@tdfy.reverse_fn_pretrained: trellis_dit/image_large_featured_latents_pretrained

  - override /data/module@loop.dataloaders: tdfy/trellis500k
  - override /data/dataset/tdfy/trellis500k@loop.dataloaders.training.dataset: ???
  - override /model/module/tdfy@module: generative-trellisDino-features-only
  - override /model/backbone/generator@module.generator.backbone: flow_matching_cfg
  - override /model/backbone/dit/embedder@tdfy.reverse_fn_pretrained.model.condition_embedder: ???

  - override /cluster: aws-h100

  - _self_

batch_size: 6

loop:
  max_epochs: ???
  callbacks:
    model_checkpoint2:
      _target_: lightning.pytorch.callbacks.ModelCheckpoint
      save_on_train_epoch_end: true
      every_n_epochs: 10
      save_top_k: -1
    gradient_scaler:
      _target_: lidra.callback.tdfy.gradual_grad_scale.GradualGradScaleCallback
      initial_scale: 30.0
      scale_growth: 0.001
    gradient_clipping:
      _target_: lidra.callback.tdfy.adaptive_gradient_clipping.AdaptiveGradientClipCallback
      max_clip_val: 1.0
      clip_percentile: 95.0
      buffer_size: 1000
    memory_manager:
      _target_: lidra.callback.tdfy.memory_manager.MemoryManagerCallback
      get_size_func: 
        _target_: lidra.callback.tdfy.memory_manager.get_input_size_slat_flow
        _partial_: true
      mem_based_func:
        _target_: lidra.callback.tdfy.memory_manager.set_grad_ckpt_slat
        _partial_: true
        slat_path: _base_models.generator.reverse_fn.backbone
      update_every: 500
    ema:
      _target_: lidra.callback.ema.EMA
      decays:
        slow: 0.9999
      default_decay_for_eval: slow
      device: null
      force_fp32: true
      recover_existing: true
  dataloaders:
    validation: null

module:
  batch_conditions_mapping: ???
  batch_preprocessing_fn:
    deterministic_sampling: True
  generator:
    backbone:
      reverse_fn:
        backbone: ${tdfy.reverse_fn}
        strength: 0.0
        unconditional_handling: add_flag
      inference_steps: 12
      training_time_sampler_fn:
        _target_: lidra.model.backbone.generator.flow_matching.model.lognorm_sampler
        _partial_: true
        mean: -1.0
        std: 1.0 

tdfy:
  collator:
    _target_: lidra.data.collator.auto_collate
  reverse_fn_pretrained:
    checkpoint_path: ???
    strict: false
    device: "cpu"
    model:
      use_fp16: True
      force_zeros_cond: True
  reverse_fn: ${tdfy.reverse_fn_pretrained}
