# @package _global_
defaults:
  - ../fm-trellis-features-fo-ft

  # generator
  - override /model/backbone/generator@module.generator.backbone: shortcut_cfg
  - override /model/module/tdfy@module: generative-trellisDino-features-only

  # dataset
  - override /data/dataset/tdfy/trellis500k@loop.dataloaders.training.dataset: training_features
  - _self_


# batch_size: 8
lr: 1e-5

module:
  generator:
    optimizer:
      weight_decay: 0.01
    backbone:
      self_consistency_cfg_strength: 2.0
      ratio_cfg_samples_in_self_consistency_target: 0.5
      reverse_fn:
        _target_: lidra.model.backbone.generator.classifier_free_guidance.ClassifierFreeGuidanceWithExternalUnconditionalProbability
        unconditional_handling: "add_flag"
        strength: 2.0
        p_unconditional: 0.1
      inference_steps: 2
      rescale_t: 1
      shortcut_loss_weight: 1.0
      self_consistency_prob: 0.5
      batch_mode: True
  validation_dump_type: null # don't save anything to disk during validation

loop:
  check_val_every_n_epoch: 2
  limit_val_batches: 1.0  # float means 100% of the validation set
  num_sanity_val_steps: -1 # validate on all batches at the beginning
  max_epochs: 50
  callbacks:
    model_checkpoint2:
      _target_: lightning.pytorch.callbacks.ModelCheckpoint
      save_on_train_epoch_end: true
      every_n_epochs: ${loop.check_val_every_n_epoch}
      save_top_k: -1

tdfy:
  reverse_fn_pretrained:
    checkpoint_path: /fsx-3dfy-v2/haotang/3dfy/lidra/logs/tagged/_submit/fm-features-trellis500k-tricksNoEMA-16x8/lightning/version_0/checkpoints/last.ckpt
    model:
      is_shortcut_model: True



