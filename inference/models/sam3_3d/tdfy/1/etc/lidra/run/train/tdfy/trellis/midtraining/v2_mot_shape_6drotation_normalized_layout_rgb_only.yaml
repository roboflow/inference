# @package _global_
defaults:
  - ../fm-trellis-trellis500k-tricks-moge-mot-shape-6drotation-normalized

  # load pretrained backbone
  # load pretrained backbone
  # - /data/dataset/tdfy/trellis500k/preprocessor@tdfy.preprocessor: train_keep_bg_w_ptmp
  # - /data/dataset/tdfy/trellis500k/preprocessor@tdfy.val_preprocessor: val_keep_bg_w_ptmp
  - /data/dataset/tdfy/trellis500k/preprocessor@tdfy.preprocessor: train_keep_bg
  - /data/dataset/tdfy/trellis500k/preprocessor@tdfy.val_preprocessor: val_keep_bg

  # - /data/dataset/tdfy/trellis500k/subset_train@loop.dataloaders.training.dataset.datasets.elephant_sketchfaball: elephant_sketchfaball
  # - /data/dataset/tdfy/trellis500k/subset_train@loop.dataloaders.training.dataset.datasets.elephant_2M: elephant_2M
  - /data/dataset/tdfy/trellis500k/subset_train@loop.dataloaders.training.dataset.datasets.elephant: elephant
  - /model/backbone@tdfy.reverse_fn_pretrained: trellis_dit/mot_image_large_shape_6drotation_normalized_layout_pretrained
  - override /data/dataset/tdfy/trellis500k@loop.dataloaders.training.dataset: training_empty
  - override /model/backbone/dit/embedder@tdfy.reverse_fn_pretrained.model.condition_embedder: image_dino_mask_embedder_fuser

module:
  pose_target_convention: ScaleShiftInvariant
  keep_preds: ["shape", "6drotation_normalized", "translation", "scale", "translation_scale"]
  # cropped image, cropped mask, full image, mask
  batch_conditions_mapping: 
    image: image
    mask: mask
    pointmap: pointmap
    rgb_image: rgb_image
    rgb_image_mask: rgb_image_mask
    rgb_pointmap: rgb_pointmap
  generator:
    backbone:
      reverse_fn:
        unconditional_handling: "add_flag"
      loss_weights:
        # help optree broadcase, it does not broadcast DictConfig
        _target_: lidra.config.utils.make_dict
        # layout midtraining we only train pose
        shape: 1.0
        6drotation_normalized: ${tdfy.pose_weight}
        translation: ${tdfy.pose_weight}
        scale: ${tdfy.pose_weight}
        translation_scale: ${tdfy.pose_weight}

lr: 1e-4  # Smaller learning rate; tune yourself

loop:
  max_epochs: 200
  dataloaders:
    training:
      dataset:
        datasets:
          elephant:
            preprocessor: ${tdfy.preprocessor}
          # elephant_sketchfaball:
          #   preprocessor: ${tdfy.preprocessor}
          # elephant_2M:
          #   preprocessor: ${tdfy.preprocessor}
    validation: null

tdfy:
  pose_weight: 0.1
  reverse_fn_pretrained:
    checkpoint_path: /checkpoint/3dfy/haotang/lidra/logs/tagged/_submit/v2-mot-shape-6drotation-normalized-midtrain-no-moge/lightning/version_0/checkpoints/last.ckpt
    strict: false
    device: "cpu"
    remove_name: null
    model:
      use_fp16: false
      force_zeros_cond: true
  reverse_fn: ${tdfy.reverse_fn_pretrained}
  train_preprocessor: ${tdfy.preprocessor}

batch_size: 6
