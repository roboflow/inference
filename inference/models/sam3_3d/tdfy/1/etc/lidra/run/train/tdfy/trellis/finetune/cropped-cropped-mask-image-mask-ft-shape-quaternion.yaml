# @package _global_
defaults:
  - ../fm-trellis-trellis500k
  - /data/dataset/tdfy/trellis500k/subset_train@loop.dataloaders.training.dataset.datasets.r3_25_morphing: r3_25_morphing
  # load pretrained backbone
  - /data/dataset/tdfy/trellis500k/preprocessor@tdfy.preprocessor: train_keep_bg
  - override /model/backbone@tdfy.reverse_fn: trellis_dit/mm_image_large_shape_quaternion_pretrained
  - override /model/module/tdfy@module: generative-featuresAndPoseToken
  - override /model/backbone/dit/embedder@tdfy.reverse_fn.model.condition_embedder: imagex2_maskx2_dino_dino

  - override /data/dataset/tdfy/trellis500k@loop.dataloaders.training.dataset: training_empty
module:
  keep_preds: ["shape", "quaternion"]
  batch_conditions_mapping: ["image", "mask", "rgb_image", "rgb_image_mask"] # cropped image, cropped mask, full image, mask
  generator:
    backbone:
      reverse_fn:
        unconditional_handling: "add_flag"
        backbone: ${tdfy.reverse_fn}
      loss_weights:
        # help optree broadcase, it does not broadcast DictConfig
        _target_: lidra.config.utils.make_dict
        shape: 1.0
        quaternion: 0.01


lr: 1e-5  # Smaller learning rate; tune yourself

loop:
  max_epochs: 100
  dataloaders:
    validation: null
    training:
      dataset:
        # _target_: torch.utils.data.dataset.ConcatDataset
        datasets:
          # _target_: lidra.config.utils.make_list_from_kwargs
          r3_25_morphing:
            preprocessor: ${tdfy.preprocessor}

tdfy:
  reverse_fn:
    strict: false
    checkpoint_path: /checkpoint/3dfy/haotang/lidra/logs/tagged/_submit/v1-pretraining-shape-quaternion-fo-only-noema/lightning/version_0/checkpoints/last.ckpt
    model:
      force_zeros_cond: True
      condition_embedder:
        use_pos_embed: true