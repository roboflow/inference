# @package _global_

cluster_path: /checkpoint/3dfy/shared/weights/tdfy
trellis_ckpts_dir: /checkpoint/3dfy/shared/weights/tdfy/TRELLIS-image-large/ckpts_fc

config_dir: /checkpoint/3dfy/haotang/dev/lidra/etc/lidra/
lidra_ckpt_dir: /checkpoint/3dfy/weiyaowang/lidra 

cluster:
  path:
    weights: /checkpoint/3dfy/shared/weights/

inference_pipeline:
  _target_: lidra.pipeline.inference_pipeline_pointmap.InferencePipelinePointMap

  ss_generator_config_path: /checkpoint/3dfy/ssax/lidra/logs/tagged/_submit/${tdfy.layout_tag_name}/config.yaml
  ss_generator_ckpt_path: /checkpoint/3dfy/ssax/lidra/logs/tagged/_submit/${tdfy.layout_tag_name}/lightning/version_0/checkpoints/${tdfy.layout_model_ckpt_path}.ckpt

  # ss_generator_config_path: /checkpoint/3dfy/haotang/lidra/logs/tagged/_submit/xiang-v2-release1010-artistdpo-planA/config_converted.yaml
  # ss_generator_ckpt_path: /checkpoint/3dfy/haotang/lidra/logs/tagged/_submit/xiang-v2-release1010-artistdpo-planA/lightning/version_0/checkpoints/epoch=4-step=200_converted.ckpt
   
  # ss_generator_config_path: /checkpoint/3dfy/ssax/lidra/logs/tagged/_submit/${tdfy.layout_tag_name}/config.yaml
  # ss_generator_ckpt_path: /fsx-3dfy-v3/ryanxiangli/3dfy/lidra/logs/tagged/_submit/xiang-v2-release1010-artistdpo-planA/lightning/version_0/checkpoints/epoch=4-step=200.ckpt


  # ss_decoder_config_path: ${trellis_ckpts_dir}/ss_decoder.yaml
  # ss_decoder_ckpt_path: /checkpoint/3dfy/shared/weights/tdfy/trellis-ss-vae-trial1-lambda1e-3-8x8/weiyao_decoder.ckpt

  slat_generator_config_path: ${cluster_path}/feature-s2-recipe_sft_depth-vae_500k_cfg-fix_mask-blur-aug_8k_fullimg_r3-0930/config_converted.yaml
  slat_generator_ckpt_path: ${cluster_path}/feature-s2-recipe_sft_depth-vae_500k_cfg-fix_mask-blur-aug_8k_fullimg_r3-0930/lightning/version_0/checkpoints/epoch=29-step=2580-v1_converted.ckpt

  ss_decoder_config_path: ${cluster_path}/ss_decoder/ss_decoder.yaml
  ss_decoder_ckpt_path: ${cluster_path}/ss_decoder/decoder.ckpt

  slat_decoder_gs_config_path: ${trellis_ckpts_dir}/slat_decoder_gs.yaml
  slat_decoder_gs_ckpt_path: ${cluster_path}/slat-depth-vae/epoch=329-step=814400-v1_converted.ckpt

  slat_decoder_gs_4_config_path: ${trellis_ckpts_dir}/slat_decoder_gs_4.yaml
  slat_decoder_gs_4_ckpt_path: ${cluster_path}/slat-depth-vae/depthdecoder_finetune_4gs_last_8.ckpt

  slat_decoder_mesh_config_path: ${trellis_ckpts_dir}/slat_decoder_mesh.yaml
  slat_decoder_mesh_ckpt_path: ${cluster_path}/trellis-train-mesh-inhouseDepth-8x8/decoder_ema0.9999_step0120000.pt

  # slat_generator_config_path: ${lidra_ckpt_dir}/logs/tagged/_submit/fm-trellisDiT-features-ObjV1-ABO-ObjGithub-nvoxels15k-dinov2_vitl14_reg-518-16x8/config.yaml
  # slat_generator_ckpt_path: ${trellis_ckpts_dir}/slat_flow_img_dit_L_64l8p2_fp16.safetensors
  # slat_decoder_gs_config_path: ${config_dir}/model/backbone/trellis_vae/slat_decoder_gs.yaml
  # slat_decoder_gs_ckpt_path: ${trellis_ckpts_dir}/slat_dec_gs_swin8_B_64l8gs32_fp16.safetensors
  # slat_decoder_mesh_config_path: ${config_dir}/model/backbone/trellis_vae/slat_decoder_mesh.yaml
  # slat_decoder_mesh_ckpt_path: ${trellis_ckpts_dir}/slat_dec_mesh_swin8_B_64l8m256c_fp16.safetensors

  pad_size: 1.0
  dtype: float16
  shape_model_dtype: bfloat16
  version: 3dfy_v3
  use_pretrained_slat: false
  slat_cfg_strength: 1
  slat_rescale_t: 1
  downsample_ss_dist: 1

  device: ${tdfy.device}
  depth_model:
    _target_: lidra.pipeline.depth_models.moge.MoGe
    model:
      _target_: moge.model.v1.MoGeModel.from_pretrained
      pretrained_model_name_or_path: Ruicheng/moge-vitl
    device: ${tdfy.device}
  clip_pointmap_beyond_scale: 5.0

  slat_condition_input_mapping: []
  slat_preprocessor:
    _target_: lidra.data.dataset.tdfy.trellis.dataset.PreProcessor
    img_transform:
      _target_: torchvision.transforms.Compose
      transforms:
        - _target_: lidra.data.dataset.tdfy.img_processing.pad_to_square_centered
          _partial_: true
        - _target_: torchvision.transforms.Resize
          size: 518
    mask_transform:
      _target_: torchvision.transforms.Compose
      transforms:
        - _target_: lidra.data.dataset.tdfy.img_processing.pad_to_square_centered
          _partial_: true
        - _target_: torchvision.transforms.Resize
          size: 518
          interpolation: 0 # nearest
    img_mask_joint_transform:
      - _target_: lidra.data.dataset.tdfy.img_and_mask_transforms.crop_around_mask_with_padding
        _partial_: true
        box_size_factor: 1.2
        padding_factor: 0.0 
  slat_mean: [
    1.09678917,   
    0.90180622,
    -1.28466444, 
    -0.91574466,
    -1.64116028,
    0.81207581,
    -1.73082393,  
    -0.51753748,
  ]
  slat_std: [
    2.26849692, 
    2.03889322, 
    2.13405562, 
    2.20259538, 
    2.05722601, 
    1.89593702, 
    2.13656548,
    2.48455034,
  ]
  
  ss_cfg_strength:
    _target_: lidra.config.utils.make_dict
    shape: 7.0
    6drotation_normalized: 5.0
    scale: 5.0
    translation: 5.0
    translation_scale: 5.0

  ss_cfg_strength_pm: 0.0
    # _target_: lidra.config.utils.make_dict
    # shape: 0.0
    # 6drotation_normalized: 5.0
    # scale: 2.0
    # translation: 2.0
    # translation_scale: 0.0

  ss_condition_input_mapping: []  
  ss_preprocessor: null

  # pose_decoder_name: null 
  pose_decoder_name: null 
  use_layout_result: false
  force_shape_in_layout: false
  decode_formats: ["gaussian"]

tdfy:
  device: cuda

  # layout_tag_name: mot6d_disparity_scene_normV2_90eitrv8_10procthor_epoch9_Feb-Sept-filterv3-tr10
  # layout_model_ckpt_path: epoch=124-step=78375-v1

  # layout_tag_name: stage1_planA1002_R3Feb-Sept-filterv3-trweight1
  # layout_model_ckpt_path: epoch=74-step=47025-v1

  # layout_tag_name: xiang-v2-release1010-artistdpo-planA
  # layout_model_ckpt_path: epoch=4-step=200

  # layout_tag_name: v2-release1009-PlanA-artist1003-nodpo-trweight1-filt9
  # layout_model_ckpt_path: epoch=3-step=4208

  layout_tag_name: v2-release1017-PlanA-layoutOnlyFTNoArtist-warmdown
  # layout_model_ckpt_path: epoch=24-step=15925-v1
  layout_model_ckpt_path: epoch=10-step=6270_medium