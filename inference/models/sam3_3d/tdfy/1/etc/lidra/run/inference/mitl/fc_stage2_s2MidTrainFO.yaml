# @package _global_

cluster_path: /large_experiments/3dfy/model_weights
trellis_ckpts_dir: ${cluster_path}/TRELLIS-image-large/ckpts

inference_pipeline:
  _target_: lidra.pipeline.inference_pipeline_stage2_only.InferenceStage2OnlyPipeline
  slat_decoder_gs_config_path: ${trellis_ckpts_dir}/slat_decoder_gs.yaml
  slat_decoder_gs_ckpt_path: ${trellis_ckpts_dir}/slat_dec_gs_swin8_B_64l8gs32_fp16.safetensors
  slat_decoder_mesh_config_path: ${trellis_ckpts_dir}/slat_decoder_mesh.yaml
  slat_decoder_mesh_ckpt_path: ${trellis_ckpts_dir}/slat_dec_mesh_swin8_B_64l8m256c_fp16.safetensors
  
  use_pretrained_slat: false
  slat_generator_config_path: ${cluster_path}/fm-features-cropped-cropped-mask-midtraining-foFix-8x8-noAug/config_converted.yaml
  slat_generator_ckpt_path: ${cluster_path}/fm-features-cropped-cropped-mask-midtraining-foFix-8x8-noAug/lightning/version_0/checkpoints/last_converted.ckpt

  dtype: float16
  version: 3dfy_mitl_s2MidTrainFO
  decode_formats: ["gaussian", "mesh"]

  slat_condition_input_mapping: []
  slat_preprocessor:
    _target_: lidra.data.dataset.tdfy.trellis.dataset.PreProcessor
    img_transform:
      _target_: torchvision.transforms.Compose
      transforms:
        - _target_: lidra.data.dataset.tdfy.img_processing.pad_to_square_centered
          _partial_: true
        - _target_: torchvision.transforms.Resize
          size: 518
    mask_transform:
      _target_: torchvision.transforms.Compose
      transforms:
        - _target_: lidra.data.dataset.tdfy.img_processing.pad_to_square_centered
          _partial_: true
        - _target_: torchvision.transforms.Resize
          size: 518
          interpolation: 0 # nearest
    img_mask_joint_transform:
      - _target_: lidra.data.dataset.tdfy.img_and_mask_transforms.crop_around_mask_with_padding
        _partial_: true
        box_size_factor: 1.2
        padding_factor: 0.0 