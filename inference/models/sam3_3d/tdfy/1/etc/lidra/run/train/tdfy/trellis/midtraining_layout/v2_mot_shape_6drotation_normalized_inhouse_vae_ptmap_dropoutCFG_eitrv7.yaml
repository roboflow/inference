# @package _global_
defaults:
  - ../midtraining/v2_mot_shape_6drotation_normalized_inhouse_vae


  - /data/dataset/tdfy/trellis500k/preprocessor@tdfy.val_preprocessor: val_keep_bg_w_ptmp_normalized
  - override /data/dataset/tdfy/trellis500k@loop.dataloaders.training.dataset:  training_eitr_v3
  - override /data/dataset/tdfy/trellis500k/preprocessor@tdfy.preprocessor: train_keep_bg_w_ptmp_normalized
  - override /data/dataset/tdfy/trellis500k@loop.dataloaders.training.dataset: training_empty

  - override /model/backbone@tdfy.reverse_fn_pretrained: trellis_dit/mot_image_large_shape_6drotation_normalized_layout_pretrained  
  - override /model/backbone/dit/embedder@tdfy.reverse_fn_pretrained.model.condition_embedder: image_dino_mask_pointmap_embedder_fuser_w_pm_cfg


module:
  pose_target_convention: ScaleShiftInvariant
  keep_preds: ["shape", "6drotation_normalized", "translation", "scale", "translation_scale"]
  # cropped image, cropped mask, full image, mask
  batch_conditions_mapping: 
    image: image
    mask: mask
    pointmap: pointmap
    rgb_image: rgb_image
    rgb_image_mask: rgb_image_mask
    rgb_pointmap: rgb_pointmap
  generator:
    backbone:
      reverse_fn:
        unconditional_handling: "add_flag"

      loss_weights:
        # help optree broadcase, it does not broadcast DictConfig
        _target_: lidra.config.utils.make_dict
        # layout midtraining we only train pose
        shape: 1.0
        6drotation_normalized: ${tdfy.pose_weight}
        translation: ${tdfy.pose_weight}
        scale: ${tdfy.pose_weight}
        translation_scale: ${tdfy.pose_weight}

    scheduler:
      _target_: torch.optim.lr_scheduler.LinearLR
      _partial_: true
      start_factor: 0.01
      end_factor: 1.0
      total_iters: 1000

    scheduler_kwargs:
      interval: step       # Update lr every step instead of epoch
      frequency: 1
      name: "train/learning_rate"

lr: 1e-4  # Smaller learning rate; tune yourself

loop:
  max_epochs: 100
  callbacks:
    ema:
      _target_: lidra.callback.ema.EMA
      decays:
        slow: 0.9999 # trellis's rate
        # medium: 0.999
        # fast: 0.99
      default_decay_for_eval: slow
      device: null
      recover_existing: true
      force_fp32: true
      start_step: 10000

    model_checkpoint2:
      every_n_epochs: 5

  dataloaders:
    training:
      dataset:
        datasets:
          _target_: lidra.config.utils.make_list_from_kwargs
          ABO: null
          HSSD: null
          ObjaverseXL_github: null
          ObjaverseXL_sketchfab: null
          ObjaverseXL_sketchfab_all: null
          shutterstock_3d: null
          elephant_trellis500k:
            preprocessor: ${tdfy.preprocessor}
            latent_dir: ${tdfy.latent_dir}
            pointmap_loader:
              pointcloud_directory: ${tdfy.pointcloud_base_dir}/moge_corrected_dense
          elephant_sketchfab_extended:
            preprocessor: ${tdfy.preprocessor}
            latent_dir: ${tdfy.latent_dir}
            pointmap_loader:
              pointcloud_directory: ${tdfy.pointcloud_base_dir}/moge_corrected_dense
          elephant_shutterstock_tranche1:
            preprocessor: ${tdfy.preprocessor}
            latent_dir: ${tdfy.latent_dir}
            pointmap_loader:
              pointcloud_directory: ${tdfy.pointcloud_base_dir}/moge_corrected_dense_shutterstock
          elephant_ego:
            preprocessor: ${tdfy.preprocessor}
            latent_dir: ${tdfy.latent_dir}
            pointmap_loader:
              pointcloud_directory: ${tdfy.pointcloud_base_dir}/moge_corrected_dense_ego
          elephant_food:
            preprocessor: ${tdfy.preprocessor}
            latent_dir: ${tdfy.latent_dir}
            pointmap_loader:
              pointcloud_directory: ${tdfy.pointcloud_base_dir}/moge_corrected_dense_food
          elephant_food_table:
            preprocessor: ${tdfy.preprocessor}
            latent_dir: ${tdfy.latent_dir}
            pointmap_loader:
              pointcloud_directory: ${tdfy.pointcloud_base_dir}/moge_corrected_dense_food_table
          elephant_shutterstock_tranche2:
            preprocessor: ${tdfy.preprocessor}
            latent_dir: ${tdfy.latent_dir}

    validation: null


tdfy:
  latent_dir: "ss_latents/trellis-ss-vae-trial1-lambda1e-3-8x8"
  pointcloud_base_dir: "/fsx-3dfy-v2/shared/datasets/eitr_data/pointmap/"
  pointmap_embedder:
    dropout_prob: 0.1
    force_drop_modalities: null
  pose_weight: 0.1
  reverse_fn_pretrained:
    checkpoint_path: /fsx-3dfy-v2/haotang/3dfy/lidra/logs/tagged/_submit/v2_mot_shape_6drotation_normalized_inhouse_vae/lightning/version_0/checkpoints/epoch=99-step=153900-v1.ckpt
    strict: false
    device: "cpu"
    remove_name: null
    model:
      use_fp16: false
      force_zeros_cond: true
  reverse_fn: ${tdfy.reverse_fn_pretrained}
  train_preprocessor: ${tdfy.preprocessor}

batch_size: 3