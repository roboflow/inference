# @package _global_
defaults:
  - ../midtraining/v2_mot_shape_6drotation_normalized_inhouse_vae

  # load pretrained backbone
  - /data/dataset/tdfy/trellis500k/subset_train@loop.dataloaders.training.dataset.datasets.artists_3d: artists_3d
  - override /data/dataset/tdfy/trellis500k@loop.dataloaders.training.dataset: training_empty

lr: 1e-5

module:
  # cropped image, cropped mask, full image, mask
  batch_conditions_mapping: 
    image: image
    mask: mask
    rgb_image: rgb_image
    rgb_image_mask: rgb_image_mask
  generator:
    backbone:
      reverse_fn:
        unconditional_handling: "add_flag"
      loss_weights:
        # help optree broadcase, it does not broadcast DictConfig
        _target_: lidra.config.utils.make_dict
        shape: 1.0
        6drotation_normalized: ${tdfy.pose_weight}

loop:
  max_epochs: 100
  dataloaders:
    validation: null
    training:
      dataset:
        # _target_: torch.utils.data.dataset.ConcatDataset
        datasets:
          # _target_: lidra.config.utils.make_list_from_kwargs
          artists_3d:
            preprocessor: ${tdfy.preprocessor}
            latent_dir: ${tdfy.latent_dir}

tdfy:
  pose_weight: 0.0
  reverse_fn_pretrained:
    checkpoint_path: /fsx-3dfy-v2/haotang/3dfy/lidra/logs/tagged/_submit/v2_mot_6drotation_normalized_no_layout_inhouse_VAE_Feb-May/lightning/version_0/checkpoints/last.ckpt    
    strict: false
    device: "cpu"
    remove_name: null
    model:
      freeze_shared_parameters: True
      use_fp16: True
      force_zeros_cond: True
      condition_embedder:
        freeze: True
  reverse_fn: ${tdfy.reverse_fn_pretrained}
  latent_dir: "ss_latents/trellis-ss-vae-trial1-lambda1e-3-8x8"

