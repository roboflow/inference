{"openapi": "3.1.0", "info": {"title": "Roboflow Inference Server", "description": "Roboflow inference server", "version": "1.0.2"}, "paths": {"/metrics": {"get": {"summary": "Metrics", "description": "Endpoint that serves Prometheus metrics.", "operationId": "metrics_metrics_get", "responses": {"200": {"description": "Successful Response", "content": {"application/json": {"schema": {}}}}}}}, "/device/stats": {"get": {"summary": "Device Stats", "operationId": "device_stats_device_stats_get", "responses": {"200": {"description": "Successful Response", "content": {"application/json": {"schema": {}}}}}}}, "/info": {"get": {"summary": "Info", "description": "Get the server name and version number", "operationId": "root_info_get", "responses": {"200": {"description": "Successful Response", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/ServerVersionInfo"}}}}}}}, "/logs": {"get": {"summary": "Get Recent Logs", "description": "Get recent application logs for debugging", "operationId": "get_logs_logs_get", "parameters": [{"name": "limit", "in": "query", "required": false, "schema": {"anyOf": [{"type": "integer"}, {"type": "null"}], "description": "Maximum number of log entries to return", "default": 100, "title": "Limit"}, "description": "Maximum number of log entries to return"}, {"name": "level", "in": "query", "required": false, "schema": {"anyOf": [{"type": "string"}, {"type": "null"}], "description": "Filter by log level (DEBUG, INFO, WARNING, ERROR, CRITICAL)", "title": "Level"}, "description": "Filter by log level (DEBUG, INFO, WARNING, ERROR, CRITICAL)"}, {"name": "since", "in": "query", "required": false, "schema": {"anyOf": [{"type": "string"}, {"type": "null"}], "description": "Return logs since this ISO timestamp", "title": "Since"}, "description": "Return logs since this ISO timestamp"}], "responses": {"200": {"description": "Successful Response", "content": {"application/json": {"schema": {}}}}, "422": {"description": "Validation Error", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/HTTPValidationError"}}}}}}}, "/model/registry": {"get": {"summary": "Get model keys", "description": "Get the ID of each loaded model", "operationId": "registry_model_registry_get", "responses": {"200": {"description": "Successful Response", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/ModelsDescriptions"}}}}}}}, "/model/add": {"post": {"summary": "Load a model", "description": "Load the model with the given model ID", "operationId": "model_add_model_add_post", "parameters": [{"name": "countinference", "in": "query", "required": false, "schema": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Countinference"}}, {"name": "service_secret", "in": "query", "required": false, "schema": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Service Secret"}}], "requestBody": {"required": true, "content": {"application/json": {"schema": {"$ref": "#/components/schemas/AddModelRequest"}}}}, "responses": {"200": {"description": "Successful Response", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/ModelsDescriptions"}}}}, "422": {"description": "Validation Error", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/HTTPValidationError"}}}}}}}, "/model/remove": {"post": {"summary": "Remove a model", "description": "Remove the model with the given model ID", "operationId": "model_remove_model_remove_post", "requestBody": {"content": {"application/json": {"schema": {"$ref": "#/components/schemas/ClearModelRequest"}}}, "required": true}, "responses": {"200": {"description": "Successful Response", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/ModelsDescriptions"}}}}, "422": {"description": "Validation Error", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/HTTPValidationError"}}}}}}}, "/model/clear": {"post": {"summary": "Remove all models", "description": "Remove all loaded models", "operationId": "model_clear_model_clear_post", "responses": {"200": {"description": "Successful Response", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/ModelsDescriptions"}}}}}}}, "/infer/object_detection": {"post": {"summary": "Object detection infer", "description": "Run inference with the specified object detection model", "operationId": "infer_object_detection_infer_object_detection_post", "parameters": [{"name": "countinference", "in": "query", "required": false, "schema": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Countinference"}}, {"name": "service_secret", "in": "query", "required": false, "schema": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Service Secret"}}], "requestBody": {"required": true, "content": {"application/json": {"schema": {"$ref": "#/components/schemas/ObjectDetectionInferenceRequest"}}}}, "responses": {"200": {"description": "Successful Response", "content": {"application/json": {"schema": {"anyOf": [{"$ref": "#/components/schemas/ObjectDetectionInferenceResponse"}, {"type": "array", "items": {"$ref": "#/components/schemas/ObjectDetectionInferenceResponse"}}, {"$ref": "#/components/schemas/StubResponse"}], "title": "Response Infer Object Detection Infer Object Detection Post"}}}}, "422": {"description": "Validation Error", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/HTTPValidationError"}}}}}}}, "/infer/instance_segmentation": {"post": {"summary": "Instance segmentation infer", "description": "Run inference with the specified instance segmentation model", "operationId": "infer_instance_segmentation_infer_instance_segmentation_post", "parameters": [{"name": "countinference", "in": "query", "required": false, "schema": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Countinference"}}, {"name": "service_secret", "in": "query", "required": false, "schema": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Service Secret"}}], "requestBody": {"required": true, "content": {"application/json": {"schema": {"$ref": "#/components/schemas/InstanceSegmentationInferenceRequest"}}}}, "responses": {"200": {"description": "Successful Response", "content": {"application/json": {"schema": {"anyOf": [{"$ref": "#/components/schemas/InstanceSegmentationInferenceResponse"}, {"$ref": "#/components/schemas/StubResponse"}], "title": "Response Infer Instance Segmentation Infer Instance Segmentation Post"}}}}, "422": {"description": "Validation Error", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/HTTPValidationError"}}}}}}}, "/infer/semantic_segmentation": {"post": {"summary": "Semantic segmentation infer", "description": "Run inference with the specified semantic segmentation model", "operationId": "infer_semantic_segmentation_infer_semantic_segmentation_post", "parameters": [{"name": "countinference", "in": "query", "required": false, "schema": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Countinference"}}, {"name": "service_secret", "in": "query", "required": false, "schema": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Service Secret"}}], "requestBody": {"required": true, "content": {"application/json": {"schema": {"$ref": "#/components/schemas/SemanticSegmentationInferenceRequest"}}}}, "responses": {"200": {"description": "Successful Response", "content": {"application/json": {"schema": {"anyOf": [{"$ref": "#/components/schemas/SemanticSegmentationInferenceResponse"}, {"$ref": "#/components/schemas/StubResponse"}], "title": "Response Infer Semantic Segmentation Infer Semantic Segmentation Post"}}}}, "422": {"description": "Validation Error", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/HTTPValidationError"}}}}}}}, "/infer/classification": {"post": {"summary": "Classification infer", "description": "Run inference with the specified classification model", "operationId": "infer_classification_infer_classification_post", "parameters": [{"name": "countinference", "in": "query", "required": false, "schema": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Countinference"}}, {"name": "service_secret", "in": "query", "required": false, "schema": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Service Secret"}}], "requestBody": {"required": true, "content": {"application/json": {"schema": {"$ref": "#/components/schemas/ClassificationInferenceRequest"}}}}, "responses": {"200": {"description": "Successful Response", "content": {"application/json": {"schema": {"anyOf": [{"$ref": "#/components/schemas/ClassificationInferenceResponse"}, {"$ref": "#/components/schemas/MultiLabelClassificationInferenceResponse"}, {"$ref": "#/components/schemas/StubResponse"}], "title": "Response Infer Classification Infer Classification Post"}}}}, "422": {"description": "Validation Error", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/HTTPValidationError"}}}}}}}, "/infer/keypoints_detection": {"post": {"summary": "Keypoints detection infer", "description": "Run inference with the specified keypoints detection model", "operationId": "infer_keypoints_infer_keypoints_detection_post", "parameters": [{"name": "countinference", "in": "query", "required": false, "schema": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Countinference"}}, {"name": "service_secret", "in": "query", "required": false, "schema": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Service Secret"}}], "requestBody": {"required": true, "content": {"application/json": {"schema": {"$ref": "#/components/schemas/KeypointsDetectionInferenceRequest"}}}}, "responses": {"200": {"description": "Successful Response", "content": {"application/json": {"schema": {"anyOf": [{"$ref": "#/components/schemas/KeypointsDetectionInferenceResponse"}, {"$ref": "#/components/schemas/StubResponse"}], "title": "Response Infer Keypoints Infer Keypoints Detection Post"}}}}, "422": {"description": "Validation Error", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/HTTPValidationError"}}}}}}}, "/infer/lmm": {"post": {"summary": "Large multi-modal model infer", "description": "Run inference with the specified large multi-modal model", "operationId": "infer_lmm_infer_lmm_post", "parameters": [{"name": "countinference", "in": "query", "required": false, "schema": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Countinference"}}, {"name": "service_secret", "in": "query", "required": false, "schema": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Service Secret"}}], "requestBody": {"required": true, "content": {"application/json": {"schema": {"$ref": "#/components/schemas/LMMInferenceRequest"}}}}, "responses": {"200": {"description": "Successful Response", "content": {"application/json": {"schema": {"anyOf": [{"$ref": "#/components/schemas/LMMInferenceResponse"}, {"type": "array", "items": {"$ref": "#/components/schemas/LMMInferenceResponse"}}, {"$ref": "#/components/schemas/StubResponse"}], "title": "Response Infer Lmm Infer Lmm Post"}}}}, "422": {"description": "Validation Error", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/HTTPValidationError"}}}}}}}, "/infer/lmm/{model_id}": {"post": {"summary": "Large multi-modal model infer with model ID in path", "description": "Run inference with the specified large multi-modal model. Model ID is specified in the URL path (can contain slashes).", "operationId": "infer_lmm_with_model_id_infer_lmm__model_id__post", "parameters": [{"name": "model_id", "in": "path", "required": true, "schema": {"type": "string", "title": "Model Id"}}, {"name": "countinference", "in": "query", "required": false, "schema": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Countinference"}}, {"name": "service_secret", "in": "query", "required": false, "schema": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Service Secret"}}], "requestBody": {"required": true, "content": {"application/json": {"schema": {"$ref": "#/components/schemas/LMMInferenceRequest"}}}}, "responses": {"200": {"description": "Successful Response", "content": {"application/json": {"schema": {"anyOf": [{"$ref": "#/components/schemas/LMMInferenceResponse"}, {"type": "array", "items": {"$ref": "#/components/schemas/LMMInferenceResponse"}}, {"$ref": "#/components/schemas/StubResponse"}], "title": "Response Infer Lmm With Model Id Infer Lmm  Model Id  Post"}}}}, "422": {"description": "Validation Error", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/HTTPValidationError"}}}}}}}, "/{workspace_name}/workflows/{workflow_id}/describe_interface": {"post": {"summary": "Endpoint to describe interface of predefined workflow", "description": "Checks Roboflow API for workflow definition, once acquired - describes workflow inputs and outputs", "operationId": "describe_predefined_workflow_interface__workspace_name__workflows__workflow_id__describe_interface_post", "parameters": [{"name": "workspace_name", "in": "path", "required": true, "schema": {"type": "string", "title": "Workspace Name"}}, {"name": "workflow_id", "in": "path", "required": true, "schema": {"type": "string", "title": "Workflow Id"}}], "requestBody": {"required": true, "content": {"application/json": {"schema": {"$ref": "#/components/schemas/PredefinedWorkflowDescribeInterfaceRequest"}}}}, "responses": {"200": {"description": "Successful Response", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/DescribeInterfaceResponse"}}}}, "422": {"description": "Validation Error", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/HTTPValidationError"}}}}}}}, "/workflows/describe_interface": {"post": {"summary": "Endpoint to describe interface of workflow given in request", "description": "Parses workflow definition and retrieves describes inputs and outputs", "operationId": "describe_workflow_interface_workflows_describe_interface_post", "requestBody": {"content": {"application/json": {"schema": {"$ref": "#/components/schemas/WorkflowSpecificationDescribeInterfaceRequest"}}}, "required": true}, "responses": {"200": {"description": "Successful Response", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/DescribeInterfaceResponse"}}}}, "422": {"description": "Validation Error", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/HTTPValidationError"}}}}}}}, "/infer/workflows/{workspace_name}/{workflow_id}": {"post": {"summary": "[LEGACY] Endpoint to run predefined workflow", "description": "Checks Roboflow API for workflow definition, once acquired - parses and executes injecting runtime parameters from request body. This endpoint is deprecated and will be removed end of Q2 2024", "operationId": "infer_from_predefined_workflow_infer_workflows__workspace_name___workflow_id__post", "deprecated": true, "parameters": [{"name": "workspace_name", "in": "path", "required": true, "schema": {"type": "string", "title": "Workspace Name"}}, {"name": "workflow_id", "in": "path", "required": true, "schema": {"type": "string", "title": "Workflow Id"}}], "requestBody": {"required": true, "content": {"application/json": {"schema": {"$ref": "#/components/schemas/PredefinedWorkflowInferenceRequest"}}}}, "responses": {"200": {"description": "Successful Response", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/WorkflowInferenceResponse"}}}}, "422": {"description": "Validation Error", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/HTTPValidationError"}}}}}}}, "/{workspace_name}/workflows/{workflow_id}": {"post": {"summary": "Endpoint to run predefined workflow", "description": "Checks Roboflow API for workflow definition, once acquired - parses and executes injecting runtime parameters from request body", "operationId": "infer_from_predefined_workflow__workspace_name__workflows__workflow_id__post", "parameters": [{"name": "workspace_name", "in": "path", "required": true, "schema": {"type": "string", "title": "Workspace Name"}}, {"name": "workflow_id", "in": "path", "required": true, "schema": {"type": "string", "title": "Workflow Id"}}], "requestBody": {"required": true, "content": {"application/json": {"schema": {"$ref": "#/components/schemas/PredefinedWorkflowInferenceRequest"}}}}, "responses": {"200": {"description": "Successful Response", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/WorkflowInferenceResponse"}}}}, "422": {"description": "Validation Error", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/HTTPValidationError"}}}}}}}, "/infer/workflows": {"post": {"summary": "[LEGACY] Endpoint to run workflow specification provided in payload", "description": "Parses and executes workflow specification, injecting runtime parameters from request body. This endpoint is deprecated and will be removed end of Q2 2024.", "operationId": "infer_from_workflow_infer_workflows_post", "requestBody": {"content": {"application/json": {"schema": {"$ref": "#/components/schemas/WorkflowSpecificationInferenceRequest"}}}, "required": true}, "responses": {"200": {"description": "Successful Response", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/WorkflowInferenceResponse"}}}}, "422": {"description": "Validation Error", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/HTTPValidationError"}}}}}, "deprecated": true}}, "/workflows/run": {"post": {"summary": "Endpoint to run workflow specification provided in payload", "description": "Parses and executes workflow specification, injecting runtime parameters from request body.", "operationId": "infer_from_workflow_workflows_run_post", "requestBody": {"content": {"application/json": {"schema": {"$ref": "#/components/schemas/WorkflowSpecificationInferenceRequest"}}}, "required": true}, "responses": {"200": {"description": "Successful Response", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/WorkflowInferenceResponse"}}}}, "422": {"description": "Validation Error", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/HTTPValidationError"}}}}}}}, "/workflows/execution_engine/versions": {"get": {"summary": "Returns available Execution Engine versions sorted from oldest to newest", "description": "Returns available Execution Engine versions sorted from oldest to newest", "operationId": "get_execution_engine_versions_workflows_execution_engine_versions_get", "responses": {"200": {"description": "Successful Response", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/ExecutionEngineVersions"}}}}}}}, "/workflows/blocks/describe": {"get": {"summary": "[LEGACY] Endpoint to get definition of workflows blocks that are accessible", "description": "Endpoint provides detailed information about workflows building blocks that are accessible in the inference server. This information could be used to programmatically build / display workflows.", "operationId": "describe_workflows_blocks_workflows_blocks_describe_get", "responses": {"200": {"description": "Successful Response", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/WorkflowsBlocksDescription"}}}}}, "deprecated": true}, "post": {"summary": "[EXPERIMENTAL] Endpoint to get definition of workflows blocks that are accessible", "description": "Endpoint provides detailed information about workflows building blocks that are accessible in the inference server. This information could be used to programmatically build / display workflows. Additionally - in request body one can specify list of dynamic blocks definitions which will be transformed into blocks and used to generate schemas and definitions of connections", "operationId": "describe_workflows_blocks_workflows_blocks_describe_post", "requestBody": {"content": {"application/json": {"schema": {"anyOf": [{"$ref": "#/components/schemas/DescribeBlocksRequest"}, {"type": "null"}], "title": "Request Payload"}}}}, "responses": {"200": {"description": "Successful Response", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/WorkflowsBlocksDescription"}}}}, "422": {"description": "Validation Error", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/HTTPValidationError"}}}}}}}, "/workflows/definition/schema": {"get": {"summary": "Endpoint to fetch the workflows block schema", "description": "Endpoint to fetch the schema of all available blocks. This information can be used to validate workflow definitions and suggest syntax in the JSON editor.", "operationId": "get_workflow_schema_workflows_definition_schema_get", "responses": {"200": {"description": "Successful Response", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/WorkflowsBlocksSchemaDescription"}}}}}}}, "/workflows/blocks/dynamic_outputs": {"post": {"summary": "[EXPERIMENTAL] Endpoint to get definition of dynamic output for workflow step", "description": "Endpoint to be used when step outputs can be discovered only after filling manifest with data.", "operationId": "get_dynamic_block_outputs_workflows_blocks_dynamic_outputs_post", "requestBody": {"content": {"application/json": {"schema": {"additionalProperties": true, "type": "object", "title": "Step Manifest"}}}, "required": true}, "responses": {"200": {"description": "Successful Response", "content": {"application/json": {"schema": {"items": {"$ref": "#/components/schemas/OutputDefinition"}, "type": "array", "title": "Response Get Dynamic Block Outputs Workflows Blocks Dynamic Outputs Post"}}}}, "422": {"description": "Validation Error", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/HTTPValidationError"}}}}}}}, "/workflows/validate": {"post": {"summary": "[EXPERIMENTAL] Endpoint to validate", "description": "Endpoint provides a way to check validity of JSON workflow definition.", "operationId": "validate_workflow_workflows_validate_post", "parameters": [{"name": "api_key", "in": "query", "required": false, "schema": {"anyOf": [{"type": "string"}, {"type": "null"}], "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval", "title": "Api Key"}, "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval"}], "requestBody": {"required": true, "content": {"application/json": {"schema": {"type": "object", "additionalProperties": true, "title": "Specification"}}}}, "responses": {"200": {"description": "Successful Response", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/WorkflowValidationStatus"}}}}, "422": {"description": "Validation Error", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/HTTPValidationError"}}}}}}}, "/initialise_webrtc_worker": {"post": {"summary": "[EXPERIMENTAL] Establishes WebRTC peer connection and processes video stream in spawned process or modal function", "description": "[EXPERIMENTAL] Establishes WebRTC peer connection and processes video stream in spawned process or modal function", "operationId": "initialise_webrtc_worker_initialise_webrtc_worker_post", "requestBody": {"content": {"application/json": {"schema": {"$ref": "#/components/schemas/WebRTCWorkerRequest"}}}, "required": true}, "responses": {"200": {"description": "Successful Response", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/InitializeWebRTCResponse"}}}}, "422": {"description": "Validation Error", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/HTTPValidationError"}}}}}}}, "/clip/embed_image": {"post": {"summary": "CLIP Image Embeddings", "description": "Run the Open AI CLIP model to embed image data.", "operationId": "clip_embed_image_clip_embed_image_post", "parameters": [{"name": "api_key", "in": "query", "required": false, "schema": {"anyOf": [{"type": "string"}, {"type": "null"}], "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval", "title": "Api Key"}, "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval"}, {"name": "countinference", "in": "query", "required": false, "schema": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Countinference"}}, {"name": "service_secret", "in": "query", "required": false, "schema": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Service Secret"}}], "requestBody": {"required": true, "content": {"application/json": {"schema": {"$ref": "#/components/schemas/ClipImageEmbeddingRequest"}}}}, "responses": {"200": {"description": "Successful Response", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/ClipEmbeddingResponse"}}}}, "422": {"description": "Validation Error", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/HTTPValidationError"}}}}}}}, "/clip/embed_text": {"post": {"summary": "CLIP Text Embeddings", "description": "Run the Open AI CLIP model to embed text data.", "operationId": "clip_embed_text_clip_embed_text_post", "parameters": [{"name": "api_key", "in": "query", "required": false, "schema": {"anyOf": [{"type": "string"}, {"type": "null"}], "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval", "title": "Api Key"}, "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval"}, {"name": "countinference", "in": "query", "required": false, "schema": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Countinference"}}, {"name": "service_secret", "in": "query", "required": false, "schema": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Service Secret"}}], "requestBody": {"required": true, "content": {"application/json": {"schema": {"$ref": "#/components/schemas/ClipTextEmbeddingRequest"}}}}, "responses": {"200": {"description": "Successful Response", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/ClipEmbeddingResponse"}}}}, "422": {"description": "Validation Error", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/HTTPValidationError"}}}}}}}, "/clip/compare": {"post": {"summary": "CLIP Compare", "description": "Run the Open AI CLIP model to compute similarity scores.", "operationId": "clip_compare_clip_compare_post", "parameters": [{"name": "api_key", "in": "query", "required": false, "schema": {"anyOf": [{"type": "string"}, {"type": "null"}], "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval", "title": "Api Key"}, "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval"}, {"name": "countinference", "in": "query", "required": false, "schema": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Countinference"}}, {"name": "service_secret", "in": "query", "required": false, "schema": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Service Secret"}}], "requestBody": {"required": true, "content": {"application/json": {"schema": {"$ref": "#/components/schemas/ClipCompareRequest"}}}}, "responses": {"200": {"description": "Successful Response", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/ClipCompareResponse"}}}}, "422": {"description": "Validation Error", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/HTTPValidationError"}}}}}}}, "/perception_encoder/embed_image": {"post": {"summary": "PE Image Embeddings", "description": "Run the Meta Perception Encoder model to embed image data.", "operationId": "pe_embed_image_perception_encoder_embed_image_post", "parameters": [{"name": "api_key", "in": "query", "required": false, "schema": {"anyOf": [{"type": "string"}, {"type": "null"}], "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval", "title": "Api Key"}, "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval"}, {"name": "countinference", "in": "query", "required": false, "schema": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Countinference"}}, {"name": "service_secret", "in": "query", "required": false, "schema": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Service Secret"}}], "requestBody": {"required": true, "content": {"application/json": {"schema": {"$ref": "#/components/schemas/PerceptionEncoderImageEmbeddingRequest"}}}}, "responses": {"200": {"description": "Successful Response", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/PerceptionEncoderEmbeddingResponse"}}}}, "422": {"description": "Validation Error", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/HTTPValidationError"}}}}}}}, "/perception_encoder/embed_text": {"post": {"summary": "Perception Encoder Text Embeddings", "description": "Run the Meta Perception Encoder model to embed text data.", "operationId": "pe_embed_text_perception_encoder_embed_text_post", "parameters": [{"name": "api_key", "in": "query", "required": false, "schema": {"anyOf": [{"type": "string"}, {"type": "null"}], "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval", "title": "Api Key"}, "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval"}, {"name": "countinference", "in": "query", "required": false, "schema": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Countinference"}}, {"name": "service_secret", "in": "query", "required": false, "schema": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Service Secret"}}], "requestBody": {"required": true, "content": {"application/json": {"schema": {"$ref": "#/components/schemas/PerceptionEncoderTextEmbeddingRequest"}}}}, "responses": {"200": {"description": "Successful Response", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/PerceptionEncoderEmbeddingResponse"}}}}, "422": {"description": "Validation Error", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/HTTPValidationError"}}}}}}}, "/perception_encoder/compare": {"post": {"summary": "Perception Encoder Compare", "description": "Run the Meta Perception Encoder model to compute similarity scores.", "operationId": "pe_compare_perception_encoder_compare_post", "parameters": [{"name": "api_key", "in": "query", "required": false, "schema": {"anyOf": [{"type": "string"}, {"type": "null"}], "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval", "title": "Api Key"}, "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval"}, {"name": "countinference", "in": "query", "required": false, "schema": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Countinference"}}, {"name": "service_secret", "in": "query", "required": false, "schema": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Service Secret"}}], "requestBody": {"required": true, "content": {"application/json": {"schema": {"$ref": "#/components/schemas/PerceptionEncoderCompareRequest"}}}}, "responses": {"200": {"description": "Successful Response", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/PerceptionEncoderCompareResponse"}}}}, "422": {"description": "Validation Error", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/HTTPValidationError"}}}}}}}, "/grounding_dino/infer": {"post": {"summary": "Grounding DINO inference.", "description": "Run the Grounding DINO zero-shot object detection model.", "operationId": "grounding_dino_infer_grounding_dino_infer_post", "parameters": [{"name": "api_key", "in": "query", "required": false, "schema": {"anyOf": [{"type": "string"}, {"type": "null"}], "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval", "title": "Api Key"}, "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval"}, {"name": "countinference", "in": "query", "required": false, "schema": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Countinference"}}, {"name": "service_secret", "in": "query", "required": false, "schema": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Service Secret"}}], "requestBody": {"required": true, "content": {"application/json": {"schema": {"$ref": "#/components/schemas/GroundingDINOInferenceRequest"}}}}, "responses": {"200": {"description": "Successful Response", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/ObjectDetectionInferenceResponse"}}}}, "422": {"description": "Validation Error", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/HTTPValidationError"}}}}}}}, "/yolo_world/infer": {"post": {"summary": "YOLO-World inference.", "description": "Run the YOLO-World zero-shot object detection model.", "operationId": "yolo_world_infer_yolo_world_infer_post", "parameters": [{"name": "api_key", "in": "query", "required": false, "schema": {"anyOf": [{"type": "string"}, {"type": "null"}], "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval", "title": "Api Key"}, "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval"}, {"name": "countinference", "in": "query", "required": false, "schema": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Countinference"}}, {"name": "service_secret", "in": "query", "required": false, "schema": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Service Secret"}}], "requestBody": {"required": true, "content": {"application/json": {"schema": {"$ref": "#/components/schemas/YOLOWorldInferenceRequest"}}}}, "responses": {"200": {"description": "Successful Response", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/ObjectDetectionInferenceResponse"}}}}, "422": {"description": "Validation Error", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/HTTPValidationError"}}}}}}}, "/doctr/ocr": {"post": {"summary": "DocTR OCR response", "description": "Run the DocTR OCR model to retrieve text in an image.", "operationId": "doctr_retrieve_text_doctr_ocr_post", "parameters": [{"name": "api_key", "in": "query", "required": false, "schema": {"anyOf": [{"type": "string"}, {"type": "null"}], "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval", "title": "Api Key"}, "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval"}, {"name": "countinference", "in": "query", "required": false, "schema": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Countinference"}}, {"name": "service_secret", "in": "query", "required": false, "schema": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Service Secret"}}], "requestBody": {"required": true, "content": {"application/json": {"schema": {"$ref": "#/components/schemas/DoctrOCRInferenceRequest"}}}}, "responses": {"200": {"description": "Successful Response", "content": {"application/json": {"schema": {"anyOf": [{"$ref": "#/components/schemas/OCRInferenceResponse"}, {"type": "array", "items": {"$ref": "#/components/schemas/OCRInferenceResponse"}}], "title": "Response Doctr Retrieve Text Doctr Ocr Post"}}}}, "422": {"description": "Validation Error", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/HTTPValidationError"}}}}}}}, "/easy_ocr/ocr": {"post": {"summary": "EasyOCR OCR response", "description": "Run the EasyOCR model to retrieve text in an image.", "operationId": "easy_ocr_retrieve_text_easy_ocr_ocr_post", "parameters": [{"name": "api_key", "in": "query", "required": false, "schema": {"anyOf": [{"type": "string"}, {"type": "null"}], "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval", "title": "Api Key"}, "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval"}, {"name": "countinference", "in": "query", "required": false, "schema": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Countinference"}}, {"name": "service_secret", "in": "query", "required": false, "schema": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Service Secret"}}], "requestBody": {"required": true, "content": {"application/json": {"schema": {"$ref": "#/components/schemas/EasyOCRInferenceRequest"}}}}, "responses": {"200": {"description": "Successful Response", "content": {"application/json": {"schema": {"anyOf": [{"$ref": "#/components/schemas/OCRInferenceResponse"}, {"type": "array", "items": {"$ref": "#/components/schemas/OCRInferenceResponse"}}], "title": "Response Easy Ocr Retrieve Text Easy Ocr Ocr Post"}}}}, "422": {"description": "Validation Error", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/HTTPValidationError"}}}}}}}, "/sam/embed_image": {"post": {"summary": "SAM Image Embeddings", "description": "Run the Meta AI Segmant Anything Model to embed image data.", "operationId": "sam_embed_image_sam_embed_image_post", "parameters": [{"name": "api_key", "in": "query", "required": false, "schema": {"anyOf": [{"type": "string"}, {"type": "null"}], "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval", "title": "Api Key"}, "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval"}, {"name": "countinference", "in": "query", "required": false, "schema": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Countinference"}}, {"name": "service_secret", "in": "query", "required": false, "schema": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Service Secret"}}], "requestBody": {"required": true, "content": {"application/json": {"schema": {"$ref": "#/components/schemas/SamEmbeddingRequest"}}}}, "responses": {"200": {"description": "Successful Response", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/SamEmbeddingResponse"}}}}, "422": {"description": "Validation Error", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/HTTPValidationError"}}}}}}}, "/sam/segment_image": {"post": {"summary": "SAM Image Segmentation", "description": "Run the Meta AI Segmant Anything Model to generate segmenations for image data.", "operationId": "sam_segment_image_sam_segment_image_post", "parameters": [{"name": "api_key", "in": "query", "required": false, "schema": {"anyOf": [{"type": "string"}, {"type": "null"}], "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval", "title": "Api Key"}, "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval"}, {"name": "countinference", "in": "query", "required": false, "schema": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Countinference"}}, {"name": "service_secret", "in": "query", "required": false, "schema": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Service Secret"}}], "requestBody": {"required": true, "content": {"application/json": {"schema": {"$ref": "#/components/schemas/SamSegmentationRequest"}}}}, "responses": {"200": {"description": "Successful Response", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/SamSegmentationResponse"}}}}, "422": {"description": "Validation Error", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/HTTPValidationError"}}}}}}}, "/sam2/embed_image": {"post": {"summary": "SAM2 Image Embeddings", "description": "Run the Meta AI Segment Anything 2 Model to embed image data.", "operationId": "sam2_embed_image_sam2_embed_image_post", "parameters": [{"name": "api_key", "in": "query", "required": false, "schema": {"anyOf": [{"type": "string"}, {"type": "null"}], "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval", "title": "Api Key"}, "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval"}, {"name": "countinference", "in": "query", "required": false, "schema": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Countinference"}}, {"name": "service_secret", "in": "query", "required": false, "schema": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Service Secret"}}], "requestBody": {"required": true, "content": {"application/json": {"schema": {"$ref": "#/components/schemas/Sam2EmbeddingRequest"}}}}, "responses": {"200": {"description": "Successful Response", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/Sam2EmbeddingResponse"}}}}, "422": {"description": "Validation Error", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/HTTPValidationError"}}}}}}}, "/sam2/segment_image": {"post": {"summary": "SAM2 Image Segmentation", "description": "Run the Meta AI Segment Anything 2 Model to generate segmenations for image data.", "operationId": "sam2_segment_image_sam2_segment_image_post", "parameters": [{"name": "api_key", "in": "query", "required": false, "schema": {"anyOf": [{"type": "string"}, {"type": "null"}], "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval", "title": "Api Key"}, "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval"}, {"name": "countinference", "in": "query", "required": false, "schema": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Countinference"}}, {"name": "service_secret", "in": "query", "required": false, "schema": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Service Secret"}}], "requestBody": {"required": true, "content": {"application/json": {"schema": {"$ref": "#/components/schemas/Sam2SegmentationRequest"}}}}, "responses": {"200": {"description": "Successful Response", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/Sam2SegmentationResponse"}}}}, "422": {"description": "Validation Error", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/HTTPValidationError"}}}}}}}, "/sam3/embed_image": {"post": {"summary": "Seg preview Image Embeddings", "description": "Run the  Model to embed image data.", "operationId": "sam3_embed_image_sam3_embed_image_post", "parameters": [{"name": "api_key", "in": "query", "required": false, "schema": {"anyOf": [{"type": "string"}, {"type": "null"}], "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval", "title": "Api Key"}, "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval"}, {"name": "countinference", "in": "query", "required": false, "schema": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Countinference"}}, {"name": "service_secret", "in": "query", "required": false, "schema": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Service Secret"}}], "requestBody": {"required": true, "content": {"application/json": {"schema": {"$ref": "#/components/schemas/Sam2EmbeddingRequest"}}}}, "responses": {"200": {"description": "Successful Response", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/Sam3EmbeddingResponse"}}}}, "422": {"description": "Validation Error", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/HTTPValidationError"}}}}}}}, "/sam3/concept_segment": {"post": {"summary": "SAM3 PCS (promptable concept segmentation)", "description": "Run the SAM3 PCS (promptable concept segmentation) to generate segmentations for image data.", "operationId": "sam3_segment_image_sam3_concept_segment_post", "parameters": [{"name": "api_key", "in": "query", "required": false, "schema": {"anyOf": [{"type": "string"}, {"type": "null"}], "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval", "title": "Api Key"}, "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval"}, {"name": "countinference", "in": "query", "required": false, "schema": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Countinference"}}, {"name": "service_secret", "in": "query", "required": false, "schema": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Service Secret"}}], "requestBody": {"required": true, "content": {"application/json": {"schema": {"$ref": "#/components/schemas/Sam3SegmentationRequest"}}}}, "responses": {"200": {"description": "Successful Response", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/Sam3SegmentationResponse"}}}}, "422": {"description": "Validation Error", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/HTTPValidationError"}}}}}}}, "/sam3/visual_segment": {"post": {"summary": "SAM3 PVS (promptable visual segmentation)", "description": "Run the SAM3 PVS (promptable visual segmentation) to generate segmentations for image data.", "operationId": "sam3_visual_segment_sam3_visual_segment_post", "parameters": [{"name": "api_key", "in": "query", "required": false, "schema": {"anyOf": [{"type": "string"}, {"type": "null"}], "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval", "title": "Api Key"}, "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval"}, {"name": "countinference", "in": "query", "required": false, "schema": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Countinference"}}, {"name": "service_secret", "in": "query", "required": false, "schema": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Service Secret"}}], "requestBody": {"required": true, "content": {"application/json": {"schema": {"$ref": "#/components/schemas/Sam2SegmentationRequest"}}}}, "responses": {"200": {"description": "Successful Response", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/Sam2SegmentationResponse"}}}}, "422": {"description": "Validation Error", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/HTTPValidationError"}}}}}}}, "/sam3_3d/infer": {"post": {"summary": "SAM3 3D Object Generation", "description": "Generate 3D meshes and Gaussian splatting from 2D images with mask prompts.", "operationId": "sam3_3d_infer_sam3_3d_infer_post", "parameters": [{"name": "api_key", "in": "query", "required": false, "schema": {"anyOf": [{"type": "string"}, {"type": "null"}], "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval", "title": "Api Key"}, "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval"}, {"name": "countinference", "in": "query", "required": false, "schema": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Countinference"}}, {"name": "service_secret", "in": "query", "required": false, "schema": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Service Secret"}}], "requestBody": {"required": true, "content": {"application/json": {"schema": {"$ref": "#/components/schemas/Sam3_3D_Objects_InferenceRequest"}}}}, "responses": {"200": {"description": "Successful Response", "content": {"application/json": {"schema": {}}}}, "422": {"description": "Validation Error", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/HTTPValidationError"}}}}}}}, "/gaze/gaze_detection": {"post": {"summary": "Gaze Detection", "description": "Run the gaze detection model to detect gaze.", "operationId": "gaze_detection_gaze_gaze_detection_post", "parameters": [{"name": "api_key", "in": "query", "required": false, "schema": {"anyOf": [{"type": "string"}, {"type": "null"}], "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval", "title": "Api Key"}, "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval"}, {"name": "countinference", "in": "query", "required": false, "schema": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Countinference"}}, {"name": "service_secret", "in": "query", "required": false, "schema": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Service Secret"}}], "requestBody": {"required": true, "content": {"application/json": {"schema": {"$ref": "#/components/schemas/GazeDetectionInferenceRequest"}}}}, "responses": {"200": {"description": "Successful Response", "content": {"application/json": {"schema": {"type": "array", "items": {"$ref": "#/components/schemas/GazeDetectionInferenceResponse"}, "title": "Response Gaze Detection Gaze Gaze Detection Post"}}}}, "422": {"description": "Validation Error", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/HTTPValidationError"}}}}}}}, "/infer/depth-estimation": {"post": {"summary": "Depth Estimation", "description": "Run the depth estimation model to generate a depth map.", "operationId": "depth_estimation_infer_depth_estimation_post", "parameters": [{"name": "api_key", "in": "query", "required": false, "schema": {"anyOf": [{"type": "string"}, {"type": "null"}], "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval", "title": "Api Key"}, "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval"}, {"name": "countinference", "in": "query", "required": false, "schema": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Countinference"}}, {"name": "service_secret", "in": "query", "required": false, "schema": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Service Secret"}}], "requestBody": {"required": true, "content": {"application/json": {"schema": {"$ref": "#/components/schemas/DepthEstimationRequest"}}}}, "responses": {"200": {"description": "Successful Response", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/DepthEstimationResponse"}}}}, "422": {"description": "Validation Error", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/HTTPValidationError"}}}}}}}, "/ocr/trocr": {"post": {"summary": "TrOCR OCR response", "description": "Run the TrOCR model to retrieve text in an image.", "operationId": "trocr_retrieve_text_ocr_trocr_post", "parameters": [{"name": "api_key", "in": "query", "required": false, "schema": {"anyOf": [{"type": "string"}, {"type": "null"}], "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval", "title": "Api Key"}, "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval"}, {"name": "countinference", "in": "query", "required": false, "schema": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Countinference"}}, {"name": "service_secret", "in": "query", "required": false, "schema": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Service Secret"}}], "requestBody": {"required": true, "content": {"application/json": {"schema": {"$ref": "#/components/schemas/TrOCRInferenceRequest"}}}}, "responses": {"200": {"description": "Successful Response", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/OCRInferenceResponse"}}}}, "422": {"description": "Validation Error", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/HTTPValidationError"}}}}}}}, "/notebook/start": {"get": {"summary": "Jupyter Lab Server Start", "description": "Starts a jupyter lab server for running development code", "operationId": "notebook_start_notebook_start_get", "parameters": [{"name": "browserless", "in": "query", "required": false, "schema": {"type": "boolean", "default": false, "title": "Browserless"}}], "responses": {"200": {"description": "Successful Response", "content": {"application/json": {"schema": {}}}}, "422": {"description": "Validation Error", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/HTTPValidationError"}}}}}}}, "/{dataset_id}/{version_id}": {"post": {"summary": "Legacy Infer From Request", "description": "Legacy inference endpoint for object detection, instance segmentation, and classification.\n\nArgs:\n    background_tasks: (BackgroundTasks) pool of fastapi background tasks\n    dataset_id (str): ID of a Roboflow dataset corresponding to the model to use for inference OR workspace ID\n    version_id (str): ID of a Roboflow dataset version corresponding to the model to use for inference OR model ID\n    api_key (Optional[str], default None): Roboflow API Key passed to the model during initialization for artifact retrieval.\n    # Other parameters described in the function signature...\n\nReturns:\n    Union[InstanceSegmentationInferenceResponse, KeypointsDetectionInferenceRequest, ObjectDetectionInferenceResponse, ClassificationInferenceResponse, MultiLabelClassificationInferenceResponse, SemanticSegmentationInferenceResponse, Any]: The response containing the inference results.", "operationId": "legacy_infer_from_request__dataset_id___version_id__post", "parameters": [{"name": "dataset_id", "in": "path", "required": true, "schema": {"type": "string", "description": "ID of a Roboflow dataset corresponding to the model to use for inference OR workspace ID", "title": "Dataset Id"}, "description": "ID of a Roboflow dataset corresponding to the model to use for inference OR workspace ID"}, {"name": "version_id", "in": "path", "required": true, "schema": {"type": "string", "description": "ID of a Roboflow dataset version corresponding to the model to use for inference OR model ID", "title": "Version Id"}, "description": "ID of a Roboflow dataset version corresponding to the model to use for inference OR model ID"}, {"name": "api_key", "in": "query", "required": false, "schema": {"anyOf": [{"type": "string"}, {"type": "null"}], "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval", "title": "Api Key"}, "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval"}, {"name": "confidence", "in": "query", "required": false, "schema": {"type": "number", "description": "The confidence threshold used to filter out predictions", "default": 0.4, "title": "Confidence"}, "description": "The confidence threshold used to filter out predictions"}, {"name": "keypoint_confidence", "in": "query", "required": false, "schema": {"type": "number", "description": "The confidence threshold used to filter out keypoints that are not visible based on model confidence", "default": 0.0, "title": "Keypoint Confidence"}, "description": "The confidence threshold used to filter out keypoints that are not visible based on model confidence"}, {"name": "format", "in": "query", "required": false, "schema": {"type": "string", "description": "One of 'json' or 'image'. If 'json' prediction data is return as a JSON string. If 'image' prediction data is visualized and overlayed on the original input image.", "default": "json", "title": "Format"}, "description": "One of 'json' or 'image'. If 'json' prediction data is return as a JSON string. If 'image' prediction data is visualized and overlayed on the original input image."}, {"name": "image", "in": "query", "required": false, "schema": {"anyOf": [{"type": "string"}, {"type": "null"}], "description": "The publically accessible URL of an image to use for inference.", "title": "Image"}, "description": "The publically accessible URL of an image to use for inference."}, {"name": "image_type", "in": "query", "required": false, "schema": {"anyOf": [{"type": "string"}, {"type": "null"}], "description": "One of base64 or numpy. Note, numpy input is not supported for Roboflow Hosted Inference.", "default": "base64", "title": "Image Type"}, "description": "One of base64 or numpy. Note, numpy input is not supported for Roboflow Hosted Inference."}, {"name": "labels", "in": "query", "required": false, "schema": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "description": "If true, labels will be include in any inference visualization.", "default": false, "title": "Labels"}, "description": "If true, labels will be include in any inference visualization."}, {"name": "mask_decode_mode", "in": "query", "required": false, "schema": {"anyOf": [{"type": "string"}, {"type": "null"}], "description": "One of 'accurate' or 'fast'. If 'accurate' the mask will be decoded using the original image size. If 'fast' the mask will be decoded using the original mask size. 'accurate' is slower but more accurate.", "default": "accurate", "title": "Mask Decode Mode"}, "description": "One of 'accurate' or 'fast'. If 'accurate' the mask will be decoded using the original image size. If 'fast' the mask will be decoded using the original mask size. 'accurate' is slower but more accurate."}, {"name": "tradeoff_factor", "in": "query", "required": false, "schema": {"anyOf": [{"type": "number"}, {"type": "null"}], "description": "The amount to tradeoff between 0='fast' and 1='accurate'", "default": 0.0, "title": "Tradeoff Factor"}, "description": "The amount to tradeoff between 0='fast' and 1='accurate'"}, {"name": "max_detections", "in": "query", "required": false, "schema": {"type": "integer", "description": "The maximum number of detections to return. This is used to limit the number of predictions returned by the model. The model may return more predictions than this number, but only the top `max_detections` predictions will be returned.", "default": 300, "title": "Max Detections"}, "description": "The maximum number of detections to return. This is used to limit the number of predictions returned by the model. The model may return more predictions than this number, but only the top `max_detections` predictions will be returned."}, {"name": "overlap", "in": "query", "required": false, "schema": {"type": "number", "description": "The IoU threhsold that must be met for a box pair to be considered duplicate during NMS", "default": 0.3, "title": "Overlap"}, "description": "The IoU threhsold that must be met for a box pair to be considered duplicate during NMS"}, {"name": "stroke", "in": "query", "required": false, "schema": {"type": "integer", "description": "The stroke width used when visualizing predictions", "default": 1, "title": "Stroke"}, "description": "The stroke width used when visualizing predictions"}, {"name": "disable_preproc_auto_orient", "in": "query", "required": false, "schema": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "description": "If true, disables automatic image orientation", "default": false, "title": "Disable Preproc Auto Orient"}, "description": "If true, disables automatic image orientation"}, {"name": "disable_preproc_contrast", "in": "query", "required": false, "schema": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "description": "If true, disables automatic contrast adjustment", "default": false, "title": "Disable Preproc Contrast"}, "description": "If true, disables automatic contrast adjustment"}, {"name": "disable_preproc_grayscale", "in": "query", "required": false, "schema": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "description": "If true, disables automatic grayscale conversion", "default": false, "title": "Disable Preproc Grayscale"}, "description": "If true, disables automatic grayscale conversion"}, {"name": "disable_preproc_static_crop", "in": "query", "required": false, "schema": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "description": "If true, disables automatic static crop", "default": false, "title": "Disable Preproc Static Crop"}, "description": "If true, disables automatic static crop"}, {"name": "disable_active_learning", "in": "query", "required": false, "schema": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "description": "If true, the predictions will be prevented from registration by Active Learning (if the functionality is enabled)", "default": false, "title": "Disable Active Learning"}, "description": "If true, the predictions will be prevented from registration by Active Learning (if the functionality is enabled)"}, {"name": "active_learning_target_dataset", "in": "query", "required": false, "schema": {"anyOf": [{"type": "string"}, {"type": "null"}], "description": "Parameter to be used when Active Learning data registration should happen against different dataset than the one pointed by model_id", "title": "Active Learning Target Dataset"}, "description": "Parameter to be used when Active Learning data registration should happen against different dataset than the one pointed by model_id"}, {"name": "source", "in": "query", "required": false, "schema": {"anyOf": [{"type": "string"}, {"type": "null"}], "description": "The source of the inference request", "default": "external", "title": "Source"}, "description": "The source of the inference request"}, {"name": "source_info", "in": "query", "required": false, "schema": {"anyOf": [{"type": "string"}, {"type": "null"}], "description": "The detailed source information of the inference request", "default": "external", "title": "Source Info"}, "description": "The detailed source information of the inference request"}], "responses": {"200": {"description": "Successful Response", "content": {"application/json": {"schema": {"anyOf": [{"$ref": "#/components/schemas/InstanceSegmentationInferenceResponse"}, {"$ref": "#/components/schemas/KeypointsDetectionInferenceResponse"}, {"$ref": "#/components/schemas/ObjectDetectionInferenceResponse"}, {"$ref": "#/components/schemas/ClassificationInferenceResponse"}, {"$ref": "#/components/schemas/MultiLabelClassificationInferenceResponse"}, {"$ref": "#/components/schemas/SemanticSegmentationInferenceResponse"}, {"$ref": "#/components/schemas/StubResponse"}, {}], "title": "Response Legacy Infer From Request  Dataset Id   Version Id  Post"}}}}, "422": {"description": "Validation Error", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/HTTPValidationError"}}}}}}, "get": {"summary": "Legacy Infer From Request", "description": "Legacy inference endpoint for object detection, instance segmentation, and classification.\n\nArgs:\n    background_tasks: (BackgroundTasks) pool of fastapi background tasks\n    dataset_id (str): ID of a Roboflow dataset corresponding to the model to use for inference OR workspace ID\n    version_id (str): ID of a Roboflow dataset version corresponding to the model to use for inference OR model ID\n    api_key (Optional[str], default None): Roboflow API Key passed to the model during initialization for artifact retrieval.\n    # Other parameters described in the function signature...\n\nReturns:\n    Union[InstanceSegmentationInferenceResponse, KeypointsDetectionInferenceRequest, ObjectDetectionInferenceResponse, ClassificationInferenceResponse, MultiLabelClassificationInferenceResponse, SemanticSegmentationInferenceResponse, Any]: The response containing the inference results.", "operationId": "legacy_infer_from_request__dataset_id___version_id__get", "parameters": [{"name": "dataset_id", "in": "path", "required": true, "schema": {"type": "string", "description": "ID of a Roboflow dataset corresponding to the model to use for inference OR workspace ID", "title": "Dataset Id"}, "description": "ID of a Roboflow dataset corresponding to the model to use for inference OR workspace ID"}, {"name": "version_id", "in": "path", "required": true, "schema": {"type": "string", "description": "ID of a Roboflow dataset version corresponding to the model to use for inference OR model ID", "title": "Version Id"}, "description": "ID of a Roboflow dataset version corresponding to the model to use for inference OR model ID"}, {"name": "api_key", "in": "query", "required": false, "schema": {"anyOf": [{"type": "string"}, {"type": "null"}], "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval", "title": "Api Key"}, "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval"}, {"name": "confidence", "in": "query", "required": false, "schema": {"type": "number", "description": "The confidence threshold used to filter out predictions", "default": 0.4, "title": "Confidence"}, "description": "The confidence threshold used to filter out predictions"}, {"name": "keypoint_confidence", "in": "query", "required": false, "schema": {"type": "number", "description": "The confidence threshold used to filter out keypoints that are not visible based on model confidence", "default": 0.0, "title": "Keypoint Confidence"}, "description": "The confidence threshold used to filter out keypoints that are not visible based on model confidence"}, {"name": "format", "in": "query", "required": false, "schema": {"type": "string", "description": "One of 'json' or 'image'. If 'json' prediction data is return as a JSON string. If 'image' prediction data is visualized and overlayed on the original input image.", "default": "json", "title": "Format"}, "description": "One of 'json' or 'image'. If 'json' prediction data is return as a JSON string. If 'image' prediction data is visualized and overlayed on the original input image."}, {"name": "image", "in": "query", "required": false, "schema": {"anyOf": [{"type": "string"}, {"type": "null"}], "description": "The publically accessible URL of an image to use for inference.", "title": "Image"}, "description": "The publically accessible URL of an image to use for inference."}, {"name": "image_type", "in": "query", "required": false, "schema": {"anyOf": [{"type": "string"}, {"type": "null"}], "description": "One of base64 or numpy. Note, numpy input is not supported for Roboflow Hosted Inference.", "default": "base64", "title": "Image Type"}, "description": "One of base64 or numpy. Note, numpy input is not supported for Roboflow Hosted Inference."}, {"name": "labels", "in": "query", "required": false, "schema": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "description": "If true, labels will be include in any inference visualization.", "default": false, "title": "Labels"}, "description": "If true, labels will be include in any inference visualization."}, {"name": "mask_decode_mode", "in": "query", "required": false, "schema": {"anyOf": [{"type": "string"}, {"type": "null"}], "description": "One of 'accurate' or 'fast'. If 'accurate' the mask will be decoded using the original image size. If 'fast' the mask will be decoded using the original mask size. 'accurate' is slower but more accurate.", "default": "accurate", "title": "Mask Decode Mode"}, "description": "One of 'accurate' or 'fast'. If 'accurate' the mask will be decoded using the original image size. If 'fast' the mask will be decoded using the original mask size. 'accurate' is slower but more accurate."}, {"name": "tradeoff_factor", "in": "query", "required": false, "schema": {"anyOf": [{"type": "number"}, {"type": "null"}], "description": "The amount to tradeoff between 0='fast' and 1='accurate'", "default": 0.0, "title": "Tradeoff Factor"}, "description": "The amount to tradeoff between 0='fast' and 1='accurate'"}, {"name": "max_detections", "in": "query", "required": false, "schema": {"type": "integer", "description": "The maximum number of detections to return. This is used to limit the number of predictions returned by the model. The model may return more predictions than this number, but only the top `max_detections` predictions will be returned.", "default": 300, "title": "Max Detections"}, "description": "The maximum number of detections to return. This is used to limit the number of predictions returned by the model. The model may return more predictions than this number, but only the top `max_detections` predictions will be returned."}, {"name": "overlap", "in": "query", "required": false, "schema": {"type": "number", "description": "The IoU threhsold that must be met for a box pair to be considered duplicate during NMS", "default": 0.3, "title": "Overlap"}, "description": "The IoU threhsold that must be met for a box pair to be considered duplicate during NMS"}, {"name": "stroke", "in": "query", "required": false, "schema": {"type": "integer", "description": "The stroke width used when visualizing predictions", "default": 1, "title": "Stroke"}, "description": "The stroke width used when visualizing predictions"}, {"name": "disable_preproc_auto_orient", "in": "query", "required": false, "schema": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "description": "If true, disables automatic image orientation", "default": false, "title": "Disable Preproc Auto Orient"}, "description": "If true, disables automatic image orientation"}, {"name": "disable_preproc_contrast", "in": "query", "required": false, "schema": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "description": "If true, disables automatic contrast adjustment", "default": false, "title": "Disable Preproc Contrast"}, "description": "If true, disables automatic contrast adjustment"}, {"name": "disable_preproc_grayscale", "in": "query", "required": false, "schema": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "description": "If true, disables automatic grayscale conversion", "default": false, "title": "Disable Preproc Grayscale"}, "description": "If true, disables automatic grayscale conversion"}, {"name": "disable_preproc_static_crop", "in": "query", "required": false, "schema": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "description": "If true, disables automatic static crop", "default": false, "title": "Disable Preproc Static Crop"}, "description": "If true, disables automatic static crop"}, {"name": "disable_active_learning", "in": "query", "required": false, "schema": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "description": "If true, the predictions will be prevented from registration by Active Learning (if the functionality is enabled)", "default": false, "title": "Disable Active Learning"}, "description": "If true, the predictions will be prevented from registration by Active Learning (if the functionality is enabled)"}, {"name": "active_learning_target_dataset", "in": "query", "required": false, "schema": {"anyOf": [{"type": "string"}, {"type": "null"}], "description": "Parameter to be used when Active Learning data registration should happen against different dataset than the one pointed by model_id", "title": "Active Learning Target Dataset"}, "description": "Parameter to be used when Active Learning data registration should happen against different dataset than the one pointed by model_id"}, {"name": "source", "in": "query", "required": false, "schema": {"anyOf": [{"type": "string"}, {"type": "null"}], "description": "The source of the inference request", "default": "external", "title": "Source"}, "description": "The source of the inference request"}, {"name": "source_info", "in": "query", "required": false, "schema": {"anyOf": [{"type": "string"}, {"type": "null"}], "description": "The detailed source information of the inference request", "default": "external", "title": "Source Info"}, "description": "The detailed source information of the inference request"}], "responses": {"200": {"description": "Successful Response", "content": {"application/json": {"schema": {"anyOf": [{"$ref": "#/components/schemas/InstanceSegmentationInferenceResponse"}, {"$ref": "#/components/schemas/KeypointsDetectionInferenceResponse"}, {"$ref": "#/components/schemas/ObjectDetectionInferenceResponse"}, {"$ref": "#/components/schemas/ClassificationInferenceResponse"}, {"$ref": "#/components/schemas/MultiLabelClassificationInferenceResponse"}, {"$ref": "#/components/schemas/SemanticSegmentationInferenceResponse"}, {"$ref": "#/components/schemas/StubResponse"}, {}], "title": "Response Legacy Infer From Request  Dataset Id   Version Id  Get"}}}}, "422": {"description": "Validation Error", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/HTTPValidationError"}}}}}}}, "/clear_cache": {"get": {"summary": "Legacy Clear Cache", "description": "Clears the model cache.\n\nThis endpoint provides a way to clear the cache of loaded models.\n\nReturns:\n    str: A string indicating that the cache has been cleared.", "operationId": "legacy_clear_cache_clear_cache_get", "responses": {"200": {"description": "Successful Response", "content": {"application/json": {"schema": {"type": "string", "title": "Response Legacy Clear Cache Clear Cache Get"}}}}}}}, "/start/{dataset_id}/{version_id}": {"get": {"summary": "Model Add Legacy", "description": "Starts a model inference session.\n\nThis endpoint initializes and starts an inference session for the specified model version.\n\nArgs:\n    dataset_id (str): ID of a Roboflow dataset corresponding to the model.\n    version_id (str): ID of a Roboflow dataset version corresponding to the model.\n    api_key (str, optional): Roboflow API Key for artifact retrieval.\n    countinference (Optional[bool]): Whether to count inference or not.\n    service_secret (Optional[str]): The service secret for the request.\n\nReturns:\n    JSONResponse: A response object containing the status and a success message.", "operationId": "model_add_legacy_start__dataset_id___version_id__get", "parameters": [{"name": "dataset_id", "in": "path", "required": true, "schema": {"type": "string", "title": "Dataset Id"}}, {"name": "version_id", "in": "path", "required": true, "schema": {"type": "string", "title": "Version Id"}}, {"name": "api_key", "in": "query", "required": false, "schema": {"type": "string", "title": "Api Key"}}, {"name": "countinference", "in": "query", "required": false, "schema": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Countinference"}}, {"name": "service_secret", "in": "query", "required": false, "schema": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Service Secret"}}], "responses": {"200": {"description": "Successful Response", "content": {"application/json": {"schema": {}}}}, "422": {"description": "Validation Error", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/HTTPValidationError"}}}}}}}, "/dashboard.html": {"get": {"summary": "Dashboard Guard", "operationId": "dashboard_guard_dashboard_html_get", "responses": {"200": {"description": "Successful Response", "content": {"application/json": {"schema": {}}}}}}, "head": {"summary": "Dashboard Guard", "operationId": "dashboard_guard_dashboard_html_head", "responses": {"200": {"description": "Successful Response", "content": {"application/json": {"schema": {}}}}}}}}, "components": {"schemas": {"AddModelRequest": {"properties": {"model_id": {"type": "string", "title": "Model Id", "description": "A unique model identifier", "example": "raccoon-detector-1"}, "model_type": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Model Type", "description": "The type of the model, usually referring to what task the model performs", "examples": ["object-detection"]}, "api_key": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Api Key", "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval"}}, "type": "object", "required": ["model_id"], "title": "AddModelRequest", "description": "Request to add a model to the inference server.\n\nAttributes:\n    model_id (str): A unique model identifier.\n    model_type (Optional[str]): The type of the model, usually referring to what task the model performs.\n    api_key (Optional[str]): Roboflow API Key that will be passed to the model during initialization for artifact retrieval."}, "BlockDescription": {"properties": {"block_schema": {"additionalProperties": true, "type": "object", "title": "Block Schema", "description": "OpenAPI specification of block manifest that can be used to create workflow step in JSON definition."}, "outputs_manifest": {"items": {"$ref": "#/components/schemas/OutputDefinition"}, "type": "array", "title": "Outputs Manifest", "description": "Definition of step outputs and their kinds"}, "block_source": {"type": "string", "title": "Block Source", "description": "Name of source plugin that defines block"}, "fully_qualified_block_class_name": {"type": "string", "title": "Fully Qualified Block Class Name", "description": "Fully qualified class name of block implementation."}, "human_friendly_block_name": {"type": "string", "title": "Human Friendly Block Name", "description": "Field generated based on class name providing human-friendly name of the block."}, "manifest_type_identifier": {"type": "string", "title": "Manifest Type Identifier", "description": "Field holds value that is used to recognise block manifest while parsing `workflow` JSON definition."}, "manifest_type_identifier_aliases": {"items": {"type": "string"}, "type": "array", "title": "Manifest Type Identifier Aliases", "description": "Aliases of `manifest_type_identifier` that are in use."}, "execution_engine_compatibility": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Execution Engine Compatibility", "description": "Execution Engine versions compatible with block."}, "input_dimensionality_offsets": {"additionalProperties": {"type": "integer"}, "type": "object", "title": "Input Dimensionality Offsets", "description": "Dimensionality offsets for input parameters"}, "dimensionality_reference_property": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Dimensionality Reference Property", "description": "Selected dimensionality reference property provided if different dimensionality for different inputs are supported."}, "output_dimensionality_offset": {"type": "integer", "title": "Output Dimensionality Offset", "description": "Dimensionality offset for block output."}}, "type": "object", "required": ["block_schema", "outputs_manifest", "block_source", "fully_qualified_block_class_name", "human_friendly_block_name", "manifest_type_identifier", "input_dimensionality_offsets", "dimensionality_reference_property", "output_dimensionality_offset"], "title": "BlockDescription"}, "Box": {"properties": {"x": {"type": "number", "title": "X"}, "y": {"type": "number", "title": "Y"}, "width": {"type": "number", "title": "Width"}, "height": {"type": "number", "title": "Height"}}, "type": "object", "required": ["x", "y", "width", "height"], "title": "Box"}, "BoxXYXY": {"properties": {"x0": {"type": "number", "title": "X0"}, "y0": {"type": "number", "title": "Y0"}, "x1": {"type": "number", "title": "X1"}, "y1": {"type": "number", "title": "Y1"}}, "type": "object", "required": ["x0", "y0", "x1", "y1"], "title": "BoxXYXY"}, "ClassificationInferenceRequest": {"properties": {"id": {"type": "string", "title": "Id"}, "api_key": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Api Key", "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval"}, "usage_billable": {"type": "boolean", "title": "Usage Billable", "default": true}, "start": {"anyOf": [{"type": "number"}, {"type": "null"}], "title": "Start"}, "source": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Source"}, "source_info": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Source Info"}, "disable_model_monitoring": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Disable Model Monitoring", "description": "If true, disables model monitoring for this request", "default": false}, "model_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Model Id", "description": "A unique model identifier", "example": "raccoon-detector-1"}, "model_type": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Model Type", "description": "The type of the model, usually referring to what task the model performs", "examples": ["object-detection"]}, "image": {"anyOf": [{"items": {"$ref": "#/components/schemas/InferenceRequestImage"}, "type": "array"}, {"$ref": "#/components/schemas/InferenceRequestImage"}], "title": "Image"}, "disable_preproc_auto_orient": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Disable Preproc Auto Orient", "description": "If true, the auto orient preprocessing step is disabled for this call.", "default": false}, "disable_preproc_contrast": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Disable Preproc Contrast", "description": "If true, the auto contrast preprocessing step is disabled for this call.", "default": false}, "disable_preproc_grayscale": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Disable Preproc Grayscale", "description": "If true, the grayscale preprocessing step is disabled for this call.", "default": false}, "disable_preproc_static_crop": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Disable Preproc Static Crop", "description": "If true, the static crop preprocessing step is disabled for this call.", "default": false}, "confidence": {"anyOf": [{"type": "number"}, {"type": "null"}], "title": "Confidence", "description": "The confidence threshold used to filter out predictions", "default": 0.4, "examples": [0.5]}, "visualization_stroke_width": {"anyOf": [{"type": "integer"}, {"type": "null"}], "title": "Visualization Stroke Width", "description": "The stroke width used when visualizing predictions", "default": 1, "examples": [1]}, "visualize_predictions": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Visualize Predictions", "description": "If true, the predictions will be drawn on the original image and returned as a base64 string", "default": false, "examples": [false]}, "disable_active_learning": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Disable Active Learning", "description": "If true, the predictions will be prevented from registration by Active Learning (if the functionality is enabled)", "default": false, "examples": [false]}, "active_learning_target_dataset": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Active Learning Target Dataset", "description": "Parameter to be used when Active Learning data registration should happen against different dataset than the one pointed by model_id", "examples": ["my_dataset"]}}, "type": "object", "required": ["id", "model_id", "image"], "title": "ClassificationInferenceRequest", "description": "Classification inference request.\n\nAttributes:\n    confidence (Optional[float]): The confidence threshold used to filter out predictions.\n    visualization_stroke_width (Optional[int]): The stroke width used when visualizing predictions.\n    visualize_predictions (Optional[bool]): If true, the predictions will be drawn on the original image and returned as a base64 string."}, "ClassificationInferenceResponse": {"properties": {"visualization": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Visualization", "description": "Base64 encoded string containing prediction visualization image data"}, "inference_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Inference Id", "description": "Unique identifier of inference"}, "frame_id": {"anyOf": [{"type": "integer"}, {"type": "null"}], "title": "Frame Id", "description": "The frame id of the image used in inference if the input was a video"}, "time": {"anyOf": [{"type": "number"}, {"type": "null"}], "title": "Time", "description": "The time in seconds it took to produce the predictions including image preprocessing"}, "image": {"anyOf": [{"items": {"$ref": "#/components/schemas/InferenceResponseImage"}, "type": "array"}, {"$ref": "#/components/schemas/InferenceResponseImage"}], "title": "Image"}, "predictions": {"items": {"$ref": "#/components/schemas/ClassificationPrediction"}, "type": "array", "title": "Predictions"}, "top": {"type": "string", "title": "Top", "description": "The top predicted class label", "default": ""}, "confidence": {"type": "number", "title": "Confidence", "description": "The confidence of the top predicted class label", "default": 0.0}, "parent_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Parent Id", "description": "Identifier of parent image region. Useful when stack of detection-models is in use to refer the RoI being the input to inference"}}, "type": "object", "required": ["image", "predictions"], "title": "ClassificationInferenceResponse", "description": "Classification inference response.\n\nAttributes:\n    predictions (List[inference.core.entities.responses.inference.ClassificationPrediction]): List of classification predictions.\n    top (str): The top predicted class label.\n    confidence (float): The confidence of the top predicted class label."}, "ClassificationPrediction": {"properties": {"class": {"type": "string", "title": "Class", "description": "The predicted class label"}, "class_id": {"type": "integer", "title": "Class Id", "description": "Numeric ID associated with the class label"}, "confidence": {"type": "number", "title": "Confidence", "description": "The class label confidence as a fraction between 0 and 1"}}, "type": "object", "required": ["class", "class_id", "confidence"], "title": "ClassificationPrediction", "description": "Classification prediction.\n\nAttributes:\n    class_name (str): The predicted class label.\n    class_id (int): Numeric ID associated with the class label.\n    confidence (float): The class label confidence as a fraction between 0 and 1."}, "ClearModelRequest": {"properties": {"model_id": {"type": "string", "title": "Model Id", "description": "A unique model identifier", "example": "raccoon-detector-1"}}, "type": "object", "required": ["model_id"], "title": "ClearModelRequest", "description": "Request to clear a model from the inference server.\n\nAttributes:\n    model_id (str): A unique model identifier."}, "ClipCompareRequest": {"properties": {"id": {"type": "string", "title": "Id"}, "api_key": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Api Key", "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval"}, "usage_billable": {"type": "boolean", "title": "Usage Billable", "default": true}, "start": {"anyOf": [{"type": "number"}, {"type": "null"}], "title": "Start"}, "source": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Source"}, "source_info": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Source Info"}, "disable_model_monitoring": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Disable Model Monitoring", "description": "If true, disables model monitoring for this request", "default": false}, "clip_version_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Clip Version Id", "description": "The version ID of CLIP to be used for this request. Must be one of RN101, RN50, RN50x16, RN50x4, RN50x64, ViT-B-16, ViT-B-32, ViT-L-14-336px, and ViT-L-14.", "default": "ViT-B-16", "examples": ["ViT-B-16"]}, "model_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Model Id"}, "subject": {"anyOf": [{"$ref": "#/components/schemas/InferenceRequestImage"}, {"type": "string"}], "title": "Subject", "description": "The type of image data provided, one of 'url' or 'base64'", "examples": ["url"]}, "subject_type": {"type": "string", "title": "Subject Type", "description": "The type of subject, one of 'image' or 'text'", "default": "image", "examples": ["image"]}, "prompt": {"anyOf": [{"items": {"$ref": "#/components/schemas/InferenceRequestImage"}, "type": "array"}, {"$ref": "#/components/schemas/InferenceRequestImage"}, {"type": "string"}, {"items": {"type": "string"}, "type": "array"}, {"additionalProperties": {"anyOf": [{"$ref": "#/components/schemas/InferenceRequestImage"}, {"type": "string"}]}, "type": "object"}], "title": "Prompt"}, "prompt_type": {"type": "string", "title": "Prompt Type", "description": "The type of prompt, one of 'image' or 'text'", "default": "text", "examples": ["text"]}}, "type": "object", "required": ["id", "subject", "prompt"], "title": "ClipCompareRequest", "description": "Request for CLIP comparison.\n\nAttributes:\n    subject (Union[InferenceRequestImage, str]): The type of image data provided, one of 'url' or 'base64'.\n    subject_type (str): The type of subject, one of 'image' or 'text'.\n    prompt (Union[List[InferenceRequestImage], InferenceRequestImage, str, List[str], Dict[str, Union[InferenceRequestImage, str]]]): The prompt for comparison.\n    prompt_type (str): The type of prompt, one of 'image' or 'text'."}, "ClipCompareResponse": {"properties": {"inference_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Inference Id", "description": "Unique identifier of inference"}, "frame_id": {"anyOf": [{"type": "integer"}, {"type": "null"}], "title": "Frame Id", "description": "The frame id of the image used in inference if the input was a video"}, "time": {"anyOf": [{"type": "number"}, {"type": "null"}], "title": "Time", "description": "The time in seconds it took to produce the similarity scores including preprocessing"}, "similarity": {"anyOf": [{"items": {"type": "number"}, "type": "array"}, {"additionalProperties": {"type": "number"}, "type": "object"}], "title": "Similarity"}, "parent_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Parent Id", "description": "Identifier of parent image region. Useful when stack of detection-models is in use to refer the RoI being the input to inference"}}, "type": "object", "required": ["similarity"], "title": "ClipCompareResponse", "description": "Response for CLIP comparison.\n\nAttributes:\n    similarity (Union[List[float], Dict[str, float]]): Similarity scores.\n    time (float): The time in seconds it took to produce the similarity scores including preprocessing."}, "ClipEmbeddingResponse": {"properties": {"inference_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Inference Id", "description": "Unique identifier of inference"}, "frame_id": {"anyOf": [{"type": "integer"}, {"type": "null"}], "title": "Frame Id", "description": "The frame id of the image used in inference if the input was a video"}, "time": {"anyOf": [{"type": "number"}, {"type": "null"}], "title": "Time", "description": "The time in seconds it took to produce the embeddings including preprocessing"}, "embeddings": {"items": {"items": {"type": "number"}, "type": "array"}, "type": "array", "title": "Embeddings", "description": "A list of embeddings, each embedding is a list of floats", "examples": ["[[0.12, 0.23, 0.34, ..., 0.43]]"]}}, "type": "object", "required": ["embeddings"], "title": "ClipEmbeddingResponse", "description": "Response for CLIP embedding.\n\nAttributes:\n    embeddings (List[List[float]]): A list of embeddings, each embedding is a list of floats.\n    time (float): The time in seconds it took to produce the embeddings including preprocessing."}, "ClipImageEmbeddingRequest": {"properties": {"id": {"type": "string", "title": "Id"}, "api_key": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Api Key", "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval"}, "usage_billable": {"type": "boolean", "title": "Usage Billable", "default": true}, "start": {"anyOf": [{"type": "number"}, {"type": "null"}], "title": "Start"}, "source": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Source"}, "source_info": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Source Info"}, "disable_model_monitoring": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Disable Model Monitoring", "description": "If true, disables model monitoring for this request", "default": false}, "clip_version_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Clip Version Id", "description": "The version ID of CLIP to be used for this request. Must be one of RN101, RN50, RN50x16, RN50x4, RN50x64, ViT-B-16, ViT-B-32, ViT-L-14-336px, and ViT-L-14.", "default": "ViT-B-16", "examples": ["ViT-B-16"]}, "model_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Model Id"}, "image": {"anyOf": [{"items": {"$ref": "#/components/schemas/InferenceRequestImage"}, "type": "array"}, {"$ref": "#/components/schemas/InferenceRequestImage"}], "title": "Image"}}, "type": "object", "required": ["id", "image"], "title": "ClipImageEmbeddingRequest", "description": "Request for CLIP image embedding.\n\nAttributes:\n    image (Union[List[InferenceRequestImage], InferenceRequestImage]): Image(s) to be embedded."}, "ClipTextEmbeddingRequest": {"properties": {"id": {"type": "string", "title": "Id"}, "api_key": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Api Key", "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval"}, "usage_billable": {"type": "boolean", "title": "Usage Billable", "default": true}, "start": {"anyOf": [{"type": "number"}, {"type": "null"}], "title": "Start"}, "source": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Source"}, "source_info": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Source Info"}, "disable_model_monitoring": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Disable Model Monitoring", "description": "If true, disables model monitoring for this request", "default": false}, "clip_version_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Clip Version Id", "description": "The version ID of CLIP to be used for this request. Must be one of RN101, RN50, RN50x16, RN50x4, RN50x64, ViT-B-16, ViT-B-32, ViT-L-14-336px, and ViT-L-14.", "default": "ViT-B-16", "examples": ["ViT-B-16"]}, "model_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Model Id"}, "text": {"anyOf": [{"items": {"type": "string"}, "type": "array"}, {"type": "string"}], "title": "Text", "description": "A string or list of strings", "examples": ["The quick brown fox jumps over the lazy dog"]}}, "type": "object", "required": ["id", "text"], "title": "ClipTextEmbeddingRequest", "description": "Request for CLIP text embedding.\n\nAttributes:\n    text (Union[List[str], str]): A string or list of strings."}, "CommandContext": {"properties": {"request_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Request Id", "description": "Server-side request ID"}, "pipeline_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Pipeline Id", "description": "Identifier of pipeline connected to operation"}}, "type": "object", "title": "CommandContext"}, "DepthEstimationRequest": {"properties": {"id": {"type": "string", "title": "Id"}, "api_key": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Api Key", "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval"}, "usage_billable": {"type": "boolean", "title": "Usage Billable", "default": true}, "start": {"anyOf": [{"type": "number"}, {"type": "null"}], "title": "Start"}, "source": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Source"}, "source_info": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Source Info"}, "disable_model_monitoring": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Disable Model Monitoring", "description": "If true, disables model monitoring for this request", "default": false}, "model_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Model Id"}, "model_type": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Model Type", "description": "The type of the model, usually referring to what task the model performs", "examples": ["object-detection"]}, "image": {"anyOf": [{"items": {"$ref": "#/components/schemas/InferenceRequestImage"}, "type": "array"}, {"$ref": "#/components/schemas/InferenceRequestImage"}], "title": "Image"}, "depth_version_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Depth Version Id", "description": "The version ID of the depth estimation model", "default": "small", "examples": ["small"]}}, "type": "object", "required": ["id", "image"], "title": "DepthEstimationRequest", "description": "Request for depth estimation.\n\nAttributes:\n    image (Union[List[InferenceRequestImage], InferenceRequestImage]): Image(s) to be estimated.\n    model_id (str): The model ID to use for depth estimation.\n    depth_version_id (Optional[str]): The version ID of the depth estimation model."}, "DepthEstimationResponse": {"properties": {"normalized_depth": {"items": {"items": {"type": "number"}, "type": "array"}, "type": "array", "title": "Normalized Depth", "description": "The normalized depth map as a 2D array of floats between 0 and 1"}, "image": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Image", "description": "Base64 encoded visualization of the depth map if visualize_predictions is True"}}, "type": "object", "required": ["normalized_depth"], "title": "DepthEstimationResponse", "description": "Response for depth estimation inference.\n\nAttributes:\n    normalized_depth (List[List[float]]): The normalized depth map as a 2D array of floats between 0 and 1.\n    image (Optional[str]): Base64 encoded visualization of the depth map if visualize_predictions is True.\n    time (float): The processing time in seconds.\n    visualization (Optional[str]): Base64 encoded visualization of the depth map if visualize_predictions is True."}, "DescribeBlocksRequest": {"properties": {"api_key": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Api Key", "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval"}, "dynamic_blocks_definitions": {"items": {"$ref": "#/components/schemas/DynamicBlockDefinition"}, "type": "array", "title": "Dynamic Blocks Definitions", "description": "Dynamic blocks to be used."}, "execution_engine_version": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Execution Engine Version", "description": "Requested Execution Engine compatibility. If given, result will only contain blocks suitable for requested EE version, otherwise - descriptions for all available blocks will be delivered."}}, "type": "object", "title": "DescribeBlocksRequest"}, "DescribeInterfaceResponse": {"properties": {"inputs": {"additionalProperties": {"items": {"type": "string"}, "type": "array"}, "type": "object", "title": "Inputs", "description": "Dictionary mapping Workflow inputs to their kinds"}, "outputs": {"additionalProperties": {"anyOf": [{"items": {"type": "string"}, "type": "array"}, {"additionalProperties": {"items": {"type": "string"}, "type": "array"}, "type": "object"}]}, "type": "object", "title": "Outputs", "description": "Dictionary mapping Workflow outputs to their kinds"}, "typing_hints": {"additionalProperties": {"type": "string"}, "type": "object", "title": "Typing Hints", "description": "Dictionary mapping name of the kind with Python typing hint for underlying serialised object"}, "kinds_schemas": {"additionalProperties": {"anyOf": [{"additionalProperties": true, "type": "object"}, {"items": {"additionalProperties": true, "type": "object"}, "type": "array"}]}, "type": "object", "title": "Kinds Schemas", "description": "Dictionary mapping name of the kind with OpenAPI 3.0 definitions of underlying objects. If list is given, entity should be treated as union of types."}}, "type": "object", "required": ["inputs", "outputs", "typing_hints", "kinds_schemas"], "title": "DescribeInterfaceResponse"}, "DoctrOCRInferenceRequest": {"properties": {"id": {"type": "string", "title": "Id"}, "api_key": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Api Key", "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval"}, "usage_billable": {"type": "boolean", "title": "Usage Billable", "default": true}, "start": {"anyOf": [{"type": "number"}, {"type": "null"}], "title": "Start"}, "source": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Source"}, "source_info": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Source Info"}, "disable_model_monitoring": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Disable Model Monitoring", "description": "If true, disables model monitoring for this request", "default": false}, "image": {"anyOf": [{"items": {"$ref": "#/components/schemas/InferenceRequestImage"}, "type": "array"}, {"$ref": "#/components/schemas/InferenceRequestImage"}], "title": "Image"}, "doctr_version_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Doctr Version Id", "default": "default"}, "model_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Model Id"}, "generate_bounding_boxes": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Generate Bounding Boxes", "default": false}}, "type": "object", "required": ["id", "image"], "title": "DoctrOCRInferenceRequest", "description": "DocTR inference request.\n\nAttributes:\n    api_key (Optional[str]): Roboflow API Key."}, "DynamicBlockDefinition": {"properties": {"type": {"type": "string", "const": "DynamicBlockDefinition", "title": "Type"}, "manifest": {"$ref": "#/components/schemas/ManifestDescription", "description": "Definition of manifest for dynamic block to be created in runtime by workflows execution engine."}, "code": {"$ref": "#/components/schemas/PythonCode", "description": "Code to be executed in run(...) method of block that will be dynamically created."}}, "type": "object", "required": ["type", "manifest", "code"], "title": "DynamicBlockDefinition"}, "DynamicInputDefinition": {"properties": {"type": {"type": "string", "const": "DynamicInputDefinition", "title": "Type"}, "has_default_value": {"type": "boolean", "title": "Has Default Value", "description": "Flag to decide if default value is provided for input", "default": false}, "default_value": {"title": "Default Value", "description": "Definition of default value for a field. Use in combination with, `has_default_value` to decide on default value if field is optional."}, "is_optional": {"type": "boolean", "title": "Is Optional", "description": "Flag deciding if `default_value` will be added for manifest field annotation.", "default": false}, "is_dimensionality_reference": {"type": "boolean", "title": "Is Dimensionality Reference", "description": "Flag deciding if declared property holds dimensionality reference - see how dimensionality works for statically defined blocks to discover meaning of the parameter.", "default": false}, "dimensionality_offset": {"type": "integer", "maximum": 1.0, "minimum": -1.0, "title": "Dimensionality Offset", "description": "Accepted dimensionality offset for parameter. Dimensionality works the same as for traditional workflows blocks.", "default": 0}, "selector_types": {"items": {"$ref": "#/components/schemas/SelectorType"}, "type": "array", "title": "Selector Types", "description": "Union of selector types accepted by input. Should be empty if field does not accept selectors."}, "selector_data_kind": {"additionalProperties": {"items": {"type": "string"}, "type": "array"}, "propertyNames": {"$ref": "#/components/schemas/SelectorType"}, "type": "object", "title": "Selector Data Kind", "description": "Mapping of `selector_types` into names of kinds to be compatible. Empty dict (default value) means wildcard kind for all selectors. If name of kind given - must be valid kind, known for workflow execution engine."}, "value_types": {"items": {"$ref": "#/components/schemas/ValueType"}, "type": "array", "title": "Value Types", "description": "List of types representing union of types for static values (non selectors) that shall be accepted for input field. Empty list represents no value types allowed."}}, "type": "object", "required": ["type"], "title": "DynamicInputDefinition"}, "DynamicOutputDefinition": {"properties": {"type": {"type": "string", "const": "DynamicOutputDefinition", "title": "Type"}, "kind": {"items": {"type": "string"}, "type": "array", "title": "Kind", "description": "List representing union of kinds for defined output"}}, "type": "object", "required": ["type"], "title": "DynamicOutputDefinition"}, "EasyOCRInferenceRequest": {"properties": {"id": {"type": "string", "title": "Id"}, "api_key": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Api Key", "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval"}, "usage_billable": {"type": "boolean", "title": "Usage Billable", "default": true}, "start": {"anyOf": [{"type": "number"}, {"type": "null"}], "title": "Start"}, "source": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Source"}, "source_info": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Source Info"}, "disable_model_monitoring": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Disable Model Monitoring", "description": "If true, disables model monitoring for this request", "default": false}, "image": {"anyOf": [{"items": {"$ref": "#/components/schemas/InferenceRequestImage"}, "type": "array"}, {"$ref": "#/components/schemas/InferenceRequestImage"}], "title": "Image"}, "easy_ocr_version_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Easy Ocr Version Id", "default": "english_g2"}, "model_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Model Id"}, "language_codes": {"anyOf": [{"items": {"type": "string"}, "type": "array"}, {"type": "null"}], "title": "Language Codes", "default": ["en"]}, "quantize": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Quantize", "description": "Quantized models are smaller and faster, but may be less accurate and won't work correctly on all hardware.", "default": false}}, "type": "object", "required": ["id", "image"], "title": "EasyOCRInferenceRequest", "description": "EasyOCR inference request.\n\nAttributes:\n    api_key (Optional[str]): Roboflow API Key."}, "ExecutionEngineVersions": {"properties": {"versions": {"items": {"type": "string"}, "type": "array", "title": "Versions"}}, "type": "object", "required": ["versions"], "title": "ExecutionEngineVersions"}, "ExternalBlockPropertyPrimitiveDefinition": {"properties": {"manifest_type_identifier": {"type": "string", "title": "Manifest Type Identifier", "description": "Identifier of block"}, "property_name": {"type": "string", "title": "Property Name", "description": "Name of specific property"}, "property_description": {"type": "string", "title": "Property Description", "description": "Description for specific property"}, "type_annotation": {"type": "string", "title": "Type Annotation", "description": "Pythonic type annotation for property", "examples": ["Union[str, int]"]}}, "type": "object", "required": ["manifest_type_identifier", "property_name", "property_description", "type_annotation"], "title": "ExternalBlockPropertyPrimitiveDefinition"}, "ExternalOperationDescription": {"properties": {"operation_type": {"type": "string", "title": "Operation Type"}, "compound": {"type": "boolean", "title": "Compound"}, "input_kind": {"items": {"type": "string"}, "type": "array", "title": "Input Kind"}, "output_kind": {"items": {"type": "string"}, "type": "array", "title": "Output Kind"}, "nested_operation_input_kind": {"anyOf": [{"items": {"type": "string"}, "type": "array"}, {"type": "null"}], "title": "Nested Operation Input Kind"}, "nested_operation_output_kind": {"anyOf": [{"items": {"type": "string"}, "type": "array"}, {"type": "null"}], "title": "Nested Operation Output Kind"}, "description": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Description"}}, "type": "object", "required": ["operation_type", "compound", "input_kind", "output_kind"], "title": "ExternalOperationDescription"}, "ExternalOperatorDescription": {"properties": {"operator_type": {"type": "string", "title": "Operator Type"}, "operands_number": {"type": "integer", "title": "Operands Number"}, "operands_kinds": {"items": {"items": {"type": "string"}, "type": "array"}, "type": "array", "title": "Operands Kinds"}, "description": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Description"}}, "type": "object", "required": ["operator_type", "operands_number", "operands_kinds"], "title": "ExternalOperatorDescription"}, "ExternalWorkflowsBlockSelectorDefinition": {"properties": {"manifest_type_identifier": {"type": "string", "title": "Manifest Type Identifier", "description": "Identifier of block"}, "property_name": {"type": "string", "title": "Property Name", "description": "Name of specific property"}, "property_description": {"type": "string", "title": "Property Description", "description": "Description for specific property"}, "compatible_element": {"type": "string", "title": "Compatible Element", "description": "Defines to what type of object (step_output, parameter, etc) reference may be pointing"}, "is_list_element": {"type": "boolean", "title": "Is List Element", "description": "Boolean flag defining if list of references will be accepted"}, "is_dict_element": {"type": "boolean", "title": "Is Dict Element", "description": "Boolean flag defining if dict of references will be accepted"}}, "type": "object", "required": ["manifest_type_identifier", "property_name", "property_description", "compatible_element", "is_list_element", "is_dict_element"], "title": "ExternalWorkflowsBlockSelectorDefinition"}, "FaceDetectionPrediction": {"properties": {"x": {"type": "number", "title": "X", "description": "The center x-axis pixel coordinate of the prediction"}, "y": {"type": "number", "title": "Y", "description": "The center y-axis pixel coordinate of the prediction"}, "width": {"type": "number", "title": "Width", "description": "The width of the prediction bounding box in number of pixels"}, "height": {"type": "number", "title": "Height", "description": "The height of the prediction bounding box in number of pixels"}, "confidence": {"type": "number", "title": "Confidence", "description": "The detection confidence as a fraction between 0 and 1"}, "class": {"type": "string", "title": "Class", "description": "The predicted class label", "default": "face"}, "class_confidence": {"anyOf": [{"type": "number"}, {"type": "null"}], "title": "Class Confidence", "description": "The class label confidence as a fraction between 0 and 1"}, "class_id": {"anyOf": [{"type": "integer"}, {"type": "null"}], "title": "Class Id", "description": "The class id of the prediction", "default": 0}, "tracker_id": {"anyOf": [{"type": "integer"}, {"type": "null"}], "title": "Tracker Id", "description": "The tracker id of the prediction if tracking is enabled"}, "detection_id": {"type": "string", "title": "Detection Id", "description": "Unique identifier of detection"}, "parent_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Parent Id", "description": "Identifier of parent image region. Useful when stack of detection-models is in use to refer the RoI being the input to inference"}, "landmarks": {"anyOf": [{"items": {"$ref": "#/components/schemas/Point-Output"}, "type": "array"}, {"items": {"$ref": "#/components/schemas/Point3D"}, "type": "array"}], "title": "Landmarks"}}, "type": "object", "required": ["x", "y", "width", "height", "confidence", "landmarks"], "title": "FaceDetectionPrediction", "description": "Face Detection prediction.\n\nAttributes:\n    class_name (str): fixed value \"face\".\n    landmarks (Union[List[inference.core.entities.responses.inference.Point], List[inference.core.entities.responses.inference.Point3D]]): The detected face landmarks."}, "GazeDetectionInferenceRequest": {"properties": {"id": {"type": "string", "title": "Id"}, "api_key": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Api Key", "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval"}, "usage_billable": {"type": "boolean", "title": "Usage Billable", "default": true}, "start": {"anyOf": [{"type": "number"}, {"type": "null"}], "title": "Start"}, "source": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Source"}, "source_info": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Source Info"}, "disable_model_monitoring": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Disable Model Monitoring", "description": "If true, disables model monitoring for this request", "default": false}, "gaze_version_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Gaze Version Id", "description": "The version ID of Gaze to be used for this request. Must be one of l2cs.", "default": "L2CS", "examples": ["L2CS"]}, "do_run_face_detection": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Do Run Face Detection", "description": "If true, face detection will be applied; if false, face detection will be ignored and the whole input image will be used for gaze detection", "default": true, "examples": [false]}, "image": {"anyOf": [{"items": {"$ref": "#/components/schemas/InferenceRequestImage"}, "type": "array"}, {"$ref": "#/components/schemas/InferenceRequestImage"}], "title": "Image"}, "model_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Model Id"}}, "type": "object", "required": ["id", "image"], "title": "GazeDetectionInferenceRequest", "description": "Request for gaze detection inference.\n\nAttributes:\n    api_key (Optional[str]): Roboflow API Key.\n    gaze_version_id (Optional[str]): The version ID of Gaze to be used for this request.\n    do_run_face_detection (Optional[bool]): If true, face detection will be applied; if false, face detection will be ignored and the whole input image will be used for gaze detection.\n    image (Union[List[InferenceRequestImage], InferenceRequestImage]): Image(s) for inference."}, "GazeDetectionInferenceResponse": {"properties": {"predictions": {"items": {"$ref": "#/components/schemas/GazeDetectionPrediction"}, "type": "array", "title": "Predictions"}, "time": {"type": "number", "title": "Time", "description": "The processing time (second)"}, "time_face_det": {"anyOf": [{"type": "number"}, {"type": "null"}], "title": "Time Face Det", "description": "The face detection time (second)"}, "time_gaze_det": {"anyOf": [{"type": "number"}, {"type": "null"}], "title": "Time Gaze Det", "description": "The gaze detection time (second)"}}, "type": "object", "required": ["predictions", "time"], "title": "GazeDetectionInferenceResponse", "description": "Response for gaze detection inference.\n\nAttributes:\n    predictions (List[inference.core.entities.responses.gaze.GazeDetectionPrediction]): List of gaze detection predictions.\n    time (float): The processing time (second)."}, "GazeDetectionPrediction": {"properties": {"face": {"$ref": "#/components/schemas/FaceDetectionPrediction"}, "yaw": {"anyOf": [{"type": "number"}, {"type": "null"}], "title": "Yaw", "description": "Yaw (radian) of the detected face"}, "pitch": {"anyOf": [{"type": "number"}, {"type": "null"}], "title": "Pitch", "description": "Pitch (radian) of the detected face"}}, "type": "object", "required": ["face", "yaw", "pitch"], "title": "GazeDetectionPrediction", "description": "Gaze Detection prediction.\n\nAttributes:\n    face (inference.core.entities.responses.inference.FaceDetectionPrediction): The face prediction.\n    yaw (float): Yaw (radian) of the detected face.\n    pitch (float): Pitch (radian) of the detected face."}, "GroundingDINOInferenceRequest": {"properties": {"id": {"type": "string", "title": "Id"}, "api_key": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Api Key", "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval"}, "usage_billable": {"type": "boolean", "title": "Usage Billable", "default": true}, "start": {"anyOf": [{"type": "number"}, {"type": "null"}], "title": "Start"}, "source": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Source"}, "source_info": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Source Info"}, "disable_model_monitoring": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Disable Model Monitoring", "description": "If true, disables model monitoring for this request", "default": false}, "model_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Model Id"}, "model_type": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Model Type", "description": "The type of the model, usually referring to what task the model performs", "examples": ["object-detection"]}, "image": {"anyOf": [{"items": {"$ref": "#/components/schemas/InferenceRequestImage"}, "type": "array"}, {"$ref": "#/components/schemas/InferenceRequestImage"}], "title": "Image"}, "disable_preproc_auto_orient": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Disable Preproc Auto Orient", "description": "If true, the auto orient preprocessing step is disabled for this call.", "default": false}, "disable_preproc_contrast": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Disable Preproc Contrast", "description": "If true, the auto contrast preprocessing step is disabled for this call.", "default": false}, "disable_preproc_grayscale": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Disable Preproc Grayscale", "description": "If true, the grayscale preprocessing step is disabled for this call.", "default": false}, "disable_preproc_static_crop": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Disable Preproc Static Crop", "description": "If true, the static crop preprocessing step is disabled for this call.", "default": false}, "text": {"items": {"type": "string"}, "type": "array", "title": "Text", "description": "A list of strings", "examples": [["person", "dog", "cat"]]}, "box_threshold": {"anyOf": [{"type": "number"}, {"type": "null"}], "title": "Box Threshold", "default": 0.5}, "grounding_dino_version_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Grounding Dino Version Id", "default": "default"}, "text_threshold": {"anyOf": [{"type": "number"}, {"type": "null"}], "title": "Text Threshold", "default": 0.5}, "class_agnostic_nms": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Class Agnostic Nms", "default": false}}, "type": "object", "required": ["id", "image", "text"], "title": "GroundingDINOInferenceRequest", "description": "Request for Grounding DINO zero-shot predictions.\n\nAttributes:\n    text (List[str]): A list of strings."}, "HTTPValidationError": {"properties": {"detail": {"items": {"$ref": "#/components/schemas/ValidationError"}, "type": "array", "title": "Detail"}}, "type": "object", "title": "HTTPValidationError"}, "InferenceRequestImage": {"properties": {"type": {"type": "string", "title": "Type", "description": "The type of image data provided, one of 'url', 'base64', or 'numpy'", "examples": ["url"]}, "value": {"anyOf": [{}, {"type": "null"}], "title": "Value", "description": "Image data corresponding to the image type, if type = 'url' then value is a string containing the url of an image, else if type = 'base64' then value is a string containing base64 encoded image data, else if type = 'numpy' then value is binary numpy data serialized using pickle.dumps(); array should 3 dimensions, channels last, with values in the range [0,255].", "examples": ["http://www.example-image-url.com"]}}, "type": "object", "required": ["type"], "title": "InferenceRequestImage", "description": "Image data for inference request.\n\nAttributes:\n    type (str): The type of image data provided, one of 'url', 'base64', or 'numpy'.\n    value (Optional[Any]): Image data corresponding to the image type."}, "InferenceResponseImage": {"properties": {"width": {"type": "integer", "title": "Width", "description": "The original width of the image used in inference"}, "height": {"type": "integer", "title": "Height", "description": "The original height of the image used in inference"}}, "type": "object", "required": ["width", "height"], "title": "InferenceResponseImage", "description": "Inference response image information.\n\nAttributes:\n    width (int): The original width of the image used in inference.\n    height (int): The original height of the image used in inference."}, "InitializeWebRTCResponse": {"properties": {"status": {"type": "string", "title": "Status", "description": "Operation status"}, "context": {"$ref": "#/components/schemas/CommandContext", "description": "Context of the command."}, "sdp": {"type": "string", "title": "Sdp"}, "type": {"type": "string", "title": "Type"}}, "type": "object", "required": ["status", "context", "sdp", "type"], "title": "InitializeWebRTCResponse"}, "InstanceSegmentationInferenceRequest": {"properties": {"id": {"type": "string", "title": "Id"}, "api_key": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Api Key", "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval"}, "usage_billable": {"type": "boolean", "title": "Usage Billable", "default": true}, "start": {"anyOf": [{"type": "number"}, {"type": "null"}], "title": "Start"}, "source": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Source"}, "source_info": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Source Info"}, "disable_model_monitoring": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Disable Model Monitoring", "description": "If true, disables model monitoring for this request", "default": false}, "model_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Model Id", "description": "A unique model identifier", "example": "raccoon-detector-1"}, "model_type": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Model Type", "description": "The type of the model, usually referring to what task the model performs", "examples": ["object-detection"]}, "image": {"anyOf": [{"items": {"$ref": "#/components/schemas/InferenceRequestImage"}, "type": "array"}, {"$ref": "#/components/schemas/InferenceRequestImage"}], "title": "Image"}, "disable_preproc_auto_orient": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Disable Preproc Auto Orient", "description": "If true, the auto orient preprocessing step is disabled for this call.", "default": false}, "disable_preproc_contrast": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Disable Preproc Contrast", "description": "If true, the auto contrast preprocessing step is disabled for this call.", "default": false}, "disable_preproc_grayscale": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Disable Preproc Grayscale", "description": "If true, the grayscale preprocessing step is disabled for this call.", "default": false}, "disable_preproc_static_crop": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Disable Preproc Static Crop", "description": "If true, the static crop preprocessing step is disabled for this call.", "default": false}, "class_agnostic_nms": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Class Agnostic Nms", "description": "If true, NMS is applied to all detections at once, if false, NMS is applied per class", "default": false, "examples": [false]}, "class_filter": {"anyOf": [{"items": {"type": "string"}, "type": "array"}, {"type": "null"}], "title": "Class Filter", "description": "If provided, only predictions for the listed classes will be returned", "examples": [["class-1", "class-2", "class-n"]]}, "confidence": {"anyOf": [{"type": "number"}, {"type": "null"}], "title": "Confidence", "description": "The confidence threshold used to filter out predictions", "default": 0.4, "examples": [0.5]}, "fix_batch_size": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Fix Batch Size", "description": "If true, the batch size will be fixed to the maximum batch size configured for this server", "default": false, "examples": [false]}, "iou_threshold": {"anyOf": [{"type": "number"}, {"type": "null"}], "title": "Iou Threshold", "description": "The IoU threhsold that must be met for a box pair to be considered duplicate during NMS", "default": 0.3, "examples": [0.5]}, "max_detections": {"anyOf": [{"type": "integer"}, {"type": "null"}], "title": "Max Detections", "description": "The maximum number of detections that will be returned", "default": 300, "examples": [300]}, "max_candidates": {"anyOf": [{"type": "integer"}, {"type": "null"}], "title": "Max Candidates", "description": "The maximum number of candidate detections passed to NMS", "default": 3000}, "visualization_labels": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Visualization Labels", "description": "If true, labels will be rendered on prediction visualizations", "default": false, "examples": [false]}, "visualization_stroke_width": {"anyOf": [{"type": "integer"}, {"type": "null"}], "title": "Visualization Stroke Width", "description": "The stroke width used when visualizing predictions", "default": 1, "examples": [1]}, "visualize_predictions": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Visualize Predictions", "description": "If true, the predictions will be drawn on the original image and returned as a base64 string", "default": false, "examples": [false]}, "disable_active_learning": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Disable Active Learning", "description": "If true, the predictions will be prevented from registration by Active Learning (if the functionality is enabled)", "default": false, "examples": [false]}, "active_learning_target_dataset": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Active Learning Target Dataset", "description": "Parameter to be used when Active Learning data registration should happen against different dataset than the one pointed by model_id", "examples": ["my_dataset"]}, "mask_decode_mode": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Mask Decode Mode", "description": "The mode used to decode instance segmentation masks, one of 'accurate', 'fast', 'tradeoff'", "default": "accurate", "examples": ["accurate"]}, "tradeoff_factor": {"anyOf": [{"type": "number"}, {"type": "null"}], "title": "Tradeoff Factor", "description": "The amount to tradeoff between 0='fast' and 1='accurate'", "default": 0.0, "examples": [0.5]}}, "type": "object", "required": ["id", "model_id", "image"], "title": "InstanceSegmentationInferenceRequest", "description": "Instance Segmentation inference request.\n\nAttributes:\n    mask_decode_mode (Optional[str]): The mode used to decode instance segmentation masks, one of 'accurate', 'fast', 'tradeoff'.\n    tradeoff_factor (Optional[float]): The amount to tradeoff between 0='fast' and 1='accurate'."}, "InstanceSegmentationInferenceResponse": {"properties": {"visualization": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Visualization", "description": "Base64 encoded string containing prediction visualization image data"}, "inference_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Inference Id", "description": "Unique identifier of inference"}, "frame_id": {"anyOf": [{"type": "integer"}, {"type": "null"}], "title": "Frame Id", "description": "The frame id of the image used in inference if the input was a video"}, "time": {"anyOf": [{"type": "number"}, {"type": "null"}], "title": "Time", "description": "The time in seconds it took to produce the predictions including image preprocessing"}, "image": {"anyOf": [{"items": {"$ref": "#/components/schemas/InferenceResponseImage"}, "type": "array"}, {"$ref": "#/components/schemas/InferenceResponseImage"}], "title": "Image"}, "predictions": {"items": {"$ref": "#/components/schemas/InstanceSegmentationPrediction"}, "type": "array", "title": "Predictions"}}, "type": "object", "required": ["image", "predictions"], "title": "InstanceSegmentationInferenceResponse", "description": "Instance Segmentation inference response.\n\nAttributes:\n    predictions (List[inference.core.entities.responses.inference.InstanceSegmentationPrediction]): List of instance segmentation predictions."}, "InstanceSegmentationPrediction": {"properties": {"x": {"type": "number", "title": "X", "description": "The center x-axis pixel coordinate of the prediction"}, "y": {"type": "number", "title": "Y", "description": "The center y-axis pixel coordinate of the prediction"}, "width": {"type": "number", "title": "Width", "description": "The width of the prediction bounding box in number of pixels"}, "height": {"type": "number", "title": "Height", "description": "The height of the prediction bounding box in number of pixels"}, "confidence": {"type": "number", "title": "Confidence", "description": "The detection confidence as a fraction between 0 and 1"}, "class": {"type": "string", "title": "Class", "description": "The predicted class label"}, "class_id": {"type": "integer", "title": "Class Id", "description": "The class id of the prediction"}, "detection_id": {"type": "string", "title": "Detection Id", "description": "Unique identifier of detection"}, "parent_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Parent Id", "description": "Identifier of parent image region"}, "class_confidence": {"anyOf": [{"type": "number"}, {"type": "null"}], "title": "Class Confidence", "description": "The class label confidence as a fraction between 0 and 1"}, "points": {"items": {"$ref": "#/components/schemas/Point-Output"}, "type": "array", "title": "Points", "description": "The list of points that make up the instance polygon"}}, "type": "object", "required": ["x", "y", "width", "height", "confidence", "class", "class_id", "points"], "title": "InstanceSegmentationPrediction"}, "Keypoint": {"properties": {"x": {"type": "number", "title": "X", "description": "The x-axis pixel coordinate of the point"}, "y": {"type": "number", "title": "Y", "description": "The y-axis pixel coordinate of the point"}, "confidence": {"type": "number", "title": "Confidence", "description": "Model confidence regarding keypoint visibility."}, "class_id": {"type": "integer", "title": "Class Id", "description": "Identifier of keypoint."}, "class": {"type": "string", "title": "Class", "description": "Type of keypoint."}}, "type": "object", "required": ["x", "y", "confidence", "class_id", "class"], "title": "Keypoint"}, "KeypointsDetectionInferenceRequest": {"properties": {"id": {"type": "string", "title": "Id"}, "api_key": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Api Key", "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval"}, "usage_billable": {"type": "boolean", "title": "Usage Billable", "default": true}, "start": {"anyOf": [{"type": "number"}, {"type": "null"}], "title": "Start"}, "source": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Source"}, "source_info": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Source Info"}, "disable_model_monitoring": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Disable Model Monitoring", "description": "If true, disables model monitoring for this request", "default": false}, "model_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Model Id", "description": "A unique model identifier", "example": "raccoon-detector-1"}, "model_type": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Model Type", "description": "The type of the model, usually referring to what task the model performs", "examples": ["object-detection"]}, "image": {"anyOf": [{"items": {"$ref": "#/components/schemas/InferenceRequestImage"}, "type": "array"}, {"$ref": "#/components/schemas/InferenceRequestImage"}], "title": "Image"}, "disable_preproc_auto_orient": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Disable Preproc Auto Orient", "description": "If true, the auto orient preprocessing step is disabled for this call.", "default": false}, "disable_preproc_contrast": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Disable Preproc Contrast", "description": "If true, the auto contrast preprocessing step is disabled for this call.", "default": false}, "disable_preproc_grayscale": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Disable Preproc Grayscale", "description": "If true, the grayscale preprocessing step is disabled for this call.", "default": false}, "disable_preproc_static_crop": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Disable Preproc Static Crop", "description": "If true, the static crop preprocessing step is disabled for this call.", "default": false}, "class_agnostic_nms": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Class Agnostic Nms", "description": "If true, NMS is applied to all detections at once, if false, NMS is applied per class", "default": false, "examples": [false]}, "class_filter": {"anyOf": [{"items": {"type": "string"}, "type": "array"}, {"type": "null"}], "title": "Class Filter", "description": "If provided, only predictions for the listed classes will be returned", "examples": [["class-1", "class-2", "class-n"]]}, "confidence": {"anyOf": [{"type": "number"}, {"type": "null"}], "title": "Confidence", "description": "The confidence threshold used to filter out predictions", "default": 0.4, "examples": [0.5]}, "fix_batch_size": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Fix Batch Size", "description": "If true, the batch size will be fixed to the maximum batch size configured for this server", "default": false, "examples": [false]}, "iou_threshold": {"anyOf": [{"type": "number"}, {"type": "null"}], "title": "Iou Threshold", "description": "The IoU threhsold that must be met for a box pair to be considered duplicate during NMS", "default": 0.3, "examples": [0.5]}, "max_detections": {"anyOf": [{"type": "integer"}, {"type": "null"}], "title": "Max Detections", "description": "The maximum number of detections that will be returned", "default": 300, "examples": [300]}, "max_candidates": {"anyOf": [{"type": "integer"}, {"type": "null"}], "title": "Max Candidates", "description": "The maximum number of candidate detections passed to NMS", "default": 3000}, "visualization_labels": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Visualization Labels", "description": "If true, labels will be rendered on prediction visualizations", "default": false, "examples": [false]}, "visualization_stroke_width": {"anyOf": [{"type": "integer"}, {"type": "null"}], "title": "Visualization Stroke Width", "description": "The stroke width used when visualizing predictions", "default": 1, "examples": [1]}, "visualize_predictions": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Visualize Predictions", "description": "If true, the predictions will be drawn on the original image and returned as a base64 string", "default": false, "examples": [false]}, "disable_active_learning": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Disable Active Learning", "description": "If true, the predictions will be prevented from registration by Active Learning (if the functionality is enabled)", "default": false, "examples": [false]}, "active_learning_target_dataset": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Active Learning Target Dataset", "description": "Parameter to be used when Active Learning data registration should happen against different dataset than the one pointed by model_id", "examples": ["my_dataset"]}, "keypoint_confidence": {"anyOf": [{"type": "number"}, {"type": "null"}], "title": "Keypoint Confidence", "description": "The confidence threshold used to filter out non visible keypoints", "default": 0.0, "examples": [0.5]}}, "type": "object", "required": ["id", "model_id", "image"], "title": "KeypointsDetectionInferenceRequest"}, "KeypointsDetectionInferenceResponse": {"properties": {"visualization": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Visualization", "description": "Base64 encoded string containing prediction visualization image data"}, "inference_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Inference Id", "description": "Unique identifier of inference"}, "frame_id": {"anyOf": [{"type": "integer"}, {"type": "null"}], "title": "Frame Id", "description": "The frame id of the image used in inference if the input was a video"}, "time": {"anyOf": [{"type": "number"}, {"type": "null"}], "title": "Time", "description": "The time in seconds it took to produce the predictions including image preprocessing"}, "image": {"anyOf": [{"items": {"$ref": "#/components/schemas/InferenceResponseImage"}, "type": "array"}, {"$ref": "#/components/schemas/InferenceResponseImage"}], "title": "Image"}, "predictions": {"items": {"$ref": "#/components/schemas/KeypointsPrediction"}, "type": "array", "title": "Predictions"}}, "type": "object", "required": ["image", "predictions"], "title": "KeypointsDetectionInferenceResponse"}, "KeypointsPrediction": {"properties": {"x": {"type": "number", "title": "X", "description": "The center x-axis pixel coordinate of the prediction"}, "y": {"type": "number", "title": "Y", "description": "The center y-axis pixel coordinate of the prediction"}, "width": {"type": "number", "title": "Width", "description": "The width of the prediction bounding box in number of pixels"}, "height": {"type": "number", "title": "Height", "description": "The height of the prediction bounding box in number of pixels"}, "confidence": {"type": "number", "title": "Confidence", "description": "The detection confidence as a fraction between 0 and 1"}, "class": {"type": "string", "title": "Class", "description": "The predicted class label"}, "class_confidence": {"anyOf": [{"type": "number"}, {"type": "null"}], "title": "Class Confidence", "description": "The class label confidence as a fraction between 0 and 1"}, "class_id": {"type": "integer", "title": "Class Id", "description": "The class id of the prediction"}, "tracker_id": {"anyOf": [{"type": "integer"}, {"type": "null"}], "title": "Tracker Id", "description": "The tracker id of the prediction if tracking is enabled"}, "detection_id": {"type": "string", "title": "Detection Id", "description": "Unique identifier of detection"}, "parent_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Parent Id", "description": "Identifier of parent image region. Useful when stack of detection-models is in use to refer the RoI being the input to inference"}, "keypoints": {"items": {"$ref": "#/components/schemas/Keypoint"}, "type": "array", "title": "Keypoints"}}, "type": "object", "required": ["x", "y", "width", "height", "confidence", "class", "class_id", "keypoints"], "title": "KeypointsPrediction"}, "Kind": {"properties": {"name": {"type": "string", "title": "Name"}, "description": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Description"}, "docs": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Docs"}, "serialised_data_type": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Serialised Data Type", "description": "Provides Python type hint for data format that should guide external clients on how to produce / consume serialised data of specific kind."}, "internal_data_type": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Internal Data Type", "description": "Provides type hint regarding internal data representation that specific kind translates into when Workflow is run by Execution Engine. Relevant for blocks developers."}}, "type": "object", "required": ["name"], "title": "Kind"}, "LMMInferenceRequest": {"properties": {"id": {"type": "string", "title": "Id"}, "api_key": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Api Key", "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval"}, "usage_billable": {"type": "boolean", "title": "Usage Billable", "default": true}, "start": {"anyOf": [{"type": "number"}, {"type": "null"}], "title": "Start"}, "source": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Source"}, "source_info": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Source Info"}, "disable_model_monitoring": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Disable Model Monitoring", "description": "If true, disables model monitoring for this request", "default": false}, "model_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Model Id", "description": "A unique model identifier", "example": "raccoon-detector-1"}, "model_type": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Model Type", "description": "The type of the model, usually referring to what task the model performs", "examples": ["object-detection"]}, "image": {"anyOf": [{"items": {"$ref": "#/components/schemas/InferenceRequestImage"}, "type": "array"}, {"$ref": "#/components/schemas/InferenceRequestImage"}], "title": "Image"}, "disable_preproc_auto_orient": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Disable Preproc Auto Orient", "description": "If true, the auto orient preprocessing step is disabled for this call.", "default": false}, "disable_preproc_contrast": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Disable Preproc Contrast", "description": "If true, the auto contrast preprocessing step is disabled for this call.", "default": false}, "disable_preproc_grayscale": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Disable Preproc Grayscale", "description": "If true, the grayscale preprocessing step is disabled for this call.", "default": false}, "disable_preproc_static_crop": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Disable Preproc Static Crop", "description": "If true, the static crop preprocessing step is disabled for this call.", "default": false}, "prompt": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Prompt", "description": "If set, use this prompt to guide the LMM", "examples": ["caption"]}}, "type": "object", "required": ["id", "model_id", "image"], "title": "LMMInferenceRequest"}, "LMMInferenceResponse": {"properties": {"inference_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Inference Id", "description": "Unique identifier of inference"}, "frame_id": {"anyOf": [{"type": "integer"}, {"type": "null"}], "title": "Frame Id", "description": "The frame id of the image used in inference if the input was a video"}, "time": {"anyOf": [{"type": "number"}, {"type": "null"}], "title": "Time", "description": "The time in seconds it took to produce the predictions including image preprocessing"}, "image": {"anyOf": [{"items": {"$ref": "#/components/schemas/InferenceResponseImage"}, "type": "array"}, {"$ref": "#/components/schemas/InferenceResponseImage"}], "title": "Image"}, "response": {"anyOf": [{"type": "string"}, {"additionalProperties": true, "type": "object"}], "title": "Response", "description": "Text/structured response generated by model"}}, "type": "object", "required": ["image", "response"], "title": "LMMInferenceResponse"}, "ManifestDescription": {"properties": {"type": {"type": "string", "const": "ManifestDescription", "title": "Type"}, "block_type": {"type": "string", "title": "Block Type", "description": "Field holds type of the bock to be dynamically created. Block can be initialised as step using the type declared in the field."}, "description": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Description", "description": "Description of the block to be used in manifest"}, "inputs": {"additionalProperties": {"$ref": "#/components/schemas/DynamicInputDefinition"}, "type": "object", "title": "Inputs", "description": "Mapping name -> input definition for block inputs (parameters for run() function ofdynamic block)"}, "outputs": {"additionalProperties": {"$ref": "#/components/schemas/DynamicOutputDefinition"}, "type": "object", "title": "Outputs", "description": "Mapping name -> output kind for block outputs."}, "output_dimensionality_offset": {"type": "integer", "maximum": 1.0, "minimum": -1.0, "title": "Output Dimensionality Offset", "description": "Definition of output dimensionality offset", "default": 0}, "ui_manifest": {"anyOf": [{"additionalProperties": true, "type": "object"}, {"type": "null"}], "title": "Ui Manifest", "description": "Configuration for UI representation of the block (icon, section, etc.)"}, "accepts_batch_input": {"type": "boolean", "title": "Accepts Batch Input", "description": "Flag to decide if function will be provided with batch data as whole or with singular batch elements while execution", "default": false}, "accepts_empty_values": {"type": "boolean", "title": "Accepts Empty Values", "description": "Flag to decide if empty (optional) values will be shipped as run() function parameters", "default": false}, "batch_oriented_parameters": {"items": {"type": "string"}, "type": "array", "title": "Batch Oriented Parameters", "description": "List of batch-oriented parameters. Value will override `accepts_batch_input` if non-empty list is provided, `accepts_batch_input` is  kept not to break backward compatibility."}, "parameters_with_scalars_and_batches": {"items": {"type": "string"}, "type": "array", "title": "Parameters With Scalars And Batches", "description": "List of parameters accepting both batches and scalars at the same time. Value will override `accepts_batch_input` if non-empty list is provided, `accepts_batch_input` is kept not to break backward compatibility."}, "get_parameters_enforcing_auto_batch_casting": {"items": {"type": "string"}, "type": "array", "title": "Get Parameters Enforcing Auto Batch Casting", "description": "List of parameters, for which auto-batch casting should be enforced, making sure that the block run(...) method will always receive the parameters as batches, not scalars. This property is important for blocks decreasing output dimensionality which do not define neither `batch_oriented_parameters` nor `parameters_with_scalars_and_batches`."}}, "type": "object", "required": ["type", "block_type", "inputs"], "title": "ManifestDescription"}, "ModelDescriptionEntity": {"properties": {"model_id": {"type": "string", "title": "Model Id", "description": "Identifier of the model", "examples": ["some-project/3"]}, "task_type": {"type": "string", "title": "Task Type", "description": "Type of the task that the model performs", "examples": ["classification"]}, "batch_size": {"anyOf": [{"type": "integer"}, {"type": "null"}], "title": "Batch Size", "description": "Batch size accepted by the model (if registered)."}, "input_height": {"anyOf": [{"type": "integer"}, {"type": "null"}], "title": "Input Height", "description": "Image input height accepted by the model (if registered)."}, "input_width": {"anyOf": [{"type": "integer"}, {"type": "null"}], "title": "Input Width", "description": "Image input width accepted by the model (if registered)."}}, "type": "object", "required": ["model_id", "task_type"], "title": "ModelDescriptionEntity"}, "ModelsDescriptions": {"properties": {"models": {"items": {"$ref": "#/components/schemas/ModelDescriptionEntity"}, "type": "array", "title": "Models", "description": "List of models that are loaded by model manager."}}, "type": "object", "required": ["models"], "title": "ModelsDescriptions"}, "MultiLabelClassificationInferenceResponse": {"properties": {"visualization": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Visualization", "description": "Base64 encoded string containing prediction visualization image data"}, "inference_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Inference Id", "description": "Unique identifier of inference"}, "frame_id": {"anyOf": [{"type": "integer"}, {"type": "null"}], "title": "Frame Id", "description": "The frame id of the image used in inference if the input was a video"}, "time": {"anyOf": [{"type": "number"}, {"type": "null"}], "title": "Time", "description": "The time in seconds it took to produce the predictions including image preprocessing"}, "image": {"anyOf": [{"items": {"$ref": "#/components/schemas/InferenceResponseImage"}, "type": "array"}, {"$ref": "#/components/schemas/InferenceResponseImage"}], "title": "Image"}, "predictions": {"additionalProperties": {"$ref": "#/components/schemas/MultiLabelClassificationPrediction"}, "type": "object", "title": "Predictions"}, "predicted_classes": {"items": {"type": "string"}, "type": "array", "title": "Predicted Classes", "description": "The list of predicted classes"}, "parent_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Parent Id", "description": "Identifier of parent image region. Useful when stack of detection-models is in use to refer the RoI being the input to inference"}}, "type": "object", "required": ["image", "predictions", "predicted_classes"], "title": "MultiLabelClassificationInferenceResponse", "description": "Multi-label Classification inference response.\n\nAttributes:\n    predictions (Dict[str, inference.core.entities.responses.inference.MultiLabelClassificationPrediction]): Dictionary of multi-label classification predictions.\n    predicted_classes (List[str]): The list of predicted classes."}, "MultiLabelClassificationPrediction": {"properties": {"confidence": {"type": "number", "title": "Confidence", "description": "The class label confidence as a fraction between 0 and 1"}, "class_id": {"type": "integer", "title": "Class Id", "description": "Numeric ID associated with the class label"}}, "type": "object", "required": ["confidence", "class_id"], "title": "MultiLabelClassificationPrediction", "description": "Multi-label Classification prediction.\n\nAttributes:\n    confidence (float): The class label confidence as a fraction between 0 and 1."}, "OCRInferenceResponse": {"properties": {"result": {"type": "string", "title": "Result", "description": "The combined OCR recognition result."}, "image": {"anyOf": [{"$ref": "#/components/schemas/InferenceResponseImage"}, {"type": "null"}], "description": "Metadata about input image dimensions"}, "predictions": {"anyOf": [{"items": {"$ref": "#/components/schemas/ObjectDetectionPrediction"}, "type": "array"}, {"type": "null"}], "title": "Predictions", "description": "List of objects detected by OCR"}, "time": {"type": "number", "title": "Time", "description": "The time in seconds it took to produce the inference including preprocessing."}, "parent_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Parent Id", "description": "Identifier of parent image region. Useful when stack of detection-models is in use to refer the RoI being the input to inference"}}, "type": "object", "required": ["result", "time"], "title": "OCRInferenceResponse", "description": "OCR Inference response.\n\nAttributes:\n    result (str): The combined OCR recognition result.\n    predictions (List[ObjectDetectionPrediction]): List of objects detected by OCR\n    time (float): The time in seconds it took to produce the inference including preprocessing"}, "ObjectDetectionInferenceRequest": {"properties": {"id": {"type": "string", "title": "Id"}, "api_key": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Api Key", "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval"}, "usage_billable": {"type": "boolean", "title": "Usage Billable", "default": true}, "start": {"anyOf": [{"type": "number"}, {"type": "null"}], "title": "Start"}, "source": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Source"}, "source_info": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Source Info"}, "disable_model_monitoring": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Disable Model Monitoring", "description": "If true, disables model monitoring for this request", "default": false}, "model_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Model Id", "description": "A unique model identifier", "example": "raccoon-detector-1"}, "model_type": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Model Type", "description": "The type of the model, usually referring to what task the model performs", "examples": ["object-detection"]}, "image": {"anyOf": [{"items": {"$ref": "#/components/schemas/InferenceRequestImage"}, "type": "array"}, {"$ref": "#/components/schemas/InferenceRequestImage"}], "title": "Image"}, "disable_preproc_auto_orient": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Disable Preproc Auto Orient", "description": "If true, the auto orient preprocessing step is disabled for this call.", "default": false}, "disable_preproc_contrast": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Disable Preproc Contrast", "description": "If true, the auto contrast preprocessing step is disabled for this call.", "default": false}, "disable_preproc_grayscale": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Disable Preproc Grayscale", "description": "If true, the grayscale preprocessing step is disabled for this call.", "default": false}, "disable_preproc_static_crop": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Disable Preproc Static Crop", "description": "If true, the static crop preprocessing step is disabled for this call.", "default": false}, "class_agnostic_nms": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Class Agnostic Nms", "description": "If true, NMS is applied to all detections at once, if false, NMS is applied per class", "default": false, "examples": [false]}, "class_filter": {"anyOf": [{"items": {"type": "string"}, "type": "array"}, {"type": "null"}], "title": "Class Filter", "description": "If provided, only predictions for the listed classes will be returned", "examples": [["class-1", "class-2", "class-n"]]}, "confidence": {"anyOf": [{"type": "number"}, {"type": "null"}], "title": "Confidence", "description": "The confidence threshold used to filter out predictions", "default": 0.4, "examples": [0.5]}, "fix_batch_size": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Fix Batch Size", "description": "If true, the batch size will be fixed to the maximum batch size configured for this server", "default": false, "examples": [false]}, "iou_threshold": {"anyOf": [{"type": "number"}, {"type": "null"}], "title": "Iou Threshold", "description": "The IoU threhsold that must be met for a box pair to be considered duplicate during NMS", "default": 0.3, "examples": [0.5]}, "max_detections": {"anyOf": [{"type": "integer"}, {"type": "null"}], "title": "Max Detections", "description": "The maximum number of detections that will be returned", "default": 300, "examples": [300]}, "max_candidates": {"anyOf": [{"type": "integer"}, {"type": "null"}], "title": "Max Candidates", "description": "The maximum number of candidate detections passed to NMS", "default": 3000}, "visualization_labels": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Visualization Labels", "description": "If true, labels will be rendered on prediction visualizations", "default": false, "examples": [false]}, "visualization_stroke_width": {"anyOf": [{"type": "integer"}, {"type": "null"}], "title": "Visualization Stroke Width", "description": "The stroke width used when visualizing predictions", "default": 1, "examples": [1]}, "visualize_predictions": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Visualize Predictions", "description": "If true, the predictions will be drawn on the original image and returned as a base64 string", "default": false, "examples": [false]}, "disable_active_learning": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Disable Active Learning", "description": "If true, the predictions will be prevented from registration by Active Learning (if the functionality is enabled)", "default": false, "examples": [false]}, "active_learning_target_dataset": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Active Learning Target Dataset", "description": "Parameter to be used when Active Learning data registration should happen against different dataset than the one pointed by model_id", "examples": ["my_dataset"]}}, "type": "object", "required": ["id", "model_id", "image"], "title": "ObjectDetectionInferenceRequest", "description": "Object Detection inference request.\n\nAttributes:\n    class_agnostic_nms (Optional[bool]): If true, NMS is applied to all detections at once, if false, NMS is applied per class.\n    class_filter (Optional[List[str]]): If provided, only predictions for the listed classes will be returned.\n    confidence (Optional[float]): The confidence threshold used to filter out predictions.\n    fix_batch_size (Optional[bool]): If true, the batch size will be fixed to the maximum batch size configured for this server.\n    iou_threshold (Optional[float]): The IoU threshold that must be met for a box pair to be considered duplicate during NMS.\n    max_detections (Optional[int]): The maximum number of detections that will be returned.\n    max_candidates (Optional[int]): The maximum number of candidate detections passed to NMS.\n    visualization_labels (Optional[bool]): If true, labels will be rendered on prediction visualizations.\n    visualization_stroke_width (Optional[int]): The stroke width used when visualizing predictions.\n    visualize_predictions (Optional[bool]): If true, the predictions will be drawn on the original image and returned as a base64 string."}, "ObjectDetectionInferenceResponse": {"properties": {"visualization": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Visualization", "description": "Base64 encoded string containing prediction visualization image data"}, "inference_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Inference Id", "description": "Unique identifier of inference"}, "frame_id": {"anyOf": [{"type": "integer"}, {"type": "null"}], "title": "Frame Id", "description": "The frame id of the image used in inference if the input was a video"}, "time": {"anyOf": [{"type": "number"}, {"type": "null"}], "title": "Time", "description": "The time in seconds it took to produce the predictions including image preprocessing"}, "image": {"anyOf": [{"items": {"$ref": "#/components/schemas/InferenceResponseImage"}, "type": "array"}, {"$ref": "#/components/schemas/InferenceResponseImage"}], "title": "Image"}, "predictions": {"items": {"$ref": "#/components/schemas/ObjectDetectionPrediction"}, "type": "array", "title": "Predictions"}}, "type": "object", "required": ["image", "predictions"], "title": "ObjectDetectionInferenceResponse", "description": "Object Detection inference response.\n\nAttributes:\n    predictions (List[inference.core.entities.responses.inference.ObjectDetectionPrediction]): List of object detection predictions."}, "ObjectDetectionPrediction": {"properties": {"x": {"type": "number", "title": "X", "description": "The center x-axis pixel coordinate of the prediction"}, "y": {"type": "number", "title": "Y", "description": "The center y-axis pixel coordinate of the prediction"}, "width": {"type": "number", "title": "Width", "description": "The width of the prediction bounding box in number of pixels"}, "height": {"type": "number", "title": "Height", "description": "The height of the prediction bounding box in number of pixels"}, "confidence": {"type": "number", "title": "Confidence", "description": "The detection confidence as a fraction between 0 and 1"}, "class": {"type": "string", "title": "Class", "description": "The predicted class label"}, "class_confidence": {"anyOf": [{"type": "number"}, {"type": "null"}], "title": "Class Confidence", "description": "The class label confidence as a fraction between 0 and 1"}, "class_id": {"type": "integer", "title": "Class Id", "description": "The class id of the prediction"}, "tracker_id": {"anyOf": [{"type": "integer"}, {"type": "null"}], "title": "Tracker Id", "description": "The tracker id of the prediction if tracking is enabled"}, "detection_id": {"type": "string", "title": "Detection Id", "description": "Unique identifier of detection"}, "parent_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Parent Id", "description": "Identifier of parent image region. Useful when stack of detection-models is in use to refer the RoI being the input to inference"}}, "type": "object", "required": ["x", "y", "width", "height", "confidence", "class", "class_id"], "title": "ObjectDetectionPrediction", "description": "Object Detection prediction.\n\nAttributes:\n    x (float): The center x-axis pixel coordinate of the prediction.\n    y (float): The center y-axis pixel coordinate of the prediction.\n    width (float): The width of the prediction bounding box in number of pixels.\n    height (float): The height of the prediction bounding box in number of pixels.\n    confidence (float): The detection confidence as a fraction between 0 and 1.\n    class_name (str): The predicted class label.\n    class_confidence (Union[float, None]): The class label confidence as a fraction between 0 and 1.\n    class_id (int): The class id of the prediction"}, "OutputDefinition": {"properties": {"name": {"type": "string", "title": "Name"}, "kind": {"items": {"$ref": "#/components/schemas/Kind"}, "type": "array", "title": "Kind"}}, "type": "object", "required": ["name"], "title": "OutputDefinition"}, "PerceptionEncoderCompareRequest": {"properties": {"id": {"type": "string", "title": "Id"}, "api_key": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Api Key", "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval"}, "usage_billable": {"type": "boolean", "title": "Usage Billable", "default": true}, "start": {"anyOf": [{"type": "number"}, {"type": "null"}], "title": "Start"}, "source": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Source"}, "source_info": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Source Info"}, "disable_model_monitoring": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Disable Model Monitoring", "description": "If true, disables model monitoring for this request", "default": false}, "perception_encoder_version_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Perception Encoder Version Id", "description": "The version ID of PERCEPTION_ENCODER to be used for this request. Must be one of RN101, RN50, RN50x16, RN50x4, RN50x64, ViT-B-16, ViT-B-32, ViT-L-14-336px, and ViT-L-14.", "default": "PE-Core-L14-336", "examples": ["PE-Core-L14-336"]}, "model_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Model Id"}, "subject": {"anyOf": [{"$ref": "#/components/schemas/InferenceRequestImage"}, {"type": "string"}], "title": "Subject", "description": "The type of image data provided, one of 'url' or 'base64'", "examples": ["url"]}, "subject_type": {"type": "string", "title": "Subject Type", "description": "The type of subject, one of 'image' or 'text'", "default": "image", "examples": ["image"]}, "prompt": {"anyOf": [{"items": {"$ref": "#/components/schemas/InferenceRequestImage"}, "type": "array"}, {"$ref": "#/components/schemas/InferenceRequestImage"}, {"type": "string"}, {"items": {"type": "string"}, "type": "array"}, {"additionalProperties": {"anyOf": [{"$ref": "#/components/schemas/InferenceRequestImage"}, {"type": "string"}]}, "type": "object"}], "title": "Prompt"}, "prompt_type": {"type": "string", "title": "Prompt Type", "description": "The type of prompt, one of 'image' or 'text'", "default": "text", "examples": ["text"]}}, "type": "object", "required": ["id", "subject", "prompt"], "title": "PerceptionEncoderCompareRequest", "description": "Request for PERCEPTION_ENCODER comparison.\n\nAttributes:\n    subject (Union[InferenceRequestImage, str]): The type of image data provided, one of 'url' or 'base64'.\n    subject_type (str): The type of subject, one of 'image' or 'text'.\n    prompt (Union[List[InferenceRequestImage], InferenceRequestImage, str, List[str], Dict[str, Union[InferenceRequestImage, str]]]): The prompt for comparison.\n    prompt_type (str): The type of prompt, one of 'image' or 'text'."}, "PerceptionEncoderCompareResponse": {"properties": {"inference_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Inference Id", "description": "Unique identifier of inference"}, "frame_id": {"anyOf": [{"type": "integer"}, {"type": "null"}], "title": "Frame Id", "description": "The frame id of the image used in inference if the input was a video"}, "time": {"anyOf": [{"type": "number"}, {"type": "null"}], "title": "Time", "description": "The time in seconds it took to produce the similarity scores including preprocessing"}, "similarity": {"anyOf": [{"items": {"type": "number"}, "type": "array"}, {"additionalProperties": {"type": "number"}, "type": "object"}], "title": "Similarity"}, "parent_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Parent Id", "description": "Identifier of parent image region. Useful when stack of detection-models is in use to refer the RoI being the input to inference"}}, "type": "object", "required": ["similarity"], "title": "PerceptionEncoderCompareResponse", "description": "Response for PERCEPTION_ENCODER comparison.\n\nAttributes:\n    similarity (Union[List[float], Dict[str, float]]): Similarity scores.\n    time (float): The time in seconds it took to produce the similarity scores including preprocessing."}, "PerceptionEncoderEmbeddingResponse": {"properties": {"inference_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Inference Id", "description": "Unique identifier of inference"}, "frame_id": {"anyOf": [{"type": "integer"}, {"type": "null"}], "title": "Frame Id", "description": "The frame id of the image used in inference if the input was a video"}, "time": {"anyOf": [{"type": "number"}, {"type": "null"}], "title": "Time", "description": "The time in seconds it took to produce the embeddings including preprocessing"}, "embeddings": {"items": {"items": {"type": "number"}, "type": "array"}, "type": "array", "title": "Embeddings", "description": "A list of embeddings, each embedding is a list of floats", "examples": ["[[0.12, 0.23, 0.34, ..., 0.43]]"]}}, "type": "object", "required": ["embeddings"], "title": "PerceptionEncoderEmbeddingResponse", "description": "Response for PERCEPTION_ENCODER embedding.\n\nAttributes:\n    embeddings (List[List[float]]): A list of embeddings, each embedding is a list of floats.\n    time (float): The time in seconds it took to produce the embeddings including preprocessing."}, "PerceptionEncoderImageEmbeddingRequest": {"properties": {"id": {"type": "string", "title": "Id"}, "api_key": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Api Key", "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval"}, "usage_billable": {"type": "boolean", "title": "Usage Billable", "default": true}, "start": {"anyOf": [{"type": "number"}, {"type": "null"}], "title": "Start"}, "source": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Source"}, "source_info": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Source Info"}, "disable_model_monitoring": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Disable Model Monitoring", "description": "If true, disables model monitoring for this request", "default": false}, "perception_encoder_version_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Perception Encoder Version Id", "description": "The version ID of PERCEPTION_ENCODER to be used for this request. Must be one of RN101, RN50, RN50x16, RN50x4, RN50x64, ViT-B-16, ViT-B-32, ViT-L-14-336px, and ViT-L-14.", "default": "PE-Core-L14-336", "examples": ["PE-Core-L14-336"]}, "model_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Model Id"}, "image": {"anyOf": [{"items": {"$ref": "#/components/schemas/InferenceRequestImage"}, "type": "array"}, {"$ref": "#/components/schemas/InferenceRequestImage"}], "title": "Image"}}, "type": "object", "required": ["id", "image"], "title": "PerceptionEncoderImageEmbeddingRequest", "description": "Request for PERCEPTION_ENCODER image embedding.\n\nAttributes:\n    image (Union[List[InferenceRequestImage], InferenceRequestImage]): Image(s) to be embedded."}, "PerceptionEncoderTextEmbeddingRequest": {"properties": {"id": {"type": "string", "title": "Id"}, "api_key": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Api Key", "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval"}, "usage_billable": {"type": "boolean", "title": "Usage Billable", "default": true}, "start": {"anyOf": [{"type": "number"}, {"type": "null"}], "title": "Start"}, "source": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Source"}, "source_info": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Source Info"}, "disable_model_monitoring": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Disable Model Monitoring", "description": "If true, disables model monitoring for this request", "default": false}, "perception_encoder_version_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Perception Encoder Version Id", "description": "The version ID of PERCEPTION_ENCODER to be used for this request. Must be one of RN101, RN50, RN50x16, RN50x4, RN50x64, ViT-B-16, ViT-B-32, ViT-L-14-336px, and ViT-L-14.", "default": "PE-Core-L14-336", "examples": ["PE-Core-L14-336"]}, "model_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Model Id"}, "text": {"anyOf": [{"items": {"type": "string"}, "type": "array"}, {"type": "string"}], "title": "Text", "description": "A string or list of strings", "examples": ["The quick brown fox jumps over the lazy dog"]}}, "type": "object", "required": ["id", "text"], "title": "PerceptionEncoderTextEmbeddingRequest", "description": "Request for PERCEPTION_ENCODER text embedding.\n\nAttributes:\n    text (Union[List[str], str]): A string or list of strings."}, "Point-Input": {"properties": {"x": {"type": "number", "title": "X"}, "y": {"type": "number", "title": "Y"}, "positive": {"type": "boolean", "title": "Positive"}}, "type": "object", "required": ["x", "y", "positive"], "title": "Point"}, "Point-Output": {"properties": {"x": {"type": "number", "title": "X", "description": "The x-axis pixel coordinate of the point"}, "y": {"type": "number", "title": "Y", "description": "The y-axis pixel coordinate of the point"}}, "type": "object", "required": ["x", "y"], "title": "Point", "description": "Point coordinates.\n\nAttributes:\n    x (float): The x-axis pixel coordinate of the point.\n    y (float): The y-axis pixel coordinate of the point."}, "Point3D": {"properties": {"x": {"type": "number", "title": "X", "description": "The x-axis pixel coordinate of the point"}, "y": {"type": "number", "title": "Y", "description": "The y-axis pixel coordinate of the point"}, "z": {"type": "number", "title": "Z", "description": "The z-axis pixel coordinate of the point"}}, "type": "object", "required": ["x", "y", "z"], "title": "Point3D", "description": "3D Point coordinates.\n\nAttributes:\n    z (float): The z-axis pixel coordinate of the point."}, "PredefinedWorkflowDescribeInterfaceRequest": {"properties": {"api_key": {"type": "string", "title": "Api Key", "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval"}, "use_cache": {"type": "boolean", "title": "Use Cache", "description": "Controls usage of cache for workflow definitions. Set this to False when you frequently modify definition saved in Roboflow app and want to fetch the newest version for the request. Only applies for Workflows definitions saved on Roboflow platform.", "default": true}, "workflow_version_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Workflow Version Id", "description": "Specific version of the workflow to fetch. If not provided, the latest version is used."}}, "type": "object", "required": ["api_key"], "title": "PredefinedWorkflowDescribeInterfaceRequest"}, "PredefinedWorkflowInferenceRequest": {"properties": {"api_key": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Api Key", "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval"}, "inputs": {"additionalProperties": true, "type": "object", "title": "Inputs", "description": "Dictionary that contains each parameter defined as an input for chosen workflow"}, "excluded_fields": {"anyOf": [{"items": {"type": "string"}, "type": "array"}, {"type": "null"}], "title": "Excluded Fields", "description": "List of field that shall be excluded from the response (among those defined in workflow specification)"}, "enable_profiling": {"type": "boolean", "title": "Enable Profiling", "description": "Flag to request Workflow run profiling. Enables Workflow profiler only when server settings allow profiling traces to be exported to clients. Only applies for Workflows definitions saved on Roboflow platform.", "default": false}, "workflow_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Workflow Id", "description": "Optional identifier of workflow"}, "use_cache": {"type": "boolean", "title": "Use Cache", "description": "Controls usage of cache for workflow definitions. Set this to False when you frequently modify definition saved in Roboflow app and want to fetch the newest version for the request.", "default": true}, "workflow_version_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Workflow Version Id", "description": "Specific version of the workflow to fetch. If not provided, the latest version is used."}}, "type": "object", "required": ["inputs"], "title": "PredefinedWorkflowInferenceRequest"}, "PythonCode": {"properties": {"type": {"type": "string", "const": "PythonCode", "title": "Type"}, "run_function_code": {"type": "string", "title": "Run Function Code", "description": "Code of python function. Content should be properly formatted including indentations. Workflows execution engine is to create dynamic module with provided function - ensuring imports of the following symbols: [Any, List, Dict, Set, sv, np, math, time, json, os, requests, cv2, shapely, Batch, WorkflowImageData, BlockResult]. Expected signature is: def run(self, ... # parameters of manifest apart from name and type). Through self, one may access self._init_results which is dict returned by `init_code` if given."}, "run_function_name": {"type": "string", "title": "Run Function Name", "description": "Name of the function shipped in `function_code`.", "default": "run"}, "init_function_code": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Init Function Code", "description": "Code of the function to perform initialisation of the block. It must be parameter-free function with signature `def init() -> Dict[str, Any]` setting self._init_results on dynamic class initialisation"}, "init_function_name": {"type": "string", "title": "Init Function Name", "description": "Name of init_code function.", "default": "init"}, "imports": {"items": {"type": "string"}, "type": "array", "title": "Imports", "description": "List of additional imports required to run the code"}}, "type": "object", "required": ["type", "run_function_code"], "title": "PythonCode"}, "RTCIceServer": {"properties": {"urls": {"items": {"type": "string"}, "type": "array", "title": "Urls"}, "username": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Username"}, "credential": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Credential"}}, "type": "object", "required": ["urls"], "title": "RTCIceServer"}, "Sam2EmbeddingRequest": {"properties": {"id": {"type": "string", "title": "Id"}, "api_key": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Api Key", "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval"}, "usage_billable": {"type": "boolean", "title": "Usage Billable", "default": true}, "start": {"anyOf": [{"type": "number"}, {"type": "null"}], "title": "Start"}, "source": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Source"}, "source_info": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Source Info"}, "disable_model_monitoring": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Disable Model Monitoring", "description": "If true, disables model monitoring for this request", "default": false}, "sam2_version_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Sam2 Version Id", "description": "The version ID of SAM to be used for this request. Must be one of hiera_tiny, hiera_small, hiera_large, hiera_b_plus", "default": "hiera_large", "examples": ["hiera_large"]}, "model_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Model Id"}, "image": {"anyOf": [{"$ref": "#/components/schemas/InferenceRequestImage"}, {"type": "null"}], "description": "The image to be embedded"}, "image_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Image Id", "description": "The ID of the image to be embedded used to cache the embedding.", "examples": ["image_id"]}}, "type": "object", "required": ["id"], "title": "Sam2EmbeddingRequest", "description": "SAM embedding request.\n\nAttributes:\n    image (Optional[inference.core.entities.requests.inference.InferenceRequestImage]): The image to be embedded.\n    image_id (Optional[str]): The ID of the image to be embedded used to cache the embedding.\n    format (Optional[str]): The format of the response. Must be one of json or binary."}, "Sam2EmbeddingResponse": {"properties": {"image_id": {"type": "string", "title": "Image Id", "description": "Image id embeddings are cached to"}, "time": {"type": "number", "title": "Time", "description": "The time in seconds it took to produce the embeddings including preprocessing"}}, "type": "object", "required": ["image_id", "time"], "title": "Sam2EmbeddingResponse", "description": "SAM embedding response.\n\nAttributes:\n    embeddings (Union[List[List[List[List[float]]]], Any]): The SAM embedding.\n    time (float): The time in seconds it took to produce the embeddings including preprocessing."}, "Sam2Prompt": {"properties": {"box": {"anyOf": [{"$ref": "#/components/schemas/Box"}, {"type": "null"}]}, "points": {"anyOf": [{"items": {"$ref": "#/components/schemas/Point-Input"}, "type": "array"}, {"type": "null"}], "title": "Points"}}, "type": "object", "title": "Sam2Prompt"}, "Sam2PromptSet": {"properties": {"prompts": {"anyOf": [{"items": {"$ref": "#/components/schemas/Sam2Prompt"}, "type": "array"}, {"type": "null"}], "title": "Prompts", "description": "An optional list of prompts for masks to predict. Each prompt can include a bounding box and / or a set of postive or negative points"}}, "type": "object", "title": "Sam2PromptSet"}, "Sam2SegmentationPrediction": {"properties": {"masks": {"anyOf": [{"items": {"items": {"items": {"type": "integer"}, "type": "array"}, "type": "array"}, "type": "array"}, {"additionalProperties": true, "type": "object"}], "title": "Masks", "description": "If polygon format, masks is a list of polygons, where each polygon is a list of points, where each point is a tuple containing the x,y pixel coordinates of the point. If rle format, masks is a dictionary with the keys 'size' and 'counts' containing the size and counts of the RLE encoding."}, "confidence": {"type": "number", "title": "Confidence", "description": "Masks confidences"}, "format": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Format", "description": "Format of the mask data: 'polygon' or 'rle'", "default": "polygon"}}, "type": "object", "required": ["masks", "confidence"], "title": "Sam2SegmentationPrediction", "description": "SAM segmentation prediction.\n\nAttributes:\n    masks (Union[List[List[List[int]]], Dict[str, Any], Any]): Mask data - either polygon coordinates or RLE encoding.\n    confidence (float): Masks confidences.\n    format (Optional[str]): Format of the mask data: 'polygon' or 'rle'."}, "Sam2SegmentationRequest": {"properties": {"id": {"type": "string", "title": "Id"}, "api_key": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Api Key", "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval"}, "usage_billable": {"type": "boolean", "title": "Usage Billable", "default": true}, "start": {"anyOf": [{"type": "number"}, {"type": "null"}], "title": "Start"}, "source": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Source"}, "source_info": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Source Info"}, "disable_model_monitoring": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Disable Model Monitoring", "description": "If true, disables model monitoring for this request", "default": false}, "sam2_version_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Sam2 Version Id", "description": "The version ID of SAM to be used for this request. Must be one of hiera_tiny, hiera_small, hiera_large, hiera_b_plus", "default": "hiera_large", "examples": ["hiera_large"]}, "model_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Model Id"}, "format": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Format", "description": "The format of the response. Must be one of 'json', 'rle', or 'binary'. If binary, masks are returned as binary numpy arrays. If json, masks are converted to polygons. If rle, masks are converted to RLE format.", "default": "json", "examples": ["json"]}, "image": {"$ref": "#/components/schemas/InferenceRequestImage", "description": "The image to be segmented."}, "image_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Image Id", "description": "The ID of the image to be segmented used to retrieve cached embeddings. If an embedding is cached, it will be used instead of generating a new embedding. If no embedding is cached, a new embedding will be generated and cached.", "examples": ["image_id"]}, "prompts": {"$ref": "#/components/schemas/Sam2PromptSet", "description": "A list of prompts for masks to predict. Each prompt can include a bounding box and / or a set of postive or negative points. Also accepts a flat array of prompts (e.g. 'prompts': [{...}, {...}]) for convenience.", "default": {}, "example": [{"prompts": [{"points": [{"positive": true, "x": 100, "y": 100}]}]}]}, "multimask_output": {"type": "boolean", "title": "Multimask Output", "description": "If true, the model will return three masks. For ambiguous input prompts (such as a single click), this will often produce better masks than a single prediction. If only a single mask is needed, the model's predicted quality score can be used to select the best mask. For non-ambiguous prompts, such as multiple input prompts, multimask_output=False can give better results.", "default": true, "examples": [true]}, "save_logits_to_cache": {"type": "boolean", "title": "Save Logits To Cache", "description": "If True, saves the low-resolution logits to the cache for potential future use. This can speed up subsequent requests with similar prompts on the same image. This feature is ignored if DISABLE_SAM2_LOGITS_CACHE env variable is set True", "default": false}, "load_logits_from_cache": {"type": "boolean", "title": "Load Logits From Cache", "description": "If True, attempts to load previously cached low-resolution logits for the given image and prompt set. This can significantly speed up inference when making multiple similar requests on the same image. This feature is ignored if DISABLE_SAM2_LOGITS_CACHE env variable is set True", "default": false}}, "type": "object", "required": ["id", "image"], "title": "Sam2SegmentationRequest", "description": "SAM segmentation request.\n\nAttributes:\n    format (Optional[str]): The format of the response.\n    image (InferenceRequestImage): The image to be segmented.\n    image_id (Optional[str]): The ID of the image to be segmented used to retrieve cached embeddings.\n    point_coords (Optional[List[List[float]]]): The coordinates of the interactive points used during decoding.\n    point_labels (Optional[List[float]]): The labels of the interactive points used during decoding."}, "Sam2SegmentationResponse": {"properties": {"predictions": {"items": {"$ref": "#/components/schemas/Sam2SegmentationPrediction"}, "type": "array", "title": "Predictions"}, "time": {"type": "number", "title": "Time", "description": "The time in seconds it took to produce the segmentation including preprocessing"}}, "type": "object", "required": ["predictions", "time"], "title": "Sam2SegmentationResponse"}, "Sam3EmbeddingResponse": {"properties": {"image_id": {"type": "string", "title": "Image Id", "description": "Image id embeddings are cached to"}, "time": {"type": "number", "title": "Time", "description": "The time in seconds it took to produce the embeddings including preprocessing"}}, "type": "object", "required": ["image_id", "time"], "title": "Sam3EmbeddingResponse"}, "Sam3Prompt": {"properties": {"type": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Type", "description": "Optional hint: 'text' or 'visual'"}, "text": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Text"}, "output_prob_thresh": {"anyOf": [{"type": "number"}, {"type": "null"}], "title": "Output Prob Thresh", "description": "Score threshold for this prompt's outputs. Overrides request-level threshold if set."}, "boxes": {"anyOf": [{"items": {"anyOf": [{"$ref": "#/components/schemas/Box"}, {"$ref": "#/components/schemas/BoxXYXY"}]}, "type": "array"}, {"type": "null"}], "title": "Boxes", "description": "Absolute pixel boxes as either XYWH or XYXY entries"}, "box_labels": {"anyOf": [{"items": {"anyOf": [{"type": "integer"}, {"type": "boolean"}]}, "type": "array"}, {"type": "null"}], "title": "Box Labels", "description": "List of 0/1 or booleans for boxes"}}, "type": "object", "title": "Sam3Prompt", "description": "Unified prompt that can contain text and/or geometry.\n\nAbsolute pixel coordinates are used for boxes. Labels accept 0/1 or booleans."}, "Sam3PromptEcho": {"properties": {"prompt_index": {"type": "integer", "title": "Prompt Index"}, "type": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Type"}, "text": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Text"}, "num_boxes": {"anyOf": [{"type": "integer"}, {"type": "null"}], "title": "Num Boxes"}}, "type": "object", "required": ["prompt_index"], "title": "Sam3PromptEcho"}, "Sam3PromptResult": {"properties": {"prompt_index": {"type": "integer", "title": "Prompt Index"}, "echo": {"$ref": "#/components/schemas/Sam3PromptEcho"}, "predictions": {"items": {"$ref": "#/components/schemas/Sam3SegmentationPrediction"}, "type": "array", "title": "Predictions"}}, "type": "object", "required": ["prompt_index", "echo", "predictions"], "title": "Sam3PromptResult"}, "Sam3SegmentationPrediction": {"properties": {"masks": {"anyOf": [{"items": {"items": {"items": {"type": "integer"}, "type": "array"}, "type": "array"}, "type": "array"}, {"additionalProperties": true, "type": "object"}], "title": "Masks", "description": "Mask data - either polygon coordinates or RLE encoding"}, "confidence": {"type": "number", "title": "Confidence", "description": "Masks confidence"}, "format": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Format", "description": "Format of the mask data: 'polygon' or 'rle'", "default": "polygon"}}, "type": "object", "required": ["masks", "confidence"], "title": "Sam3SegmentationPrediction"}, "Sam3SegmentationRequest": {"properties": {"id": {"type": "string", "title": "Id"}, "api_key": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Api Key", "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval"}, "usage_billable": {"type": "boolean", "title": "Usage Billable", "default": true}, "start": {"anyOf": [{"type": "number"}, {"type": "null"}], "title": "Start"}, "source": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Source"}, "source_info": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Source Info"}, "disable_model_monitoring": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Disable Model Monitoring", "description": "If true, disables model monitoring for this request", "default": false}, "model_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Model Id", "description": "The model ID of SAM3. Use 'sam3/sam3_final' to target the generic base model.", "default": "sam3/sam3_final"}, "format": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Format", "description": "One of 'polygon', 'rle'", "default": "polygon"}, "image": {"$ref": "#/components/schemas/InferenceRequestImage", "description": "The image to be segmented."}, "image_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Image Id", "description": "Optional ID for caching embeddings."}, "output_prob_thresh": {"anyOf": [{"type": "number"}, {"type": "null"}], "title": "Output Prob Thresh", "description": "Score threshold for outputs.", "default": 0.5}, "prompts": {"items": {"$ref": "#/components/schemas/Sam3Prompt"}, "type": "array", "minItems": 1, "title": "Prompts", "description": "List of prompts (text and/or visual)"}, "nms_iou_threshold": {"anyOf": [{"type": "number"}, {"type": "null"}], "title": "Nms Iou Threshold", "description": "IoU threshold for cross-prompt NMS. If None, NMS is disabled. Must be in [0.0, 1.0] when set."}}, "type": "object", "required": ["id", "image", "prompts"], "title": "Sam3SegmentationRequest"}, "Sam3SegmentationResponse": {"properties": {"prompt_results": {"items": {"$ref": "#/components/schemas/Sam3PromptResult"}, "type": "array", "title": "Prompt Results"}, "time": {"type": "number", "title": "Time", "description": "The time in seconds it took to produce the segmentation including preprocessing"}}, "type": "object", "required": ["prompt_results", "time"], "title": "Sam3SegmentationResponse"}, "Sam3_3D_Objects_InferenceRequest": {"properties": {"id": {"type": "string", "title": "Id"}, "api_key": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Api Key", "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval"}, "usage_billable": {"type": "boolean", "title": "Usage Billable", "default": true}, "start": {"anyOf": [{"type": "number"}, {"type": "null"}], "title": "Start"}, "source": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Source"}, "source_info": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Source Info"}, "disable_model_monitoring": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Disable Model Monitoring", "description": "If true, disables model monitoring for this request", "default": false}, "image": {"$ref": "#/components/schemas/InferenceRequestImage", "description": "The input image to be used for 3D generation."}, "mask_input": {"title": "Mask Input", "description": "Mask input in any supported format: polygon [x1,y1,x2,y2,...], binary mask (base64), RLE dict, or list of these."}, "model_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Model Id", "description": "The model ID for SAM3_3D.", "default": "sam3-3d-objects"}, "output_meshes": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Output Meshes", "description": "SAM3 3D always outputs object gaussians, and can optionally output object meshes if output_meshes is True.", "default": true}, "output_scene": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Output Scene", "description": "Output the combined scene reconstruction in addition to individual object reconstructions.", "default": true}, "with_mesh_postprocess": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "With Mesh Postprocess", "description": "Enable mesh postprocessing.", "default": true}, "with_texture_baking": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "With Texture Baking", "description": "Enable texture baking for meshes.", "default": true}, "use_distillations": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Use Distillations", "description": "Use the distilled versions of the model components.", "default": false}}, "type": "object", "required": ["id", "image", "mask_input"], "title": "Sam3_3D_Objects_InferenceRequest", "description": "SAM3D inference request for 3D object generation.\n\nAttributes:\n    api_key (Optional[str]): Roboflow API Key.\n    image (InferenceRequestImage): The input image to be used for 3D generation.\n    mask_input: Mask(s) in any supported format - polygon, binary mask, or RLE."}, "SamEmbeddingRequest": {"properties": {"id": {"type": "string", "title": "Id"}, "api_key": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Api Key", "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval"}, "usage_billable": {"type": "boolean", "title": "Usage Billable", "default": true}, "start": {"anyOf": [{"type": "number"}, {"type": "null"}], "title": "Start"}, "source": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Source"}, "source_info": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Source Info"}, "disable_model_monitoring": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Disable Model Monitoring", "description": "If true, disables model monitoring for this request", "default": false}, "sam_version_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Sam Version Id", "description": "The version ID of SAM to be used for this request. Must be one of vit_h, vit_l, or vit_b.", "default": "vit_h", "examples": ["vit_h"]}, "model_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Model Id"}, "image": {"anyOf": [{"$ref": "#/components/schemas/InferenceRequestImage"}, {"type": "null"}], "description": "The image to be embedded"}, "image_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Image Id", "description": "The ID of the image to be embedded used to cache the embedding.", "examples": ["image_id"]}, "format": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Format", "description": "The format of the response. Must be one of json or binary. If binary, embedding is returned as a binary numpy array.", "default": "json", "examples": ["json"]}}, "type": "object", "required": ["id"], "title": "SamEmbeddingRequest", "description": "SAM embedding request.\n\nAttributes:\n    image (Optional[inference.core.entities.requests.inference.InferenceRequestImage]): The image to be embedded.\n    image_id (Optional[str]): The ID of the image to be embedded used to cache the embedding.\n    format (Optional[str]): The format of the response. Must be one of json or binary."}, "SamEmbeddingResponse": {"properties": {"embeddings": {"anyOf": [{"items": {"items": {"items": {"items": {"type": "number"}, "type": "array"}, "type": "array"}, "type": "array"}, "type": "array"}, {}], "title": "Embeddings", "description": "If request format is json, embeddings is a series of nested lists representing the SAM embedding. If request format is binary, embeddings is a binary numpy array. The dimensions of the embedding are 1 x 256 x 64 x 64.", "examples": ["[[[[0.1, 0.2, 0.3, ...] ...] ...]]"]}, "time": {"type": "number", "title": "Time", "description": "The time in seconds it took to produce the embeddings including preprocessing"}}, "type": "object", "required": ["embeddings", "time"], "title": "SamEmbeddingResponse", "description": "SAM embedding response.\n\nAttributes:\n    embeddings (Union[List[List[List[List[float]]]], Any]): The SAM embedding.\n    time (float): The time in seconds it took to produce the embeddings including preprocessing."}, "SamSegmentationRequest": {"properties": {"id": {"type": "string", "title": "Id"}, "api_key": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Api Key", "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval"}, "usage_billable": {"type": "boolean", "title": "Usage Billable", "default": true}, "start": {"anyOf": [{"type": "number"}, {"type": "null"}], "title": "Start"}, "source": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Source"}, "source_info": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Source Info"}, "disable_model_monitoring": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Disable Model Monitoring", "description": "If true, disables model monitoring for this request", "default": false}, "sam_version_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Sam Version Id", "description": "The version ID of SAM to be used for this request. Must be one of vit_h, vit_l, or vit_b.", "default": "vit_h", "examples": ["vit_h"]}, "model_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Model Id"}, "embeddings": {"anyOf": [{"items": {"items": {"items": {"items": {"type": "number"}, "type": "array"}, "type": "array"}, "type": "array"}, "type": "array"}, {}, {"type": "null"}], "title": "Embeddings", "description": "The embeddings to be decoded. The dimensions of the embeddings are 1 x 256 x 64 x 64. If embeddings is not provided, image must be provided.", "examples": ["[[[[0.1, 0.2, 0.3, ...] ...] ...]]"]}, "embeddings_format": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Embeddings Format", "description": "The format of the embeddings. Must be one of json or binary. If binary, embeddings are expected to be a binary numpy array.", "default": "json", "examples": ["json"]}, "format": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Format", "description": "The format of the response. Must be one of json or binary. If binary, masks are returned as binary numpy arrays. If json, masks are converted to polygons, then returned as json.", "default": "json", "examples": ["json"]}, "image": {"anyOf": [{"$ref": "#/components/schemas/InferenceRequestImage"}, {"type": "null"}], "description": "The image to be segmented. Only required if embeddings are not provided."}, "image_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Image Id", "description": "The ID of the image to be segmented used to retrieve cached embeddings. If an embedding is cached, it will be used instead of generating a new embedding. If no embedding is cached, a new embedding will be generated and cached.", "examples": ["image_id"]}, "has_mask_input": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Has Mask Input", "description": "Whether or not the request includes a mask input. If true, the mask input must be provided.", "default": false, "examples": [true]}, "mask_input": {"anyOf": [{"items": {"items": {"items": {"type": "number"}, "type": "array"}, "type": "array"}, "type": "array"}, {}, {"type": "null"}], "title": "Mask Input", "description": "The set of output masks. If request format is json, masks is a list of polygons, where each polygon is a list of points, where each point is a tuple containing the x,y pixel coordinates of the point. If request format is binary, masks is a list of binary numpy arrays. The dimensions of each mask are 256 x 256. This is the same as the output, low resolution mask from the previous inference."}, "mask_input_format": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Mask Input Format", "description": "The format of the mask input. Must be one of json or binary. If binary, mask input is expected to be a binary numpy array.", "default": "json", "examples": ["json"]}, "orig_im_size": {"anyOf": [{"items": {"type": "integer"}, "type": "array"}, {"type": "null"}], "title": "Orig Im Size", "description": "The original size of the image used to generate the embeddings. This is only required if the image is not provided.", "examples": [[640, 320]]}, "point_coords": {"anyOf": [{"items": {"items": {"type": "number"}, "type": "array"}, "type": "array"}, {"type": "null"}], "title": "Point Coords", "description": "The coordinates of the interactive points used during decoding. Each point (x,y pair) corresponds to a label in point_labels.", "default": [[0.0, 0.0]], "examples": [[[10.0, 10.0]]]}, "point_labels": {"anyOf": [{"items": {"type": "number"}, "type": "array"}, {"type": "null"}], "title": "Point Labels", "description": "The labels of the interactive points used during decoding. A 1 represents a positive point (part of the object to be segmented). A -1 represents a negative point (not part of the object to be segmented). Each label corresponds to a point in point_coords.", "default": [-1], "examples": [[1]]}, "use_mask_input_cache": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Use Mask Input Cache", "description": "Whether or not to use the mask input cache. If true, the mask input cache will be used if it exists. If false, the mask input cache will not be used.", "default": true, "examples": [true]}}, "type": "object", "required": ["id"], "title": "SamSegmentationRequest", "description": "SAM segmentation request.\n\nAttributes:\n    embeddings (Optional[Union[List[List[List[List[float]]]], Any]]): The embeddings to be decoded.\n    embeddings_format (Optional[str]): The format of the embeddings.\n    format (Optional[str]): The format of the response.\n    image (Optional[InferenceRequestImage]): The image to be segmented.\n    image_id (Optional[str]): The ID of the image to be segmented used to retrieve cached embeddings.\n    has_mask_input (Optional[bool]): Whether or not the request includes a mask input.\n    mask_input (Optional[Union[List[List[List[float]]], Any]]): The set of output masks.\n    mask_input_format (Optional[str]): The format of the mask input.\n    orig_im_size (Optional[List[int]]): The original size of the image used to generate the embeddings.\n    point_coords (Optional[List[List[float]]]): The coordinates of the interactive points used during decoding.\n    point_labels (Optional[List[float]]): The labels of the interactive points used during decoding.\n    use_mask_input_cache (Optional[bool]): Whether or not to use the mask input cache."}, "SamSegmentationResponse": {"properties": {"masks": {"anyOf": [{"items": {"items": {"items": {"type": "integer"}, "type": "array"}, "type": "array"}, "type": "array"}, {}], "title": "Masks", "description": "The set of output masks. If request format is json, masks is a list of polygons, where each polygon is a list of points, where each point is a tuple containing the x,y pixel coordinates of the point. If request format is binary, masks is a list of binary numpy arrays. The dimensions of each mask are the same as the dimensions of the input image."}, "low_res_masks": {"anyOf": [{"items": {"items": {"items": {"type": "integer"}, "type": "array"}, "type": "array"}, "type": "array"}, {}], "title": "Low Res Masks", "description": "The set of output masks. If request format is json, masks is a list of polygons, where each polygon is a list of points, where each point is a tuple containing the x,y pixel coordinates of the point. If request format is binary, masks is a list of binary numpy arrays. The dimensions of each mask are 256 x 256"}, "time": {"type": "number", "title": "Time", "description": "The time in seconds it took to produce the segmentation including preprocessing"}}, "type": "object", "required": ["masks", "low_res_masks", "time"], "title": "SamSegmentationResponse", "description": "SAM segmentation response.\n\nAttributes:\n    masks (Union[List[List[List[int]]], Any]): The set of output masks.\n    low_res_masks (Union[List[List[List[int]]], Any]): The set of output low-resolution masks.\n    time (float): The time in seconds it took to produce the segmentation including preprocessing."}, "SelectorType": {"type": "string", "enum": ["input_image", "step_output_image", "input_parameter", "step_output", "generic"], "title": "SelectorType"}, "SemanticSegmentationInferenceRequest": {"properties": {"id": {"type": "string", "title": "Id"}, "api_key": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Api Key", "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval"}, "usage_billable": {"type": "boolean", "title": "Usage Billable", "default": true}, "start": {"anyOf": [{"type": "number"}, {"type": "null"}], "title": "Start"}, "source": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Source"}, "source_info": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Source Info"}, "disable_model_monitoring": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Disable Model Monitoring", "description": "If true, disables model monitoring for this request", "default": false}, "model_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Model Id", "description": "A unique model identifier", "example": "raccoon-detector-1"}, "model_type": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Model Type", "description": "The type of the model, usually referring to what task the model performs", "examples": ["object-detection"]}, "image": {"anyOf": [{"items": {"$ref": "#/components/schemas/InferenceRequestImage"}, "type": "array"}, {"$ref": "#/components/schemas/InferenceRequestImage"}], "title": "Image"}, "disable_preproc_auto_orient": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Disable Preproc Auto Orient", "description": "If true, the auto orient preprocessing step is disabled for this call.", "default": false}, "disable_preproc_contrast": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Disable Preproc Contrast", "description": "If true, the auto contrast preprocessing step is disabled for this call.", "default": false}, "disable_preproc_grayscale": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Disable Preproc Grayscale", "description": "If true, the grayscale preprocessing step is disabled for this call.", "default": false}, "disable_preproc_static_crop": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Disable Preproc Static Crop", "description": "If true, the static crop preprocessing step is disabled for this call.", "default": false}}, "type": "object", "required": ["id", "model_id", "image"], "title": "SemanticSegmentationInferenceRequest", "description": "Semantic Segmentation inference request."}, "SemanticSegmentationInferenceResponse": {"properties": {"visualization": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Visualization", "description": "Base64 encoded string containing prediction visualization image data"}, "inference_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Inference Id", "description": "Unique identifier of inference"}, "frame_id": {"anyOf": [{"type": "integer"}, {"type": "null"}], "title": "Frame Id", "description": "The frame id of the image used in inference if the input was a video"}, "time": {"anyOf": [{"type": "number"}, {"type": "null"}], "title": "Time", "description": "The time in seconds it took to produce the predictions including image preprocessing"}, "image": {"anyOf": [{"items": {"$ref": "#/components/schemas/InferenceResponseImage"}, "type": "array"}, {"$ref": "#/components/schemas/InferenceResponseImage"}], "title": "Image"}, "predictions": {"$ref": "#/components/schemas/SemanticSegmentationPrediction"}}, "type": "object", "required": ["image", "predictions"], "title": "SemanticSegmentationInferenceResponse", "description": "Semantic Segmentation inference response.\n\nAttributes:\n    predictions (inference.core.entities.responses.inference.SemanticSegmentationPrediction): Semantic segmentation predictions."}, "SemanticSegmentationPrediction": {"properties": {"segmentation_mask": {"type": "string", "title": "Segmentation Mask", "description": "base64-encoded PNG of predicted class label at each pixel"}, "class_map": {"additionalProperties": {"type": "string"}, "type": "object", "title": "Class Map", "description": "Map of pixel intensity value to class label"}, "confidence_mask": {"type": "string", "title": "Confidence Mask", "description": "base64-encoded PNG of predicted class confidence at each pixel"}}, "type": "object", "required": ["segmentation_mask", "class_map", "confidence_mask"], "title": "SemanticSegmentationPrediction"}, "ServerVersionInfo": {"properties": {"name": {"type": "string", "title": "Name", "examples": ["Roboflow Inference Server"]}, "version": {"type": "string", "title": "Version", "examples": ["0.0.1"]}, "uuid": {"type": "string", "title": "Uuid", "examples": ["9c18c6f4-2266-41fb-8a0f-c12ae28f6fbe"]}}, "type": "object", "required": ["name", "version", "uuid"], "title": "ServerVersionInfo", "description": "Server version information.\n\nAttributes:\n    name (str): Server name.\n    version (str): Server version.\n    uuid (str): Server UUID."}, "StubResponse": {"properties": {"visualization": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Visualization", "description": "Base64 encoded string containing prediction visualization image data"}, "inference_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Inference Id", "description": "Unique identifier of inference"}, "frame_id": {"anyOf": [{"type": "integer"}, {"type": "null"}], "title": "Frame Id", "description": "The frame id of the image used in inference if the input was a video"}, "time": {"anyOf": [{"type": "number"}, {"type": "null"}], "title": "Time", "description": "The time in seconds it took to produce the predictions including image preprocessing"}, "is_stub": {"type": "boolean", "title": "Is Stub", "description": "Field to mark prediction type as stub"}, "model_id": {"type": "string", "title": "Model Id", "description": "Identifier of a model stub that was called"}, "task_type": {"type": "string", "title": "Task Type", "description": "Task type of the project"}}, "type": "object", "required": ["is_stub", "model_id", "task_type"], "title": "StubResponse"}, "TrOCRInferenceRequest": {"properties": {"id": {"type": "string", "title": "Id"}, "api_key": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Api Key", "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval"}, "usage_billable": {"type": "boolean", "title": "Usage Billable", "default": true}, "start": {"anyOf": [{"type": "number"}, {"type": "null"}], "title": "Start"}, "source": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Source"}, "source_info": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Source Info"}, "disable_model_monitoring": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Disable Model Monitoring", "description": "If true, disables model monitoring for this request", "default": false}, "image": {"anyOf": [{"items": {"$ref": "#/components/schemas/InferenceRequestImage"}, "type": "array"}, {"$ref": "#/components/schemas/InferenceRequestImage"}], "title": "Image"}, "trocr_version_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Trocr Version Id", "default": "trocr-base-printed"}, "model_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Model Id"}}, "type": "object", "required": ["id", "image"], "title": "TrOCRInferenceRequest", "description": "TrOCR inference request.\n\nAttributes:\n    api_key (Optional[str]): Roboflow API Key."}, "UniversalQueryLanguageDescription": {"properties": {"operations_description": {"items": {"$ref": "#/components/schemas/ExternalOperationDescription"}, "type": "array", "title": "Operations Description"}, "operators_descriptions": {"items": {"$ref": "#/components/schemas/ExternalOperatorDescription"}, "type": "array", "title": "Operators Descriptions"}}, "type": "object", "required": ["operations_description", "operators_descriptions"], "title": "UniversalQueryLanguageDescription"}, "ValidationError": {"properties": {"loc": {"items": {"anyOf": [{"type": "string"}, {"type": "integer"}]}, "type": "array", "title": "Location"}, "msg": {"type": "string", "title": "Message"}, "type": {"type": "string", "title": "Error Type"}}, "type": "object", "required": ["loc", "msg", "type"], "title": "ValidationError"}, "ValueType": {"type": "string", "enum": ["any", "integer", "float", "boolean", "dict", "list", "string"], "title": "ValueType"}, "WebRTCConfig": {"properties": {"iceServers": {"items": {"$ref": "#/components/schemas/RTCIceServer"}, "type": "array", "title": "Iceservers"}}, "type": "object", "required": ["iceServers"], "title": "WebRTCConfig"}, "WebRTCOffer": {"properties": {"type": {"type": "string", "title": "Type"}, "sdp": {"type": "string", "title": "Sdp"}}, "type": "object", "required": ["type", "sdp"], "title": "WebRTCOffer"}, "WebRTCTURNConfig": {"properties": {"urls": {"type": "string", "title": "Urls"}, "username": {"type": "string", "title": "Username"}, "credential": {"type": "string", "title": "Credential"}}, "type": "object", "required": ["urls", "username", "credential"], "title": "WebRTCTURNConfig"}, "WebRTCWorkerRequest": {"properties": {"api_key": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Api Key"}, "workflow_configuration": {"$ref": "#/components/schemas/WorkflowConfiguration"}, "is_preview": {"type": "boolean", "title": "Is Preview", "default": false}, "webrtc_offer": {"$ref": "#/components/schemas/WebRTCOffer"}, "webrtc_config": {"anyOf": [{"$ref": "#/components/schemas/WebRTCConfig"}, {"type": "null"}]}, "webrtc_turn_config": {"anyOf": [{"$ref": "#/components/schemas/WebRTCTURNConfig"}, {"type": "null"}]}, "webrtc_realtime_processing": {"type": "boolean", "title": "Webrtc Realtime Processing", "default": true}, "stream_output": {"anyOf": [{"items": {"type": "string"}, "type": "array"}, {"type": "null"}], "title": "Stream Output"}, "data_output": {"anyOf": [{"items": {"type": "string"}, "type": "array"}, {"type": "null"}], "title": "Data Output"}, "declared_fps": {"anyOf": [{"type": "number"}, {"type": "null"}], "title": "Declared Fps"}, "rtsp_url": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Rtsp Url"}, "mjpeg_url": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Mjpeg Url"}, "processing_timeout": {"anyOf": [{"type": "integer"}, {"type": "null"}], "title": "Processing Timeout", "default": 3600}, "processing_session_started": {"anyOf": [{"type": "string", "format": "date-time"}, {"type": "null"}], "title": "Processing Session Started"}, "requested_plan": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Requested Plan", "default": "webrtc-gpu-small"}, "requested_gpu": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Requested Gpu"}, "requested_region": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Requested Region"}}, "type": "object", "required": ["workflow_configuration", "webrtc_offer"], "title": "WebRTCWorkerRequest"}, "WorkflowConfiguration": {"properties": {"type": {"type": "string", "const": "WorkflowConfiguration", "title": "Type"}, "workflow_specification": {"anyOf": [{"additionalProperties": true, "type": "object"}, {"type": "null"}], "title": "Workflow Specification"}, "workspace_name": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Workspace Name"}, "workflow_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Workflow Id"}, "workflow_version_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Workflow Version Id"}, "image_input_name": {"type": "string", "title": "Image Input Name", "default": "image"}, "workflows_parameters": {"anyOf": [{"additionalProperties": true, "type": "object"}, {"type": "null"}], "title": "Workflows Parameters"}, "workflows_thread_pool_workers": {"type": "integer", "title": "Workflows Thread Pool Workers", "default": 4}, "cancel_thread_pool_tasks_on_exit": {"type": "boolean", "title": "Cancel Thread Pool Tasks On Exit", "default": true}, "video_metadata_input_name": {"type": "string", "title": "Video Metadata Input Name", "default": "video_metadata"}}, "type": "object", "required": ["type"], "title": "WorkflowConfiguration"}, "WorkflowInferenceResponse": {"properties": {"outputs": {"items": {"additionalProperties": true, "type": "object"}, "type": "array", "title": "Outputs", "description": "Dictionary with keys defined in workflow output and serialised values"}, "profiler_trace": {"anyOf": [{"items": {"additionalProperties": true, "type": "object"}, "type": "array"}, {"type": "null"}], "title": "Profiler Trace", "description": "Profiler events"}}, "type": "object", "required": ["outputs"], "title": "WorkflowInferenceResponse"}, "WorkflowSpecificationDescribeInterfaceRequest": {"properties": {"api_key": {"type": "string", "title": "Api Key", "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval"}, "specification": {"additionalProperties": true, "type": "object", "title": "Specification"}}, "type": "object", "required": ["api_key", "specification"], "title": "WorkflowSpecificationDescribeInterfaceRequest"}, "WorkflowSpecificationInferenceRequest": {"properties": {"api_key": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Api Key", "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval"}, "inputs": {"additionalProperties": true, "type": "object", "title": "Inputs", "description": "Dictionary that contains each parameter defined as an input for chosen workflow"}, "excluded_fields": {"anyOf": [{"items": {"type": "string"}, "type": "array"}, {"type": "null"}], "title": "Excluded Fields", "description": "List of field that shall be excluded from the response (among those defined in workflow specification)"}, "enable_profiling": {"type": "boolean", "title": "Enable Profiling", "description": "Flag to request Workflow run profiling. Enables Workflow profiler only when server settings allow profiling traces to be exported to clients. Only applies for Workflows definitions saved on Roboflow platform.", "default": false}, "workflow_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Workflow Id", "description": "Optional identifier of workflow"}, "specification": {"additionalProperties": true, "type": "object", "title": "Specification"}, "is_preview": {"type": "boolean", "title": "Is Preview", "description": "Reserved, used internally by Roboflow to distinguish between preview and non-preview runs", "default": false}}, "type": "object", "required": ["inputs", "specification"], "title": "WorkflowSpecificationInferenceRequest"}, "WorkflowValidationStatus": {"properties": {"status": {"type": "string", "title": "Status", "description": "Represents validation status"}}, "type": "object", "required": ["status"], "title": "WorkflowValidationStatus"}, "WorkflowsBlocksDescription": {"properties": {"blocks": {"items": {"$ref": "#/components/schemas/BlockDescription"}, "type": "array", "title": "Blocks", "description": "List of loaded blocks descriptions"}, "declared_kinds": {"items": {"$ref": "#/components/schemas/Kind"}, "type": "array", "title": "Declared Kinds", "description": "List of kinds defined for blocks"}, "kinds_connections": {"additionalProperties": {"items": {"$ref": "#/components/schemas/ExternalWorkflowsBlockSelectorDefinition"}, "type": "array"}, "type": "object", "title": "Kinds Connections", "description": "Mapping from kind name into list of blocks properties accepting references of that kind"}, "primitives_connections": {"items": {"$ref": "#/components/schemas/ExternalBlockPropertyPrimitiveDefinition"}, "type": "array", "title": "Primitives Connections", "description": "List defining all properties for all blocks that can be filled with primitive values in workflow definition."}, "universal_query_language_description": {"$ref": "#/components/schemas/UniversalQueryLanguageDescription", "description": "Definitions of Universal Query Language operations and operators"}, "dynamic_block_definition_schema": {"additionalProperties": true, "type": "object", "title": "Dynamic Block Definition Schema", "description": "Schema for dynamic block definition"}}, "type": "object", "required": ["blocks", "declared_kinds", "kinds_connections", "primitives_connections", "universal_query_language_description", "dynamic_block_definition_schema"], "title": "WorkflowsBlocksDescription"}, "WorkflowsBlocksSchemaDescription": {"properties": {"schema": {"additionalProperties": true, "type": "object", "title": "Schema", "description": "Schema for validating block definitions"}}, "type": "object", "required": ["schema"], "title": "WorkflowsBlocksSchemaDescription"}, "YOLOWorldInferenceRequest": {"properties": {"id": {"type": "string", "title": "Id"}, "api_key": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Api Key", "description": "Roboflow API Key that will be passed to the model during initialization for artifact retrieval"}, "usage_billable": {"type": "boolean", "title": "Usage Billable", "default": true}, "start": {"anyOf": [{"type": "number"}, {"type": "null"}], "title": "Start"}, "source": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Source"}, "source_info": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Source Info"}, "disable_model_monitoring": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Disable Model Monitoring", "description": "If true, disables model monitoring for this request", "default": false}, "model_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Model Id"}, "model_type": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Model Type", "description": "The type of the model, usually referring to what task the model performs", "examples": ["object-detection"]}, "image": {"anyOf": [{"items": {"$ref": "#/components/schemas/InferenceRequestImage"}, "type": "array"}, {"$ref": "#/components/schemas/InferenceRequestImage"}], "title": "Image"}, "disable_preproc_auto_orient": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Disable Preproc Auto Orient", "description": "If true, the auto orient preprocessing step is disabled for this call.", "default": false}, "disable_preproc_contrast": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Disable Preproc Contrast", "description": "If true, the auto contrast preprocessing step is disabled for this call.", "default": false}, "disable_preproc_grayscale": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Disable Preproc Grayscale", "description": "If true, the grayscale preprocessing step is disabled for this call.", "default": false}, "disable_preproc_static_crop": {"anyOf": [{"type": "boolean"}, {"type": "null"}], "title": "Disable Preproc Static Crop", "description": "If true, the static crop preprocessing step is disabled for this call.", "default": false}, "text": {"items": {"type": "string"}, "type": "array", "title": "Text", "description": "A list of strings", "examples": [["person", "dog", "cat"]]}, "yolo_world_version_id": {"anyOf": [{"type": "string"}, {"type": "null"}], "title": "Yolo World Version Id", "default": "l"}, "confidence": {"anyOf": [{"type": "number"}, {"type": "null"}], "title": "Confidence", "default": 0.4}}, "type": "object", "required": ["id", "image", "text"], "title": "YOLOWorldInferenceRequest", "description": "Request for Grounding DINO zero-shot predictions.\n\nAttributes:\n    text (List[str]): A list of strings."}}}}