
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Scalable, on-device computer vision deployment.">
      
      
        <meta name="author" content="Roboflow">
      
      
        <link rel="canonical" href="https://inference.roboflow.com/reference/inference_sdk/http/client/">
      
      
        <link rel="prev" href="../../config/">
      
      
        <link rel="next" href="../entities/">
      
      
        
      
      
      <link rel="icon" href="../../../../favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.4+insiders-4.53.15">
    
    
      
        <title>Client - Roboflow Inference</title>
      
    
    
      <link rel="stylesheet" href="../../../../assets/stylesheets/main.f15084e1.min.css">
      
        
        <link rel="stylesheet" href="../../../../assets/stylesheets/palette.ab4e12ef.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Inter:300,300i,400,400i,700,700i%7Cui-monospace:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Inter";--md-code-font:"ui-monospace"}</style>
      
    
    
      <link rel="stylesheet" href="../../../../assets/_mkdocstrings.css">
    
      <link rel="stylesheet" href="../../../../styles/cookbooks.css">
    
      <link rel="stylesheet" href="../../../../styles.css">
    
    <script>__md_scope=new URL("../../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      
  


  
  

<script id="__analytics">function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-T0CED2YY8K"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-T0CED2YY8K",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-T0CED2YY8K",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script>
  
    <script>"undefined"!=typeof __md_analytics&&__md_analytics()</script>
  

    
    
  
  

  
<meta property="og:type" content="website" />
<meta property="og:title" content="Client - Roboflow Inference" />
<meta property="og:description" content="Scalable, on-device computer vision deployment." />
<meta property="og:image" content="https://inference.roboflow.com/assets/images/social/reference/inference_sdk/http/client.png" />
<meta property="og:image:type" content="image/png" />
<meta property="og:image:width" content="1200" />
<meta property="og:image:height" content="630" />
<meta property="og:url" content="https://inference.roboflow.com/reference/inference_sdk/http/client/" />
<meta property="twitter:card" content="summary_large_image" />
<meta property="twitter:title" content="Client - Roboflow Inference" />
<meta property="twitter:description" content="Scalable, on-device computer vision deployment." />
<meta property="twitter:image" content="https://inference.roboflow.com/assets/images/social/reference/inference_sdk/http/client.png" />
</head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="custom" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#inference_sdk.http.client" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <div data-md-color-scheme="default" data-md-component="outdated" hidden>
        
      </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../../.." title="Roboflow Inference" class="md-header__button md-logo" aria-label="Roboflow Inference" data-md-component="logo">
      
  <img src="../../../../roboflow-logomark-white.svg" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Roboflow Inference
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Client
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="custom" data-md-color-accent="indigo"  aria-hidden="true"  type="radio" name="__palette" id="__palette_0">
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="Share" aria-label="Share" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/roboflow/inference" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    roboflow/inference
  </div>
</a>
      </div>
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../../start/overview/" class="md-tabs__link">
          
  
    
  
  Start

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../../quickstart/run_a_model/" class="md-tabs__link">
          
  
    
  
  Models

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../../workflows/about/" class="md-tabs__link">
          
  
    
  
  Workflows

        </a>
      </li>
    
  

      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../../../../quickstart/roboflow_ecosystem/" class="md-tabs__link">
          
  
    
  
  Reference

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../../workflows/gallery/basic_workflows/" class="md-tabs__link">
          
  
    
  
  Examples

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
  
        
      
  

      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../../.." title="Roboflow Inference" class="md-nav__button md-logo" aria-label="Roboflow Inference" data-md-component="logo">
      
  <img src="../../../../roboflow-logomark-white.svg" alt="logo">

    </a>
    Roboflow Inference
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/roboflow/inference" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    roboflow/inference
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../../start/overview/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    
  
    Start
  

    
  </span>
  
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../../quickstart/run_a_model/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    
  
    Models
  

    
  </span>
  
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../../workflows/about/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    
  
    Workflows
  

    
  </span>
  
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
        
        
      
      
    
    
      
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" checked>
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="">
            
  
  <span class="md-ellipsis">
    
  
    Reference
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            
  
    Reference
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../quickstart/roboflow_ecosystem/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    
  
    Roboflow Ecosystem
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../using_inference/inference_pipeline/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    
  
    InferencePipeline
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
      
        
      
        
      
    
    
      
      
    
    
      
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_3" checked>
        
          
          <label class="md-nav__link" for="__nav_4_3" id="__nav_4_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    
  
    Python SDK
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_4_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    Python SDK
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../inference_helpers/inference_sdk/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    
  
    Inference Client
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
      
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_3_2" checked>
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    
  
    Reference
  

    
  </span>
  
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_4_3_2" id="__nav_4_3_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_4_3_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_4_3_2">
            <span class="md-nav__icon md-icon"></span>
            
  
    Reference
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../config/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    
  
    Config
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
      
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_3_2_3" checked>
        
          
          <label class="md-nav__link" for="__nav_4_3_2_3" id="__nav_4_3_2_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    
  
    Http
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_4_3_2_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_4_3_2_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    Http
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    
  
    Client
  

    
  </span>
  
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    
  
    Client
  

    
  </span>
  
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#inference_sdk.http.client" class="md-nav__link">
    <span class="md-ellipsis">
      
        client
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient" class="md-nav__link">
    <span class="md-ellipsis">
      
        InferenceHTTPClient
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="InferenceHTTPClient">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.client_mode" class="md-nav__link">
    <span class="md-ellipsis">
      
        client_mode
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.inference_configuration" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference_configuration
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.selected_model" class="md-nav__link">
    <span class="md-ellipsis">
      
        selected_model
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.webrtc" class="md-nav__link">
    <span class="md-ellipsis">
      
        webrtc
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      
        __init__
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.clip_compare" class="md-nav__link">
    <span class="md-ellipsis">
      
        clip_compare
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.clip_compare_async" class="md-nav__link">
    <span class="md-ellipsis">
      
        clip_compare_async
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.configure" class="md-nav__link">
    <span class="md-ellipsis">
      
        configure
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.consume_inference_pipeline_result" class="md-nav__link">
    <span class="md-ellipsis">
      
        consume_inference_pipeline_result
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.depth_estimation" class="md-nav__link">
    <span class="md-ellipsis">
      
        depth_estimation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.depth_estimation_async" class="md-nav__link">
    <span class="md-ellipsis">
      
        depth_estimation_async
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.detect_gazes" class="md-nav__link">
    <span class="md-ellipsis">
      
        detect_gazes
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.detect_gazes_async" class="md-nav__link">
    <span class="md-ellipsis">
      
        detect_gazes_async
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.get_clip_image_embeddings" class="md-nav__link">
    <span class="md-ellipsis">
      
        get_clip_image_embeddings
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.get_clip_image_embeddings_async" class="md-nav__link">
    <span class="md-ellipsis">
      
        get_clip_image_embeddings_async
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.get_clip_text_embeddings" class="md-nav__link">
    <span class="md-ellipsis">
      
        get_clip_text_embeddings
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.get_clip_text_embeddings_async" class="md-nav__link">
    <span class="md-ellipsis">
      
        get_clip_text_embeddings_async
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.get_inference_pipeline_status" class="md-nav__link">
    <span class="md-ellipsis">
      
        get_inference_pipeline_status
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.get_model_description" class="md-nav__link">
    <span class="md-ellipsis">
      
        get_model_description
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.get_model_description_async" class="md-nav__link">
    <span class="md-ellipsis">
      
        get_model_description_async
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.get_perception_encoder_image_embeddings" class="md-nav__link">
    <span class="md-ellipsis">
      
        get_perception_encoder_image_embeddings
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.get_perception_encoder_text_embeddings" class="md-nav__link">
    <span class="md-ellipsis">
      
        get_perception_encoder_text_embeddings
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.get_server_info" class="md-nav__link">
    <span class="md-ellipsis">
      
        get_server_info
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.infer" class="md-nav__link">
    <span class="md-ellipsis">
      
        infer
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.infer_async" class="md-nav__link">
    <span class="md-ellipsis">
      
        infer_async
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.infer_from_api_v0" class="md-nav__link">
    <span class="md-ellipsis">
      
        infer_from_api_v0
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.infer_from_api_v0_async" class="md-nav__link">
    <span class="md-ellipsis">
      
        infer_from_api_v0_async
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.infer_from_workflow" class="md-nav__link">
    <span class="md-ellipsis">
      
        infer_from_workflow
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.infer_from_yolo_world" class="md-nav__link">
    <span class="md-ellipsis">
      
        infer_from_yolo_world
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.infer_from_yolo_world_async" class="md-nav__link">
    <span class="md-ellipsis">
      
        infer_from_yolo_world_async
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.infer_lmm" class="md-nav__link">
    <span class="md-ellipsis">
      
        infer_lmm
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.infer_lmm_async" class="md-nav__link">
    <span class="md-ellipsis">
      
        infer_lmm_async
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.infer_on_stream" class="md-nav__link">
    <span class="md-ellipsis">
      
        infer_on_stream
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.init" class="md-nav__link">
    <span class="md-ellipsis">
      
        init
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.list_inference_pipelines" class="md-nav__link">
    <span class="md-ellipsis">
      
        list_inference_pipelines
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.list_loaded_models" class="md-nav__link">
    <span class="md-ellipsis">
      
        list_loaded_models
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.list_loaded_models_async" class="md-nav__link">
    <span class="md-ellipsis">
      
        list_loaded_models_async
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.load_model" class="md-nav__link">
    <span class="md-ellipsis">
      
        load_model
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.load_model_async" class="md-nav__link">
    <span class="md-ellipsis">
      
        load_model_async
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.ocr_image" class="md-nav__link">
    <span class="md-ellipsis">
      
        ocr_image
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.ocr_image_async" class="md-nav__link">
    <span class="md-ellipsis">
      
        ocr_image_async
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.pause_inference_pipeline" class="md-nav__link">
    <span class="md-ellipsis">
      
        pause_inference_pipeline
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.resume_inference_pipeline" class="md-nav__link">
    <span class="md-ellipsis">
      
        resume_inference_pipeline
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.run_workflow" class="md-nav__link">
    <span class="md-ellipsis">
      
        run_workflow
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.sam2_segment_image" class="md-nav__link">
    <span class="md-ellipsis">
      
        sam2_segment_image
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.sam2_segment_image_async" class="md-nav__link">
    <span class="md-ellipsis">
      
        sam2_segment_image_async
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.sam3_3d_infer" class="md-nav__link">
    <span class="md-ellipsis">
      
        sam3_3d_infer
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.sam3_3d_infer_async" class="md-nav__link">
    <span class="md-ellipsis">
      
        sam3_3d_infer_async
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.sam3_concept_segment" class="md-nav__link">
    <span class="md-ellipsis">
      
        sam3_concept_segment
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.sam3_concept_segment_async" class="md-nav__link">
    <span class="md-ellipsis">
      
        sam3_concept_segment_async
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.sam3_embed_image" class="md-nav__link">
    <span class="md-ellipsis">
      
        sam3_embed_image
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.sam3_embed_image_async" class="md-nav__link">
    <span class="md-ellipsis">
      
        sam3_embed_image_async
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.sam3_visual_segment" class="md-nav__link">
    <span class="md-ellipsis">
      
        sam3_visual_segment
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.sam3_visual_segment_async" class="md-nav__link">
    <span class="md-ellipsis">
      
        sam3_visual_segment_async
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.select_api_v0" class="md-nav__link">
    <span class="md-ellipsis">
      
        select_api_v0
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.select_api_v1" class="md-nav__link">
    <span class="md-ellipsis">
      
        select_api_v1
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.select_model" class="md-nav__link">
    <span class="md-ellipsis">
      
        select_model
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.start_inference_pipeline_with_workflow" class="md-nav__link">
    <span class="md-ellipsis">
      
        start_inference_pipeline_with_workflow
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.terminate_inference_pipeline" class="md-nav__link">
    <span class="md-ellipsis">
      
        terminate_inference_pipeline
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.unload_model" class="md-nav__link">
    <span class="md-ellipsis">
      
        unload_model
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.use_api_v0" class="md-nav__link">
    <span class="md-ellipsis">
      
        use_api_v0
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.use_api_v1" class="md-nav__link">
    <span class="md-ellipsis">
      
        use_api_v1
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.use_configuration" class="md-nav__link">
    <span class="md-ellipsis">
      
        use_configuration
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.use_model" class="md-nav__link">
    <span class="md-ellipsis">
      
        use_model
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../entities/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    
  
    Entities
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../errors/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    
  
    Errors
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../utils/aliases/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    
  
    Utils
  

    
  </span>
  
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
      
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../utils/decorators/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    
  
    Utils
  

    
  </span>
  
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../webrtc/client/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    
  
    Webrtc
  

    
  </span>
  
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../../inference_helpers/inference_cli/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    
  
    Command Line Interface
  

    
  </span>
  
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
      
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../../api/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    
  
    HTTP API
  

    
  </span>
  
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../inference/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    
  
    inference Python Package
  

    
  </span>
  
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
      
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../../enterprise/parallel_processing/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    
  
    Enterprise Features
  

    
  </span>
  
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../../quickstart/docker/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    
  
    Server Configuration
  

    
  </span>
  
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../using_inference/offline_weights_download/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    
  
    Model Weights Download
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../contributing/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    
  
    Contribute to Inference
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://github.com/roboflow/inference/releases" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    
  
    Changelog
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../../workflows/gallery/basic_workflows/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    
  
    Examples
  

    
  </span>
  
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#inference_sdk.http.client" class="md-nav__link">
    <span class="md-ellipsis">
      
        client
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient" class="md-nav__link">
    <span class="md-ellipsis">
      
        InferenceHTTPClient
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="InferenceHTTPClient">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.client_mode" class="md-nav__link">
    <span class="md-ellipsis">
      
        client_mode
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.inference_configuration" class="md-nav__link">
    <span class="md-ellipsis">
      
        inference_configuration
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.selected_model" class="md-nav__link">
    <span class="md-ellipsis">
      
        selected_model
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.webrtc" class="md-nav__link">
    <span class="md-ellipsis">
      
        webrtc
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      
        __init__
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.clip_compare" class="md-nav__link">
    <span class="md-ellipsis">
      
        clip_compare
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.clip_compare_async" class="md-nav__link">
    <span class="md-ellipsis">
      
        clip_compare_async
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.configure" class="md-nav__link">
    <span class="md-ellipsis">
      
        configure
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.consume_inference_pipeline_result" class="md-nav__link">
    <span class="md-ellipsis">
      
        consume_inference_pipeline_result
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.depth_estimation" class="md-nav__link">
    <span class="md-ellipsis">
      
        depth_estimation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.depth_estimation_async" class="md-nav__link">
    <span class="md-ellipsis">
      
        depth_estimation_async
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.detect_gazes" class="md-nav__link">
    <span class="md-ellipsis">
      
        detect_gazes
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.detect_gazes_async" class="md-nav__link">
    <span class="md-ellipsis">
      
        detect_gazes_async
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.get_clip_image_embeddings" class="md-nav__link">
    <span class="md-ellipsis">
      
        get_clip_image_embeddings
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.get_clip_image_embeddings_async" class="md-nav__link">
    <span class="md-ellipsis">
      
        get_clip_image_embeddings_async
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.get_clip_text_embeddings" class="md-nav__link">
    <span class="md-ellipsis">
      
        get_clip_text_embeddings
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.get_clip_text_embeddings_async" class="md-nav__link">
    <span class="md-ellipsis">
      
        get_clip_text_embeddings_async
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.get_inference_pipeline_status" class="md-nav__link">
    <span class="md-ellipsis">
      
        get_inference_pipeline_status
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.get_model_description" class="md-nav__link">
    <span class="md-ellipsis">
      
        get_model_description
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.get_model_description_async" class="md-nav__link">
    <span class="md-ellipsis">
      
        get_model_description_async
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.get_perception_encoder_image_embeddings" class="md-nav__link">
    <span class="md-ellipsis">
      
        get_perception_encoder_image_embeddings
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.get_perception_encoder_text_embeddings" class="md-nav__link">
    <span class="md-ellipsis">
      
        get_perception_encoder_text_embeddings
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.get_server_info" class="md-nav__link">
    <span class="md-ellipsis">
      
        get_server_info
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.infer" class="md-nav__link">
    <span class="md-ellipsis">
      
        infer
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.infer_async" class="md-nav__link">
    <span class="md-ellipsis">
      
        infer_async
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.infer_from_api_v0" class="md-nav__link">
    <span class="md-ellipsis">
      
        infer_from_api_v0
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.infer_from_api_v0_async" class="md-nav__link">
    <span class="md-ellipsis">
      
        infer_from_api_v0_async
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.infer_from_workflow" class="md-nav__link">
    <span class="md-ellipsis">
      
        infer_from_workflow
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.infer_from_yolo_world" class="md-nav__link">
    <span class="md-ellipsis">
      
        infer_from_yolo_world
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.infer_from_yolo_world_async" class="md-nav__link">
    <span class="md-ellipsis">
      
        infer_from_yolo_world_async
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.infer_lmm" class="md-nav__link">
    <span class="md-ellipsis">
      
        infer_lmm
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.infer_lmm_async" class="md-nav__link">
    <span class="md-ellipsis">
      
        infer_lmm_async
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.infer_on_stream" class="md-nav__link">
    <span class="md-ellipsis">
      
        infer_on_stream
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.init" class="md-nav__link">
    <span class="md-ellipsis">
      
        init
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.list_inference_pipelines" class="md-nav__link">
    <span class="md-ellipsis">
      
        list_inference_pipelines
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.list_loaded_models" class="md-nav__link">
    <span class="md-ellipsis">
      
        list_loaded_models
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.list_loaded_models_async" class="md-nav__link">
    <span class="md-ellipsis">
      
        list_loaded_models_async
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.load_model" class="md-nav__link">
    <span class="md-ellipsis">
      
        load_model
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.load_model_async" class="md-nav__link">
    <span class="md-ellipsis">
      
        load_model_async
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.ocr_image" class="md-nav__link">
    <span class="md-ellipsis">
      
        ocr_image
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.ocr_image_async" class="md-nav__link">
    <span class="md-ellipsis">
      
        ocr_image_async
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.pause_inference_pipeline" class="md-nav__link">
    <span class="md-ellipsis">
      
        pause_inference_pipeline
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.resume_inference_pipeline" class="md-nav__link">
    <span class="md-ellipsis">
      
        resume_inference_pipeline
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.run_workflow" class="md-nav__link">
    <span class="md-ellipsis">
      
        run_workflow
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.sam2_segment_image" class="md-nav__link">
    <span class="md-ellipsis">
      
        sam2_segment_image
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.sam2_segment_image_async" class="md-nav__link">
    <span class="md-ellipsis">
      
        sam2_segment_image_async
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.sam3_3d_infer" class="md-nav__link">
    <span class="md-ellipsis">
      
        sam3_3d_infer
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.sam3_3d_infer_async" class="md-nav__link">
    <span class="md-ellipsis">
      
        sam3_3d_infer_async
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.sam3_concept_segment" class="md-nav__link">
    <span class="md-ellipsis">
      
        sam3_concept_segment
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.sam3_concept_segment_async" class="md-nav__link">
    <span class="md-ellipsis">
      
        sam3_concept_segment_async
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.sam3_embed_image" class="md-nav__link">
    <span class="md-ellipsis">
      
        sam3_embed_image
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.sam3_embed_image_async" class="md-nav__link">
    <span class="md-ellipsis">
      
        sam3_embed_image_async
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.sam3_visual_segment" class="md-nav__link">
    <span class="md-ellipsis">
      
        sam3_visual_segment
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.sam3_visual_segment_async" class="md-nav__link">
    <span class="md-ellipsis">
      
        sam3_visual_segment_async
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.select_api_v0" class="md-nav__link">
    <span class="md-ellipsis">
      
        select_api_v0
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.select_api_v1" class="md-nav__link">
    <span class="md-ellipsis">
      
        select_api_v1
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.select_model" class="md-nav__link">
    <span class="md-ellipsis">
      
        select_model
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.start_inference_pipeline_with_workflow" class="md-nav__link">
    <span class="md-ellipsis">
      
        start_inference_pipeline_with_workflow
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.terminate_inference_pipeline" class="md-nav__link">
    <span class="md-ellipsis">
      
        terminate_inference_pipeline
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.unload_model" class="md-nav__link">
    <span class="md-ellipsis">
      
        unload_model
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.use_api_v0" class="md-nav__link">
    <span class="md-ellipsis">
      
        use_api_v0
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.use_api_v1" class="md-nav__link">
    <span class="md-ellipsis">
      
        use_api_v1
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.use_configuration" class="md-nav__link">
    <span class="md-ellipsis">
      
        use_configuration
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference_sdk.http.client.InferenceHTTPClient.use_model" class="md-nav__link">
    <span class="md-ellipsis">
      
        use_model
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
  
    
            <div class="md-content" data-md-component="content">
              
              <article class="md-content__inner md-typeset">
                
                  


  
    <a href="https://github.com/roboflow/inference/tree/main/inference_sdk/http/client.py" title="Edit this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"/></svg>
    </a>
  
  


  <h1>Client</h1>

<div class="doc doc-object doc-module">



<a id="inference_sdk.http.client"></a>
    <div class="doc doc-contents first">










<div class="doc doc-children">









<div class="doc doc-object doc-class">



<h2 id="inference_sdk.http.client.InferenceHTTPClient" class="doc doc-heading">
            <code>InferenceHTTPClient</code>


<a href="#inference_sdk.http.client.InferenceHTTPClient" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents ">



        <p>HTTP client for making inference requests to Roboflow's API.</p>
<p>This client handles authentication, request formatting, and error handling for
interacting with Roboflow's inference endpoints. It supports both synchronous
and asynchronous requests.</p>


<p><span class="doc-section-title">Attributes:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><a class="autorefs autorefs-internal" href="#inference_sdk.http.client.InferenceHTTPClient.inference_configuration">inference_configuration</a></code></td>
            <td>
                  <code><a class="autorefs autorefs-internal" href="../entities/#inference_sdk.http.entities.InferenceConfiguration">InferenceConfiguration</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Configuration settings for
inference requests.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><a class="autorefs autorefs-internal" href="#inference_sdk.http.client.InferenceHTTPClient.client_mode">client_mode</a></code></td>
            <td>
                  <code><a class="autorefs autorefs-internal" href="../entities/#inference_sdk.http.entities.HTTPClientMode">HTTPClientMode</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The API version mode being used (V0 or V1).</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><a class="autorefs autorefs-internal" href="#inference_sdk.http.client.InferenceHTTPClient.selected_model">selected_model</a></code></td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="str">str</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Currently selected model identifier, if any.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<details class="example" open>
  <summary>Example</summary>
  <div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">inference_sdk</span><span class="w"> </span><span class="kn">import</span> <span class="n">InferenceHTTPClient</span>

<span class="n">client</span> <span class="o">=</span> <span class="n">InferenceHTTPClient</span><span class="p">(</span>
    <span class="n">api_url</span><span class="o">=</span><span class="s2">&quot;http://localhost:9001&quot;</span><span class="p">,</span> <span class="c1"># use local inference server</span>
    <span class="c1"># api_key=&quot;&lt;YOUR API KEY&gt;&quot; # optional to access your private data and models</span>
<span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">run_workflow</span><span class="p">(</span>
    <span class="n">workspace_name</span><span class="o">=</span><span class="s2">&quot;roboflow-docs&quot;</span><span class="p">,</span>
    <span class="n">workflow_id</span><span class="o">=</span><span class="s2">&quot;model-comparison&quot;</span><span class="p">,</span>
    <span class="n">images</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">&quot;image&quot;</span><span class="p">:</span> <span class="s2">&quot;https://media.roboflow.com/workflows/examples/bleachers.jpg&quot;</span>
    <span class="p">},</span>
    <span class="n">parameters</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">&quot;model1&quot;</span><span class="p">:</span> <span class="s2">&quot;yolov8n-640&quot;</span><span class="p">,</span>
        <span class="s2">&quot;model2&quot;</span><span class="p">:</span> <span class="s2">&quot;yolov11n-640&quot;</span>
    <span class="p">}</span>
<span class="p">)</span>
</code></pre></div>
</details>







              <details class="mkdocstrings-source">
                <summary>Source code in <code>inference_sdk/http/client.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 191</span>
<span class="normal"> 192</span>
<span class="normal"> 193</span>
<span class="normal"> 194</span>
<span class="normal"> 195</span>
<span class="normal"> 196</span>
<span class="normal"> 197</span>
<span class="normal"> 198</span>
<span class="normal"> 199</span>
<span class="normal"> 200</span>
<span class="normal"> 201</span>
<span class="normal"> 202</span>
<span class="normal"> 203</span>
<span class="normal"> 204</span>
<span class="normal"> 205</span>
<span class="normal"> 206</span>
<span class="normal"> 207</span>
<span class="normal"> 208</span>
<span class="normal"> 209</span>
<span class="normal"> 210</span>
<span class="normal"> 211</span>
<span class="normal"> 212</span>
<span class="normal"> 213</span>
<span class="normal"> 214</span>
<span class="normal"> 215</span>
<span class="normal"> 216</span>
<span class="normal"> 217</span>
<span class="normal"> 218</span>
<span class="normal"> 219</span>
<span class="normal"> 220</span>
<span class="normal"> 221</span>
<span class="normal"> 222</span>
<span class="normal"> 223</span>
<span class="normal"> 224</span>
<span class="normal"> 225</span>
<span class="normal"> 226</span>
<span class="normal"> 227</span>
<span class="normal"> 228</span>
<span class="normal"> 229</span>
<span class="normal"> 230</span>
<span class="normal"> 231</span>
<span class="normal"> 232</span>
<span class="normal"> 233</span>
<span class="normal"> 234</span>
<span class="normal"> 235</span>
<span class="normal"> 236</span>
<span class="normal"> 237</span>
<span class="normal"> 238</span>
<span class="normal"> 239</span>
<span class="normal"> 240</span>
<span class="normal"> 241</span>
<span class="normal"> 242</span>
<span class="normal"> 243</span>
<span class="normal"> 244</span>
<span class="normal"> 245</span>
<span class="normal"> 246</span>
<span class="normal"> 247</span>
<span class="normal"> 248</span>
<span class="normal"> 249</span>
<span class="normal"> 250</span>
<span class="normal"> 251</span>
<span class="normal"> 252</span>
<span class="normal"> 253</span>
<span class="normal"> 254</span>
<span class="normal"> 255</span>
<span class="normal"> 256</span>
<span class="normal"> 257</span>
<span class="normal"> 258</span>
<span class="normal"> 259</span>
<span class="normal"> 260</span>
<span class="normal"> 261</span>
<span class="normal"> 262</span>
<span class="normal"> 263</span>
<span class="normal"> 264</span>
<span class="normal"> 265</span>
<span class="normal"> 266</span>
<span class="normal"> 267</span>
<span class="normal"> 268</span>
<span class="normal"> 269</span>
<span class="normal"> 270</span>
<span class="normal"> 271</span>
<span class="normal"> 272</span>
<span class="normal"> 273</span>
<span class="normal"> 274</span>
<span class="normal"> 275</span>
<span class="normal"> 276</span>
<span class="normal"> 277</span>
<span class="normal"> 278</span>
<span class="normal"> 279</span>
<span class="normal"> 280</span>
<span class="normal"> 281</span>
<span class="normal"> 282</span>
<span class="normal"> 283</span>
<span class="normal"> 284</span>
<span class="normal"> 285</span>
<span class="normal"> 286</span>
<span class="normal"> 287</span>
<span class="normal"> 288</span>
<span class="normal"> 289</span>
<span class="normal"> 290</span>
<span class="normal"> 291</span>
<span class="normal"> 292</span>
<span class="normal"> 293</span>
<span class="normal"> 294</span>
<span class="normal"> 295</span>
<span class="normal"> 296</span>
<span class="normal"> 297</span>
<span class="normal"> 298</span>
<span class="normal"> 299</span>
<span class="normal"> 300</span>
<span class="normal"> 301</span>
<span class="normal"> 302</span>
<span class="normal"> 303</span>
<span class="normal"> 304</span>
<span class="normal"> 305</span>
<span class="normal"> 306</span>
<span class="normal"> 307</span>
<span class="normal"> 308</span>
<span class="normal"> 309</span>
<span class="normal"> 310</span>
<span class="normal"> 311</span>
<span class="normal"> 312</span>
<span class="normal"> 313</span>
<span class="normal"> 314</span>
<span class="normal"> 315</span>
<span class="normal"> 316</span>
<span class="normal"> 317</span>
<span class="normal"> 318</span>
<span class="normal"> 319</span>
<span class="normal"> 320</span>
<span class="normal"> 321</span>
<span class="normal"> 322</span>
<span class="normal"> 323</span>
<span class="normal"> 324</span>
<span class="normal"> 325</span>
<span class="normal"> 326</span>
<span class="normal"> 327</span>
<span class="normal"> 328</span>
<span class="normal"> 329</span>
<span class="normal"> 330</span>
<span class="normal"> 331</span>
<span class="normal"> 332</span>
<span class="normal"> 333</span>
<span class="normal"> 334</span>
<span class="normal"> 335</span>
<span class="normal"> 336</span>
<span class="normal"> 337</span>
<span class="normal"> 338</span>
<span class="normal"> 339</span>
<span class="normal"> 340</span>
<span class="normal"> 341</span>
<span class="normal"> 342</span>
<span class="normal"> 343</span>
<span class="normal"> 344</span>
<span class="normal"> 345</span>
<span class="normal"> 346</span>
<span class="normal"> 347</span>
<span class="normal"> 348</span>
<span class="normal"> 349</span>
<span class="normal"> 350</span>
<span class="normal"> 351</span>
<span class="normal"> 352</span>
<span class="normal"> 353</span>
<span class="normal"> 354</span>
<span class="normal"> 355</span>
<span class="normal"> 356</span>
<span class="normal"> 357</span>
<span class="normal"> 358</span>
<span class="normal"> 359</span>
<span class="normal"> 360</span>
<span class="normal"> 361</span>
<span class="normal"> 362</span>
<span class="normal"> 363</span>
<span class="normal"> 364</span>
<span class="normal"> 365</span>
<span class="normal"> 366</span>
<span class="normal"> 367</span>
<span class="normal"> 368</span>
<span class="normal"> 369</span>
<span class="normal"> 370</span>
<span class="normal"> 371</span>
<span class="normal"> 372</span>
<span class="normal"> 373</span>
<span class="normal"> 374</span>
<span class="normal"> 375</span>
<span class="normal"> 376</span>
<span class="normal"> 377</span>
<span class="normal"> 378</span>
<span class="normal"> 379</span>
<span class="normal"> 380</span>
<span class="normal"> 381</span>
<span class="normal"> 382</span>
<span class="normal"> 383</span>
<span class="normal"> 384</span>
<span class="normal"> 385</span>
<span class="normal"> 386</span>
<span class="normal"> 387</span>
<span class="normal"> 388</span>
<span class="normal"> 389</span>
<span class="normal"> 390</span>
<span class="normal"> 391</span>
<span class="normal"> 392</span>
<span class="normal"> 393</span>
<span class="normal"> 394</span>
<span class="normal"> 395</span>
<span class="normal"> 396</span>
<span class="normal"> 397</span>
<span class="normal"> 398</span>
<span class="normal"> 399</span>
<span class="normal"> 400</span>
<span class="normal"> 401</span>
<span class="normal"> 402</span>
<span class="normal"> 403</span>
<span class="normal"> 404</span>
<span class="normal"> 405</span>
<span class="normal"> 406</span>
<span class="normal"> 407</span>
<span class="normal"> 408</span>
<span class="normal"> 409</span>
<span class="normal"> 410</span>
<span class="normal"> 411</span>
<span class="normal"> 412</span>
<span class="normal"> 413</span>
<span class="normal"> 414</span>
<span class="normal"> 415</span>
<span class="normal"> 416</span>
<span class="normal"> 417</span>
<span class="normal"> 418</span>
<span class="normal"> 419</span>
<span class="normal"> 420</span>
<span class="normal"> 421</span>
<span class="normal"> 422</span>
<span class="normal"> 423</span>
<span class="normal"> 424</span>
<span class="normal"> 425</span>
<span class="normal"> 426</span>
<span class="normal"> 427</span>
<span class="normal"> 428</span>
<span class="normal"> 429</span>
<span class="normal"> 430</span>
<span class="normal"> 431</span>
<span class="normal"> 432</span>
<span class="normal"> 433</span>
<span class="normal"> 434</span>
<span class="normal"> 435</span>
<span class="normal"> 436</span>
<span class="normal"> 437</span>
<span class="normal"> 438</span>
<span class="normal"> 439</span>
<span class="normal"> 440</span>
<span class="normal"> 441</span>
<span class="normal"> 442</span>
<span class="normal"> 443</span>
<span class="normal"> 444</span>
<span class="normal"> 445</span>
<span class="normal"> 446</span>
<span class="normal"> 447</span>
<span class="normal"> 448</span>
<span class="normal"> 449</span>
<span class="normal"> 450</span>
<span class="normal"> 451</span>
<span class="normal"> 452</span>
<span class="normal"> 453</span>
<span class="normal"> 454</span>
<span class="normal"> 455</span>
<span class="normal"> 456</span>
<span class="normal"> 457</span>
<span class="normal"> 458</span>
<span class="normal"> 459</span>
<span class="normal"> 460</span>
<span class="normal"> 461</span>
<span class="normal"> 462</span>
<span class="normal"> 463</span>
<span class="normal"> 464</span>
<span class="normal"> 465</span>
<span class="normal"> 466</span>
<span class="normal"> 467</span>
<span class="normal"> 468</span>
<span class="normal"> 469</span>
<span class="normal"> 470</span>
<span class="normal"> 471</span>
<span class="normal"> 472</span>
<span class="normal"> 473</span>
<span class="normal"> 474</span>
<span class="normal"> 475</span>
<span class="normal"> 476</span>
<span class="normal"> 477</span>
<span class="normal"> 478</span>
<span class="normal"> 479</span>
<span class="normal"> 480</span>
<span class="normal"> 481</span>
<span class="normal"> 482</span>
<span class="normal"> 483</span>
<span class="normal"> 484</span>
<span class="normal"> 485</span>
<span class="normal"> 486</span>
<span class="normal"> 487</span>
<span class="normal"> 488</span>
<span class="normal"> 489</span>
<span class="normal"> 490</span>
<span class="normal"> 491</span>
<span class="normal"> 492</span>
<span class="normal"> 493</span>
<span class="normal"> 494</span>
<span class="normal"> 495</span>
<span class="normal"> 496</span>
<span class="normal"> 497</span>
<span class="normal"> 498</span>
<span class="normal"> 499</span>
<span class="normal"> 500</span>
<span class="normal"> 501</span>
<span class="normal"> 502</span>
<span class="normal"> 503</span>
<span class="normal"> 504</span>
<span class="normal"> 505</span>
<span class="normal"> 506</span>
<span class="normal"> 507</span>
<span class="normal"> 508</span>
<span class="normal"> 509</span>
<span class="normal"> 510</span>
<span class="normal"> 511</span>
<span class="normal"> 512</span>
<span class="normal"> 513</span>
<span class="normal"> 514</span>
<span class="normal"> 515</span>
<span class="normal"> 516</span>
<span class="normal"> 517</span>
<span class="normal"> 518</span>
<span class="normal"> 519</span>
<span class="normal"> 520</span>
<span class="normal"> 521</span>
<span class="normal"> 522</span>
<span class="normal"> 523</span>
<span class="normal"> 524</span>
<span class="normal"> 525</span>
<span class="normal"> 526</span>
<span class="normal"> 527</span>
<span class="normal"> 528</span>
<span class="normal"> 529</span>
<span class="normal"> 530</span>
<span class="normal"> 531</span>
<span class="normal"> 532</span>
<span class="normal"> 533</span>
<span class="normal"> 534</span>
<span class="normal"> 535</span>
<span class="normal"> 536</span>
<span class="normal"> 537</span>
<span class="normal"> 538</span>
<span class="normal"> 539</span>
<span class="normal"> 540</span>
<span class="normal"> 541</span>
<span class="normal"> 542</span>
<span class="normal"> 543</span>
<span class="normal"> 544</span>
<span class="normal"> 545</span>
<span class="normal"> 546</span>
<span class="normal"> 547</span>
<span class="normal"> 548</span>
<span class="normal"> 549</span>
<span class="normal"> 550</span>
<span class="normal"> 551</span>
<span class="normal"> 552</span>
<span class="normal"> 553</span>
<span class="normal"> 554</span>
<span class="normal"> 555</span>
<span class="normal"> 556</span>
<span class="normal"> 557</span>
<span class="normal"> 558</span>
<span class="normal"> 559</span>
<span class="normal"> 560</span>
<span class="normal"> 561</span>
<span class="normal"> 562</span>
<span class="normal"> 563</span>
<span class="normal"> 564</span>
<span class="normal"> 565</span>
<span class="normal"> 566</span>
<span class="normal"> 567</span>
<span class="normal"> 568</span>
<span class="normal"> 569</span>
<span class="normal"> 570</span>
<span class="normal"> 571</span>
<span class="normal"> 572</span>
<span class="normal"> 573</span>
<span class="normal"> 574</span>
<span class="normal"> 575</span>
<span class="normal"> 576</span>
<span class="normal"> 577</span>
<span class="normal"> 578</span>
<span class="normal"> 579</span>
<span class="normal"> 580</span>
<span class="normal"> 581</span>
<span class="normal"> 582</span>
<span class="normal"> 583</span>
<span class="normal"> 584</span>
<span class="normal"> 585</span>
<span class="normal"> 586</span>
<span class="normal"> 587</span>
<span class="normal"> 588</span>
<span class="normal"> 589</span>
<span class="normal"> 590</span>
<span class="normal"> 591</span>
<span class="normal"> 592</span>
<span class="normal"> 593</span>
<span class="normal"> 594</span>
<span class="normal"> 595</span>
<span class="normal"> 596</span>
<span class="normal"> 597</span>
<span class="normal"> 598</span>
<span class="normal"> 599</span>
<span class="normal"> 600</span>
<span class="normal"> 601</span>
<span class="normal"> 602</span>
<span class="normal"> 603</span>
<span class="normal"> 604</span>
<span class="normal"> 605</span>
<span class="normal"> 606</span>
<span class="normal"> 607</span>
<span class="normal"> 608</span>
<span class="normal"> 609</span>
<span class="normal"> 610</span>
<span class="normal"> 611</span>
<span class="normal"> 612</span>
<span class="normal"> 613</span>
<span class="normal"> 614</span>
<span class="normal"> 615</span>
<span class="normal"> 616</span>
<span class="normal"> 617</span>
<span class="normal"> 618</span>
<span class="normal"> 619</span>
<span class="normal"> 620</span>
<span class="normal"> 621</span>
<span class="normal"> 622</span>
<span class="normal"> 623</span>
<span class="normal"> 624</span>
<span class="normal"> 625</span>
<span class="normal"> 626</span>
<span class="normal"> 627</span>
<span class="normal"> 628</span>
<span class="normal"> 629</span>
<span class="normal"> 630</span>
<span class="normal"> 631</span>
<span class="normal"> 632</span>
<span class="normal"> 633</span>
<span class="normal"> 634</span>
<span class="normal"> 635</span>
<span class="normal"> 636</span>
<span class="normal"> 637</span>
<span class="normal"> 638</span>
<span class="normal"> 639</span>
<span class="normal"> 640</span>
<span class="normal"> 641</span>
<span class="normal"> 642</span>
<span class="normal"> 643</span>
<span class="normal"> 644</span>
<span class="normal"> 645</span>
<span class="normal"> 646</span>
<span class="normal"> 647</span>
<span class="normal"> 648</span>
<span class="normal"> 649</span>
<span class="normal"> 650</span>
<span class="normal"> 651</span>
<span class="normal"> 652</span>
<span class="normal"> 653</span>
<span class="normal"> 654</span>
<span class="normal"> 655</span>
<span class="normal"> 656</span>
<span class="normal"> 657</span>
<span class="normal"> 658</span>
<span class="normal"> 659</span>
<span class="normal"> 660</span>
<span class="normal"> 661</span>
<span class="normal"> 662</span>
<span class="normal"> 663</span>
<span class="normal"> 664</span>
<span class="normal"> 665</span>
<span class="normal"> 666</span>
<span class="normal"> 667</span>
<span class="normal"> 668</span>
<span class="normal"> 669</span>
<span class="normal"> 670</span>
<span class="normal"> 671</span>
<span class="normal"> 672</span>
<span class="normal"> 673</span>
<span class="normal"> 674</span>
<span class="normal"> 675</span>
<span class="normal"> 676</span>
<span class="normal"> 677</span>
<span class="normal"> 678</span>
<span class="normal"> 679</span>
<span class="normal"> 680</span>
<span class="normal"> 681</span>
<span class="normal"> 682</span>
<span class="normal"> 683</span>
<span class="normal"> 684</span>
<span class="normal"> 685</span>
<span class="normal"> 686</span>
<span class="normal"> 687</span>
<span class="normal"> 688</span>
<span class="normal"> 689</span>
<span class="normal"> 690</span>
<span class="normal"> 691</span>
<span class="normal"> 692</span>
<span class="normal"> 693</span>
<span class="normal"> 694</span>
<span class="normal"> 695</span>
<span class="normal"> 696</span>
<span class="normal"> 697</span>
<span class="normal"> 698</span>
<span class="normal"> 699</span>
<span class="normal"> 700</span>
<span class="normal"> 701</span>
<span class="normal"> 702</span>
<span class="normal"> 703</span>
<span class="normal"> 704</span>
<span class="normal"> 705</span>
<span class="normal"> 706</span>
<span class="normal"> 707</span>
<span class="normal"> 708</span>
<span class="normal"> 709</span>
<span class="normal"> 710</span>
<span class="normal"> 711</span>
<span class="normal"> 712</span>
<span class="normal"> 713</span>
<span class="normal"> 714</span>
<span class="normal"> 715</span>
<span class="normal"> 716</span>
<span class="normal"> 717</span>
<span class="normal"> 718</span>
<span class="normal"> 719</span>
<span class="normal"> 720</span>
<span class="normal"> 721</span>
<span class="normal"> 722</span>
<span class="normal"> 723</span>
<span class="normal"> 724</span>
<span class="normal"> 725</span>
<span class="normal"> 726</span>
<span class="normal"> 727</span>
<span class="normal"> 728</span>
<span class="normal"> 729</span>
<span class="normal"> 730</span>
<span class="normal"> 731</span>
<span class="normal"> 732</span>
<span class="normal"> 733</span>
<span class="normal"> 734</span>
<span class="normal"> 735</span>
<span class="normal"> 736</span>
<span class="normal"> 737</span>
<span class="normal"> 738</span>
<span class="normal"> 739</span>
<span class="normal"> 740</span>
<span class="normal"> 741</span>
<span class="normal"> 742</span>
<span class="normal"> 743</span>
<span class="normal"> 744</span>
<span class="normal"> 745</span>
<span class="normal"> 746</span>
<span class="normal"> 747</span>
<span class="normal"> 748</span>
<span class="normal"> 749</span>
<span class="normal"> 750</span>
<span class="normal"> 751</span>
<span class="normal"> 752</span>
<span class="normal"> 753</span>
<span class="normal"> 754</span>
<span class="normal"> 755</span>
<span class="normal"> 756</span>
<span class="normal"> 757</span>
<span class="normal"> 758</span>
<span class="normal"> 759</span>
<span class="normal"> 760</span>
<span class="normal"> 761</span>
<span class="normal"> 762</span>
<span class="normal"> 763</span>
<span class="normal"> 764</span>
<span class="normal"> 765</span>
<span class="normal"> 766</span>
<span class="normal"> 767</span>
<span class="normal"> 768</span>
<span class="normal"> 769</span>
<span class="normal"> 770</span>
<span class="normal"> 771</span>
<span class="normal"> 772</span>
<span class="normal"> 773</span>
<span class="normal"> 774</span>
<span class="normal"> 775</span>
<span class="normal"> 776</span>
<span class="normal"> 777</span>
<span class="normal"> 778</span>
<span class="normal"> 779</span>
<span class="normal"> 780</span>
<span class="normal"> 781</span>
<span class="normal"> 782</span>
<span class="normal"> 783</span>
<span class="normal"> 784</span>
<span class="normal"> 785</span>
<span class="normal"> 786</span>
<span class="normal"> 787</span>
<span class="normal"> 788</span>
<span class="normal"> 789</span>
<span class="normal"> 790</span>
<span class="normal"> 791</span>
<span class="normal"> 792</span>
<span class="normal"> 793</span>
<span class="normal"> 794</span>
<span class="normal"> 795</span>
<span class="normal"> 796</span>
<span class="normal"> 797</span>
<span class="normal"> 798</span>
<span class="normal"> 799</span>
<span class="normal"> 800</span>
<span class="normal"> 801</span>
<span class="normal"> 802</span>
<span class="normal"> 803</span>
<span class="normal"> 804</span>
<span class="normal"> 805</span>
<span class="normal"> 806</span>
<span class="normal"> 807</span>
<span class="normal"> 808</span>
<span class="normal"> 809</span>
<span class="normal"> 810</span>
<span class="normal"> 811</span>
<span class="normal"> 812</span>
<span class="normal"> 813</span>
<span class="normal"> 814</span>
<span class="normal"> 815</span>
<span class="normal"> 816</span>
<span class="normal"> 817</span>
<span class="normal"> 818</span>
<span class="normal"> 819</span>
<span class="normal"> 820</span>
<span class="normal"> 821</span>
<span class="normal"> 822</span>
<span class="normal"> 823</span>
<span class="normal"> 824</span>
<span class="normal"> 825</span>
<span class="normal"> 826</span>
<span class="normal"> 827</span>
<span class="normal"> 828</span>
<span class="normal"> 829</span>
<span class="normal"> 830</span>
<span class="normal"> 831</span>
<span class="normal"> 832</span>
<span class="normal"> 833</span>
<span class="normal"> 834</span>
<span class="normal"> 835</span>
<span class="normal"> 836</span>
<span class="normal"> 837</span>
<span class="normal"> 838</span>
<span class="normal"> 839</span>
<span class="normal"> 840</span>
<span class="normal"> 841</span>
<span class="normal"> 842</span>
<span class="normal"> 843</span>
<span class="normal"> 844</span>
<span class="normal"> 845</span>
<span class="normal"> 846</span>
<span class="normal"> 847</span>
<span class="normal"> 848</span>
<span class="normal"> 849</span>
<span class="normal"> 850</span>
<span class="normal"> 851</span>
<span class="normal"> 852</span>
<span class="normal"> 853</span>
<span class="normal"> 854</span>
<span class="normal"> 855</span>
<span class="normal"> 856</span>
<span class="normal"> 857</span>
<span class="normal"> 858</span>
<span class="normal"> 859</span>
<span class="normal"> 860</span>
<span class="normal"> 861</span>
<span class="normal"> 862</span>
<span class="normal"> 863</span>
<span class="normal"> 864</span>
<span class="normal"> 865</span>
<span class="normal"> 866</span>
<span class="normal"> 867</span>
<span class="normal"> 868</span>
<span class="normal"> 869</span>
<span class="normal"> 870</span>
<span class="normal"> 871</span>
<span class="normal"> 872</span>
<span class="normal"> 873</span>
<span class="normal"> 874</span>
<span class="normal"> 875</span>
<span class="normal"> 876</span>
<span class="normal"> 877</span>
<span class="normal"> 878</span>
<span class="normal"> 879</span>
<span class="normal"> 880</span>
<span class="normal"> 881</span>
<span class="normal"> 882</span>
<span class="normal"> 883</span>
<span class="normal"> 884</span>
<span class="normal"> 885</span>
<span class="normal"> 886</span>
<span class="normal"> 887</span>
<span class="normal"> 888</span>
<span class="normal"> 889</span>
<span class="normal"> 890</span>
<span class="normal"> 891</span>
<span class="normal"> 892</span>
<span class="normal"> 893</span>
<span class="normal"> 894</span>
<span class="normal"> 895</span>
<span class="normal"> 896</span>
<span class="normal"> 897</span>
<span class="normal"> 898</span>
<span class="normal"> 899</span>
<span class="normal"> 900</span>
<span class="normal"> 901</span>
<span class="normal"> 902</span>
<span class="normal"> 903</span>
<span class="normal"> 904</span>
<span class="normal"> 905</span>
<span class="normal"> 906</span>
<span class="normal"> 907</span>
<span class="normal"> 908</span>
<span class="normal"> 909</span>
<span class="normal"> 910</span>
<span class="normal"> 911</span>
<span class="normal"> 912</span>
<span class="normal"> 913</span>
<span class="normal"> 914</span>
<span class="normal"> 915</span>
<span class="normal"> 916</span>
<span class="normal"> 917</span>
<span class="normal"> 918</span>
<span class="normal"> 919</span>
<span class="normal"> 920</span>
<span class="normal"> 921</span>
<span class="normal"> 922</span>
<span class="normal"> 923</span>
<span class="normal"> 924</span>
<span class="normal"> 925</span>
<span class="normal"> 926</span>
<span class="normal"> 927</span>
<span class="normal"> 928</span>
<span class="normal"> 929</span>
<span class="normal"> 930</span>
<span class="normal"> 931</span>
<span class="normal"> 932</span>
<span class="normal"> 933</span>
<span class="normal"> 934</span>
<span class="normal"> 935</span>
<span class="normal"> 936</span>
<span class="normal"> 937</span>
<span class="normal"> 938</span>
<span class="normal"> 939</span>
<span class="normal"> 940</span>
<span class="normal"> 941</span>
<span class="normal"> 942</span>
<span class="normal"> 943</span>
<span class="normal"> 944</span>
<span class="normal"> 945</span>
<span class="normal"> 946</span>
<span class="normal"> 947</span>
<span class="normal"> 948</span>
<span class="normal"> 949</span>
<span class="normal"> 950</span>
<span class="normal"> 951</span>
<span class="normal"> 952</span>
<span class="normal"> 953</span>
<span class="normal"> 954</span>
<span class="normal"> 955</span>
<span class="normal"> 956</span>
<span class="normal"> 957</span>
<span class="normal"> 958</span>
<span class="normal"> 959</span>
<span class="normal"> 960</span>
<span class="normal"> 961</span>
<span class="normal"> 962</span>
<span class="normal"> 963</span>
<span class="normal"> 964</span>
<span class="normal"> 965</span>
<span class="normal"> 966</span>
<span class="normal"> 967</span>
<span class="normal"> 968</span>
<span class="normal"> 969</span>
<span class="normal"> 970</span>
<span class="normal"> 971</span>
<span class="normal"> 972</span>
<span class="normal"> 973</span>
<span class="normal"> 974</span>
<span class="normal"> 975</span>
<span class="normal"> 976</span>
<span class="normal"> 977</span>
<span class="normal"> 978</span>
<span class="normal"> 979</span>
<span class="normal"> 980</span>
<span class="normal"> 981</span>
<span class="normal"> 982</span>
<span class="normal"> 983</span>
<span class="normal"> 984</span>
<span class="normal"> 985</span>
<span class="normal"> 986</span>
<span class="normal"> 987</span>
<span class="normal"> 988</span>
<span class="normal"> 989</span>
<span class="normal"> 990</span>
<span class="normal"> 991</span>
<span class="normal"> 992</span>
<span class="normal"> 993</span>
<span class="normal"> 994</span>
<span class="normal"> 995</span>
<span class="normal"> 996</span>
<span class="normal"> 997</span>
<span class="normal"> 998</span>
<span class="normal"> 999</span>
<span class="normal">1000</span>
<span class="normal">1001</span>
<span class="normal">1002</span>
<span class="normal">1003</span>
<span class="normal">1004</span>
<span class="normal">1005</span>
<span class="normal">1006</span>
<span class="normal">1007</span>
<span class="normal">1008</span>
<span class="normal">1009</span>
<span class="normal">1010</span>
<span class="normal">1011</span>
<span class="normal">1012</span>
<span class="normal">1013</span>
<span class="normal">1014</span>
<span class="normal">1015</span>
<span class="normal">1016</span>
<span class="normal">1017</span>
<span class="normal">1018</span>
<span class="normal">1019</span>
<span class="normal">1020</span>
<span class="normal">1021</span>
<span class="normal">1022</span>
<span class="normal">1023</span>
<span class="normal">1024</span>
<span class="normal">1025</span>
<span class="normal">1026</span>
<span class="normal">1027</span>
<span class="normal">1028</span>
<span class="normal">1029</span>
<span class="normal">1030</span>
<span class="normal">1031</span>
<span class="normal">1032</span>
<span class="normal">1033</span>
<span class="normal">1034</span>
<span class="normal">1035</span>
<span class="normal">1036</span>
<span class="normal">1037</span>
<span class="normal">1038</span>
<span class="normal">1039</span>
<span class="normal">1040</span>
<span class="normal">1041</span>
<span class="normal">1042</span>
<span class="normal">1043</span>
<span class="normal">1044</span>
<span class="normal">1045</span>
<span class="normal">1046</span>
<span class="normal">1047</span>
<span class="normal">1048</span>
<span class="normal">1049</span>
<span class="normal">1050</span>
<span class="normal">1051</span>
<span class="normal">1052</span>
<span class="normal">1053</span>
<span class="normal">1054</span>
<span class="normal">1055</span>
<span class="normal">1056</span>
<span class="normal">1057</span>
<span class="normal">1058</span>
<span class="normal">1059</span>
<span class="normal">1060</span>
<span class="normal">1061</span>
<span class="normal">1062</span>
<span class="normal">1063</span>
<span class="normal">1064</span>
<span class="normal">1065</span>
<span class="normal">1066</span>
<span class="normal">1067</span>
<span class="normal">1068</span>
<span class="normal">1069</span>
<span class="normal">1070</span>
<span class="normal">1071</span>
<span class="normal">1072</span>
<span class="normal">1073</span>
<span class="normal">1074</span>
<span class="normal">1075</span>
<span class="normal">1076</span>
<span class="normal">1077</span>
<span class="normal">1078</span>
<span class="normal">1079</span>
<span class="normal">1080</span>
<span class="normal">1081</span>
<span class="normal">1082</span>
<span class="normal">1083</span>
<span class="normal">1084</span>
<span class="normal">1085</span>
<span class="normal">1086</span>
<span class="normal">1087</span>
<span class="normal">1088</span>
<span class="normal">1089</span>
<span class="normal">1090</span>
<span class="normal">1091</span>
<span class="normal">1092</span>
<span class="normal">1093</span>
<span class="normal">1094</span>
<span class="normal">1095</span>
<span class="normal">1096</span>
<span class="normal">1097</span>
<span class="normal">1098</span>
<span class="normal">1099</span>
<span class="normal">1100</span>
<span class="normal">1101</span>
<span class="normal">1102</span>
<span class="normal">1103</span>
<span class="normal">1104</span>
<span class="normal">1105</span>
<span class="normal">1106</span>
<span class="normal">1107</span>
<span class="normal">1108</span>
<span class="normal">1109</span>
<span class="normal">1110</span>
<span class="normal">1111</span>
<span class="normal">1112</span>
<span class="normal">1113</span>
<span class="normal">1114</span>
<span class="normal">1115</span>
<span class="normal">1116</span>
<span class="normal">1117</span>
<span class="normal">1118</span>
<span class="normal">1119</span>
<span class="normal">1120</span>
<span class="normal">1121</span>
<span class="normal">1122</span>
<span class="normal">1123</span>
<span class="normal">1124</span>
<span class="normal">1125</span>
<span class="normal">1126</span>
<span class="normal">1127</span>
<span class="normal">1128</span>
<span class="normal">1129</span>
<span class="normal">1130</span>
<span class="normal">1131</span>
<span class="normal">1132</span>
<span class="normal">1133</span>
<span class="normal">1134</span>
<span class="normal">1135</span>
<span class="normal">1136</span>
<span class="normal">1137</span>
<span class="normal">1138</span>
<span class="normal">1139</span>
<span class="normal">1140</span>
<span class="normal">1141</span>
<span class="normal">1142</span>
<span class="normal">1143</span>
<span class="normal">1144</span>
<span class="normal">1145</span>
<span class="normal">1146</span>
<span class="normal">1147</span>
<span class="normal">1148</span>
<span class="normal">1149</span>
<span class="normal">1150</span>
<span class="normal">1151</span>
<span class="normal">1152</span>
<span class="normal">1153</span>
<span class="normal">1154</span>
<span class="normal">1155</span>
<span class="normal">1156</span>
<span class="normal">1157</span>
<span class="normal">1158</span>
<span class="normal">1159</span>
<span class="normal">1160</span>
<span class="normal">1161</span>
<span class="normal">1162</span>
<span class="normal">1163</span>
<span class="normal">1164</span>
<span class="normal">1165</span>
<span class="normal">1166</span>
<span class="normal">1167</span>
<span class="normal">1168</span>
<span class="normal">1169</span>
<span class="normal">1170</span>
<span class="normal">1171</span>
<span class="normal">1172</span>
<span class="normal">1173</span>
<span class="normal">1174</span>
<span class="normal">1175</span>
<span class="normal">1176</span>
<span class="normal">1177</span>
<span class="normal">1178</span>
<span class="normal">1179</span>
<span class="normal">1180</span>
<span class="normal">1181</span>
<span class="normal">1182</span>
<span class="normal">1183</span>
<span class="normal">1184</span>
<span class="normal">1185</span>
<span class="normal">1186</span>
<span class="normal">1187</span>
<span class="normal">1188</span>
<span class="normal">1189</span>
<span class="normal">1190</span>
<span class="normal">1191</span>
<span class="normal">1192</span>
<span class="normal">1193</span>
<span class="normal">1194</span>
<span class="normal">1195</span>
<span class="normal">1196</span>
<span class="normal">1197</span>
<span class="normal">1198</span>
<span class="normal">1199</span>
<span class="normal">1200</span>
<span class="normal">1201</span>
<span class="normal">1202</span>
<span class="normal">1203</span>
<span class="normal">1204</span>
<span class="normal">1205</span>
<span class="normal">1206</span>
<span class="normal">1207</span>
<span class="normal">1208</span>
<span class="normal">1209</span>
<span class="normal">1210</span>
<span class="normal">1211</span>
<span class="normal">1212</span>
<span class="normal">1213</span>
<span class="normal">1214</span>
<span class="normal">1215</span>
<span class="normal">1216</span>
<span class="normal">1217</span>
<span class="normal">1218</span>
<span class="normal">1219</span>
<span class="normal">1220</span>
<span class="normal">1221</span>
<span class="normal">1222</span>
<span class="normal">1223</span>
<span class="normal">1224</span>
<span class="normal">1225</span>
<span class="normal">1226</span>
<span class="normal">1227</span>
<span class="normal">1228</span>
<span class="normal">1229</span>
<span class="normal">1230</span>
<span class="normal">1231</span>
<span class="normal">1232</span>
<span class="normal">1233</span>
<span class="normal">1234</span>
<span class="normal">1235</span>
<span class="normal">1236</span>
<span class="normal">1237</span>
<span class="normal">1238</span>
<span class="normal">1239</span>
<span class="normal">1240</span>
<span class="normal">1241</span>
<span class="normal">1242</span>
<span class="normal">1243</span>
<span class="normal">1244</span>
<span class="normal">1245</span>
<span class="normal">1246</span>
<span class="normal">1247</span>
<span class="normal">1248</span>
<span class="normal">1249</span>
<span class="normal">1250</span>
<span class="normal">1251</span>
<span class="normal">1252</span>
<span class="normal">1253</span>
<span class="normal">1254</span>
<span class="normal">1255</span>
<span class="normal">1256</span>
<span class="normal">1257</span>
<span class="normal">1258</span>
<span class="normal">1259</span>
<span class="normal">1260</span>
<span class="normal">1261</span>
<span class="normal">1262</span>
<span class="normal">1263</span>
<span class="normal">1264</span>
<span class="normal">1265</span>
<span class="normal">1266</span>
<span class="normal">1267</span>
<span class="normal">1268</span>
<span class="normal">1269</span>
<span class="normal">1270</span>
<span class="normal">1271</span>
<span class="normal">1272</span>
<span class="normal">1273</span>
<span class="normal">1274</span>
<span class="normal">1275</span>
<span class="normal">1276</span>
<span class="normal">1277</span>
<span class="normal">1278</span>
<span class="normal">1279</span>
<span class="normal">1280</span>
<span class="normal">1281</span>
<span class="normal">1282</span>
<span class="normal">1283</span>
<span class="normal">1284</span>
<span class="normal">1285</span>
<span class="normal">1286</span>
<span class="normal">1287</span>
<span class="normal">1288</span>
<span class="normal">1289</span>
<span class="normal">1290</span>
<span class="normal">1291</span>
<span class="normal">1292</span>
<span class="normal">1293</span>
<span class="normal">1294</span>
<span class="normal">1295</span>
<span class="normal">1296</span>
<span class="normal">1297</span>
<span class="normal">1298</span>
<span class="normal">1299</span>
<span class="normal">1300</span>
<span class="normal">1301</span>
<span class="normal">1302</span>
<span class="normal">1303</span>
<span class="normal">1304</span>
<span class="normal">1305</span>
<span class="normal">1306</span>
<span class="normal">1307</span>
<span class="normal">1308</span>
<span class="normal">1309</span>
<span class="normal">1310</span>
<span class="normal">1311</span>
<span class="normal">1312</span>
<span class="normal">1313</span>
<span class="normal">1314</span>
<span class="normal">1315</span>
<span class="normal">1316</span>
<span class="normal">1317</span>
<span class="normal">1318</span>
<span class="normal">1319</span>
<span class="normal">1320</span>
<span class="normal">1321</span>
<span class="normal">1322</span>
<span class="normal">1323</span>
<span class="normal">1324</span>
<span class="normal">1325</span>
<span class="normal">1326</span>
<span class="normal">1327</span>
<span class="normal">1328</span>
<span class="normal">1329</span>
<span class="normal">1330</span>
<span class="normal">1331</span>
<span class="normal">1332</span>
<span class="normal">1333</span>
<span class="normal">1334</span>
<span class="normal">1335</span>
<span class="normal">1336</span>
<span class="normal">1337</span>
<span class="normal">1338</span>
<span class="normal">1339</span>
<span class="normal">1340</span>
<span class="normal">1341</span>
<span class="normal">1342</span>
<span class="normal">1343</span>
<span class="normal">1344</span>
<span class="normal">1345</span>
<span class="normal">1346</span>
<span class="normal">1347</span>
<span class="normal">1348</span>
<span class="normal">1349</span>
<span class="normal">1350</span>
<span class="normal">1351</span>
<span class="normal">1352</span>
<span class="normal">1353</span>
<span class="normal">1354</span>
<span class="normal">1355</span>
<span class="normal">1356</span>
<span class="normal">1357</span>
<span class="normal">1358</span>
<span class="normal">1359</span>
<span class="normal">1360</span>
<span class="normal">1361</span>
<span class="normal">1362</span>
<span class="normal">1363</span>
<span class="normal">1364</span>
<span class="normal">1365</span>
<span class="normal">1366</span>
<span class="normal">1367</span>
<span class="normal">1368</span>
<span class="normal">1369</span>
<span class="normal">1370</span>
<span class="normal">1371</span>
<span class="normal">1372</span>
<span class="normal">1373</span>
<span class="normal">1374</span>
<span class="normal">1375</span>
<span class="normal">1376</span>
<span class="normal">1377</span>
<span class="normal">1378</span>
<span class="normal">1379</span>
<span class="normal">1380</span>
<span class="normal">1381</span>
<span class="normal">1382</span>
<span class="normal">1383</span>
<span class="normal">1384</span>
<span class="normal">1385</span>
<span class="normal">1386</span>
<span class="normal">1387</span>
<span class="normal">1388</span>
<span class="normal">1389</span>
<span class="normal">1390</span>
<span class="normal">1391</span>
<span class="normal">1392</span>
<span class="normal">1393</span>
<span class="normal">1394</span>
<span class="normal">1395</span>
<span class="normal">1396</span>
<span class="normal">1397</span>
<span class="normal">1398</span>
<span class="normal">1399</span>
<span class="normal">1400</span>
<span class="normal">1401</span>
<span class="normal">1402</span>
<span class="normal">1403</span>
<span class="normal">1404</span>
<span class="normal">1405</span>
<span class="normal">1406</span>
<span class="normal">1407</span>
<span class="normal">1408</span>
<span class="normal">1409</span>
<span class="normal">1410</span>
<span class="normal">1411</span>
<span class="normal">1412</span>
<span class="normal">1413</span>
<span class="normal">1414</span>
<span class="normal">1415</span>
<span class="normal">1416</span>
<span class="normal">1417</span>
<span class="normal">1418</span>
<span class="normal">1419</span>
<span class="normal">1420</span>
<span class="normal">1421</span>
<span class="normal">1422</span>
<span class="normal">1423</span>
<span class="normal">1424</span>
<span class="normal">1425</span>
<span class="normal">1426</span>
<span class="normal">1427</span>
<span class="normal">1428</span>
<span class="normal">1429</span>
<span class="normal">1430</span>
<span class="normal">1431</span>
<span class="normal">1432</span>
<span class="normal">1433</span>
<span class="normal">1434</span>
<span class="normal">1435</span>
<span class="normal">1436</span>
<span class="normal">1437</span>
<span class="normal">1438</span>
<span class="normal">1439</span>
<span class="normal">1440</span>
<span class="normal">1441</span>
<span class="normal">1442</span>
<span class="normal">1443</span>
<span class="normal">1444</span>
<span class="normal">1445</span>
<span class="normal">1446</span>
<span class="normal">1447</span>
<span class="normal">1448</span>
<span class="normal">1449</span>
<span class="normal">1450</span>
<span class="normal">1451</span>
<span class="normal">1452</span>
<span class="normal">1453</span>
<span class="normal">1454</span>
<span class="normal">1455</span>
<span class="normal">1456</span>
<span class="normal">1457</span>
<span class="normal">1458</span>
<span class="normal">1459</span>
<span class="normal">1460</span>
<span class="normal">1461</span>
<span class="normal">1462</span>
<span class="normal">1463</span>
<span class="normal">1464</span>
<span class="normal">1465</span>
<span class="normal">1466</span>
<span class="normal">1467</span>
<span class="normal">1468</span>
<span class="normal">1469</span>
<span class="normal">1470</span>
<span class="normal">1471</span>
<span class="normal">1472</span>
<span class="normal">1473</span>
<span class="normal">1474</span>
<span class="normal">1475</span>
<span class="normal">1476</span>
<span class="normal">1477</span>
<span class="normal">1478</span>
<span class="normal">1479</span>
<span class="normal">1480</span>
<span class="normal">1481</span>
<span class="normal">1482</span>
<span class="normal">1483</span>
<span class="normal">1484</span>
<span class="normal">1485</span>
<span class="normal">1486</span>
<span class="normal">1487</span>
<span class="normal">1488</span>
<span class="normal">1489</span>
<span class="normal">1490</span>
<span class="normal">1491</span>
<span class="normal">1492</span>
<span class="normal">1493</span>
<span class="normal">1494</span>
<span class="normal">1495</span>
<span class="normal">1496</span>
<span class="normal">1497</span>
<span class="normal">1498</span>
<span class="normal">1499</span>
<span class="normal">1500</span>
<span class="normal">1501</span>
<span class="normal">1502</span>
<span class="normal">1503</span>
<span class="normal">1504</span>
<span class="normal">1505</span>
<span class="normal">1506</span>
<span class="normal">1507</span>
<span class="normal">1508</span>
<span class="normal">1509</span>
<span class="normal">1510</span>
<span class="normal">1511</span>
<span class="normal">1512</span>
<span class="normal">1513</span>
<span class="normal">1514</span>
<span class="normal">1515</span>
<span class="normal">1516</span>
<span class="normal">1517</span>
<span class="normal">1518</span>
<span class="normal">1519</span>
<span class="normal">1520</span>
<span class="normal">1521</span>
<span class="normal">1522</span>
<span class="normal">1523</span>
<span class="normal">1524</span>
<span class="normal">1525</span>
<span class="normal">1526</span>
<span class="normal">1527</span>
<span class="normal">1528</span>
<span class="normal">1529</span>
<span class="normal">1530</span>
<span class="normal">1531</span>
<span class="normal">1532</span>
<span class="normal">1533</span>
<span class="normal">1534</span>
<span class="normal">1535</span>
<span class="normal">1536</span>
<span class="normal">1537</span>
<span class="normal">1538</span>
<span class="normal">1539</span>
<span class="normal">1540</span>
<span class="normal">1541</span>
<span class="normal">1542</span>
<span class="normal">1543</span>
<span class="normal">1544</span>
<span class="normal">1545</span>
<span class="normal">1546</span>
<span class="normal">1547</span>
<span class="normal">1548</span>
<span class="normal">1549</span>
<span class="normal">1550</span>
<span class="normal">1551</span>
<span class="normal">1552</span>
<span class="normal">1553</span>
<span class="normal">1554</span>
<span class="normal">1555</span>
<span class="normal">1556</span>
<span class="normal">1557</span>
<span class="normal">1558</span>
<span class="normal">1559</span>
<span class="normal">1560</span>
<span class="normal">1561</span>
<span class="normal">1562</span>
<span class="normal">1563</span>
<span class="normal">1564</span>
<span class="normal">1565</span>
<span class="normal">1566</span>
<span class="normal">1567</span>
<span class="normal">1568</span>
<span class="normal">1569</span>
<span class="normal">1570</span>
<span class="normal">1571</span>
<span class="normal">1572</span>
<span class="normal">1573</span>
<span class="normal">1574</span>
<span class="normal">1575</span>
<span class="normal">1576</span>
<span class="normal">1577</span>
<span class="normal">1578</span>
<span class="normal">1579</span>
<span class="normal">1580</span>
<span class="normal">1581</span>
<span class="normal">1582</span>
<span class="normal">1583</span>
<span class="normal">1584</span>
<span class="normal">1585</span>
<span class="normal">1586</span>
<span class="normal">1587</span>
<span class="normal">1588</span>
<span class="normal">1589</span>
<span class="normal">1590</span>
<span class="normal">1591</span>
<span class="normal">1592</span>
<span class="normal">1593</span>
<span class="normal">1594</span>
<span class="normal">1595</span>
<span class="normal">1596</span>
<span class="normal">1597</span>
<span class="normal">1598</span>
<span class="normal">1599</span>
<span class="normal">1600</span>
<span class="normal">1601</span>
<span class="normal">1602</span>
<span class="normal">1603</span>
<span class="normal">1604</span>
<span class="normal">1605</span>
<span class="normal">1606</span>
<span class="normal">1607</span>
<span class="normal">1608</span>
<span class="normal">1609</span>
<span class="normal">1610</span>
<span class="normal">1611</span>
<span class="normal">1612</span>
<span class="normal">1613</span>
<span class="normal">1614</span>
<span class="normal">1615</span>
<span class="normal">1616</span>
<span class="normal">1617</span>
<span class="normal">1618</span>
<span class="normal">1619</span>
<span class="normal">1620</span>
<span class="normal">1621</span>
<span class="normal">1622</span>
<span class="normal">1623</span>
<span class="normal">1624</span>
<span class="normal">1625</span>
<span class="normal">1626</span>
<span class="normal">1627</span>
<span class="normal">1628</span>
<span class="normal">1629</span>
<span class="normal">1630</span>
<span class="normal">1631</span>
<span class="normal">1632</span>
<span class="normal">1633</span>
<span class="normal">1634</span>
<span class="normal">1635</span>
<span class="normal">1636</span>
<span class="normal">1637</span>
<span class="normal">1638</span>
<span class="normal">1639</span>
<span class="normal">1640</span>
<span class="normal">1641</span>
<span class="normal">1642</span>
<span class="normal">1643</span>
<span class="normal">1644</span>
<span class="normal">1645</span>
<span class="normal">1646</span>
<span class="normal">1647</span>
<span class="normal">1648</span>
<span class="normal">1649</span>
<span class="normal">1650</span>
<span class="normal">1651</span>
<span class="normal">1652</span>
<span class="normal">1653</span>
<span class="normal">1654</span>
<span class="normal">1655</span>
<span class="normal">1656</span>
<span class="normal">1657</span>
<span class="normal">1658</span>
<span class="normal">1659</span>
<span class="normal">1660</span>
<span class="normal">1661</span>
<span class="normal">1662</span>
<span class="normal">1663</span>
<span class="normal">1664</span>
<span class="normal">1665</span>
<span class="normal">1666</span>
<span class="normal">1667</span>
<span class="normal">1668</span>
<span class="normal">1669</span>
<span class="normal">1670</span>
<span class="normal">1671</span>
<span class="normal">1672</span>
<span class="normal">1673</span>
<span class="normal">1674</span>
<span class="normal">1675</span>
<span class="normal">1676</span>
<span class="normal">1677</span>
<span class="normal">1678</span>
<span class="normal">1679</span>
<span class="normal">1680</span>
<span class="normal">1681</span>
<span class="normal">1682</span>
<span class="normal">1683</span>
<span class="normal">1684</span>
<span class="normal">1685</span>
<span class="normal">1686</span>
<span class="normal">1687</span>
<span class="normal">1688</span>
<span class="normal">1689</span>
<span class="normal">1690</span>
<span class="normal">1691</span>
<span class="normal">1692</span>
<span class="normal">1693</span>
<span class="normal">1694</span>
<span class="normal">1695</span>
<span class="normal">1696</span>
<span class="normal">1697</span>
<span class="normal">1698</span>
<span class="normal">1699</span>
<span class="normal">1700</span>
<span class="normal">1701</span>
<span class="normal">1702</span>
<span class="normal">1703</span>
<span class="normal">1704</span>
<span class="normal">1705</span>
<span class="normal">1706</span>
<span class="normal">1707</span>
<span class="normal">1708</span>
<span class="normal">1709</span>
<span class="normal">1710</span>
<span class="normal">1711</span>
<span class="normal">1712</span>
<span class="normal">1713</span>
<span class="normal">1714</span>
<span class="normal">1715</span>
<span class="normal">1716</span>
<span class="normal">1717</span>
<span class="normal">1718</span>
<span class="normal">1719</span>
<span class="normal">1720</span>
<span class="normal">1721</span>
<span class="normal">1722</span>
<span class="normal">1723</span>
<span class="normal">1724</span>
<span class="normal">1725</span>
<span class="normal">1726</span>
<span class="normal">1727</span>
<span class="normal">1728</span>
<span class="normal">1729</span>
<span class="normal">1730</span>
<span class="normal">1731</span>
<span class="normal">1732</span>
<span class="normal">1733</span>
<span class="normal">1734</span>
<span class="normal">1735</span>
<span class="normal">1736</span>
<span class="normal">1737</span>
<span class="normal">1738</span>
<span class="normal">1739</span>
<span class="normal">1740</span>
<span class="normal">1741</span>
<span class="normal">1742</span>
<span class="normal">1743</span>
<span class="normal">1744</span>
<span class="normal">1745</span>
<span class="normal">1746</span>
<span class="normal">1747</span>
<span class="normal">1748</span>
<span class="normal">1749</span>
<span class="normal">1750</span>
<span class="normal">1751</span>
<span class="normal">1752</span>
<span class="normal">1753</span>
<span class="normal">1754</span>
<span class="normal">1755</span>
<span class="normal">1756</span>
<span class="normal">1757</span>
<span class="normal">1758</span>
<span class="normal">1759</span>
<span class="normal">1760</span>
<span class="normal">1761</span>
<span class="normal">1762</span>
<span class="normal">1763</span>
<span class="normal">1764</span>
<span class="normal">1765</span>
<span class="normal">1766</span>
<span class="normal">1767</span>
<span class="normal">1768</span>
<span class="normal">1769</span>
<span class="normal">1770</span>
<span class="normal">1771</span>
<span class="normal">1772</span>
<span class="normal">1773</span>
<span class="normal">1774</span>
<span class="normal">1775</span>
<span class="normal">1776</span>
<span class="normal">1777</span>
<span class="normal">1778</span>
<span class="normal">1779</span>
<span class="normal">1780</span>
<span class="normal">1781</span>
<span class="normal">1782</span>
<span class="normal">1783</span>
<span class="normal">1784</span>
<span class="normal">1785</span>
<span class="normal">1786</span>
<span class="normal">1787</span>
<span class="normal">1788</span>
<span class="normal">1789</span>
<span class="normal">1790</span>
<span class="normal">1791</span>
<span class="normal">1792</span>
<span class="normal">1793</span>
<span class="normal">1794</span>
<span class="normal">1795</span>
<span class="normal">1796</span>
<span class="normal">1797</span>
<span class="normal">1798</span>
<span class="normal">1799</span>
<span class="normal">1800</span>
<span class="normal">1801</span>
<span class="normal">1802</span>
<span class="normal">1803</span>
<span class="normal">1804</span>
<span class="normal">1805</span>
<span class="normal">1806</span>
<span class="normal">1807</span>
<span class="normal">1808</span>
<span class="normal">1809</span>
<span class="normal">1810</span>
<span class="normal">1811</span>
<span class="normal">1812</span>
<span class="normal">1813</span>
<span class="normal">1814</span>
<span class="normal">1815</span>
<span class="normal">1816</span>
<span class="normal">1817</span>
<span class="normal">1818</span>
<span class="normal">1819</span>
<span class="normal">1820</span>
<span class="normal">1821</span>
<span class="normal">1822</span>
<span class="normal">1823</span>
<span class="normal">1824</span>
<span class="normal">1825</span>
<span class="normal">1826</span>
<span class="normal">1827</span>
<span class="normal">1828</span>
<span class="normal">1829</span>
<span class="normal">1830</span>
<span class="normal">1831</span>
<span class="normal">1832</span>
<span class="normal">1833</span>
<span class="normal">1834</span>
<span class="normal">1835</span>
<span class="normal">1836</span>
<span class="normal">1837</span>
<span class="normal">1838</span>
<span class="normal">1839</span>
<span class="normal">1840</span>
<span class="normal">1841</span>
<span class="normal">1842</span>
<span class="normal">1843</span>
<span class="normal">1844</span>
<span class="normal">1845</span>
<span class="normal">1846</span>
<span class="normal">1847</span>
<span class="normal">1848</span>
<span class="normal">1849</span>
<span class="normal">1850</span>
<span class="normal">1851</span>
<span class="normal">1852</span>
<span class="normal">1853</span>
<span class="normal">1854</span>
<span class="normal">1855</span>
<span class="normal">1856</span>
<span class="normal">1857</span>
<span class="normal">1858</span>
<span class="normal">1859</span>
<span class="normal">1860</span>
<span class="normal">1861</span>
<span class="normal">1862</span>
<span class="normal">1863</span>
<span class="normal">1864</span>
<span class="normal">1865</span>
<span class="normal">1866</span>
<span class="normal">1867</span>
<span class="normal">1868</span>
<span class="normal">1869</span>
<span class="normal">1870</span>
<span class="normal">1871</span>
<span class="normal">1872</span>
<span class="normal">1873</span>
<span class="normal">1874</span>
<span class="normal">1875</span>
<span class="normal">1876</span>
<span class="normal">1877</span>
<span class="normal">1878</span>
<span class="normal">1879</span>
<span class="normal">1880</span>
<span class="normal">1881</span>
<span class="normal">1882</span>
<span class="normal">1883</span>
<span class="normal">1884</span>
<span class="normal">1885</span>
<span class="normal">1886</span>
<span class="normal">1887</span>
<span class="normal">1888</span>
<span class="normal">1889</span>
<span class="normal">1890</span>
<span class="normal">1891</span>
<span class="normal">1892</span>
<span class="normal">1893</span>
<span class="normal">1894</span>
<span class="normal">1895</span>
<span class="normal">1896</span>
<span class="normal">1897</span>
<span class="normal">1898</span>
<span class="normal">1899</span>
<span class="normal">1900</span>
<span class="normal">1901</span>
<span class="normal">1902</span>
<span class="normal">1903</span>
<span class="normal">1904</span>
<span class="normal">1905</span>
<span class="normal">1906</span>
<span class="normal">1907</span>
<span class="normal">1908</span>
<span class="normal">1909</span>
<span class="normal">1910</span>
<span class="normal">1911</span>
<span class="normal">1912</span>
<span class="normal">1913</span>
<span class="normal">1914</span>
<span class="normal">1915</span>
<span class="normal">1916</span>
<span class="normal">1917</span>
<span class="normal">1918</span>
<span class="normal">1919</span>
<span class="normal">1920</span>
<span class="normal">1921</span>
<span class="normal">1922</span>
<span class="normal">1923</span>
<span class="normal">1924</span>
<span class="normal">1925</span>
<span class="normal">1926</span>
<span class="normal">1927</span>
<span class="normal">1928</span>
<span class="normal">1929</span>
<span class="normal">1930</span>
<span class="normal">1931</span>
<span class="normal">1932</span>
<span class="normal">1933</span>
<span class="normal">1934</span>
<span class="normal">1935</span>
<span class="normal">1936</span>
<span class="normal">1937</span>
<span class="normal">1938</span>
<span class="normal">1939</span>
<span class="normal">1940</span>
<span class="normal">1941</span>
<span class="normal">1942</span>
<span class="normal">1943</span>
<span class="normal">1944</span>
<span class="normal">1945</span>
<span class="normal">1946</span>
<span class="normal">1947</span>
<span class="normal">1948</span>
<span class="normal">1949</span>
<span class="normal">1950</span>
<span class="normal">1951</span>
<span class="normal">1952</span>
<span class="normal">1953</span>
<span class="normal">1954</span>
<span class="normal">1955</span>
<span class="normal">1956</span>
<span class="normal">1957</span>
<span class="normal">1958</span>
<span class="normal">1959</span>
<span class="normal">1960</span>
<span class="normal">1961</span>
<span class="normal">1962</span>
<span class="normal">1963</span>
<span class="normal">1964</span>
<span class="normal">1965</span>
<span class="normal">1966</span>
<span class="normal">1967</span>
<span class="normal">1968</span>
<span class="normal">1969</span>
<span class="normal">1970</span>
<span class="normal">1971</span>
<span class="normal">1972</span>
<span class="normal">1973</span>
<span class="normal">1974</span>
<span class="normal">1975</span>
<span class="normal">1976</span>
<span class="normal">1977</span>
<span class="normal">1978</span>
<span class="normal">1979</span>
<span class="normal">1980</span>
<span class="normal">1981</span>
<span class="normal">1982</span>
<span class="normal">1983</span>
<span class="normal">1984</span>
<span class="normal">1985</span>
<span class="normal">1986</span>
<span class="normal">1987</span>
<span class="normal">1988</span>
<span class="normal">1989</span>
<span class="normal">1990</span>
<span class="normal">1991</span>
<span class="normal">1992</span>
<span class="normal">1993</span>
<span class="normal">1994</span>
<span class="normal">1995</span>
<span class="normal">1996</span>
<span class="normal">1997</span>
<span class="normal">1998</span>
<span class="normal">1999</span>
<span class="normal">2000</span>
<span class="normal">2001</span>
<span class="normal">2002</span>
<span class="normal">2003</span>
<span class="normal">2004</span>
<span class="normal">2005</span>
<span class="normal">2006</span>
<span class="normal">2007</span>
<span class="normal">2008</span>
<span class="normal">2009</span>
<span class="normal">2010</span>
<span class="normal">2011</span>
<span class="normal">2012</span>
<span class="normal">2013</span>
<span class="normal">2014</span>
<span class="normal">2015</span>
<span class="normal">2016</span>
<span class="normal">2017</span>
<span class="normal">2018</span>
<span class="normal">2019</span>
<span class="normal">2020</span>
<span class="normal">2021</span>
<span class="normal">2022</span>
<span class="normal">2023</span>
<span class="normal">2024</span>
<span class="normal">2025</span>
<span class="normal">2026</span>
<span class="normal">2027</span>
<span class="normal">2028</span>
<span class="normal">2029</span>
<span class="normal">2030</span>
<span class="normal">2031</span>
<span class="normal">2032</span>
<span class="normal">2033</span>
<span class="normal">2034</span>
<span class="normal">2035</span>
<span class="normal">2036</span>
<span class="normal">2037</span>
<span class="normal">2038</span>
<span class="normal">2039</span>
<span class="normal">2040</span>
<span class="normal">2041</span>
<span class="normal">2042</span>
<span class="normal">2043</span>
<span class="normal">2044</span>
<span class="normal">2045</span>
<span class="normal">2046</span>
<span class="normal">2047</span>
<span class="normal">2048</span>
<span class="normal">2049</span>
<span class="normal">2050</span>
<span class="normal">2051</span>
<span class="normal">2052</span>
<span class="normal">2053</span>
<span class="normal">2054</span>
<span class="normal">2055</span>
<span class="normal">2056</span>
<span class="normal">2057</span>
<span class="normal">2058</span>
<span class="normal">2059</span>
<span class="normal">2060</span>
<span class="normal">2061</span>
<span class="normal">2062</span>
<span class="normal">2063</span>
<span class="normal">2064</span>
<span class="normal">2065</span>
<span class="normal">2066</span>
<span class="normal">2067</span>
<span class="normal">2068</span>
<span class="normal">2069</span>
<span class="normal">2070</span>
<span class="normal">2071</span>
<span class="normal">2072</span>
<span class="normal">2073</span>
<span class="normal">2074</span>
<span class="normal">2075</span>
<span class="normal">2076</span>
<span class="normal">2077</span>
<span class="normal">2078</span>
<span class="normal">2079</span>
<span class="normal">2080</span>
<span class="normal">2081</span>
<span class="normal">2082</span>
<span class="normal">2083</span>
<span class="normal">2084</span>
<span class="normal">2085</span>
<span class="normal">2086</span>
<span class="normal">2087</span>
<span class="normal">2088</span>
<span class="normal">2089</span>
<span class="normal">2090</span>
<span class="normal">2091</span>
<span class="normal">2092</span>
<span class="normal">2093</span>
<span class="normal">2094</span>
<span class="normal">2095</span>
<span class="normal">2096</span>
<span class="normal">2097</span>
<span class="normal">2098</span>
<span class="normal">2099</span>
<span class="normal">2100</span>
<span class="normal">2101</span>
<span class="normal">2102</span>
<span class="normal">2103</span>
<span class="normal">2104</span>
<span class="normal">2105</span>
<span class="normal">2106</span>
<span class="normal">2107</span>
<span class="normal">2108</span>
<span class="normal">2109</span>
<span class="normal">2110</span>
<span class="normal">2111</span>
<span class="normal">2112</span>
<span class="normal">2113</span>
<span class="normal">2114</span>
<span class="normal">2115</span>
<span class="normal">2116</span>
<span class="normal">2117</span>
<span class="normal">2118</span>
<span class="normal">2119</span>
<span class="normal">2120</span>
<span class="normal">2121</span>
<span class="normal">2122</span>
<span class="normal">2123</span>
<span class="normal">2124</span>
<span class="normal">2125</span>
<span class="normal">2126</span>
<span class="normal">2127</span>
<span class="normal">2128</span>
<span class="normal">2129</span>
<span class="normal">2130</span>
<span class="normal">2131</span>
<span class="normal">2132</span>
<span class="normal">2133</span>
<span class="normal">2134</span>
<span class="normal">2135</span>
<span class="normal">2136</span>
<span class="normal">2137</span>
<span class="normal">2138</span>
<span class="normal">2139</span>
<span class="normal">2140</span>
<span class="normal">2141</span>
<span class="normal">2142</span>
<span class="normal">2143</span>
<span class="normal">2144</span>
<span class="normal">2145</span>
<span class="normal">2146</span>
<span class="normal">2147</span>
<span class="normal">2148</span>
<span class="normal">2149</span>
<span class="normal">2150</span>
<span class="normal">2151</span>
<span class="normal">2152</span>
<span class="normal">2153</span>
<span class="normal">2154</span>
<span class="normal">2155</span>
<span class="normal">2156</span>
<span class="normal">2157</span>
<span class="normal">2158</span>
<span class="normal">2159</span>
<span class="normal">2160</span>
<span class="normal">2161</span>
<span class="normal">2162</span>
<span class="normal">2163</span>
<span class="normal">2164</span>
<span class="normal">2165</span>
<span class="normal">2166</span>
<span class="normal">2167</span>
<span class="normal">2168</span>
<span class="normal">2169</span>
<span class="normal">2170</span>
<span class="normal">2171</span>
<span class="normal">2172</span>
<span class="normal">2173</span>
<span class="normal">2174</span>
<span class="normal">2175</span>
<span class="normal">2176</span>
<span class="normal">2177</span>
<span class="normal">2178</span>
<span class="normal">2179</span>
<span class="normal">2180</span>
<span class="normal">2181</span>
<span class="normal">2182</span>
<span class="normal">2183</span>
<span class="normal">2184</span>
<span class="normal">2185</span>
<span class="normal">2186</span>
<span class="normal">2187</span>
<span class="normal">2188</span>
<span class="normal">2189</span>
<span class="normal">2190</span>
<span class="normal">2191</span>
<span class="normal">2192</span>
<span class="normal">2193</span>
<span class="normal">2194</span>
<span class="normal">2195</span>
<span class="normal">2196</span>
<span class="normal">2197</span>
<span class="normal">2198</span>
<span class="normal">2199</span>
<span class="normal">2200</span>
<span class="normal">2201</span>
<span class="normal">2202</span>
<span class="normal">2203</span>
<span class="normal">2204</span>
<span class="normal">2205</span>
<span class="normal">2206</span>
<span class="normal">2207</span>
<span class="normal">2208</span>
<span class="normal">2209</span>
<span class="normal">2210</span>
<span class="normal">2211</span>
<span class="normal">2212</span>
<span class="normal">2213</span>
<span class="normal">2214</span>
<span class="normal">2215</span>
<span class="normal">2216</span>
<span class="normal">2217</span>
<span class="normal">2218</span>
<span class="normal">2219</span>
<span class="normal">2220</span>
<span class="normal">2221</span>
<span class="normal">2222</span>
<span class="normal">2223</span>
<span class="normal">2224</span>
<span class="normal">2225</span>
<span class="normal">2226</span>
<span class="normal">2227</span>
<span class="normal">2228</span>
<span class="normal">2229</span>
<span class="normal">2230</span>
<span class="normal">2231</span>
<span class="normal">2232</span>
<span class="normal">2233</span>
<span class="normal">2234</span>
<span class="normal">2235</span>
<span class="normal">2236</span>
<span class="normal">2237</span>
<span class="normal">2238</span>
<span class="normal">2239</span>
<span class="normal">2240</span>
<span class="normal">2241</span>
<span class="normal">2242</span>
<span class="normal">2243</span>
<span class="normal">2244</span>
<span class="normal">2245</span>
<span class="normal">2246</span>
<span class="normal">2247</span>
<span class="normal">2248</span>
<span class="normal">2249</span>
<span class="normal">2250</span>
<span class="normal">2251</span>
<span class="normal">2252</span>
<span class="normal">2253</span>
<span class="normal">2254</span>
<span class="normal">2255</span>
<span class="normal">2256</span>
<span class="normal">2257</span>
<span class="normal">2258</span>
<span class="normal">2259</span>
<span class="normal">2260</span>
<span class="normal">2261</span>
<span class="normal">2262</span>
<span class="normal">2263</span>
<span class="normal">2264</span>
<span class="normal">2265</span>
<span class="normal">2266</span>
<span class="normal">2267</span>
<span class="normal">2268</span>
<span class="normal">2269</span>
<span class="normal">2270</span>
<span class="normal">2271</span>
<span class="normal">2272</span>
<span class="normal">2273</span>
<span class="normal">2274</span>
<span class="normal">2275</span>
<span class="normal">2276</span>
<span class="normal">2277</span>
<span class="normal">2278</span>
<span class="normal">2279</span>
<span class="normal">2280</span>
<span class="normal">2281</span>
<span class="normal">2282</span>
<span class="normal">2283</span>
<span class="normal">2284</span>
<span class="normal">2285</span>
<span class="normal">2286</span>
<span class="normal">2287</span>
<span class="normal">2288</span>
<span class="normal">2289</span>
<span class="normal">2290</span>
<span class="normal">2291</span>
<span class="normal">2292</span>
<span class="normal">2293</span>
<span class="normal">2294</span>
<span class="normal">2295</span>
<span class="normal">2296</span>
<span class="normal">2297</span>
<span class="normal">2298</span>
<span class="normal">2299</span>
<span class="normal">2300</span>
<span class="normal">2301</span>
<span class="normal">2302</span>
<span class="normal">2303</span>
<span class="normal">2304</span>
<span class="normal">2305</span>
<span class="normal">2306</span>
<span class="normal">2307</span>
<span class="normal">2308</span>
<span class="normal">2309</span>
<span class="normal">2310</span>
<span class="normal">2311</span>
<span class="normal">2312</span>
<span class="normal">2313</span>
<span class="normal">2314</span>
<span class="normal">2315</span>
<span class="normal">2316</span>
<span class="normal">2317</span>
<span class="normal">2318</span>
<span class="normal">2319</span>
<span class="normal">2320</span>
<span class="normal">2321</span>
<span class="normal">2322</span>
<span class="normal">2323</span>
<span class="normal">2324</span>
<span class="normal">2325</span>
<span class="normal">2326</span>
<span class="normal">2327</span>
<span class="normal">2328</span>
<span class="normal">2329</span>
<span class="normal">2330</span>
<span class="normal">2331</span>
<span class="normal">2332</span>
<span class="normal">2333</span>
<span class="normal">2334</span>
<span class="normal">2335</span>
<span class="normal">2336</span>
<span class="normal">2337</span>
<span class="normal">2338</span>
<span class="normal">2339</span>
<span class="normal">2340</span>
<span class="normal">2341</span>
<span class="normal">2342</span>
<span class="normal">2343</span>
<span class="normal">2344</span>
<span class="normal">2345</span>
<span class="normal">2346</span>
<span class="normal">2347</span>
<span class="normal">2348</span>
<span class="normal">2349</span>
<span class="normal">2350</span>
<span class="normal">2351</span>
<span class="normal">2352</span>
<span class="normal">2353</span>
<span class="normal">2354</span>
<span class="normal">2355</span>
<span class="normal">2356</span>
<span class="normal">2357</span>
<span class="normal">2358</span>
<span class="normal">2359</span>
<span class="normal">2360</span>
<span class="normal">2361</span>
<span class="normal">2362</span>
<span class="normal">2363</span>
<span class="normal">2364</span>
<span class="normal">2365</span>
<span class="normal">2366</span>
<span class="normal">2367</span>
<span class="normal">2368</span>
<span class="normal">2369</span>
<span class="normal">2370</span>
<span class="normal">2371</span>
<span class="normal">2372</span>
<span class="normal">2373</span>
<span class="normal">2374</span>
<span class="normal">2375</span>
<span class="normal">2376</span>
<span class="normal">2377</span>
<span class="normal">2378</span>
<span class="normal">2379</span>
<span class="normal">2380</span>
<span class="normal">2381</span>
<span class="normal">2382</span>
<span class="normal">2383</span>
<span class="normal">2384</span>
<span class="normal">2385</span>
<span class="normal">2386</span>
<span class="normal">2387</span>
<span class="normal">2388</span>
<span class="normal">2389</span>
<span class="normal">2390</span>
<span class="normal">2391</span>
<span class="normal">2392</span>
<span class="normal">2393</span>
<span class="normal">2394</span>
<span class="normal">2395</span>
<span class="normal">2396</span>
<span class="normal">2397</span>
<span class="normal">2398</span>
<span class="normal">2399</span>
<span class="normal">2400</span>
<span class="normal">2401</span>
<span class="normal">2402</span>
<span class="normal">2403</span>
<span class="normal">2404</span>
<span class="normal">2405</span>
<span class="normal">2406</span>
<span class="normal">2407</span>
<span class="normal">2408</span>
<span class="normal">2409</span>
<span class="normal">2410</span>
<span class="normal">2411</span>
<span class="normal">2412</span>
<span class="normal">2413</span>
<span class="normal">2414</span>
<span class="normal">2415</span>
<span class="normal">2416</span>
<span class="normal">2417</span>
<span class="normal">2418</span>
<span class="normal">2419</span>
<span class="normal">2420</span>
<span class="normal">2421</span>
<span class="normal">2422</span>
<span class="normal">2423</span>
<span class="normal">2424</span>
<span class="normal">2425</span>
<span class="normal">2426</span>
<span class="normal">2427</span>
<span class="normal">2428</span>
<span class="normal">2429</span>
<span class="normal">2430</span>
<span class="normal">2431</span>
<span class="normal">2432</span>
<span class="normal">2433</span>
<span class="normal">2434</span>
<span class="normal">2435</span>
<span class="normal">2436</span>
<span class="normal">2437</span>
<span class="normal">2438</span>
<span class="normal">2439</span>
<span class="normal">2440</span>
<span class="normal">2441</span>
<span class="normal">2442</span>
<span class="normal">2443</span>
<span class="normal">2444</span>
<span class="normal">2445</span>
<span class="normal">2446</span>
<span class="normal">2447</span>
<span class="normal">2448</span>
<span class="normal">2449</span>
<span class="normal">2450</span>
<span class="normal">2451</span>
<span class="normal">2452</span>
<span class="normal">2453</span>
<span class="normal">2454</span>
<span class="normal">2455</span>
<span class="normal">2456</span>
<span class="normal">2457</span>
<span class="normal">2458</span>
<span class="normal">2459</span>
<span class="normal">2460</span>
<span class="normal">2461</span>
<span class="normal">2462</span>
<span class="normal">2463</span>
<span class="normal">2464</span>
<span class="normal">2465</span>
<span class="normal">2466</span>
<span class="normal">2467</span>
<span class="normal">2468</span>
<span class="normal">2469</span>
<span class="normal">2470</span>
<span class="normal">2471</span>
<span class="normal">2472</span>
<span class="normal">2473</span>
<span class="normal">2474</span>
<span class="normal">2475</span>
<span class="normal">2476</span>
<span class="normal">2477</span>
<span class="normal">2478</span>
<span class="normal">2479</span>
<span class="normal">2480</span>
<span class="normal">2481</span>
<span class="normal">2482</span>
<span class="normal">2483</span>
<span class="normal">2484</span>
<span class="normal">2485</span>
<span class="normal">2486</span>
<span class="normal">2487</span>
<span class="normal">2488</span>
<span class="normal">2489</span>
<span class="normal">2490</span>
<span class="normal">2491</span>
<span class="normal">2492</span>
<span class="normal">2493</span>
<span class="normal">2494</span>
<span class="normal">2495</span>
<span class="normal">2496</span>
<span class="normal">2497</span>
<span class="normal">2498</span>
<span class="normal">2499</span>
<span class="normal">2500</span>
<span class="normal">2501</span>
<span class="normal">2502</span>
<span class="normal">2503</span>
<span class="normal">2504</span>
<span class="normal">2505</span>
<span class="normal">2506</span>
<span class="normal">2507</span>
<span class="normal">2508</span>
<span class="normal">2509</span>
<span class="normal">2510</span>
<span class="normal">2511</span>
<span class="normal">2512</span>
<span class="normal">2513</span>
<span class="normal">2514</span>
<span class="normal">2515</span>
<span class="normal">2516</span>
<span class="normal">2517</span>
<span class="normal">2518</span>
<span class="normal">2519</span>
<span class="normal">2520</span>
<span class="normal">2521</span>
<span class="normal">2522</span>
<span class="normal">2523</span>
<span class="normal">2524</span>
<span class="normal">2525</span>
<span class="normal">2526</span>
<span class="normal">2527</span>
<span class="normal">2528</span>
<span class="normal">2529</span>
<span class="normal">2530</span>
<span class="normal">2531</span>
<span class="normal">2532</span>
<span class="normal">2533</span>
<span class="normal">2534</span>
<span class="normal">2535</span>
<span class="normal">2536</span>
<span class="normal">2537</span>
<span class="normal">2538</span>
<span class="normal">2539</span>
<span class="normal">2540</span>
<span class="normal">2541</span>
<span class="normal">2542</span>
<span class="normal">2543</span>
<span class="normal">2544</span>
<span class="normal">2545</span>
<span class="normal">2546</span>
<span class="normal">2547</span>
<span class="normal">2548</span>
<span class="normal">2549</span>
<span class="normal">2550</span>
<span class="normal">2551</span>
<span class="normal">2552</span>
<span class="normal">2553</span>
<span class="normal">2554</span>
<span class="normal">2555</span>
<span class="normal">2556</span>
<span class="normal">2557</span>
<span class="normal">2558</span>
<span class="normal">2559</span>
<span class="normal">2560</span>
<span class="normal">2561</span>
<span class="normal">2562</span>
<span class="normal">2563</span>
<span class="normal">2564</span>
<span class="normal">2565</span>
<span class="normal">2566</span>
<span class="normal">2567</span>
<span class="normal">2568</span>
<span class="normal">2569</span>
<span class="normal">2570</span>
<span class="normal">2571</span>
<span class="normal">2572</span>
<span class="normal">2573</span>
<span class="normal">2574</span>
<span class="normal">2575</span>
<span class="normal">2576</span>
<span class="normal">2577</span>
<span class="normal">2578</span>
<span class="normal">2579</span>
<span class="normal">2580</span>
<span class="normal">2581</span>
<span class="normal">2582</span>
<span class="normal">2583</span>
<span class="normal">2584</span>
<span class="normal">2585</span>
<span class="normal">2586</span>
<span class="normal">2587</span>
<span class="normal">2588</span>
<span class="normal">2589</span>
<span class="normal">2590</span>
<span class="normal">2591</span>
<span class="normal">2592</span>
<span class="normal">2593</span>
<span class="normal">2594</span>
<span class="normal">2595</span>
<span class="normal">2596</span>
<span class="normal">2597</span>
<span class="normal">2598</span>
<span class="normal">2599</span>
<span class="normal">2600</span>
<span class="normal">2601</span>
<span class="normal">2602</span>
<span class="normal">2603</span>
<span class="normal">2604</span>
<span class="normal">2605</span>
<span class="normal">2606</span>
<span class="normal">2607</span>
<span class="normal">2608</span>
<span class="normal">2609</span>
<span class="normal">2610</span>
<span class="normal">2611</span>
<span class="normal">2612</span>
<span class="normal">2613</span>
<span class="normal">2614</span>
<span class="normal">2615</span>
<span class="normal">2616</span>
<span class="normal">2617</span>
<span class="normal">2618</span>
<span class="normal">2619</span>
<span class="normal">2620</span>
<span class="normal">2621</span>
<span class="normal">2622</span>
<span class="normal">2623</span>
<span class="normal">2624</span>
<span class="normal">2625</span>
<span class="normal">2626</span>
<span class="normal">2627</span>
<span class="normal">2628</span>
<span class="normal">2629</span>
<span class="normal">2630</span>
<span class="normal">2631</span>
<span class="normal">2632</span>
<span class="normal">2633</span>
<span class="normal">2634</span>
<span class="normal">2635</span>
<span class="normal">2636</span>
<span class="normal">2637</span>
<span class="normal">2638</span>
<span class="normal">2639</span>
<span class="normal">2640</span>
<span class="normal">2641</span>
<span class="normal">2642</span>
<span class="normal">2643</span>
<span class="normal">2644</span>
<span class="normal">2645</span>
<span class="normal">2646</span>
<span class="normal">2647</span>
<span class="normal">2648</span>
<span class="normal">2649</span>
<span class="normal">2650</span>
<span class="normal">2651</span>
<span class="normal">2652</span>
<span class="normal">2653</span>
<span class="normal">2654</span>
<span class="normal">2655</span>
<span class="normal">2656</span>
<span class="normal">2657</span>
<span class="normal">2658</span>
<span class="normal">2659</span>
<span class="normal">2660</span>
<span class="normal">2661</span>
<span class="normal">2662</span>
<span class="normal">2663</span>
<span class="normal">2664</span>
<span class="normal">2665</span>
<span class="normal">2666</span>
<span class="normal">2667</span>
<span class="normal">2668</span>
<span class="normal">2669</span>
<span class="normal">2670</span>
<span class="normal">2671</span>
<span class="normal">2672</span>
<span class="normal">2673</span>
<span class="normal">2674</span>
<span class="normal">2675</span>
<span class="normal">2676</span>
<span class="normal">2677</span>
<span class="normal">2678</span>
<span class="normal">2679</span>
<span class="normal">2680</span>
<span class="normal">2681</span>
<span class="normal">2682</span>
<span class="normal">2683</span>
<span class="normal">2684</span>
<span class="normal">2685</span>
<span class="normal">2686</span>
<span class="normal">2687</span>
<span class="normal">2688</span>
<span class="normal">2689</span>
<span class="normal">2690</span>
<span class="normal">2691</span>
<span class="normal">2692</span>
<span class="normal">2693</span>
<span class="normal">2694</span>
<span class="normal">2695</span>
<span class="normal">2696</span>
<span class="normal">2697</span>
<span class="normal">2698</span>
<span class="normal">2699</span>
<span class="normal">2700</span>
<span class="normal">2701</span>
<span class="normal">2702</span>
<span class="normal">2703</span>
<span class="normal">2704</span>
<span class="normal">2705</span>
<span class="normal">2706</span>
<span class="normal">2707</span>
<span class="normal">2708</span>
<span class="normal">2709</span>
<span class="normal">2710</span>
<span class="normal">2711</span>
<span class="normal">2712</span>
<span class="normal">2713</span>
<span class="normal">2714</span>
<span class="normal">2715</span>
<span class="normal">2716</span>
<span class="normal">2717</span>
<span class="normal">2718</span>
<span class="normal">2719</span>
<span class="normal">2720</span>
<span class="normal">2721</span>
<span class="normal">2722</span>
<span class="normal">2723</span>
<span class="normal">2724</span>
<span class="normal">2725</span>
<span class="normal">2726</span>
<span class="normal">2727</span>
<span class="normal">2728</span>
<span class="normal">2729</span>
<span class="normal">2730</span>
<span class="normal">2731</span>
<span class="normal">2732</span>
<span class="normal">2733</span>
<span class="normal">2734</span>
<span class="normal">2735</span>
<span class="normal">2736</span>
<span class="normal">2737</span>
<span class="normal">2738</span>
<span class="normal">2739</span>
<span class="normal">2740</span>
<span class="normal">2741</span>
<span class="normal">2742</span>
<span class="normal">2743</span>
<span class="normal">2744</span>
<span class="normal">2745</span>
<span class="normal">2746</span>
<span class="normal">2747</span>
<span class="normal">2748</span>
<span class="normal">2749</span>
<span class="normal">2750</span>
<span class="normal">2751</span>
<span class="normal">2752</span>
<span class="normal">2753</span>
<span class="normal">2754</span>
<span class="normal">2755</span>
<span class="normal">2756</span>
<span class="normal">2757</span>
<span class="normal">2758</span>
<span class="normal">2759</span>
<span class="normal">2760</span>
<span class="normal">2761</span>
<span class="normal">2762</span>
<span class="normal">2763</span>
<span class="normal">2764</span>
<span class="normal">2765</span>
<span class="normal">2766</span>
<span class="normal">2767</span>
<span class="normal">2768</span>
<span class="normal">2769</span>
<span class="normal">2770</span>
<span class="normal">2771</span>
<span class="normal">2772</span>
<span class="normal">2773</span>
<span class="normal">2774</span>
<span class="normal">2775</span>
<span class="normal">2776</span>
<span class="normal">2777</span>
<span class="normal">2778</span>
<span class="normal">2779</span>
<span class="normal">2780</span>
<span class="normal">2781</span>
<span class="normal">2782</span>
<span class="normal">2783</span>
<span class="normal">2784</span>
<span class="normal">2785</span>
<span class="normal">2786</span>
<span class="normal">2787</span>
<span class="normal">2788</span>
<span class="normal">2789</span>
<span class="normal">2790</span>
<span class="normal">2791</span>
<span class="normal">2792</span>
<span class="normal">2793</span>
<span class="normal">2794</span>
<span class="normal">2795</span>
<span class="normal">2796</span>
<span class="normal">2797</span>
<span class="normal">2798</span>
<span class="normal">2799</span>
<span class="normal">2800</span>
<span class="normal">2801</span>
<span class="normal">2802</span>
<span class="normal">2803</span>
<span class="normal">2804</span>
<span class="normal">2805</span>
<span class="normal">2806</span>
<span class="normal">2807</span>
<span class="normal">2808</span>
<span class="normal">2809</span>
<span class="normal">2810</span>
<span class="normal">2811</span>
<span class="normal">2812</span>
<span class="normal">2813</span>
<span class="normal">2814</span>
<span class="normal">2815</span>
<span class="normal">2816</span>
<span class="normal">2817</span>
<span class="normal">2818</span>
<span class="normal">2819</span>
<span class="normal">2820</span>
<span class="normal">2821</span>
<span class="normal">2822</span>
<span class="normal">2823</span>
<span class="normal">2824</span>
<span class="normal">2825</span>
<span class="normal">2826</span>
<span class="normal">2827</span>
<span class="normal">2828</span>
<span class="normal">2829</span>
<span class="normal">2830</span>
<span class="normal">2831</span>
<span class="normal">2832</span>
<span class="normal">2833</span>
<span class="normal">2834</span>
<span class="normal">2835</span>
<span class="normal">2836</span>
<span class="normal">2837</span>
<span class="normal">2838</span>
<span class="normal">2839</span>
<span class="normal">2840</span>
<span class="normal">2841</span>
<span class="normal">2842</span>
<span class="normal">2843</span>
<span class="normal">2844</span>
<span class="normal">2845</span>
<span class="normal">2846</span>
<span class="normal">2847</span>
<span class="normal">2848</span>
<span class="normal">2849</span>
<span class="normal">2850</span>
<span class="normal">2851</span>
<span class="normal">2852</span>
<span class="normal">2853</span>
<span class="normal">2854</span>
<span class="normal">2855</span>
<span class="normal">2856</span>
<span class="normal">2857</span>
<span class="normal">2858</span>
<span class="normal">2859</span>
<span class="normal">2860</span>
<span class="normal">2861</span>
<span class="normal">2862</span>
<span class="normal">2863</span>
<span class="normal">2864</span>
<span class="normal">2865</span>
<span class="normal">2866</span>
<span class="normal">2867</span>
<span class="normal">2868</span>
<span class="normal">2869</span>
<span class="normal">2870</span>
<span class="normal">2871</span>
<span class="normal">2872</span>
<span class="normal">2873</span>
<span class="normal">2874</span>
<span class="normal">2875</span>
<span class="normal">2876</span>
<span class="normal">2877</span>
<span class="normal">2878</span>
<span class="normal">2879</span>
<span class="normal">2880</span>
<span class="normal">2881</span>
<span class="normal">2882</span>
<span class="normal">2883</span>
<span class="normal">2884</span>
<span class="normal">2885</span>
<span class="normal">2886</span>
<span class="normal">2887</span>
<span class="normal">2888</span>
<span class="normal">2889</span>
<span class="normal">2890</span>
<span class="normal">2891</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">InferenceHTTPClient</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;HTTP client for making inference requests to Roboflow&#39;s API.</span>

<span class="sd">    This client handles authentication, request formatting, and error handling for</span>
<span class="sd">    interacting with Roboflow&#39;s inference endpoints. It supports both synchronous</span>
<span class="sd">    and asynchronous requests.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        inference_configuration (InferenceConfiguration): Configuration settings for</span>
<span class="sd">            inference requests.</span>
<span class="sd">        client_mode (HTTPClientMode): The API version mode being used (V0 or V1).</span>
<span class="sd">        selected_model (Optional[str]): Currently selected model identifier, if any.</span>

<span class="sd">    Example:</span>
<span class="sd">        ```python</span>
<span class="sd">        from inference_sdk import InferenceHTTPClient</span>

<span class="sd">        client = InferenceHTTPClient(</span>
<span class="sd">            api_url=&quot;http://localhost:9001&quot;, # use local inference server</span>
<span class="sd">            # api_key=&quot;&lt;YOUR API KEY&gt;&quot; # optional to access your private data and models</span>
<span class="sd">        )</span>

<span class="sd">        result = client.run_workflow(</span>
<span class="sd">            workspace_name=&quot;roboflow-docs&quot;,</span>
<span class="sd">            workflow_id=&quot;model-comparison&quot;,</span>
<span class="sd">            images={</span>
<span class="sd">                &quot;image&quot;: &quot;https://media.roboflow.com/workflows/examples/bleachers.jpg&quot;</span>
<span class="sd">            },</span>
<span class="sd">            parameters={</span>
<span class="sd">                &quot;model1&quot;: &quot;yolov8n-640&quot;,</span>
<span class="sd">                &quot;model2&quot;: &quot;yolov11n-640&quot;</span>
<span class="sd">            }</span>
<span class="sd">        )</span>
<span class="sd">        ```</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">init</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">api_url</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">api_key</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;InferenceHTTPClient&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize a new InferenceHTTPClient instance.</span>

<span class="sd">        Args:</span>
<span class="sd">            api_url (str): The base URL for the inference API.</span>
<span class="sd">            api_key (Optional[str], optional): API key for authentication. Defaults to None.</span>

<span class="sd">        Returns:</span>
<span class="sd">            InferenceHTTPClient: A new instance of the InferenceHTTPClient.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span><span class="n">api_url</span><span class="o">=</span><span class="n">api_url</span><span class="p">,</span> <span class="n">api_key</span><span class="o">=</span><span class="n">api_key</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">api_url</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">api_key</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize a new InferenceHTTPClient instance.</span>

<span class="sd">        Args:</span>
<span class="sd">            api_url (str): The base URL for the inference API.</span>
<span class="sd">            api_key (Optional[str], optional): API key for authentication. Defaults to None.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__api_url</span> <span class="o">=</span> <span class="n">api_url</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__api_key</span> <span class="o">=</span> <span class="n">api_key</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__inference_configuration</span> <span class="o">=</span> <span class="n">InferenceConfiguration</span><span class="o">.</span><span class="n">init_default</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__client_mode</span> <span class="o">=</span> <span class="n">_determine_client_mode</span><span class="p">(</span><span class="n">api_url</span><span class="o">=</span><span class="n">api_url</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__selected_model</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__webrtc_client</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;WebRTCClient&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">inference_configuration</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">InferenceConfiguration</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the current inference configuration.</span>

<span class="sd">        Returns:</span>
<span class="sd">            InferenceConfiguration: The current inference configuration settings.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__inference_configuration</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">client_mode</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">HTTPClientMode</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the current client mode.</span>

<span class="sd">        Returns:</span>
<span class="sd">            HTTPClientMode: The current API version mode (V0 or V1).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__client_mode</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">selected_model</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the currently selected model identifier.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Optional[str]: The identifier of the currently selected model, if any.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__selected_model</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">webrtc</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;WebRTCClient&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Lazy accessor for the WebRTC client namespace.</span>

<span class="sd">        Returns:</span>
<span class="sd">            WebRTCClient: Namespaced WebRTC API bound to this HTTP client.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">inference_sdk.webrtc.client</span><span class="w"> </span><span class="kn">import</span> <span class="n">WebRTCClient</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">__webrtc_client</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__webrtc_client</span> <span class="o">=</span> <span class="n">WebRTCClient</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__api_url</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">__api_key</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__webrtc_client</span>

    <span class="nd">@contextmanager</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">use_configuration</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">inference_configuration</span><span class="p">:</span> <span class="n">InferenceConfiguration</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Generator</span><span class="p">[</span><span class="s2">&quot;InferenceHTTPClient&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Temporarily use a different inference configuration.</span>

<span class="sd">        Args:</span>
<span class="sd">            inference_configuration (InferenceConfiguration): The temporary configuration to use.</span>

<span class="sd">        Yields:</span>
<span class="sd">            Generator[InferenceHTTPClient, None, None]: The client instance with temporary configuration.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">previous_configuration</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__inference_configuration</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__inference_configuration</span> <span class="o">=</span> <span class="n">inference_configuration</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">yield</span> <span class="bp">self</span>
        <span class="k">finally</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__inference_configuration</span> <span class="o">=</span> <span class="n">previous_configuration</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">configure</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">inference_configuration</span><span class="p">:</span> <span class="n">InferenceConfiguration</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;InferenceHTTPClient&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Configure the client with new inference settings.</span>

<span class="sd">        Args:</span>
<span class="sd">            inference_configuration (InferenceConfiguration): The new configuration to apply.</span>

<span class="sd">        Returns:</span>
<span class="sd">            InferenceHTTPClient: The client instance with updated configuration.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__inference_configuration</span> <span class="o">=</span> <span class="n">inference_configuration</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">select_api_v0</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;InferenceHTTPClient&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Select API version 0 for client operations.</span>

<span class="sd">        Returns:</span>
<span class="sd">            InferenceHTTPClient: The client instance with API v0 selected.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__client_mode</span> <span class="o">=</span> <span class="n">HTTPClientMode</span><span class="o">.</span><span class="n">V0</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">select_api_v1</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;InferenceHTTPClient&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Select API version 1 for client operations.</span>

<span class="sd">        Returns:</span>
<span class="sd">            InferenceHTTPClient: The client instance with API v1 selected.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__client_mode</span> <span class="o">=</span> <span class="n">HTTPClientMode</span><span class="o">.</span><span class="n">V1</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="nd">@contextmanager</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">use_api_v0</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Generator</span><span class="p">[</span><span class="s2">&quot;InferenceHTTPClient&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Temporarily use API version 0 for client operations.</span>

<span class="sd">        Yields:</span>
<span class="sd">            Generator[InferenceHTTPClient, None, None]: The client instance temporarily using API v0.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">previous_client_mode</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__client_mode</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__client_mode</span> <span class="o">=</span> <span class="n">HTTPClientMode</span><span class="o">.</span><span class="n">V0</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">yield</span> <span class="bp">self</span>
        <span class="k">finally</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__client_mode</span> <span class="o">=</span> <span class="n">previous_client_mode</span>

    <span class="nd">@contextmanager</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">use_api_v1</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Generator</span><span class="p">[</span><span class="s2">&quot;InferenceHTTPClient&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Temporarily use API version 1 for client operations.</span>

<span class="sd">        Yields:</span>
<span class="sd">            Generator[InferenceHTTPClient, None, None]: The client instance temporarily using API v1.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">previous_client_mode</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__client_mode</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__client_mode</span> <span class="o">=</span> <span class="n">HTTPClientMode</span><span class="o">.</span><span class="n">V1</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">yield</span> <span class="bp">self</span>
        <span class="k">finally</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__client_mode</span> <span class="o">=</span> <span class="n">previous_client_mode</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">select_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;InferenceHTTPClient&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Select a model for inference operations.</span>

<span class="sd">        Args:</span>
<span class="sd">            model_id (str): The identifier of the model to select.</span>

<span class="sd">        Returns:</span>
<span class="sd">            InferenceHTTPClient: The client instance with the selected model.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__selected_model</span> <span class="o">=</span> <span class="n">model_id</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="nd">@contextmanager</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">use_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Generator</span><span class="p">[</span><span class="s2">&quot;InferenceHTTPClient&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Temporarily use a specific model for inference operations.</span>

<span class="sd">        Args:</span>
<span class="sd">            model_id (str): The identifier of the model to use.</span>

<span class="sd">        Yields:</span>
<span class="sd">            Generator[InferenceHTTPClient, None, None]: The client instance temporarily using the specified model.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">previous_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__selected_model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__selected_model</span> <span class="o">=</span> <span class="n">model_id</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">yield</span> <span class="bp">self</span>
        <span class="k">finally</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__selected_model</span> <span class="o">=</span> <span class="n">previous_model</span>

    <span class="nd">@wrap_errors</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">get_server_info</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ServerInfo</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get information about the inference server.</span>

<span class="sd">        Returns:</span>
<span class="sd">            ServerInfo: Information about the server configuration and status.</span>

<span class="sd">        Raises:</span>
<span class="sd">            HTTPCallErrorError: If there is an error in the HTTP call.</span>
<span class="sd">            HTTPClientError: If there is an error with the server connection.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__api_url</span><span class="si">}</span><span class="s2">/info&quot;</span><span class="p">)</span>
        <span class="n">response</span><span class="o">.</span><span class="n">raise_for_status</span><span class="p">()</span>
        <span class="n">response_payload</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">ServerInfo</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">response_payload</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">infer_on_stream</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">input_uri</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">model_id</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Generator</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="nb">dict</span><span class="p">],</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Run inference on a video stream or sequence of images.</span>

<span class="sd">        Args:</span>
<span class="sd">            input_uri (str): URI of the input stream or directory.</span>
<span class="sd">            model_id (Optional[str], optional): Model identifier to use for inference. Defaults to None.</span>

<span class="sd">        Yields:</span>
<span class="sd">            Generator[Tuple[Union[str, int], np.ndarray, dict], None, None]: Tuples of (frame reference, frame data, prediction).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">reference</span><span class="p">,</span> <span class="n">frame</span> <span class="ow">in</span> <span class="n">load_stream_inference_input</span><span class="p">(</span>
            <span class="n">input_uri</span><span class="o">=</span><span class="n">input_uri</span><span class="p">,</span>
            <span class="n">image_extensions</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">__inference_configuration</span><span class="o">.</span><span class="n">image_extensions_for_directory_scan</span><span class="p">,</span>
        <span class="p">):</span>
            <span class="n">prediction</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">infer</span><span class="p">(</span>
                <span class="n">inference_input</span><span class="o">=</span><span class="n">frame</span><span class="p">,</span>
                <span class="n">model_id</span><span class="o">=</span><span class="n">model_id</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">yield</span> <span class="n">reference</span><span class="p">,</span> <span class="n">frame</span><span class="p">,</span> <span class="n">prediction</span>

    <span class="nd">@wrap_errors</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">infer</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">inference_input</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">]],</span>
        <span class="n">model_id</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Run inference on one or more images.</span>

<span class="sd">        Args:</span>
<span class="sd">            inference_input (Union[ImagesReference, List[ImagesReference]]): Input image(s) for inference.</span>
<span class="sd">            model_id (Optional[str], optional): Model identifier to use for inference. Defaults to None.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Union[dict, List[dict]]: Inference results for the input image(s).</span>

<span class="sd">        Raises:</span>
<span class="sd">            HTTPCallErrorError: If there is an error in the HTTP call.</span>
<span class="sd">            HTTPClientError: If there is an error with the server connection.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">__client_mode</span> <span class="ow">is</span> <span class="n">HTTPClientMode</span><span class="o">.</span><span class="n">V0</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">infer_from_api_v0</span><span class="p">(</span>
                <span class="n">inference_input</span><span class="o">=</span><span class="n">inference_input</span><span class="p">,</span>
                <span class="n">model_id</span><span class="o">=</span><span class="n">model_id</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">infer_from_api_v1</span><span class="p">(</span>
            <span class="n">inference_input</span><span class="o">=</span><span class="n">inference_input</span><span class="p">,</span>
            <span class="n">model_id</span><span class="o">=</span><span class="n">model_id</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="nd">@wrap_errors_async</span>
    <span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">infer_async</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">inference_input</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">]],</span>
        <span class="n">model_id</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Run inference asynchronously on one or more images.</span>

<span class="sd">        Args:</span>
<span class="sd">            inference_input (Union[ImagesReference, List[ImagesReference]]): Input image(s) for inference.</span>
<span class="sd">            model_id (Optional[str], optional): Model identifier to use for inference. Defaults to None.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Union[dict, List[dict]]: Inference results for the input image(s).</span>

<span class="sd">        Raises:</span>
<span class="sd">            HTTPCallErrorError: If there is an error in the HTTP call.</span>
<span class="sd">            HTTPClientError: If there is an error with the server connection.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">__client_mode</span> <span class="ow">is</span> <span class="n">HTTPClientMode</span><span class="o">.</span><span class="n">V0</span><span class="p">:</span>
            <span class="k">return</span> <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">infer_from_api_v0_async</span><span class="p">(</span>
                <span class="n">inference_input</span><span class="o">=</span><span class="n">inference_input</span><span class="p">,</span>
                <span class="n">model_id</span><span class="o">=</span><span class="n">model_id</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">infer_from_api_v1_async</span><span class="p">(</span>
            <span class="n">inference_input</span><span class="o">=</span><span class="n">inference_input</span><span class="p">,</span>
            <span class="n">model_id</span><span class="o">=</span><span class="n">model_id</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">infer_from_api_v0</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">inference_input</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">]],</span>
        <span class="n">model_id</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Run inference using API v0.</span>

<span class="sd">        Args:</span>
<span class="sd">            inference_input (Union[ImagesReference, List[ImagesReference]]): Input image(s) for inference.</span>
<span class="sd">            model_id (Optional[str], optional): Model identifier to use for inference. Defaults to None.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Union[dict, List[dict]]: Inference results for the input image(s).</span>

<span class="sd">        Raises:</span>
<span class="sd">            ModelNotSelectedError: If no model is selected.</span>
<span class="sd">            APIKeyNotProvided: If API key is required but not provided.</span>
<span class="sd">            InvalidModelIdentifier: If the model identifier format is invalid.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">requests_data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_prepare_infer_from_api_v0_request_data</span><span class="p">(</span>
            <span class="n">inference_input</span><span class="o">=</span><span class="n">inference_input</span><span class="p">,</span>
            <span class="n">model_id</span><span class="o">=</span><span class="n">model_id</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">responses</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_execute_infer_from_api_request</span><span class="p">(</span>
            <span class="n">requests_data</span><span class="o">=</span><span class="n">requests_data</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">request_data</span><span class="p">,</span> <span class="n">response</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">requests_data</span><span class="p">,</span> <span class="n">responses</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">response_contains_jpeg_image</span><span class="p">(</span><span class="n">response</span><span class="o">=</span><span class="n">response</span><span class="p">):</span>
                <span class="n">visualisation</span> <span class="o">=</span> <span class="n">transform_visualisation_bytes</span><span class="p">(</span>
                    <span class="n">visualisation</span><span class="o">=</span><span class="n">response</span><span class="o">.</span><span class="n">content</span><span class="p">,</span>
                    <span class="n">expected_format</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">__inference_configuration</span><span class="o">.</span><span class="n">output_visualisation_format</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">parsed_response</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;visualization&quot;</span><span class="p">:</span> <span class="n">visualisation</span><span class="p">}</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">parsed_response</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>
                <span class="k">if</span> <span class="n">parsed_response</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;visualization&quot;</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">parsed_response</span><span class="p">[</span><span class="s2">&quot;visualization&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">transform_base64_visualisation</span><span class="p">(</span>
                        <span class="n">visualisation</span><span class="o">=</span><span class="n">parsed_response</span><span class="p">[</span><span class="s2">&quot;visualization&quot;</span><span class="p">],</span>
                        <span class="n">expected_format</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">__inference_configuration</span><span class="o">.</span><span class="n">output_visualisation_format</span><span class="p">,</span>
                    <span class="p">)</span>
            <span class="n">parsed_response</span> <span class="o">=</span> <span class="n">adjust_prediction_to_client_scaling_factor</span><span class="p">(</span>
                <span class="n">prediction</span><span class="o">=</span><span class="n">parsed_response</span><span class="p">,</span>
                <span class="n">scaling_factor</span><span class="o">=</span><span class="n">request_data</span><span class="o">.</span><span class="n">image_scaling_factors</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
            <span class="p">)</span>
            <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">parsed_response</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">unwrap_single_element_list</span><span class="p">(</span><span class="n">sequence</span><span class="o">=</span><span class="n">results</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_execute_infer_from_api_request</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">requests_data</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">RequestData</span><span class="p">],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Response</span><span class="p">]:</span>
        <span class="n">responses</span> <span class="o">=</span> <span class="n">execute_requests_packages</span><span class="p">(</span>
            <span class="n">requests_data</span><span class="o">=</span><span class="n">requests_data</span><span class="p">,</span>
            <span class="n">request_method</span><span class="o">=</span><span class="n">RequestMethod</span><span class="o">.</span><span class="n">POST</span><span class="p">,</span>
            <span class="n">max_concurrent_requests</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">__inference_configuration</span><span class="o">.</span><span class="n">max_concurrent_requests</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">responses</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_prepare_infer_from_api_v0_request_data</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">inference_input</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">]],</span>
        <span class="n">model_id</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">RequestData</span><span class="p">]:</span>
        <span class="n">model_id_to_be_used</span> <span class="o">=</span> <span class="n">model_id</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">__selected_model</span>
        <span class="n">_ensure_model_is_selected</span><span class="p">(</span><span class="n">model_id</span><span class="o">=</span><span class="n">model_id_to_be_used</span><span class="p">)</span>
        <span class="n">_ensure_api_key_provided</span><span class="p">(</span><span class="n">api_key</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">__api_key</span><span class="p">)</span>
        <span class="n">model_id_to_be_used</span> <span class="o">=</span> <span class="n">resolve_roboflow_model_alias</span><span class="p">(</span><span class="n">model_id</span><span class="o">=</span><span class="n">model_id_to_be_used</span><span class="p">)</span>
        <span class="n">model_id_chunks</span> <span class="o">=</span> <span class="n">model_id_to_be_used</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;/&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">model_id_chunks</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">InvalidModelIdentifier</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Invalid model id: </span><span class="si">{</span><span class="n">model_id</span><span class="si">}</span><span class="s2">. Expected format: project_id/model_version_id.&quot;</span>
            <span class="p">)</span>
        <span class="n">max_height</span><span class="p">,</span> <span class="n">max_width</span> <span class="o">=</span> <span class="n">_determine_client_downsizing_parameters</span><span class="p">(</span>
            <span class="n">client_downsizing_disabled</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">__inference_configuration</span><span class="o">.</span><span class="n">client_downsizing_disabled</span><span class="p">,</span>
            <span class="n">model_description</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">default_max_input_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">__inference_configuration</span><span class="o">.</span><span class="n">default_max_input_size</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">encoded_inference_inputs</span> <span class="o">=</span> <span class="n">load_static_inference_input</span><span class="p">(</span>
            <span class="n">inference_input</span><span class="o">=</span><span class="n">inference_input</span><span class="p">,</span>
            <span class="n">max_height</span><span class="o">=</span><span class="n">max_height</span><span class="p">,</span>
            <span class="n">max_width</span><span class="o">=</span><span class="n">max_width</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">params</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;api_key&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">__api_key</span><span class="p">,</span>
        <span class="p">}</span>
        <span class="n">params</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__inference_configuration</span><span class="o">.</span><span class="n">to_legacy_call_parameters</span><span class="p">())</span>

        <span class="n">execution_id_value</span> <span class="o">=</span> <span class="n">execution_id</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
        <span class="n">headers</span> <span class="o">=</span> <span class="n">DEFAULT_HEADERS</span>
        <span class="k">if</span> <span class="n">execution_id_value</span><span class="p">:</span>
            <span class="n">headers</span> <span class="o">=</span> <span class="n">headers</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
            <span class="n">headers</span><span class="p">[</span><span class="n">EXECUTION_ID_HEADER</span><span class="p">]</span> <span class="o">=</span> <span class="n">execution_id_value</span>

        <span class="n">requests_data</span> <span class="o">=</span> <span class="n">prepare_requests_data</span><span class="p">(</span>
            <span class="n">url</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__api_url</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">model_id_chunks</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">model_id_chunks</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
            <span class="n">encoded_inference_inputs</span><span class="o">=</span><span class="n">encoded_inference_inputs</span><span class="p">,</span>
            <span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">,</span>
            <span class="n">parameters</span><span class="o">=</span><span class="n">params</span><span class="p">,</span>
            <span class="n">payload</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">max_batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">image_placement</span><span class="o">=</span><span class="n">ImagePlacement</span><span class="o">.</span><span class="n">DATA</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">requests_data</span>

    <span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">infer_from_api_v0_async</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">inference_input</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">]],</span>
        <span class="n">model_id</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Run inference using API v0 asynchronously.</span>

<span class="sd">        Args:</span>
<span class="sd">            inference_input (Union[ImagesReference, List[ImagesReference]]): Input image(s) for inference.</span>
<span class="sd">            model_id (Optional[str], optional): Model identifier to use for inference. Defaults to None.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Union[dict, List[dict]]: Inference results for the input image(s).</span>

<span class="sd">        Raises:</span>
<span class="sd">            ModelNotSelectedError: If no model is selected.</span>
<span class="sd">            APIKeyNotProvided: If API key is required but not provided.</span>
<span class="sd">            InvalidModelIdentifier: If the model identifier format is invalid.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">model_id_to_be_used</span> <span class="o">=</span> <span class="n">model_id</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">__selected_model</span>
        <span class="n">_ensure_model_is_selected</span><span class="p">(</span><span class="n">model_id</span><span class="o">=</span><span class="n">model_id_to_be_used</span><span class="p">)</span>
        <span class="n">_ensure_api_key_provided</span><span class="p">(</span><span class="n">api_key</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">__api_key</span><span class="p">)</span>
        <span class="n">model_id_to_be_used</span> <span class="o">=</span> <span class="n">resolve_roboflow_model_alias</span><span class="p">(</span><span class="n">model_id</span><span class="o">=</span><span class="n">model_id_to_be_used</span><span class="p">)</span>
        <span class="n">model_id_chunks</span> <span class="o">=</span> <span class="n">model_id_to_be_used</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;/&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">model_id_chunks</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">InvalidModelIdentifier</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Invalid model id: </span><span class="si">{</span><span class="n">model_id</span><span class="si">}</span><span class="s2">. Expected format: project_id/model_version_id.&quot;</span>
            <span class="p">)</span>
        <span class="n">max_height</span><span class="p">,</span> <span class="n">max_width</span> <span class="o">=</span> <span class="n">_determine_client_downsizing_parameters</span><span class="p">(</span>
            <span class="n">client_downsizing_disabled</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">__inference_configuration</span><span class="o">.</span><span class="n">client_downsizing_disabled</span><span class="p">,</span>
            <span class="n">model_description</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">default_max_input_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">__inference_configuration</span><span class="o">.</span><span class="n">default_max_input_size</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">encoded_inference_inputs</span> <span class="o">=</span> <span class="k">await</span> <span class="n">load_static_inference_input_async</span><span class="p">(</span>
            <span class="n">inference_input</span><span class="o">=</span><span class="n">inference_input</span><span class="p">,</span>
            <span class="n">max_height</span><span class="o">=</span><span class="n">max_height</span><span class="p">,</span>
            <span class="n">max_width</span><span class="o">=</span><span class="n">max_width</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">params</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;api_key&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">__api_key</span><span class="p">,</span>
        <span class="p">}</span>
        <span class="n">params</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__inference_configuration</span><span class="o">.</span><span class="n">to_legacy_call_parameters</span><span class="p">())</span>

        <span class="n">execution_id_value</span> <span class="o">=</span> <span class="n">execution_id</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
        <span class="n">headers</span> <span class="o">=</span> <span class="n">DEFAULT_HEADERS</span>
        <span class="k">if</span> <span class="n">execution_id_value</span><span class="p">:</span>
            <span class="n">headers</span> <span class="o">=</span> <span class="n">headers</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
            <span class="n">headers</span><span class="p">[</span><span class="n">EXECUTION_ID_HEADER</span><span class="p">]</span> <span class="o">=</span> <span class="n">execution_id_value</span>

        <span class="n">requests_data</span> <span class="o">=</span> <span class="n">prepare_requests_data</span><span class="p">(</span>
            <span class="n">url</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__api_url</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">model_id_chunks</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">model_id_chunks</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
            <span class="n">encoded_inference_inputs</span><span class="o">=</span><span class="n">encoded_inference_inputs</span><span class="p">,</span>
            <span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">,</span>
            <span class="n">parameters</span><span class="o">=</span><span class="n">params</span><span class="p">,</span>
            <span class="n">payload</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">max_batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">image_placement</span><span class="o">=</span><span class="n">ImagePlacement</span><span class="o">.</span><span class="n">DATA</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">responses</span> <span class="o">=</span> <span class="k">await</span> <span class="n">execute_requests_packages_async</span><span class="p">(</span>
            <span class="n">requests_data</span><span class="o">=</span><span class="n">requests_data</span><span class="p">,</span>
            <span class="n">request_method</span><span class="o">=</span><span class="n">RequestMethod</span><span class="o">.</span><span class="n">POST</span><span class="p">,</span>
            <span class="n">max_concurrent_requests</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">__inference_configuration</span><span class="o">.</span><span class="n">max_concurrent_requests</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">request_data</span><span class="p">,</span> <span class="n">response</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">requests_data</span><span class="p">,</span> <span class="n">responses</span><span class="p">):</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">issubclass</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">response</span><span class="p">),</span> <span class="nb">dict</span><span class="p">):</span>
                <span class="n">visualisation</span> <span class="o">=</span> <span class="n">transform_visualisation_bytes</span><span class="p">(</span>
                    <span class="n">visualisation</span><span class="o">=</span><span class="n">response</span><span class="p">,</span>
                    <span class="n">expected_format</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">__inference_configuration</span><span class="o">.</span><span class="n">output_visualisation_format</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">parsed_response</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;visualization&quot;</span><span class="p">:</span> <span class="n">visualisation</span><span class="p">}</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">parsed_response</span> <span class="o">=</span> <span class="n">response</span>
                <span class="k">if</span> <span class="n">parsed_response</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;visualization&quot;</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">parsed_response</span><span class="p">[</span><span class="s2">&quot;visualization&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">transform_base64_visualisation</span><span class="p">(</span>
                        <span class="n">visualisation</span><span class="o">=</span><span class="n">parsed_response</span><span class="p">[</span><span class="s2">&quot;visualization&quot;</span><span class="p">],</span>
                        <span class="n">expected_format</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">__inference_configuration</span><span class="o">.</span><span class="n">output_visualisation_format</span><span class="p">,</span>
                    <span class="p">)</span>
            <span class="n">parsed_response</span> <span class="o">=</span> <span class="n">adjust_prediction_to_client_scaling_factor</span><span class="p">(</span>
                <span class="n">prediction</span><span class="o">=</span><span class="n">parsed_response</span><span class="p">,</span>
                <span class="n">scaling_factor</span><span class="o">=</span><span class="n">request_data</span><span class="o">.</span><span class="n">image_scaling_factors</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
            <span class="p">)</span>
            <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">parsed_response</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">unwrap_single_element_list</span><span class="p">(</span><span class="n">sequence</span><span class="o">=</span><span class="n">results</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">infer_from_api_v1</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">inference_input</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">]],</span>
        <span class="n">model_id</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]]:</span>
        <span class="n">requests_data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_prepare_infer_from_api_v1_request_data</span><span class="p">(</span>
            <span class="n">inference_input</span><span class="o">=</span><span class="n">inference_input</span><span class="p">,</span>
            <span class="n">model_id</span><span class="o">=</span><span class="n">model_id</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">responses</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_execute_infer_from_api_request</span><span class="p">(</span>
            <span class="n">requests_data</span><span class="o">=</span><span class="n">requests_data</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">request_data</span><span class="p">,</span> <span class="n">response</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">requests_data</span><span class="p">,</span> <span class="n">responses</span><span class="p">):</span>
            <span class="n">parsed_response</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">issubclass</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">parsed_response</span><span class="p">),</span> <span class="nb">list</span><span class="p">):</span>
                <span class="n">parsed_response</span> <span class="o">=</span> <span class="p">[</span><span class="n">parsed_response</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">parsed_response_element</span><span class="p">,</span> <span class="n">scaling_factor</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
                <span class="n">parsed_response</span><span class="p">,</span> <span class="n">request_data</span><span class="o">.</span><span class="n">image_scaling_factors</span>
            <span class="p">):</span>
                <span class="k">if</span> <span class="n">parsed_response_element</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;visualization&quot;</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">parsed_response_element</span><span class="p">[</span><span class="s2">&quot;visualization&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
                        <span class="n">transform_base64_visualisation</span><span class="p">(</span>
                            <span class="n">visualisation</span><span class="o">=</span><span class="n">parsed_response_element</span><span class="p">[</span><span class="s2">&quot;visualization&quot;</span><span class="p">],</span>
                            <span class="n">expected_format</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">__inference_configuration</span><span class="o">.</span><span class="n">output_visualisation_format</span><span class="p">,</span>
                        <span class="p">)</span>
                    <span class="p">)</span>
                <span class="n">parsed_response_element</span> <span class="o">=</span> <span class="n">adjust_prediction_to_client_scaling_factor</span><span class="p">(</span>
                    <span class="n">prediction</span><span class="o">=</span><span class="n">parsed_response_element</span><span class="p">,</span>
                    <span class="n">scaling_factor</span><span class="o">=</span><span class="n">scaling_factor</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">parsed_response_element</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">unwrap_single_element_list</span><span class="p">(</span><span class="n">sequence</span><span class="o">=</span><span class="n">results</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_prepare_infer_from_api_v1_request_data</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">inference_input</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">]],</span>
        <span class="n">model_id</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">RequestData</span><span class="p">]:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__ensure_v1_client_mode</span><span class="p">()</span>
        <span class="n">model_id_to_be_used</span> <span class="o">=</span> <span class="n">model_id</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">__selected_model</span>
        <span class="n">_ensure_model_is_selected</span><span class="p">(</span><span class="n">model_id</span><span class="o">=</span><span class="n">model_id_to_be_used</span><span class="p">)</span>
        <span class="n">model_id_to_be_used</span> <span class="o">=</span> <span class="n">resolve_roboflow_model_alias</span><span class="p">(</span><span class="n">model_id</span><span class="o">=</span><span class="n">model_id_to_be_used</span><span class="p">)</span>
        <span class="n">model_description</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_model_description</span><span class="p">(</span><span class="n">model_id</span><span class="o">=</span><span class="n">model_id_to_be_used</span><span class="p">)</span>
        <span class="n">max_height</span><span class="p">,</span> <span class="n">max_width</span> <span class="o">=</span> <span class="n">_determine_client_downsizing_parameters</span><span class="p">(</span>
            <span class="n">client_downsizing_disabled</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">__inference_configuration</span><span class="o">.</span><span class="n">client_downsizing_disabled</span><span class="p">,</span>
            <span class="n">model_description</span><span class="o">=</span><span class="n">model_description</span><span class="p">,</span>
            <span class="n">default_max_input_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">__inference_configuration</span><span class="o">.</span><span class="n">default_max_input_size</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">model_description</span><span class="o">.</span><span class="n">task_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">NEW_INFERENCE_ENDPOINTS</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">ModelTaskTypeNotSupportedError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Model task </span><span class="si">{</span><span class="n">model_description</span><span class="o">.</span><span class="n">task_type</span><span class="si">}</span><span class="s2"> is not supported by API v1 client.&quot;</span>
            <span class="p">)</span>
        <span class="n">encoded_inference_inputs</span> <span class="o">=</span> <span class="n">load_static_inference_input</span><span class="p">(</span>
            <span class="n">inference_input</span><span class="o">=</span><span class="n">inference_input</span><span class="p">,</span>
            <span class="n">max_height</span><span class="o">=</span><span class="n">max_height</span><span class="p">,</span>
            <span class="n">max_width</span><span class="o">=</span><span class="n">max_width</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">payload</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;api_key&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">__api_key</span><span class="p">,</span>
            <span class="s2">&quot;model_id&quot;</span><span class="p">:</span> <span class="n">model_id_to_be_used</span><span class="p">,</span>
        <span class="p">}</span>
        <span class="n">endpoint</span> <span class="o">=</span> <span class="n">NEW_INFERENCE_ENDPOINTS</span><span class="p">[</span><span class="n">model_description</span><span class="o">.</span><span class="n">task_type</span><span class="p">]</span>
        <span class="n">payload</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__inference_configuration</span><span class="o">.</span><span class="n">to_api_call_parameters</span><span class="p">(</span>
                <span class="n">client_mode</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">__client_mode</span><span class="p">,</span>
                <span class="n">task_type</span><span class="o">=</span><span class="n">model_description</span><span class="o">.</span><span class="n">task_type</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">)</span>
        <span class="n">requests_data</span> <span class="o">=</span> <span class="n">prepare_requests_data</span><span class="p">(</span>
            <span class="n">url</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__api_url</span><span class="si">}{</span><span class="n">endpoint</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
            <span class="n">encoded_inference_inputs</span><span class="o">=</span><span class="n">encoded_inference_inputs</span><span class="p">,</span>
            <span class="n">headers</span><span class="o">=</span><span class="n">DEFAULT_HEADERS</span><span class="p">,</span>
            <span class="n">parameters</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">payload</span><span class="o">=</span><span class="n">payload</span><span class="p">,</span>
            <span class="n">max_batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">__inference_configuration</span><span class="o">.</span><span class="n">max_batch_size</span><span class="p">,</span>
            <span class="n">image_placement</span><span class="o">=</span><span class="n">ImagePlacement</span><span class="o">.</span><span class="n">JSON</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">requests_data</span>

    <span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">infer_from_api_v1_async</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">inference_input</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">]],</span>
        <span class="n">model_id</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]]:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__ensure_v1_client_mode</span><span class="p">()</span>
        <span class="n">model_id_to_be_used</span> <span class="o">=</span> <span class="n">model_id</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">__selected_model</span>
        <span class="n">_ensure_model_is_selected</span><span class="p">(</span><span class="n">model_id</span><span class="o">=</span><span class="n">model_id_to_be_used</span><span class="p">)</span>
        <span class="n">model_id_to_be_used</span> <span class="o">=</span> <span class="n">resolve_roboflow_model_alias</span><span class="p">(</span><span class="n">model_id</span><span class="o">=</span><span class="n">model_id_to_be_used</span><span class="p">)</span>
        <span class="n">model_description</span> <span class="o">=</span> <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_model_description_async</span><span class="p">(</span>
            <span class="n">model_id</span><span class="o">=</span><span class="n">model_id_to_be_used</span>
        <span class="p">)</span>
        <span class="n">max_height</span><span class="p">,</span> <span class="n">max_width</span> <span class="o">=</span> <span class="n">_determine_client_downsizing_parameters</span><span class="p">(</span>
            <span class="n">client_downsizing_disabled</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">__inference_configuration</span><span class="o">.</span><span class="n">client_downsizing_disabled</span><span class="p">,</span>
            <span class="n">model_description</span><span class="o">=</span><span class="n">model_description</span><span class="p">,</span>
            <span class="n">default_max_input_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">__inference_configuration</span><span class="o">.</span><span class="n">default_max_input_size</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">model_description</span><span class="o">.</span><span class="n">task_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">NEW_INFERENCE_ENDPOINTS</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">ModelTaskTypeNotSupportedError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Model task </span><span class="si">{</span><span class="n">model_description</span><span class="o">.</span><span class="n">task_type</span><span class="si">}</span><span class="s2"> is not supported by API v1 client.&quot;</span>
            <span class="p">)</span>
        <span class="n">encoded_inference_inputs</span> <span class="o">=</span> <span class="k">await</span> <span class="n">load_static_inference_input_async</span><span class="p">(</span>
            <span class="n">inference_input</span><span class="o">=</span><span class="n">inference_input</span><span class="p">,</span>
            <span class="n">max_height</span><span class="o">=</span><span class="n">max_height</span><span class="p">,</span>
            <span class="n">max_width</span><span class="o">=</span><span class="n">max_width</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">payload</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;api_key&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">__api_key</span><span class="p">,</span>
            <span class="s2">&quot;model_id&quot;</span><span class="p">:</span> <span class="n">model_id_to_be_used</span><span class="p">,</span>
        <span class="p">}</span>
        <span class="n">endpoint</span> <span class="o">=</span> <span class="n">NEW_INFERENCE_ENDPOINTS</span><span class="p">[</span><span class="n">model_description</span><span class="o">.</span><span class="n">task_type</span><span class="p">]</span>
        <span class="n">payload</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__inference_configuration</span><span class="o">.</span><span class="n">to_api_call_parameters</span><span class="p">(</span>
                <span class="n">client_mode</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">__client_mode</span><span class="p">,</span>
                <span class="n">task_type</span><span class="o">=</span><span class="n">model_description</span><span class="o">.</span><span class="n">task_type</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">)</span>
        <span class="n">requests_data</span> <span class="o">=</span> <span class="n">prepare_requests_data</span><span class="p">(</span>
            <span class="n">url</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__api_url</span><span class="si">}{</span><span class="n">endpoint</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
            <span class="n">encoded_inference_inputs</span><span class="o">=</span><span class="n">encoded_inference_inputs</span><span class="p">,</span>
            <span class="n">headers</span><span class="o">=</span><span class="n">DEFAULT_HEADERS</span><span class="p">,</span>
            <span class="n">parameters</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">payload</span><span class="o">=</span><span class="n">payload</span><span class="p">,</span>
            <span class="n">max_batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">__inference_configuration</span><span class="o">.</span><span class="n">max_batch_size</span><span class="p">,</span>
            <span class="n">image_placement</span><span class="o">=</span><span class="n">ImagePlacement</span><span class="o">.</span><span class="n">JSON</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">responses</span> <span class="o">=</span> <span class="k">await</span> <span class="n">execute_requests_packages_async</span><span class="p">(</span>
            <span class="n">requests_data</span><span class="o">=</span><span class="n">requests_data</span><span class="p">,</span>
            <span class="n">request_method</span><span class="o">=</span><span class="n">RequestMethod</span><span class="o">.</span><span class="n">POST</span><span class="p">,</span>
            <span class="n">max_concurrent_requests</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">__inference_configuration</span><span class="o">.</span><span class="n">max_concurrent_requests</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">request_data</span><span class="p">,</span> <span class="n">parsed_response</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">requests_data</span><span class="p">,</span> <span class="n">responses</span><span class="p">):</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">issubclass</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">parsed_response</span><span class="p">),</span> <span class="nb">list</span><span class="p">):</span>
                <span class="n">parsed_response</span> <span class="o">=</span> <span class="p">[</span><span class="n">parsed_response</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">parsed_response_element</span><span class="p">,</span> <span class="n">scaling_factor</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
                <span class="n">parsed_response</span><span class="p">,</span> <span class="n">request_data</span><span class="o">.</span><span class="n">image_scaling_factors</span>
            <span class="p">):</span>
                <span class="k">if</span> <span class="n">parsed_response_element</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;visualization&quot;</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">parsed_response_element</span><span class="p">[</span><span class="s2">&quot;visualization&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
                        <span class="n">transform_base64_visualisation</span><span class="p">(</span>
                            <span class="n">visualisation</span><span class="o">=</span><span class="n">parsed_response_element</span><span class="p">[</span><span class="s2">&quot;visualization&quot;</span><span class="p">],</span>
                            <span class="n">expected_format</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">__inference_configuration</span><span class="o">.</span><span class="n">output_visualisation_format</span><span class="p">,</span>
                        <span class="p">)</span>
                    <span class="p">)</span>
                <span class="n">parsed_response_element</span> <span class="o">=</span> <span class="n">adjust_prediction_to_client_scaling_factor</span><span class="p">(</span>
                    <span class="n">prediction</span><span class="o">=</span><span class="n">parsed_response_element</span><span class="p">,</span>
                    <span class="n">scaling_factor</span><span class="o">=</span><span class="n">scaling_factor</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">parsed_response_element</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">unwrap_single_element_list</span><span class="p">(</span><span class="n">sequence</span><span class="o">=</span><span class="n">results</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">get_model_description</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">model_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">allow_loading</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ModelDescription</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the description of a model.</span>

<span class="sd">        Args:</span>
<span class="sd">            model_id (str): The identifier of the model.</span>
<span class="sd">            allow_loading (bool, optional): Whether to load the model if not already loaded. Defaults to True.</span>

<span class="sd">        Returns:</span>
<span class="sd">            ModelDescription: Description of the model.</span>

<span class="sd">        Raises:</span>
<span class="sd">            WrongClientModeError: If not in API v1 mode.</span>
<span class="sd">            ModelNotInitializedError: If the model is not initialized and cannot be loaded.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__ensure_v1_client_mode</span><span class="p">()</span>
        <span class="n">de_aliased_model_id</span> <span class="o">=</span> <span class="n">resolve_roboflow_model_alias</span><span class="p">(</span><span class="n">model_id</span><span class="o">=</span><span class="n">model_id</span><span class="p">)</span>
        <span class="n">registered_models</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">list_loaded_models</span><span class="p">()</span>
        <span class="n">matching_model</span> <span class="o">=</span> <span class="n">filter_model_descriptions</span><span class="p">(</span>
            <span class="n">descriptions</span><span class="o">=</span><span class="n">registered_models</span><span class="o">.</span><span class="n">models</span><span class="p">,</span>
            <span class="n">model_id</span><span class="o">=</span><span class="n">de_aliased_model_id</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">matching_model</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">allow_loading</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
            <span class="n">registered_models</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="n">model_id</span><span class="o">=</span><span class="n">de_aliased_model_id</span><span class="p">)</span>
            <span class="n">matching_model</span> <span class="o">=</span> <span class="n">filter_model_descriptions</span><span class="p">(</span>
                <span class="n">descriptions</span><span class="o">=</span><span class="n">registered_models</span><span class="o">.</span><span class="n">models</span><span class="p">,</span>
                <span class="n">model_id</span><span class="o">=</span><span class="n">de_aliased_model_id</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">matching_model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">matching_model</span>
        <span class="k">raise</span> <span class="n">ModelNotInitializedError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Model </span><span class="si">{</span><span class="n">model_id</span><span class="si">}</span><span class="s2"> (de-aliased: </span><span class="si">{</span><span class="n">de_aliased_model_id</span><span class="si">}</span><span class="s2">) is not initialised and cannot &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;retrieve its description.&quot;</span>
        <span class="p">)</span>

    <span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">get_model_description_async</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">model_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">allow_loading</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ModelDescription</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the description of a model asynchronously.</span>

<span class="sd">        Args:</span>
<span class="sd">            model_id (str): The identifier of the model.</span>
<span class="sd">            allow_loading (bool, optional): Whether to load the model if not already loaded. Defaults to True.</span>

<span class="sd">        Returns:</span>
<span class="sd">            ModelDescription: Description of the model.</span>

<span class="sd">        Raises:</span>
<span class="sd">            WrongClientModeError: If not in API v1 mode.</span>
<span class="sd">            ModelNotInitializedError: If the model is not initialized and cannot be loaded.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__ensure_v1_client_mode</span><span class="p">()</span>
        <span class="n">de_aliased_model_id</span> <span class="o">=</span> <span class="n">resolve_roboflow_model_alias</span><span class="p">(</span><span class="n">model_id</span><span class="o">=</span><span class="n">model_id</span><span class="p">)</span>
        <span class="n">registered_models</span> <span class="o">=</span> <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">list_loaded_models_async</span><span class="p">()</span>
        <span class="n">matching_model</span> <span class="o">=</span> <span class="n">filter_model_descriptions</span><span class="p">(</span>
            <span class="n">descriptions</span><span class="o">=</span><span class="n">registered_models</span><span class="o">.</span><span class="n">models</span><span class="p">,</span>
            <span class="n">model_id</span><span class="o">=</span><span class="n">de_aliased_model_id</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">matching_model</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">allow_loading</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
            <span class="n">registered_models</span> <span class="o">=</span> <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">load_model_async</span><span class="p">(</span>
                <span class="n">model_id</span><span class="o">=</span><span class="n">de_aliased_model_id</span>
            <span class="p">)</span>
            <span class="n">matching_model</span> <span class="o">=</span> <span class="n">filter_model_descriptions</span><span class="p">(</span>
                <span class="n">descriptions</span><span class="o">=</span><span class="n">registered_models</span><span class="o">.</span><span class="n">models</span><span class="p">,</span>
                <span class="n">model_id</span><span class="o">=</span><span class="n">de_aliased_model_id</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">matching_model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">matching_model</span>
        <span class="k">raise</span> <span class="n">ModelNotInitializedError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Model </span><span class="si">{</span><span class="n">model_id</span><span class="si">}</span><span class="s2"> (de-aliased: </span><span class="si">{</span><span class="n">de_aliased_model_id</span><span class="si">}</span><span class="s2">) is not initialised and cannot &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;retrieve its description.&quot;</span>
        <span class="p">)</span>

    <span class="nd">@wrap_errors</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">list_loaded_models</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">RegisteredModels</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;List all models currently loaded on the server.</span>

<span class="sd">        Returns:</span>
<span class="sd">            RegisteredModels: Information about registered models.</span>

<span class="sd">        Raises:</span>
<span class="sd">            WrongClientModeError: If not in API v1 mode.</span>
<span class="sd">            HTTPCallErrorError: If there is an error in the HTTP call.</span>
<span class="sd">            HTTPClientError: If there is an error with the server connection.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__ensure_v1_client_mode</span><span class="p">()</span>
        <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__api_url</span><span class="si">}</span><span class="s2">/model/registry?api_key=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__api_key</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>
        <span class="n">response</span><span class="o">.</span><span class="n">raise_for_status</span><span class="p">()</span>
        <span class="n">response_payload</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">RegisteredModels</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">response_payload</span><span class="p">)</span>

    <span class="nd">@wrap_errors_async</span>
    <span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">list_loaded_models_async</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">RegisteredModels</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;List all models currently loaded on the server asynchronously.</span>

<span class="sd">        Returns:</span>
<span class="sd">            RegisteredModels: Information about registered models.</span>

<span class="sd">        Raises:</span>
<span class="sd">            WrongClientModeError: If not in API v1 mode.</span>
<span class="sd">            HTTPCallErrorError: If there is an error in the HTTP call.</span>
<span class="sd">            HTTPClientError: If there is an error with the server connection.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__ensure_v1_client_mode</span><span class="p">()</span>
        <span class="k">async</span> <span class="k">with</span> <span class="n">aiohttp</span><span class="o">.</span><span class="n">ClientSession</span><span class="p">()</span> <span class="k">as</span> <span class="n">session</span><span class="p">:</span>
            <span class="k">async</span> <span class="k">with</span> <span class="n">session</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__api_url</span><span class="si">}</span><span class="s2">/model/registry?api_key=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__api_key</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span> <span class="k">as</span> <span class="n">response</span><span class="p">:</span>
                <span class="n">response</span><span class="o">.</span><span class="n">raise_for_status</span><span class="p">()</span>
                <span class="n">response_payload</span> <span class="o">=</span> <span class="k">await</span> <span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>
                <span class="k">return</span> <span class="n">RegisteredModels</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">response_payload</span><span class="p">)</span>

    <span class="nd">@wrap_errors</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">load_model</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">model_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">set_as_default</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">RegisteredModels</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Load a model onto the server.</span>

<span class="sd">        Args:</span>
<span class="sd">            model_id (str): The identifier of the model to load.</span>
<span class="sd">            set_as_default (bool, optional): Whether to set this model as the default. Defaults to False.</span>

<span class="sd">        Returns:</span>
<span class="sd">            RegisteredModels: Updated information about registered models.</span>

<span class="sd">        Raises:</span>
<span class="sd">            WrongClientModeError: If not in API v1 mode.</span>
<span class="sd">            HTTPCallErrorError: If there is an error in the HTTP call.</span>
<span class="sd">            HTTPClientError: If there is an error with the server connection.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__ensure_v1_client_mode</span><span class="p">()</span>
        <span class="n">de_aliased_model_id</span> <span class="o">=</span> <span class="n">resolve_roboflow_model_alias</span><span class="p">(</span><span class="n">model_id</span><span class="o">=</span><span class="n">model_id</span><span class="p">)</span>
        <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">post</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__api_url</span><span class="si">}</span><span class="s2">/model/add&quot;</span><span class="p">,</span>
            <span class="n">json</span><span class="o">=</span><span class="p">{</span>
                <span class="s2">&quot;model_id&quot;</span><span class="p">:</span> <span class="n">de_aliased_model_id</span><span class="p">,</span>
                <span class="s2">&quot;api_key&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">__api_key</span><span class="p">,</span>
            <span class="p">},</span>
            <span class="n">headers</span><span class="o">=</span><span class="n">DEFAULT_HEADERS</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">response</span><span class="o">.</span><span class="n">raise_for_status</span><span class="p">()</span>
        <span class="n">response_payload</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">set_as_default</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__selected_model</span> <span class="o">=</span> <span class="n">de_aliased_model_id</span>
        <span class="k">return</span> <span class="n">RegisteredModels</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">response_payload</span><span class="p">)</span>

    <span class="nd">@wrap_errors_async</span>
    <span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">load_model_async</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">model_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">set_as_default</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">RegisteredModels</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Load a model onto the server asynchronously.</span>

<span class="sd">        Args:</span>
<span class="sd">            model_id (str): The identifier of the model to load.</span>
<span class="sd">            set_as_default (bool, optional): Whether to set this model as the default. Defaults to False.</span>

<span class="sd">        Returns:</span>
<span class="sd">            RegisteredModels: Updated information about registered models.</span>

<span class="sd">        Raises:</span>
<span class="sd">            WrongClientModeError: If not in API v1 mode.</span>
<span class="sd">            HTTPCallErrorError: If there is an error in the HTTP call.</span>
<span class="sd">            HTTPClientError: If there is an error with the server connection.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__ensure_v1_client_mode</span><span class="p">()</span>
        <span class="n">de_aliased_model_id</span> <span class="o">=</span> <span class="n">resolve_roboflow_model_alias</span><span class="p">(</span><span class="n">model_id</span><span class="o">=</span><span class="n">model_id</span><span class="p">)</span>
        <span class="n">payload</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;model_id&quot;</span><span class="p">:</span> <span class="n">de_aliased_model_id</span><span class="p">,</span>
            <span class="s2">&quot;api_key&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">__api_key</span><span class="p">,</span>
        <span class="p">}</span>
        <span class="k">async</span> <span class="k">with</span> <span class="n">aiohttp</span><span class="o">.</span><span class="n">ClientSession</span><span class="p">()</span> <span class="k">as</span> <span class="n">session</span><span class="p">:</span>
            <span class="k">async</span> <span class="k">with</span> <span class="n">session</span><span class="o">.</span><span class="n">post</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__api_url</span><span class="si">}</span><span class="s2">/model/add&quot;</span><span class="p">,</span>
                <span class="n">json</span><span class="o">=</span><span class="n">payload</span><span class="p">,</span>
                <span class="n">headers</span><span class="o">=</span><span class="n">DEFAULT_HEADERS</span><span class="p">,</span>
            <span class="p">)</span> <span class="k">as</span> <span class="n">response</span><span class="p">:</span>
                <span class="n">response</span><span class="o">.</span><span class="n">raise_for_status</span><span class="p">()</span>
                <span class="n">response_payload</span> <span class="o">=</span> <span class="k">await</span> <span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">set_as_default</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__selected_model</span> <span class="o">=</span> <span class="n">de_aliased_model_id</span>
        <span class="k">return</span> <span class="n">RegisteredModels</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">response_payload</span><span class="p">)</span>

    <span class="nd">@wrap_errors</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">unload_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">RegisteredModels</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Unload a model from the server.</span>

<span class="sd">        Args:</span>
<span class="sd">            model_id (str): The identifier of the model to unload.</span>

<span class="sd">        Returns:</span>
<span class="sd">            RegisteredModels: Updated information about registered models.</span>

<span class="sd">        Raises:</span>
<span class="sd">            WrongClientModeError: If not in API v1 mode.</span>
<span class="sd">            HTTPCallErrorError: If there is an error in the HTTP call.</span>
<span class="sd">            HTTPClientError: If there is an error with the server connection.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__ensure_v1_client_mode</span><span class="p">()</span>
        <span class="n">de_aliased_model_id</span> <span class="o">=</span> <span class="n">resolve_roboflow_model_alias</span><span class="p">(</span><span class="n">model_id</span><span class="o">=</span><span class="n">model_id</span><span class="p">)</span>
        <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">post</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__api_url</span><span class="si">}</span><span class="s2">/model/remove&quot;</span><span class="p">,</span>
            <span class="n">json</span><span class="o">=</span><span class="p">{</span>
                <span class="s2">&quot;model_id&quot;</span><span class="p">:</span> <span class="n">de_aliased_model_id</span><span class="p">,</span>
            <span class="p">},</span>
            <span class="n">headers</span><span class="o">=</span><span class="n">DEFAULT_HEADERS</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">response</span><span class="o">.</span><span class="n">raise_for_status</span><span class="p">()</span>
        <span class="n">response_payload</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="n">de_aliased_model_id</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">__selected_model</span>
            <span class="ow">or</span> <span class="n">model_id</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">__selected_model</span>
        <span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__selected_model</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">return</span> <span class="n">RegisteredModels</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">response_payload</span><span class="p">)</span>

    <span class="nd">@wrap_errors_async</span>
    <span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">unload_model_async</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">RegisteredModels</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__ensure_v1_client_mode</span><span class="p">()</span>
        <span class="n">de_aliased_model_id</span> <span class="o">=</span> <span class="n">resolve_roboflow_model_alias</span><span class="p">(</span><span class="n">model_id</span><span class="o">=</span><span class="n">model_id</span><span class="p">)</span>
        <span class="k">async</span> <span class="k">with</span> <span class="n">aiohttp</span><span class="o">.</span><span class="n">ClientSession</span><span class="p">()</span> <span class="k">as</span> <span class="n">session</span><span class="p">:</span>
            <span class="k">async</span> <span class="k">with</span> <span class="n">session</span><span class="o">.</span><span class="n">post</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__api_url</span><span class="si">}</span><span class="s2">/model/remove&quot;</span><span class="p">,</span>
                <span class="n">json</span><span class="o">=</span><span class="p">{</span>
                    <span class="s2">&quot;model_id&quot;</span><span class="p">:</span> <span class="n">de_aliased_model_id</span><span class="p">,</span>
                <span class="p">},</span>
                <span class="n">headers</span><span class="o">=</span><span class="n">DEFAULT_HEADERS</span><span class="p">,</span>
            <span class="p">)</span> <span class="k">as</span> <span class="n">response</span><span class="p">:</span>
                <span class="n">response</span><span class="o">.</span><span class="n">raise_for_status</span><span class="p">()</span>
                <span class="n">response_payload</span> <span class="o">=</span> <span class="k">await</span> <span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="n">de_aliased_model_id</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">__selected_model</span>
            <span class="ow">or</span> <span class="n">model_id</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">__selected_model</span>
        <span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__selected_model</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">return</span> <span class="n">RegisteredModels</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">response_payload</span><span class="p">)</span>

    <span class="nd">@wrap_errors</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">unload_all_models</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">RegisteredModels</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__ensure_v1_client_mode</span><span class="p">()</span>
        <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">post</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__api_url</span><span class="si">}</span><span class="s2">/model/clear&quot;</span><span class="p">)</span>
        <span class="n">response</span><span class="o">.</span><span class="n">raise_for_status</span><span class="p">()</span>
        <span class="n">response_payload</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__selected_model</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">return</span> <span class="n">RegisteredModels</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">response_payload</span><span class="p">)</span>

    <span class="nd">@wrap_errors_async</span>
    <span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">unload_all_models_async</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">RegisteredModels</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__ensure_v1_client_mode</span><span class="p">()</span>
        <span class="k">async</span> <span class="k">with</span> <span class="n">aiohttp</span><span class="o">.</span><span class="n">ClientSession</span><span class="p">()</span> <span class="k">as</span> <span class="n">session</span><span class="p">:</span>
            <span class="k">async</span> <span class="k">with</span> <span class="n">session</span><span class="o">.</span><span class="n">post</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__api_url</span><span class="si">}</span><span class="s2">/model/clear&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">response</span><span class="p">:</span>
                <span class="n">response</span><span class="o">.</span><span class="n">raise_for_status</span><span class="p">()</span>
                <span class="n">response_payload</span> <span class="o">=</span> <span class="k">await</span> <span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__selected_model</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">return</span> <span class="n">RegisteredModels</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">response_payload</span><span class="p">)</span>

    <span class="nd">@wrap_errors</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">ocr_image</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">inference_input</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">]],</span>
        <span class="n">model</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;doctr&quot;</span><span class="p">,</span>
        <span class="n">version</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">quantize</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">generate_bounding_boxes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">language_codes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Run OCR on input image(s).</span>

<span class="sd">        Args:</span>
<span class="sd">            inference_input (Union[ImagesReference, List[ImagesReference]]): Input image(s) for OCR.</span>
<span class="sd">            model (str, optional): OCR model to use (&#39;doctr&#39; or &#39;trocr&#39;). Defaults to &quot;doctr&quot;.</span>
<span class="sd">            version (Optional[str], optional): Model version to use. Defaults to None.</span>
<span class="sd">                For trocr, supported versions are: &#39;trocr-small-printed&#39;, &#39;trocr-base-printed&#39;, &#39;trocr-large-printed&#39;.</span>
<span class="sd">            quantize: (Optional[bool]): flag of EasyOCR to decide which version of model to load</span>
<span class="sd">            generate_bounding_boxes: (Optional[bool]): flag of some models (like DocTR) to decide if output variant</span>
<span class="sd">                with sv.Detections(...) compatible bounding boxes should be returned (due to historical reasons, some</span>
<span class="sd">                old implementations were flattening detected OCR structure into text and were only returning that as</span>
<span class="sd">                results).</span>
<span class="sd">            language_codes: (Optional[List[str]]): Parameter of EasyOCR that dictates the code of languages that</span>
<span class="sd">                model should recognise (leave blank for default for given OCR model version).</span>
<span class="sd">        Returns:</span>
<span class="sd">            Union[dict, List[dict]]: OCR results for the input image(s).</span>

<span class="sd">        Raises:</span>
<span class="sd">            HTTPCallErrorError: If there is an error in the HTTP call.</span>
<span class="sd">            HTTPClientError: If there is an error with the server connection.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">encoded_inference_inputs</span> <span class="o">=</span> <span class="n">load_static_inference_input</span><span class="p">(</span>
            <span class="n">inference_input</span><span class="o">=</span><span class="n">inference_input</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">payload</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__initialise_payload</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">version</span><span class="p">:</span>
            <span class="n">key</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="si">}</span><span class="s2">_version_id&quot;</span>
            <span class="n">payload</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">version</span>
        <span class="k">if</span> <span class="n">quantize</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;quantize&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">quantize</span>
        <span class="k">if</span> <span class="n">generate_bounding_boxes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;generate_bounding_boxes&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">generate_bounding_boxes</span>
        <span class="k">if</span> <span class="n">language_codes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;language_codes&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">language_codes</span>
        <span class="n">model_path</span> <span class="o">=</span> <span class="n">resolve_ocr_path</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="n">model</span><span class="p">)</span>
        <span class="n">url</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__wrap_url_with_api_key</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__api_url</span><span class="si">}{</span><span class="n">model_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">requests_data</span> <span class="o">=</span> <span class="n">prepare_requests_data</span><span class="p">(</span>
            <span class="n">url</span><span class="o">=</span><span class="n">url</span><span class="p">,</span>
            <span class="n">encoded_inference_inputs</span><span class="o">=</span><span class="n">encoded_inference_inputs</span><span class="p">,</span>
            <span class="n">headers</span><span class="o">=</span><span class="n">DEFAULT_HEADERS</span><span class="p">,</span>
            <span class="n">parameters</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">payload</span><span class="o">=</span><span class="n">payload</span><span class="p">,</span>
            <span class="n">max_batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">image_placement</span><span class="o">=</span><span class="n">ImagePlacement</span><span class="o">.</span><span class="n">JSON</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">responses</span> <span class="o">=</span> <span class="n">execute_requests_packages</span><span class="p">(</span>
            <span class="n">requests_data</span><span class="o">=</span><span class="n">requests_data</span><span class="p">,</span>
            <span class="n">request_method</span><span class="o">=</span><span class="n">RequestMethod</span><span class="o">.</span><span class="n">POST</span><span class="p">,</span>
            <span class="n">max_concurrent_requests</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">__inference_configuration</span><span class="o">.</span><span class="n">max_concurrent_requests</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">results</span> <span class="o">=</span> <span class="p">[</span><span class="n">r</span><span class="o">.</span><span class="n">json</span><span class="p">()</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">responses</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">unwrap_single_element_list</span><span class="p">(</span><span class="n">sequence</span><span class="o">=</span><span class="n">results</span><span class="p">)</span>

    <span class="nd">@wrap_errors_async</span>
    <span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">ocr_image_async</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">inference_input</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">]],</span>
        <span class="n">model</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;doctr&quot;</span><span class="p">,</span>
        <span class="n">version</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">quantize</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">generate_bounding_boxes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">language_codes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Run OCR on input image(s) asynchronously.</span>

<span class="sd">        Args:</span>
<span class="sd">            inference_input (Union[ImagesReference, List[ImagesReference]]): Input image(s) for OCR.</span>
<span class="sd">            model (str, optional): OCR model to use (&#39;doctr&#39; or &#39;trocr&#39;). Defaults to &quot;doctr&quot;.</span>
<span class="sd">            version (Optional[str], optional): Model version to use. Defaults to None.</span>
<span class="sd">                For trocr, supported versions are: &#39;trocr-small-printed&#39;, &#39;trocr-base-printed&#39;, &#39;trocr-large-printed&#39;.</span>
<span class="sd">            quantize: (Optional[bool]): flag of EasyOCR to decide which version of model to load</span>
<span class="sd">            generate_bounding_boxes: (Optional[bool]): flag of some models (like DocTR) to decide if output variant</span>
<span class="sd">                with sv.Detections(...) compatible bounding boxes should be returned (due to historical reasons, some</span>
<span class="sd">                old implementations were flattening detected OCR structure into text and were only returning that as</span>
<span class="sd">                results).</span>
<span class="sd">            language_codes: (Optional[List[str]]): Parameter of EasyOCR that dictates the code of languages that</span>
<span class="sd">                model should recognise (leave blank for default for given OCR model version).</span>
<span class="sd">        Returns:</span>
<span class="sd">            Union[dict, List[dict]]: OCR results for the input image(s).</span>

<span class="sd">        Raises:</span>
<span class="sd">            HTTPCallErrorError: If there is an error in the HTTP call.</span>
<span class="sd">            HTTPClientError: If there is an error with the server connection.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">encoded_inference_inputs</span> <span class="o">=</span> <span class="k">await</span> <span class="n">load_static_inference_input_async</span><span class="p">(</span>
            <span class="n">inference_input</span><span class="o">=</span><span class="n">inference_input</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">payload</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__initialise_payload</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">version</span><span class="p">:</span>
            <span class="n">key</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="si">}</span><span class="s2">_version_id&quot;</span>
            <span class="n">payload</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">version</span>
        <span class="k">if</span> <span class="n">quantize</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;quantize&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">quantize</span>
        <span class="k">if</span> <span class="n">generate_bounding_boxes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;generate_bounding_boxes&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">generate_bounding_boxes</span>
        <span class="k">if</span> <span class="n">language_codes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;language_codes&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">language_codes</span>
        <span class="n">model_path</span> <span class="o">=</span> <span class="n">resolve_ocr_path</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="n">model</span><span class="p">)</span>
        <span class="n">url</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__wrap_url_with_api_key</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__api_url</span><span class="si">}{</span><span class="n">model_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">requests_data</span> <span class="o">=</span> <span class="n">prepare_requests_data</span><span class="p">(</span>
            <span class="n">url</span><span class="o">=</span><span class="n">url</span><span class="p">,</span>
            <span class="n">encoded_inference_inputs</span><span class="o">=</span><span class="n">encoded_inference_inputs</span><span class="p">,</span>
            <span class="n">headers</span><span class="o">=</span><span class="n">DEFAULT_HEADERS</span><span class="p">,</span>
            <span class="n">parameters</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">payload</span><span class="o">=</span><span class="n">payload</span><span class="p">,</span>
            <span class="n">max_batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">image_placement</span><span class="o">=</span><span class="n">ImagePlacement</span><span class="o">.</span><span class="n">JSON</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">responses</span> <span class="o">=</span> <span class="k">await</span> <span class="n">execute_requests_packages_async</span><span class="p">(</span>
            <span class="n">requests_data</span><span class="o">=</span><span class="n">requests_data</span><span class="p">,</span>
            <span class="n">request_method</span><span class="o">=</span><span class="n">RequestMethod</span><span class="o">.</span><span class="n">POST</span><span class="p">,</span>
            <span class="n">max_concurrent_requests</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">__inference_configuration</span><span class="o">.</span><span class="n">max_concurrent_requests</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">unwrap_single_element_list</span><span class="p">(</span><span class="n">sequence</span><span class="o">=</span><span class="n">responses</span><span class="p">)</span>

    <span class="nd">@wrap_errors</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">detect_gazes</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">inference_input</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">]],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Detect gazes in input image(s).</span>

<span class="sd">        Args:</span>
<span class="sd">            inference_input (Union[ImagesReference, List[ImagesReference]]): Input image(s) for gaze detection.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Union[dict, List[dict]]: Gaze detection results for the input image(s).</span>

<span class="sd">        Raises:</span>
<span class="sd">            WrongClientModeError: If not in API v1 mode.</span>
<span class="sd">            HTTPCallErrorError: If there is an error in the HTTP call.</span>
<span class="sd">            HTTPClientError: If there is an error with the server connection.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__ensure_v1_client_mode</span><span class="p">()</span>  <span class="c1"># Lambda does not support Gaze, so we require v1 mode of client</span>
        <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_post_images</span><span class="p">(</span>
            <span class="n">inference_input</span><span class="o">=</span><span class="n">inference_input</span><span class="p">,</span> <span class="n">endpoint</span><span class="o">=</span><span class="s2">&quot;/gaze/gaze_detection&quot;</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">combine_gaze_detections</span><span class="p">(</span><span class="n">detections</span><span class="o">=</span><span class="n">result</span><span class="p">)</span>

    <span class="nd">@wrap_errors_async</span>
    <span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">detect_gazes_async</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">inference_input</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">]],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Detect gazes in input image(s) asynchronously.</span>

<span class="sd">        Args:</span>
<span class="sd">            inference_input (Union[ImagesReference, List[ImagesReference]]): Input image(s) for gaze detection.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Union[dict, List[dict]]: Gaze detection results for the input image(s).</span>

<span class="sd">        Raises:</span>
<span class="sd">            WrongClientModeError: If not in API v1 mode.</span>
<span class="sd">            HTTPCallErrorError: If there is an error in the HTTP call.</span>
<span class="sd">            HTTPClientError: If there is an error with the server connection.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__ensure_v1_client_mode</span><span class="p">()</span>  <span class="c1"># Lambda does not support Gaze, so we require v1 mode of client</span>
        <span class="n">result</span> <span class="o">=</span> <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">_post_images_async</span><span class="p">(</span>
            <span class="n">inference_input</span><span class="o">=</span><span class="n">inference_input</span><span class="p">,</span> <span class="n">endpoint</span><span class="o">=</span><span class="s2">&quot;/gaze/gaze_detection&quot;</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">combine_gaze_detections</span><span class="p">(</span><span class="n">detections</span><span class="o">=</span><span class="n">result</span><span class="p">)</span>

    <span class="nd">@wrap_errors</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">get_clip_image_embeddings</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">inference_input</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">]],</span>
        <span class="n">clip_version</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get CLIP embeddings for input image(s).</span>

<span class="sd">        Args:</span>
<span class="sd">            inference_input (Union[ImagesReference, List[ImagesReference]]): Input image(s) to embed.</span>
<span class="sd">            clip_version (Optional[str], optional): Version of CLIP model to use. Defaults to None.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Union[dict, List[dict]]: CLIP embeddings for the input image(s).</span>

<span class="sd">        Raises:</span>
<span class="sd">            HTTPCallErrorError: If there is an error in the HTTP call.</span>
<span class="sd">            HTTPClientError: If there is an error with the server connection.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">extra_payload</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">if</span> <span class="n">clip_version</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">extra_payload</span><span class="p">[</span><span class="s2">&quot;clip_version_id&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">clip_version</span>
        <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_post_images</span><span class="p">(</span>
            <span class="n">inference_input</span><span class="o">=</span><span class="n">inference_input</span><span class="p">,</span>
            <span class="n">endpoint</span><span class="o">=</span><span class="s2">&quot;/clip/embed_image&quot;</span><span class="p">,</span>
            <span class="n">extra_payload</span><span class="o">=</span><span class="n">extra_payload</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">combine_clip_embeddings</span><span class="p">(</span><span class="n">embeddings</span><span class="o">=</span><span class="n">result</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">unwrap_single_element_list</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>

    <span class="nd">@wrap_errors_async</span>
    <span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">get_clip_image_embeddings_async</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">inference_input</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">]],</span>
        <span class="n">clip_version</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get CLIP embeddings for input image(s) asynchronously.</span>

<span class="sd">        Args:</span>
<span class="sd">            inference_input (Union[ImagesReference, List[ImagesReference]]): Input image(s) to embed.</span>
<span class="sd">            clip_version (Optional[str], optional): Version of CLIP model to use. Defaults to None.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Union[dict, List[dict]]: CLIP embeddings for the input image(s).</span>

<span class="sd">        Raises:</span>
<span class="sd">            HTTPCallErrorError: If there is an error in the HTTP call.</span>
<span class="sd">            HTTPClientError: If there is an error with the server connection.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">extra_payload</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">if</span> <span class="n">clip_version</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">extra_payload</span><span class="p">[</span><span class="s2">&quot;clip_version_id&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">clip_version</span>
        <span class="n">result</span> <span class="o">=</span> <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">_post_images_async</span><span class="p">(</span>
            <span class="n">inference_input</span><span class="o">=</span><span class="n">inference_input</span><span class="p">,</span>
            <span class="n">endpoint</span><span class="o">=</span><span class="s2">&quot;/clip/embed_image&quot;</span><span class="p">,</span>
            <span class="n">extra_payload</span><span class="o">=</span><span class="n">extra_payload</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">combine_clip_embeddings</span><span class="p">(</span><span class="n">embeddings</span><span class="o">=</span><span class="n">result</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">unwrap_single_element_list</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>

    <span class="nd">@wrap_errors</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">get_clip_text_embeddings</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">text</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
        <span class="n">clip_version</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get CLIP embeddings for input text(s).</span>

<span class="sd">        Args:</span>
<span class="sd">            text (Union[str, List[str]]): Input text(s) to embed.</span>
<span class="sd">            clip_version (Optional[str], optional): Version of CLIP model to use. Defaults to None.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Union[dict, List[dict]]: CLIP embeddings for the input text(s).</span>

<span class="sd">        Raises:</span>
<span class="sd">            HTTPCallErrorError: If there is an error in the HTTP call.</span>
<span class="sd">            HTTPClientError: If there is an error with the server connection.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">payload</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__initialise_payload</span><span class="p">()</span>
        <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">text</span>
        <span class="k">if</span> <span class="n">clip_version</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;clip_version_id&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">clip_version</span>
        <span class="n">headers</span> <span class="o">=</span> <span class="n">DEFAULT_HEADERS</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">execution_id_value</span> <span class="o">=</span> <span class="n">execution_id</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">execution_id_value</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">headers</span><span class="p">[</span><span class="n">EXECUTION_ID_HEADER</span><span class="p">]</span> <span class="o">=</span> <span class="n">execution_id_value</span>

        <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">post</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__wrap_url_with_api_key</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__api_url</span><span class="si">}</span><span class="s2">/clip/embed_text&quot;</span><span class="p">),</span>
            <span class="n">json</span><span class="o">=</span><span class="n">payload</span><span class="p">,</span>
            <span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">_collect_processing_time_from_response</span><span class="p">(</span>
            <span class="n">response</span><span class="p">,</span> <span class="n">model_id</span><span class="o">=</span><span class="n">clip_version</span> <span class="ow">or</span> <span class="s2">&quot;clip&quot;</span>
        <span class="p">)</span>
        <span class="n">api_key_safe_raise_for_status</span><span class="p">(</span><span class="n">response</span><span class="o">=</span><span class="n">response</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">unwrap_single_element_list</span><span class="p">(</span><span class="n">sequence</span><span class="o">=</span><span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">())</span>

    <span class="nd">@wrap_errors_async</span>
    <span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">get_clip_text_embeddings_async</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">text</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
        <span class="n">clip_version</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get CLIP embeddings for input text(s) asynchronously.</span>

<span class="sd">        Args:</span>
<span class="sd">            text (Union[str, List[str]]): Input text(s) to embed.</span>
<span class="sd">            clip_version (Optional[str], optional): Version of CLIP model to use. Defaults to None.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Union[dict, List[dict]]: CLIP embeddings for the input text(s).</span>

<span class="sd">        Raises:</span>
<span class="sd">            HTTPCallErrorError: If there is an error in the HTTP call.</span>
<span class="sd">            HTTPClientError: If there is an error with the server connection.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">payload</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__initialise_payload</span><span class="p">()</span>
        <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">text</span>
        <span class="k">if</span> <span class="n">clip_version</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;clip_version_id&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">clip_version</span>
        <span class="k">async</span> <span class="k">with</span> <span class="n">aiohttp</span><span class="o">.</span><span class="n">ClientSession</span><span class="p">()</span> <span class="k">as</span> <span class="n">session</span><span class="p">:</span>
            <span class="k">async</span> <span class="k">with</span> <span class="n">session</span><span class="o">.</span><span class="n">post</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">__wrap_url_with_api_key</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__api_url</span><span class="si">}</span><span class="s2">/clip/embed_text&quot;</span><span class="p">),</span>
                <span class="n">json</span><span class="o">=</span><span class="n">payload</span><span class="p">,</span>
                <span class="n">headers</span><span class="o">=</span><span class="n">DEFAULT_HEADERS</span><span class="p">,</span>
            <span class="p">)</span> <span class="k">as</span> <span class="n">response</span><span class="p">:</span>
                <span class="n">response</span><span class="o">.</span><span class="n">raise_for_status</span><span class="p">()</span>
                <span class="n">response_payload</span> <span class="o">=</span> <span class="k">await</span> <span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">unwrap_single_element_list</span><span class="p">(</span><span class="n">sequence</span><span class="o">=</span><span class="n">response_payload</span><span class="p">)</span>

    <span class="nd">@wrap_errors</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">clip_compare</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">subject</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">ImagesReference</span><span class="p">],</span>
        <span class="n">prompt</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">ImagesReference</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">]],</span>
        <span class="n">subject_type</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;image&quot;</span><span class="p">,</span>
        <span class="n">prompt_type</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;text&quot;</span><span class="p">,</span>
        <span class="n">clip_version</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Compare a subject against prompts using CLIP embeddings.</span>

<span class="sd">        Args:</span>
<span class="sd">            subject (Union[str, ImagesReference]): The subject to compare (image or text).</span>
<span class="sd">            prompt (Union[str, List[str], ImagesReference, List[ImagesReference]]): The prompt(s) to compare against.</span>
<span class="sd">            subject_type (str, optional): Type of subject (&#39;image&#39; or &#39;text&#39;). Defaults to &quot;image&quot;.</span>
<span class="sd">            prompt_type (str, optional): Type of prompt(s) (&#39;image&#39; or &#39;text&#39;). Defaults to &quot;text&quot;.</span>
<span class="sd">            clip_version (Optional[str], optional): Version of CLIP model to use. Defaults to None.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Union[dict, List[dict]]: Comparison results between subject and prompt(s).</span>

<span class="sd">        Raises:</span>
<span class="sd">            InvalidParameterError: If subject_type or prompt_type is invalid.</span>
<span class="sd">            HTTPCallErrorError: If there is an error in the HTTP call.</span>
<span class="sd">            HTTPClientError: If there is an error with the server connection.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="n">subject_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">CLIP_ARGUMENT_TYPES</span>
            <span class="ow">or</span> <span class="n">prompt_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">CLIP_ARGUMENT_TYPES</span>
        <span class="p">):</span>
            <span class="k">raise</span> <span class="n">InvalidParameterError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Could not accept `subject_type` and `prompt_type` with values different than </span><span class="si">{</span><span class="n">CLIP_ARGUMENT_TYPES</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
        <span class="n">payload</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__initialise_payload</span><span class="p">()</span>
        <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;subject_type&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">subject_type</span>
        <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;prompt_type&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">prompt_type</span>
        <span class="k">if</span> <span class="n">clip_version</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;clip_version_id&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">clip_version</span>
        <span class="k">if</span> <span class="n">subject_type</span> <span class="o">==</span> <span class="s2">&quot;image&quot;</span><span class="p">:</span>
            <span class="n">encoded_image</span> <span class="o">=</span> <span class="n">load_static_inference_input</span><span class="p">(</span>
                <span class="n">inference_input</span><span class="o">=</span><span class="n">subject</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">payload</span> <span class="o">=</span> <span class="n">inject_images_into_payload</span><span class="p">(</span>
                <span class="n">payload</span><span class="o">=</span><span class="n">payload</span><span class="p">,</span> <span class="n">encoded_images</span><span class="o">=</span><span class="n">encoded_image</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="s2">&quot;subject&quot;</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;subject&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">subject</span>
        <span class="k">if</span> <span class="n">prompt_type</span> <span class="o">==</span> <span class="s2">&quot;image&quot;</span><span class="p">:</span>
            <span class="n">encoded_inference_inputs</span> <span class="o">=</span> <span class="n">load_static_inference_input</span><span class="p">(</span>
                <span class="n">inference_input</span><span class="o">=</span><span class="n">prompt</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">payload</span> <span class="o">=</span> <span class="n">inject_images_into_payload</span><span class="p">(</span>
                <span class="n">payload</span><span class="o">=</span><span class="n">payload</span><span class="p">,</span> <span class="n">encoded_images</span><span class="o">=</span><span class="n">encoded_inference_inputs</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="s2">&quot;prompt&quot;</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;prompt&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">prompt</span>

        <span class="n">headers</span> <span class="o">=</span> <span class="n">DEFAULT_HEADERS</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">execution_id_value</span> <span class="o">=</span> <span class="n">execution_id</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">execution_id_value</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">headers</span><span class="p">[</span><span class="n">EXECUTION_ID_HEADER</span><span class="p">]</span> <span class="o">=</span> <span class="n">execution_id_value</span>

        <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">post</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__wrap_url_with_api_key</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__api_url</span><span class="si">}</span><span class="s2">/clip/compare&quot;</span><span class="p">),</span>
            <span class="n">json</span><span class="o">=</span><span class="n">payload</span><span class="p">,</span>
            <span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">_collect_processing_time_from_response</span><span class="p">(</span>
            <span class="n">response</span><span class="p">,</span> <span class="n">model_id</span><span class="o">=</span><span class="n">clip_version</span> <span class="ow">or</span> <span class="s2">&quot;clip&quot;</span>
        <span class="p">)</span>
        <span class="n">api_key_safe_raise_for_status</span><span class="p">(</span><span class="n">response</span><span class="o">=</span><span class="n">response</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>

    <span class="nd">@wrap_errors_async</span>
    <span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">clip_compare_async</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">subject</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">ImagesReference</span><span class="p">],</span>
        <span class="n">prompt</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">ImagesReference</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">]],</span>
        <span class="n">subject_type</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;image&quot;</span><span class="p">,</span>
        <span class="n">prompt_type</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;text&quot;</span><span class="p">,</span>
        <span class="n">clip_version</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Compare a subject against prompts using CLIP embeddings asynchronously.</span>

<span class="sd">        Args:</span>
<span class="sd">            subject (Union[str, ImagesReference]): The subject to compare (image or text).</span>
<span class="sd">            prompt (Union[str, List[str], ImagesReference, List[ImagesReference]]): The prompt(s) to compare against.</span>
<span class="sd">            subject_type (str, optional): Type of subject (&#39;image&#39; or &#39;text&#39;). Defaults to &quot;image&quot;.</span>
<span class="sd">            prompt_type (str, optional): Type of prompt(s) (&#39;image&#39; or &#39;text&#39;). Defaults to &quot;text&quot;.</span>
<span class="sd">            clip_version (Optional[str], optional): Version of CLIP model to use. Defaults to None.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Union[dict, List[dict]]: Comparison results between subject and prompt(s).</span>

<span class="sd">        Raises:</span>
<span class="sd">            InvalidParameterError: If subject_type or prompt_type is invalid.</span>
<span class="sd">            HTTPCallErrorError: If there is an error in the HTTP call.</span>
<span class="sd">            HTTPClientError: If there is an error with the server connection.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="n">subject_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">CLIP_ARGUMENT_TYPES</span>
            <span class="ow">or</span> <span class="n">prompt_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">CLIP_ARGUMENT_TYPES</span>
        <span class="p">):</span>
            <span class="k">raise</span> <span class="n">InvalidParameterError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Could not accept `subject_type` and `prompt_type` with values different than </span><span class="si">{</span><span class="n">CLIP_ARGUMENT_TYPES</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
        <span class="n">payload</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__initialise_payload</span><span class="p">()</span>
        <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;subject_type&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">subject_type</span>
        <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;prompt_type&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">prompt_type</span>
        <span class="k">if</span> <span class="n">clip_version</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;clip_version_id&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">clip_version</span>
        <span class="k">if</span> <span class="n">subject_type</span> <span class="o">==</span> <span class="s2">&quot;image&quot;</span><span class="p">:</span>
            <span class="n">encoded_image</span> <span class="o">=</span> <span class="k">await</span> <span class="n">load_static_inference_input_async</span><span class="p">(</span>
                <span class="n">inference_input</span><span class="o">=</span><span class="n">subject</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">payload</span> <span class="o">=</span> <span class="n">inject_images_into_payload</span><span class="p">(</span>
                <span class="n">payload</span><span class="o">=</span><span class="n">payload</span><span class="p">,</span> <span class="n">encoded_images</span><span class="o">=</span><span class="n">encoded_image</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="s2">&quot;subject&quot;</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;subject&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">subject</span>
        <span class="k">if</span> <span class="n">prompt_type</span> <span class="o">==</span> <span class="s2">&quot;image&quot;</span><span class="p">:</span>
            <span class="n">encoded_inference_inputs</span> <span class="o">=</span> <span class="k">await</span> <span class="n">load_static_inference_input_async</span><span class="p">(</span>
                <span class="n">inference_input</span><span class="o">=</span><span class="n">prompt</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">payload</span> <span class="o">=</span> <span class="n">inject_images_into_payload</span><span class="p">(</span>
                <span class="n">payload</span><span class="o">=</span><span class="n">payload</span><span class="p">,</span> <span class="n">encoded_images</span><span class="o">=</span><span class="n">encoded_inference_inputs</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="s2">&quot;prompt&quot;</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;prompt&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">prompt</span>

        <span class="k">async</span> <span class="k">with</span> <span class="n">aiohttp</span><span class="o">.</span><span class="n">ClientSession</span><span class="p">()</span> <span class="k">as</span> <span class="n">session</span><span class="p">:</span>
            <span class="k">async</span> <span class="k">with</span> <span class="n">session</span><span class="o">.</span><span class="n">post</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">__wrap_url_with_api_key</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__api_url</span><span class="si">}</span><span class="s2">/clip/compare&quot;</span><span class="p">),</span>
                <span class="n">json</span><span class="o">=</span><span class="n">payload</span><span class="p">,</span>
                <span class="n">headers</span><span class="o">=</span><span class="n">DEFAULT_HEADERS</span><span class="p">,</span>
            <span class="p">)</span> <span class="k">as</span> <span class="n">response</span><span class="p">:</span>
                <span class="n">response</span><span class="o">.</span><span class="n">raise_for_status</span><span class="p">()</span>
                <span class="k">return</span> <span class="k">await</span> <span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>

    <span class="nd">@wrap_errors</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">get_perception_encoder_image_embeddings</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">inference_input</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">]],</span>
        <span class="n">perception_encoder_version</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get Perception Encoder embeddings for input image(s).&quot;&quot;&quot;</span>
        <span class="n">extra_payload</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">if</span> <span class="n">perception_encoder_version</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">extra_payload</span><span class="p">[</span><span class="s2">&quot;perception_encoder_version_id&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">perception_encoder_version</span>
        <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_post_images</span><span class="p">(</span>
            <span class="n">inference_input</span><span class="o">=</span><span class="n">inference_input</span><span class="p">,</span>
            <span class="n">endpoint</span><span class="o">=</span><span class="s2">&quot;/perception_encoder/embed_image&quot;</span><span class="p">,</span>
            <span class="n">extra_payload</span><span class="o">=</span><span class="n">extra_payload</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">unwrap_single_element_list</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>

    <span class="nd">@wrap_errors</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">get_perception_encoder_text_embeddings</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">text</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
        <span class="n">perception_encoder_version</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get Perception Encoder embeddings for input text(s).&quot;&quot;&quot;</span>
        <span class="n">payload</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__initialise_payload</span><span class="p">()</span>
        <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">text</span>
        <span class="k">if</span> <span class="n">perception_encoder_version</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;perception_encoder_version_id&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">perception_encoder_version</span>

        <span class="n">headers</span> <span class="o">=</span> <span class="n">DEFAULT_HEADERS</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">execution_id_value</span> <span class="o">=</span> <span class="n">execution_id</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">execution_id_value</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">headers</span><span class="p">[</span><span class="n">EXECUTION_ID_HEADER</span><span class="p">]</span> <span class="o">=</span> <span class="n">execution_id_value</span>

        <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">post</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__wrap_url_with_api_key</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__api_url</span><span class="si">}</span><span class="s2">/perception_encoder/embed_text&quot;</span>
            <span class="p">),</span>
            <span class="n">json</span><span class="o">=</span><span class="n">payload</span><span class="p">,</span>
            <span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">_collect_processing_time_from_response</span><span class="p">(</span>
            <span class="n">response</span><span class="p">,</span>
            <span class="n">model_id</span><span class="o">=</span><span class="n">perception_encoder_version</span> <span class="ow">or</span> <span class="s2">&quot;perception_encoder&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">api_key_safe_raise_for_status</span><span class="p">(</span><span class="n">response</span><span class="o">=</span><span class="n">response</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">unwrap_single_element_list</span><span class="p">(</span><span class="n">sequence</span><span class="o">=</span><span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">())</span>

    <span class="nd">@wrap_errors</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">infer_lmm</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">inference_input</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">]],</span>
        <span class="n">model_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">prompt</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">model_id_in_path</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Run inference using a Large Multimodal Model (LMM).</span>

<span class="sd">        This method supports various vision-language models including Florence-2,</span>
<span class="sd">        Moondream2, SmolVLM, Qwen2.5-VL, Qwen3-VL, and PaliGemma.</span>

<span class="sd">        Args:</span>
<span class="sd">            inference_input (Union[ImagesReference, List[ImagesReference]]): Input image(s)</span>
<span class="sd">                for inference. Can be file paths, URLs, base64 strings, numpy arrays, or PIL images.</span>
<span class="sd">            model_id (str): The identifier of the LMM model to use. Examples include:</span>
<span class="sd">                - &quot;florence-2-base&quot;, &quot;florence-2-large&quot; for Florence-2</span>
<span class="sd">                - &quot;moondream2/moondream2_2b_jul24&quot; for Moondream2</span>
<span class="sd">                - &quot;smolvlm2/smolvlm-2.2b-instruct&quot; for SmolVLM</span>
<span class="sd">                - &quot;qwen25-vl-7b&quot; for Qwen2.5-VL</span>
<span class="sd">                - &quot;qwen3vl-2b-instruct&quot; for Qwen3-VL</span>
<span class="sd">            prompt (Optional[str], optional): Text prompt to guide the model. Defaults to None.</span>
<span class="sd">            model_id_in_path (bool, optional): If True, includes model_id in the URL path</span>
<span class="sd">                (e.g., /infer/lmm/florence-2-base) which enables path-based routing.</span>
<span class="sd">                If False (default), model_id is only sent in the request body.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Union[dict, List[dict]]: Inference results containing the model response.</span>
<span class="sd">                The structure depends on the specific model used.</span>

<span class="sd">        Raises:</span>
<span class="sd">            HTTPCallErrorError: If there is an error in the HTTP call.</span>
<span class="sd">            HTTPClientError: If there is an error with the server connection.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">extra_payload</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;model_id&quot;</span><span class="p">:</span> <span class="n">model_id</span><span class="p">}</span>
        <span class="k">if</span> <span class="n">prompt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">extra_payload</span><span class="p">[</span><span class="s2">&quot;prompt&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">prompt</span>

        <span class="k">if</span> <span class="n">model_id_in_path</span><span class="p">:</span>
            <span class="n">endpoint</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;/infer/lmm/</span><span class="si">{</span><span class="n">model_id</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">endpoint</span> <span class="o">=</span> <span class="s2">&quot;/infer/lmm&quot;</span>

        <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_post_images</span><span class="p">(</span>
            <span class="n">inference_input</span><span class="o">=</span><span class="n">inference_input</span><span class="p">,</span>
            <span class="n">endpoint</span><span class="o">=</span><span class="n">endpoint</span><span class="p">,</span>
            <span class="n">extra_payload</span><span class="o">=</span><span class="n">extra_payload</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">result</span>

    <span class="nd">@wrap_errors_async</span>
    <span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">infer_lmm_async</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">inference_input</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">]],</span>
        <span class="n">model_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">prompt</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">model_id_in_path</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Run inference using a Large Multimodal Model (LMM) asynchronously.</span>

<span class="sd">        This method supports various vision-language models including Florence-2,</span>
<span class="sd">        Moondream2, SmolVLM, Qwen2.5-VL, Qwen3-VL, and PaliGemma.</span>

<span class="sd">        Args:</span>
<span class="sd">            inference_input (Union[ImagesReference, List[ImagesReference]]): Input image(s)</span>
<span class="sd">                for inference. Can be file paths, URLs, base64 strings, numpy arrays, or PIL images.</span>
<span class="sd">            model_id (str): The identifier of the LMM model to use.</span>
<span class="sd">            prompt (Optional[str], optional): Text prompt to guide the model. Defaults to None.</span>
<span class="sd">            model_id_in_path (bool, optional): If True, includes model_id in the URL path</span>
<span class="sd">                (e.g., /infer/lmm/florence-2-base) which enables path-based routing.</span>
<span class="sd">                If False (default), model_id is only sent in the request body.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Union[dict, List[dict]]: Inference results containing the model response.</span>

<span class="sd">        Raises:</span>
<span class="sd">            HTTPCallErrorError: If there is an error in the HTTP call.</span>
<span class="sd">            HTTPClientError: If there is an error with the server connection.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">extra_payload</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;model_id&quot;</span><span class="p">:</span> <span class="n">model_id</span><span class="p">}</span>
        <span class="k">if</span> <span class="n">prompt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">extra_payload</span><span class="p">[</span><span class="s2">&quot;prompt&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">prompt</span>

        <span class="k">if</span> <span class="n">model_id_in_path</span><span class="p">:</span>
            <span class="n">endpoint</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;/infer/lmm/</span><span class="si">{</span><span class="n">model_id</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">endpoint</span> <span class="o">=</span> <span class="s2">&quot;/infer/lmm&quot;</span>

        <span class="n">result</span> <span class="o">=</span> <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">_post_images_async</span><span class="p">(</span>
            <span class="n">inference_input</span><span class="o">=</span><span class="n">inference_input</span><span class="p">,</span>
            <span class="n">endpoint</span><span class="o">=</span><span class="n">endpoint</span><span class="p">,</span>
            <span class="n">extra_payload</span><span class="o">=</span><span class="n">extra_payload</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">result</span>

    <span class="nd">@wrap_errors</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">depth_estimation</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">inference_input</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">]],</span>
        <span class="n">model_id</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;depth-anything-v3/small&quot;</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Run depth estimation on input image(s).</span>

<span class="sd">        This method estimates depth maps from images using models like Depth Anything.</span>

<span class="sd">        Args:</span>
<span class="sd">            inference_input (Union[ImagesReference, List[ImagesReference]]): Input image(s)</span>
<span class="sd">                for depth estimation. Can be file paths, URLs, base64 strings, numpy arrays,</span>
<span class="sd">                or PIL images.</span>
<span class="sd">            model_id (str, optional): The depth estimation model to use. Defaults to</span>
<span class="sd">                &quot;depth-anything-v3/small&quot;. Supported models include:</span>
<span class="sd">                - &quot;depth-anything-v2/small&quot;</span>
<span class="sd">                - &quot;depth-anything-v3/small&quot;</span>
<span class="sd">                - &quot;depth-anything-v3/base&quot;</span>

<span class="sd">        Returns:</span>
<span class="sd">            Union[dict, List[dict]]: Depth estimation results containing:</span>
<span class="sd">                - normalized_depth: The normalized depth map as a list</span>
<span class="sd">                - image: Hex-encoded visualization of the depth map</span>

<span class="sd">        Raises:</span>
<span class="sd">            HTTPCallErrorError: If there is an error in the HTTP call.</span>
<span class="sd">            HTTPClientError: If there is an error with the server connection.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">extra_payload</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;model_id&quot;</span><span class="p">:</span> <span class="n">model_id</span><span class="p">}</span>
        <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_post_images</span><span class="p">(</span>
            <span class="n">inference_input</span><span class="o">=</span><span class="n">inference_input</span><span class="p">,</span>
            <span class="n">endpoint</span><span class="o">=</span><span class="s2">&quot;/infer/depth-estimation&quot;</span><span class="p">,</span>
            <span class="n">extra_payload</span><span class="o">=</span><span class="n">extra_payload</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">result</span>

    <span class="nd">@wrap_errors_async</span>
    <span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">depth_estimation_async</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">inference_input</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">]],</span>
        <span class="n">model_id</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;depth-anything-v3/small&quot;</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Run depth estimation on input image(s) asynchronously.</span>

<span class="sd">        Args:</span>
<span class="sd">            inference_input (Union[ImagesReference, List[ImagesReference]]): Input image(s)</span>
<span class="sd">                for depth estimation.</span>
<span class="sd">            model_id (str, optional): The depth estimation model to use. Defaults to</span>
<span class="sd">                &quot;depth-anything-v3/small&quot;.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Union[dict, List[dict]]: Depth estimation results.</span>

<span class="sd">        Raises:</span>
<span class="sd">            HTTPCallErrorError: If there is an error in the HTTP call.</span>
<span class="sd">            HTTPClientError: If there is an error with the server connection.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">extra_payload</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;model_id&quot;</span><span class="p">:</span> <span class="n">model_id</span><span class="p">}</span>
        <span class="n">result</span> <span class="o">=</span> <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">_post_images_async</span><span class="p">(</span>
            <span class="n">inference_input</span><span class="o">=</span><span class="n">inference_input</span><span class="p">,</span>
            <span class="n">endpoint</span><span class="o">=</span><span class="s2">&quot;/infer/depth-estimation&quot;</span><span class="p">,</span>
            <span class="n">extra_payload</span><span class="o">=</span><span class="n">extra_payload</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">result</span>

    <span class="nd">@wrap_errors</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">sam2_segment_image</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">inference_input</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">]],</span>
        <span class="n">prompts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">sam2_version_id</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;hiera_tiny&quot;</span><span class="p">,</span>
        <span class="n">multimask_output</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">mask_input_format</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;json&quot;</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Run Segment Anything 2 (SAM2) segmentation on input image(s).</span>

<span class="sd">        This method performs instance segmentation using SAM2, which can segment</span>
<span class="sd">        objects based on point or box prompts.</span>

<span class="sd">        Args:</span>
<span class="sd">            inference_input (Union[ImagesReference, List[ImagesReference]]): Input image(s)</span>
<span class="sd">                for segmentation. Can be file paths, URLs, base64 strings, numpy arrays,</span>
<span class="sd">                or PIL images.</span>
<span class="sd">            prompts (Optional[List[dict]], optional): List of prompt dictionaries. Each prompt</span>
<span class="sd">                can contain:</span>
<span class="sd">                - &quot;box&quot;: {&quot;x&quot;: float, &quot;y&quot;: float, &quot;width&quot;: float, &quot;height&quot;: float}</span>
<span class="sd">                - &quot;points&quot;: [{&quot;x&quot;: float, &quot;y&quot;: float, &quot;positive&quot;: bool}, ...]</span>
<span class="sd">                Defaults to None (automatic segmentation).</span>
<span class="sd">            sam2_version_id (str, optional): Version of SAM2 model to use. Options are</span>
<span class="sd">                &quot;hiera_large&quot;, &quot;hiera_small&quot;, &quot;hiera_tiny&quot;, &quot;hiera_b_plus&quot;.</span>
<span class="sd">                Defaults to &quot;hiera_tiny&quot;.</span>
<span class="sd">            multimask_output (bool, optional): Whether to output multiple masks per prompt.</span>
<span class="sd">                Defaults to True.</span>
<span class="sd">            mask_input_format (str, optional): Format for mask output. Defaults to &quot;json&quot;.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Union[dict, List[dict]]: Segmentation results containing predictions with masks,</span>
<span class="sd">                confidence scores, and bounding boxes.</span>

<span class="sd">        Raises:</span>
<span class="sd">            HTTPCallErrorError: If there is an error in the HTTP call.</span>
<span class="sd">            HTTPClientError: If there is an error with the server connection.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">extra_payload</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;sam2_version_id&quot;</span><span class="p">:</span> <span class="n">sam2_version_id</span><span class="p">,</span>
            <span class="s2">&quot;multimask_output&quot;</span><span class="p">:</span> <span class="n">multimask_output</span><span class="p">,</span>
            <span class="s2">&quot;format&quot;</span><span class="p">:</span> <span class="n">mask_input_format</span><span class="p">,</span>
        <span class="p">}</span>
        <span class="k">if</span> <span class="n">prompts</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">extra_payload</span><span class="p">[</span><span class="s2">&quot;prompts&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;prompts&quot;</span><span class="p">:</span> <span class="n">prompts</span><span class="p">}</span>
        <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_post_images</span><span class="p">(</span>
            <span class="n">inference_input</span><span class="o">=</span><span class="n">inference_input</span><span class="p">,</span>
            <span class="n">endpoint</span><span class="o">=</span><span class="s2">&quot;/sam2/segment_image&quot;</span><span class="p">,</span>
            <span class="n">extra_payload</span><span class="o">=</span><span class="n">extra_payload</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">result</span>

    <span class="nd">@wrap_errors_async</span>
    <span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">sam2_segment_image_async</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">inference_input</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">]],</span>
        <span class="n">prompts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">sam2_version_id</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;hiera_tiny&quot;</span><span class="p">,</span>
        <span class="n">multimask_output</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">mask_input_format</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;json&quot;</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Run Segment Anything 2 (SAM2) segmentation on input image(s) asynchronously.</span>

<span class="sd">        Args:</span>
<span class="sd">            inference_input (Union[ImagesReference, List[ImagesReference]]): Input image(s)</span>
<span class="sd">                for segmentation.</span>
<span class="sd">            prompts (Optional[List[dict]], optional): List of prompt dictionaries.</span>
<span class="sd">                Defaults to None.</span>
<span class="sd">            sam2_version_id (str, optional): Version of SAM2 model. Defaults to &quot;hiera_tiny&quot;.</span>
<span class="sd">            multimask_output (bool, optional): Whether to output multiple masks. Defaults to True.</span>
<span class="sd">            mask_input_format (str, optional): Format for mask output. Defaults to &quot;json&quot;.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Union[dict, List[dict]]: Segmentation results.</span>

<span class="sd">        Raises:</span>
<span class="sd">            HTTPCallErrorError: If there is an error in the HTTP call.</span>
<span class="sd">            HTTPClientError: If there is an error with the server connection.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">extra_payload</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;sam2_version_id&quot;</span><span class="p">:</span> <span class="n">sam2_version_id</span><span class="p">,</span>
            <span class="s2">&quot;multimask_output&quot;</span><span class="p">:</span> <span class="n">multimask_output</span><span class="p">,</span>
            <span class="s2">&quot;format&quot;</span><span class="p">:</span> <span class="n">mask_input_format</span><span class="p">,</span>
        <span class="p">}</span>
        <span class="k">if</span> <span class="n">prompts</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">extra_payload</span><span class="p">[</span><span class="s2">&quot;prompts&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;prompts&quot;</span><span class="p">:</span> <span class="n">prompts</span><span class="p">}</span>
        <span class="n">result</span> <span class="o">=</span> <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">_post_images_async</span><span class="p">(</span>
            <span class="n">inference_input</span><span class="o">=</span><span class="n">inference_input</span><span class="p">,</span>
            <span class="n">endpoint</span><span class="o">=</span><span class="s2">&quot;/sam2/segment_image&quot;</span><span class="p">,</span>
            <span class="n">extra_payload</span><span class="o">=</span><span class="n">extra_payload</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">result</span>

    <span class="nd">@wrap_errors</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">sam3_3d_infer</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">inference_input</span><span class="p">:</span> <span class="n">ImagesReference</span><span class="p">,</span>
        <span class="n">mask_input</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
        <span class="n">model_id</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;sam3-3d-objects&quot;</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">output_meshes</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">output_scene</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">with_mesh_postprocess</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">with_texture_baking</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">use_distillations</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate 3D meshes and Gaussian splatting from a 2D image with mask prompts.</span>

<span class="sd">        This method uses SAM3 3D to generate 3D representations from 2D images</span>
<span class="sd">        with mask prompts.</span>

<span class="sd">        Args:</span>
<span class="sd">            inference_input (ImagesReference): Input image for 3D generation.</span>
<span class="sd">                Can be a file path, URL, base64 string, numpy array, or PIL image.</span>
<span class="sd">            mask_input (Any): Mask input in any supported format:</span>
<span class="sd">                - Polygon coordinates: [x1, y1, x2, y2, ...]</span>
<span class="sd">                - Binary mask (as numpy array or base64)</span>
<span class="sd">                - RLE dictionary</span>
<span class="sd">                - List of any of the above for multiple masks</span>
<span class="sd">            model_id (str, optional): The SAM3 3D model to use. Defaults to &quot;sam3-3d-objects&quot;.</span>
<span class="sd">            output_meshes (bool, optional): SAM3 3D always outputs object gaussians, and can</span>
<span class="sd">                optionally output object meshes if output_meshes is True. Defaults to True.</span>
<span class="sd">            output_scene (bool, optional): Output the combined scene reconstruction in</span>
<span class="sd">                addition to individual object reconstructions. Defaults to True.</span>
<span class="sd">            with_mesh_postprocess (bool, optional): Enable mesh postprocessing. Defaults to True.</span>
<span class="sd">            with_texture_baking (bool, optional): Enable texture baking for meshes. Defaults to True.</span>
<span class="sd">            use_distillations (bool, optional): Use the distilled versions of the model components.</span>

<span class="sd">        Returns:</span>
<span class="sd">            dict: Response containing base64-encoded 3D outputs:</span>
<span class="sd">                - mesh_glb: Scene mesh in GLB format (base64 encoded) if output_meshes=True, otherwise None.</span>
<span class="sd">                - gaussian_ply: Combined Gaussian splatting in PLY format (base64 encoded)</span>
<span class="sd">                - objects: List of individual objects, each containing:</span>
<span class="sd">                    - mesh_glb: Object mesh (base64) if output_scene=True and output_meshes=True, otherwise None.</span>
<span class="sd">                    - gaussian_ply: Object Gaussian (base64) if output_scene=True, otherwise None.</span>
<span class="sd">                    - metadata: {&quot;rotation&quot;: [...], &quot;translation&quot;: [...], &quot;scale&quot;: [...]}</span>
<span class="sd">                - time: Inference time in seconds</span>

<span class="sd">        Raises:</span>
<span class="sd">            HTTPCallErrorError: If there is an error in the HTTP call.</span>
<span class="sd">            HTTPClientError: If there is an error with the server connection.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">encoded_inference_inputs</span> <span class="o">=</span> <span class="n">load_static_inference_input</span><span class="p">(</span>
            <span class="n">inference_input</span><span class="o">=</span><span class="n">inference_input</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">payload</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__initialise_payload</span><span class="p">()</span>
        <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;model_id&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">model_id</span>
        <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;mask_input&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">mask_input</span>
        <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;output_meshes&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">output_meshes</span>
        <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;output_scene&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">output_scene</span>
        <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;with_mesh_postprocess&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">with_mesh_postprocess</span>
        <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;with_texture_baking&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">with_texture_baking</span>
        <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;use_distillations&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">use_distillations</span>

        <span class="n">url</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__wrap_url_with_api_key</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__api_url</span><span class="si">}</span><span class="s2">/sam3_3d/infer&quot;</span><span class="p">)</span>
        <span class="n">requests_data</span> <span class="o">=</span> <span class="n">prepare_requests_data</span><span class="p">(</span>
            <span class="n">url</span><span class="o">=</span><span class="n">url</span><span class="p">,</span>
            <span class="n">encoded_inference_inputs</span><span class="o">=</span><span class="n">encoded_inference_inputs</span><span class="p">,</span>
            <span class="n">headers</span><span class="o">=</span><span class="n">DEFAULT_HEADERS</span><span class="p">,</span>
            <span class="n">parameters</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">payload</span><span class="o">=</span><span class="n">payload</span><span class="p">,</span>
            <span class="n">max_batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">image_placement</span><span class="o">=</span><span class="n">ImagePlacement</span><span class="o">.</span><span class="n">JSON</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">responses</span> <span class="o">=</span> <span class="n">execute_requests_packages</span><span class="p">(</span>
            <span class="n">requests_data</span><span class="o">=</span><span class="n">requests_data</span><span class="p">,</span>
            <span class="n">request_method</span><span class="o">=</span><span class="n">RequestMethod</span><span class="o">.</span><span class="n">POST</span><span class="p">,</span>
            <span class="n">max_concurrent_requests</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">__inference_configuration</span><span class="o">.</span><span class="n">max_concurrent_requests</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">responses</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>

    <span class="nd">@wrap_errors_async</span>
    <span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">sam3_3d_infer_async</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">inference_input</span><span class="p">:</span> <span class="n">ImagesReference</span><span class="p">,</span>
        <span class="n">mask_input</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
        <span class="n">model_id</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;sam3-3d-objects&quot;</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">output_meshes</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">output_scene</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">with_mesh_postprocess</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">with_texture_baking</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">use_distillations</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate 3D meshes and Gaussian splatting from a 2D image asynchronously.</span>

<span class="sd">        Args:</span>
<span class="sd">            inference_input (ImagesReference): Input image for 3D generation.</span>
<span class="sd">            mask_input (Any): Mask input in any supported format.</span>
<span class="sd">            model_id (str, optional): The SAM3 3D model to use. Defaults to &quot;sam3-3d-objects&quot;.</span>
<span class="sd">            output_meshes (bool, optional): SAM3 3D always outputs object gaussians, and can</span>
<span class="sd">                optionally output object meshes if output_meshes is True. Defaults to True.</span>
<span class="sd">            output_scene (bool, optional): Output the combined scene reconstruction in</span>
<span class="sd">                addition to individual object reconstructions. Defaults to True.</span>
<span class="sd">            with_mesh_postprocess (bool, optional): Enable mesh postprocessing. Defaults to True.</span>
<span class="sd">            with_texture_baking (bool, optional): Enable texture baking for meshes. Defaults to True.</span>
<span class="sd">            use_distillations (bool, optional): Use the distilled versions of the model components.</span>

<span class="sd">        Returns:</span>
<span class="sd">            dict: Response containing base64-encoded 3D outputs:</span>
<span class="sd">                - mesh_glb: Scene mesh in GLB format (base64 encoded) if output_meshes=True, otherwise None.</span>
<span class="sd">                - gaussian_ply: Combined Gaussian splatting in PLY format (base64 encoded)</span>
<span class="sd">                - objects: List of individual objects, each containing:</span>
<span class="sd">                    - mesh_glb: Object mesh (base64) if output_scene=True and output_meshes=True, otherwise None.</span>
<span class="sd">                    - gaussian_ply: Object Gaussian (base64) if output_scene=True, otherwise None.</span>
<span class="sd">                    - metadata: {&quot;rotation&quot;: [...], &quot;translation&quot;: [...], &quot;scale&quot;: [...]}</span>
<span class="sd">                - time: Inference time in seconds</span>

<span class="sd">        Raises:</span>
<span class="sd">            HTTPCallErrorError: If there is an error in the HTTP call.</span>
<span class="sd">            HTTPClientError: If there is an error with the server connection.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">encoded_inference_inputs</span> <span class="o">=</span> <span class="k">await</span> <span class="n">load_static_inference_input_async</span><span class="p">(</span>
            <span class="n">inference_input</span><span class="o">=</span><span class="n">inference_input</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">payload</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__initialise_payload</span><span class="p">()</span>
        <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;model_id&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">model_id</span>
        <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;mask_input&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">mask_input</span>
        <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;output_meshes&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">output_meshes</span>
        <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;output_scene&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">output_scene</span>
        <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;with_mesh_postprocess&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">with_mesh_postprocess</span>
        <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;with_texture_baking&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">with_texture_baking</span>
        <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;use_distillations&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">use_distillations</span>

        <span class="n">url</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__wrap_url_with_api_key</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__api_url</span><span class="si">}</span><span class="s2">/sam3_3d/infer&quot;</span><span class="p">)</span>
        <span class="n">requests_data</span> <span class="o">=</span> <span class="n">prepare_requests_data</span><span class="p">(</span>
            <span class="n">url</span><span class="o">=</span><span class="n">url</span><span class="p">,</span>
            <span class="n">encoded_inference_inputs</span><span class="o">=</span><span class="n">encoded_inference_inputs</span><span class="p">,</span>
            <span class="n">headers</span><span class="o">=</span><span class="n">DEFAULT_HEADERS</span><span class="p">,</span>
            <span class="n">parameters</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">payload</span><span class="o">=</span><span class="n">payload</span><span class="p">,</span>
            <span class="n">max_batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">image_placement</span><span class="o">=</span><span class="n">ImagePlacement</span><span class="o">.</span><span class="n">JSON</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">responses</span> <span class="o">=</span> <span class="k">await</span> <span class="n">execute_requests_packages_async</span><span class="p">(</span>
            <span class="n">requests_data</span><span class="o">=</span><span class="n">requests_data</span><span class="p">,</span>
            <span class="n">request_method</span><span class="o">=</span><span class="n">RequestMethod</span><span class="o">.</span><span class="n">POST</span><span class="p">,</span>
            <span class="n">max_concurrent_requests</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">__inference_configuration</span><span class="o">.</span><span class="n">max_concurrent_requests</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">responses</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="nd">@wrap_errors</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">sam3_concept_segment</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">inference_input</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">]],</span>
        <span class="n">prompts</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">],</span>
        <span class="n">model_id</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;sam3/sam3_final&quot;</span><span class="p">,</span>
        <span class="n">output_prob_thresh</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
        <span class="n">nms_iou_threshold</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="nb">format</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;polygon&quot;</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Run SAM3 promptable concept segmentation (PCS) on input image(s).</span>

<span class="sd">        Performs zero-shot instance segmentation using text or visual prompts.</span>

<span class="sd">        Args:</span>
<span class="sd">            inference_input: Input image(s) for segmentation.</span>
<span class="sd">            prompts: List of prompt dicts, each with keys like &quot;type&quot;, &quot;text&quot;,</span>
<span class="sd">                &quot;output_prob_thresh&quot;, &quot;boxes&quot;, &quot;box_labels&quot;.</span>
<span class="sd">            model_id: SAM3 model to use. Defaults to &quot;sam3/sam3_final&quot;.</span>
<span class="sd">            output_prob_thresh: Global confidence threshold. Defaults to 0.5.</span>
<span class="sd">            nms_iou_threshold: IoU threshold for cross-prompt NMS. None disables NMS.</span>
<span class="sd">            format: Output mask format, &quot;polygon&quot; or &quot;rle&quot;. Defaults to &quot;polygon&quot;.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Segmentation results with prompt_results containing predictions.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">extra_payload</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;model_id&quot;</span><span class="p">:</span> <span class="n">model_id</span><span class="p">,</span>
            <span class="s2">&quot;prompts&quot;</span><span class="p">:</span> <span class="n">prompts</span><span class="p">,</span>
            <span class="s2">&quot;output_prob_thresh&quot;</span><span class="p">:</span> <span class="n">output_prob_thresh</span><span class="p">,</span>
            <span class="s2">&quot;format&quot;</span><span class="p">:</span> <span class="nb">format</span><span class="p">,</span>
        <span class="p">}</span>
        <span class="k">if</span> <span class="n">nms_iou_threshold</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">extra_payload</span><span class="p">[</span><span class="s2">&quot;nms_iou_threshold&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">nms_iou_threshold</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_post_images</span><span class="p">(</span>
            <span class="n">inference_input</span><span class="o">=</span><span class="n">inference_input</span><span class="p">,</span>
            <span class="n">endpoint</span><span class="o">=</span><span class="s2">&quot;/sam3/concept_segment&quot;</span><span class="p">,</span>
            <span class="n">extra_payload</span><span class="o">=</span><span class="n">extra_payload</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="nd">@wrap_errors_async</span>
    <span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">sam3_concept_segment_async</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">inference_input</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">]],</span>
        <span class="n">prompts</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">],</span>
        <span class="n">model_id</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;sam3/sam3_final&quot;</span><span class="p">,</span>
        <span class="n">output_prob_thresh</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
        <span class="n">nms_iou_threshold</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="nb">format</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;polygon&quot;</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Run SAM3 promptable concept segmentation (PCS) asynchronously.</span>

<span class="sd">        Args:</span>
<span class="sd">            inference_input: Input image(s) for segmentation.</span>
<span class="sd">            prompts: List of prompt dicts.</span>
<span class="sd">            model_id: SAM3 model to use. Defaults to &quot;sam3/sam3_final&quot;.</span>
<span class="sd">            output_prob_thresh: Global confidence threshold. Defaults to 0.5.</span>
<span class="sd">            nms_iou_threshold: IoU threshold for cross-prompt NMS. None disables NMS.</span>
<span class="sd">            format: Output mask format, &quot;polygon&quot; or &quot;rle&quot;. Defaults to &quot;polygon&quot;.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Segmentation results with prompt_results containing predictions.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">extra_payload</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;model_id&quot;</span><span class="p">:</span> <span class="n">model_id</span><span class="p">,</span>
            <span class="s2">&quot;prompts&quot;</span><span class="p">:</span> <span class="n">prompts</span><span class="p">,</span>
            <span class="s2">&quot;output_prob_thresh&quot;</span><span class="p">:</span> <span class="n">output_prob_thresh</span><span class="p">,</span>
            <span class="s2">&quot;format&quot;</span><span class="p">:</span> <span class="nb">format</span><span class="p">,</span>
        <span class="p">}</span>
        <span class="k">if</span> <span class="n">nms_iou_threshold</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">extra_payload</span><span class="p">[</span><span class="s2">&quot;nms_iou_threshold&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">nms_iou_threshold</span>
        <span class="k">return</span> <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">_post_images_async</span><span class="p">(</span>
            <span class="n">inference_input</span><span class="o">=</span><span class="n">inference_input</span><span class="p">,</span>
            <span class="n">endpoint</span><span class="o">=</span><span class="s2">&quot;/sam3/concept_segment&quot;</span><span class="p">,</span>
            <span class="n">extra_payload</span><span class="o">=</span><span class="n">extra_payload</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="nd">@wrap_errors</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">sam3_visual_segment</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">inference_input</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">]],</span>
        <span class="n">prompts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">multimask_output</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">mask_input_format</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;json&quot;</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Run SAM3 promptable visual segmentation (PVS) on input image(s).</span>

<span class="sd">        Performs instance segmentation using point or box prompts.</span>

<span class="sd">        Args:</span>
<span class="sd">            inference_input: Input image(s) for segmentation.</span>
<span class="sd">            prompts: List of prompt dicts with &quot;box&quot; and/or &quot;points&quot; keys.</span>
<span class="sd">                Defaults to None (automatic segmentation).</span>
<span class="sd">            multimask_output: Whether to output multiple masks per prompt.</span>
<span class="sd">                Defaults to True.</span>
<span class="sd">            mask_input_format: Format for mask output. Defaults to &quot;json&quot;.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Segmentation results containing predictions with masks.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">extra_payload</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;multimask_output&quot;</span><span class="p">:</span> <span class="n">multimask_output</span><span class="p">,</span>
            <span class="s2">&quot;format&quot;</span><span class="p">:</span> <span class="n">mask_input_format</span><span class="p">,</span>
        <span class="p">}</span>
        <span class="k">if</span> <span class="n">prompts</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">extra_payload</span><span class="p">[</span><span class="s2">&quot;prompts&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;prompts&quot;</span><span class="p">:</span> <span class="n">prompts</span><span class="p">}</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_post_images</span><span class="p">(</span>
            <span class="n">inference_input</span><span class="o">=</span><span class="n">inference_input</span><span class="p">,</span>
            <span class="n">endpoint</span><span class="o">=</span><span class="s2">&quot;/sam3/visual_segment&quot;</span><span class="p">,</span>
            <span class="n">extra_payload</span><span class="o">=</span><span class="n">extra_payload</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="nd">@wrap_errors_async</span>
    <span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">sam3_visual_segment_async</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">inference_input</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">]],</span>
        <span class="n">prompts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">multimask_output</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">mask_input_format</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;json&quot;</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Run SAM3 promptable visual segmentation (PVS) asynchronously.</span>

<span class="sd">        Args:</span>
<span class="sd">            inference_input: Input image(s) for segmentation.</span>
<span class="sd">            prompts: List of prompt dicts. Defaults to None.</span>
<span class="sd">            multimask_output: Whether to output multiple masks. Defaults to True.</span>
<span class="sd">            mask_input_format: Format for mask output. Defaults to &quot;json&quot;.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Segmentation results containing predictions with masks.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">extra_payload</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;multimask_output&quot;</span><span class="p">:</span> <span class="n">multimask_output</span><span class="p">,</span>
            <span class="s2">&quot;format&quot;</span><span class="p">:</span> <span class="n">mask_input_format</span><span class="p">,</span>
        <span class="p">}</span>
        <span class="k">if</span> <span class="n">prompts</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">extra_payload</span><span class="p">[</span><span class="s2">&quot;prompts&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;prompts&quot;</span><span class="p">:</span> <span class="n">prompts</span><span class="p">}</span>
        <span class="k">return</span> <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">_post_images_async</span><span class="p">(</span>
            <span class="n">inference_input</span><span class="o">=</span><span class="n">inference_input</span><span class="p">,</span>
            <span class="n">endpoint</span><span class="o">=</span><span class="s2">&quot;/sam3/visual_segment&quot;</span><span class="p">,</span>
            <span class="n">extra_payload</span><span class="o">=</span><span class="n">extra_payload</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="nd">@wrap_errors</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">sam3_embed_image</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">inference_input</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">]],</span>
        <span class="n">image_id</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate SAM3 image embeddings.</span>

<span class="sd">        Args:</span>
<span class="sd">            inference_input: Input image(s) to embed.</span>
<span class="sd">            image_id: Optional cache ID for embeddings. Defaults to None.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Embedding results with image_id and processing time.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">extra_payload</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">if</span> <span class="n">image_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">extra_payload</span><span class="p">[</span><span class="s2">&quot;image_id&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">image_id</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_post_images</span><span class="p">(</span>
            <span class="n">inference_input</span><span class="o">=</span><span class="n">inference_input</span><span class="p">,</span>
            <span class="n">endpoint</span><span class="o">=</span><span class="s2">&quot;/sam3/embed_image&quot;</span><span class="p">,</span>
            <span class="n">extra_payload</span><span class="o">=</span><span class="n">extra_payload</span> <span class="k">if</span> <span class="n">extra_payload</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="nd">@wrap_errors_async</span>
    <span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">sam3_embed_image_async</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">inference_input</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">]],</span>
        <span class="n">image_id</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate SAM3 image embeddings asynchronously.</span>

<span class="sd">        Args:</span>
<span class="sd">            inference_input: Input image(s) to embed.</span>
<span class="sd">            image_id: Optional cache ID for embeddings. Defaults to None.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Embedding results with image_id and processing time.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">extra_payload</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">if</span> <span class="n">image_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">extra_payload</span><span class="p">[</span><span class="s2">&quot;image_id&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">image_id</span>
        <span class="k">return</span> <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">_post_images_async</span><span class="p">(</span>
            <span class="n">inference_input</span><span class="o">=</span><span class="n">inference_input</span><span class="p">,</span>
            <span class="n">endpoint</span><span class="o">=</span><span class="s2">&quot;/sam3/embed_image&quot;</span><span class="p">,</span>
            <span class="n">extra_payload</span><span class="o">=</span><span class="n">extra_payload</span> <span class="k">if</span> <span class="n">extra_payload</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="nd">@deprecated</span><span class="p">(</span>
        <span class="n">reason</span><span class="o">=</span><span class="s2">&quot;Please use run_workflow(...) method. This method will be removed end of Q2 2024&quot;</span>
    <span class="p">)</span>
    <span class="nd">@wrap_errors</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">infer_from_workflow</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">workspace_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">workflow_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">specification</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">images</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">parameters</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">excluded_fields</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">use_cache</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">enable_profiling</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">workflow_version_id</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Run inference using a workflow specification.</span>

<span class="sd">        Triggers inference from workflow specification at the inference HTTP</span>
<span class="sd">        side. Either (`workspace_name` and `workflow_name`) or `workflow_specification` must be</span>
<span class="sd">        provided. In the first case - definition of workflow will be fetched</span>
<span class="sd">        from Roboflow API, in the latter - `workflow_specification` will be</span>
<span class="sd">        used. `images` and `parameters` will be merged into workflow inputs,</span>
<span class="sd">        the distinction is made to make sure the SDK can easily serialise</span>
<span class="sd">        images and prepare a proper payload. Supported images are numpy arrays,</span>
<span class="sd">        PIL.Image and base64 images, links to images and local paths.</span>
<span class="sd">        `excluded_fields` will be added to request to filter out results</span>
<span class="sd">        of workflow execution at the server side.</span>

<span class="sd">        Args:</span>
<span class="sd">            workspace_name (Optional[str], optional): Name of the workspace containing the workflow. Defaults to None.</span>
<span class="sd">            workflow_name (Optional[str], optional): Name of the workflow. Defaults to None.</span>
<span class="sd">            specification (Optional[dict], optional): Direct workflow specification. Defaults to None.</span>
<span class="sd">            images (Optional[Dict[str, Any]], optional): Images to process. Defaults to None.</span>
<span class="sd">            parameters (Optional[Dict[str, Any]], optional): Additional parameters for the workflow. Defaults to None.</span>
<span class="sd">            excluded_fields (Optional[List[str]], optional): Fields to exclude from results. Defaults to None.</span>
<span class="sd">            use_cache (bool, optional): Whether to use cached results. Defaults to True.</span>
<span class="sd">            enable_profiling (bool, optional): Whether to enable profiling. Defaults to False.</span>

<span class="sd">        Returns:</span>
<span class="sd">            List[Dict[str, Any]]: Results of the workflow execution.</span>

<span class="sd">        Raises:</span>
<span class="sd">            InvalidParameterError: If neither workflow identifiers nor specification is provided.</span>
<span class="sd">            HTTPCallErrorError: If there is an error in the HTTP call.</span>
<span class="sd">            HTTPClientError: If there is an error with the server connection.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_run_workflow</span><span class="p">(</span>
            <span class="n">workspace_name</span><span class="o">=</span><span class="n">workspace_name</span><span class="p">,</span>
            <span class="n">workflow_id</span><span class="o">=</span><span class="n">workflow_name</span><span class="p">,</span>
            <span class="n">specification</span><span class="o">=</span><span class="n">specification</span><span class="p">,</span>
            <span class="n">images</span><span class="o">=</span><span class="n">images</span><span class="p">,</span>
            <span class="n">parameters</span><span class="o">=</span><span class="n">parameters</span><span class="p">,</span>
            <span class="n">excluded_fields</span><span class="o">=</span><span class="n">excluded_fields</span><span class="p">,</span>
            <span class="n">legacy_endpoints</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">use_cache</span><span class="o">=</span><span class="n">use_cache</span><span class="p">,</span>
            <span class="n">enable_profiling</span><span class="o">=</span><span class="n">enable_profiling</span><span class="p">,</span>
            <span class="n">workflow_version_id</span><span class="o">=</span><span class="n">workflow_version_id</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="nd">@wrap_errors</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">run_workflow</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">workspace_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">workflow_id</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">specification</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">images</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">parameters</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">excluded_fields</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">use_cache</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">enable_profiling</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">workflow_version_id</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Run inference using a workflow specification.</span>

<span class="sd">        Triggers inference from workflow specification at the inference HTTP</span>
<span class="sd">        side. Either (`workspace_name` and `workflow_id`) or `workflow_specification` must be</span>
<span class="sd">        provided. In the first case - definition of workflow will be fetched</span>
<span class="sd">        from Roboflow API, in the latter - `workflow_specification` will be</span>
<span class="sd">        used. `images` and `parameters` will be merged into workflow inputs,</span>
<span class="sd">        the distinction is made to make sure the SDK can easily serialise</span>
<span class="sd">        images and prepare a proper payload. Supported images are numpy arrays,</span>
<span class="sd">        PIL.Image and base64 images, links to images and local paths.</span>
<span class="sd">        `excluded_fields` will be added to request to filter out results</span>
<span class="sd">        of workflow execution at the server side.</span>

<span class="sd">        **Important!**</span>
<span class="sd">        Method is not compatible with inference server &lt;=0.9.18. Please migrate to newer version of</span>
<span class="sd">        the server before end of Q2 2024. Until that is done - use old method: infer_from_workflow(...).</span>

<span class="sd">        Note:</span>
<span class="sd">            Method is not compatible with inference server &lt;=0.9.18. Please migrate to newer version of</span>
<span class="sd">            the server before end of Q2 2024. Until that is done - use old method: infer_from_workflow(...).</span>

<span class="sd">        Args:</span>
<span class="sd">            workspace_name (Optional[str], optional): Name of the workspace containing the workflow. Defaults to None.</span>
<span class="sd">            workflow_id (Optional[str], optional): ID of the workflow. Defaults to None.</span>
<span class="sd">            specification (Optional[dict], optional): Direct workflow specification. Defaults to None.</span>
<span class="sd">            images (Optional[Dict[str, Any]], optional): Images to process. Defaults to None.</span>
<span class="sd">            parameters (Optional[Dict[str, Any]], optional): Additional parameters for the workflow. Defaults to None.</span>
<span class="sd">            excluded_fields (Optional[List[str]], optional): Fields to exclude from results. Defaults to None.</span>
<span class="sd">            use_cache (bool, optional): Whether to use cached results. Defaults to True.</span>
<span class="sd">            enable_profiling (bool, optional): Whether to enable profiling. Defaults to False.</span>

<span class="sd">        Returns:</span>
<span class="sd">            List[Dict[str, Any]]: Results of the workflow execution.</span>

<span class="sd">        Raises:</span>
<span class="sd">            InvalidParameterError: If neither workflow identifiers nor specification is provided.</span>
<span class="sd">            HTTPCallErrorError: If there is an error in the HTTP call.</span>
<span class="sd">            HTTPClientError: If there is an error with the server connection.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_run_workflow</span><span class="p">(</span>
            <span class="n">workspace_name</span><span class="o">=</span><span class="n">workspace_name</span><span class="p">,</span>
            <span class="n">workflow_id</span><span class="o">=</span><span class="n">workflow_id</span><span class="p">,</span>
            <span class="n">specification</span><span class="o">=</span><span class="n">specification</span><span class="p">,</span>
            <span class="n">images</span><span class="o">=</span><span class="n">images</span><span class="p">,</span>
            <span class="n">parameters</span><span class="o">=</span><span class="n">parameters</span><span class="p">,</span>
            <span class="n">excluded_fields</span><span class="o">=</span><span class="n">excluded_fields</span><span class="p">,</span>
            <span class="n">legacy_endpoints</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">use_cache</span><span class="o">=</span><span class="n">use_cache</span><span class="p">,</span>
            <span class="n">enable_profiling</span><span class="o">=</span><span class="n">enable_profiling</span><span class="p">,</span>
            <span class="n">workflow_version_id</span><span class="o">=</span><span class="n">workflow_version_id</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_run_workflow</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">workspace_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">workflow_id</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">specification</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">images</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">parameters</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">excluded_fields</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">legacy_endpoints</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">use_cache</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">enable_profiling</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">workflow_version_id</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]:</span>
        <span class="n">response</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_execute_workflow_request</span><span class="p">(</span>
            <span class="n">workspace_name</span><span class="o">=</span><span class="n">workspace_name</span><span class="p">,</span>
            <span class="n">workflow_id</span><span class="o">=</span><span class="n">workflow_id</span><span class="p">,</span>
            <span class="n">specification</span><span class="o">=</span><span class="n">specification</span><span class="p">,</span>
            <span class="n">images</span><span class="o">=</span><span class="n">images</span><span class="p">,</span>
            <span class="n">parameters</span><span class="o">=</span><span class="n">parameters</span><span class="p">,</span>
            <span class="n">excluded_fields</span><span class="o">=</span><span class="n">excluded_fields</span><span class="p">,</span>
            <span class="n">legacy_endpoints</span><span class="o">=</span><span class="n">legacy_endpoints</span><span class="p">,</span>
            <span class="n">use_cache</span><span class="o">=</span><span class="n">use_cache</span><span class="p">,</span>
            <span class="n">enable_profiling</span><span class="o">=</span><span class="n">enable_profiling</span><span class="p">,</span>
            <span class="n">workflow_version_id</span><span class="o">=</span><span class="n">workflow_version_id</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">response_data</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>
        <span class="n">workflow_outputs</span> <span class="o">=</span> <span class="n">response_data</span><span class="p">[</span><span class="s2">&quot;outputs&quot;</span><span class="p">]</span>
        <span class="n">profiler_trace</span> <span class="o">=</span> <span class="n">response_data</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;profiler_trace&quot;</span><span class="p">,</span> <span class="p">[])</span>
        <span class="k">if</span> <span class="n">enable_profiling</span><span class="p">:</span>
            <span class="n">save_workflows_profiler_trace</span><span class="p">(</span>
                <span class="n">directory</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">__inference_configuration</span><span class="o">.</span><span class="n">profiling_directory</span><span class="p">,</span>
                <span class="n">profiler_trace</span><span class="o">=</span><span class="n">profiler_trace</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">decode_workflow_outputs</span><span class="p">(</span>
            <span class="n">workflow_outputs</span><span class="o">=</span><span class="n">workflow_outputs</span><span class="p">,</span>
            <span class="n">expected_format</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">__inference_configuration</span><span class="o">.</span><span class="n">output_visualisation_format</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_execute_workflow_request</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">workspace_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">workflow_id</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">specification</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">images</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">parameters</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">excluded_fields</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">legacy_endpoints</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">use_cache</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">enable_profiling</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">workflow_version_id</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Response</span><span class="p">:</span>
        <span class="n">named_workflow_specified</span> <span class="o">=</span> <span class="p">(</span><span class="n">workspace_name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span>
            <span class="n">workflow_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">named_workflow_specified</span> <span class="o">!=</span> <span class="p">(</span><span class="n">specification</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)):</span>
            <span class="k">raise</span> <span class="n">InvalidParameterError</span><span class="p">(</span>
                <span class="s2">&quot;Parameters (`workspace_name`, `workflow_id` / `workflow_name`) can be used mutually exclusive with &quot;</span>
                <span class="s2">&quot;`specification`, but at least one must be set.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">images</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">images</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">if</span> <span class="n">parameters</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">parameters</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">payload</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;api_key&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">__api_key</span><span class="p">,</span>
            <span class="s2">&quot;use_cache&quot;</span><span class="p">:</span> <span class="n">use_cache</span><span class="p">,</span>
            <span class="s2">&quot;enable_profiling&quot;</span><span class="p">:</span> <span class="n">enable_profiling</span><span class="p">,</span>
        <span class="p">}</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">image_name</span><span class="p">,</span> <span class="n">image</span> <span class="ow">in</span> <span class="n">images</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">loaded_image</span> <span class="o">=</span> <span class="n">load_nested_batches_of_inference_input</span><span class="p">(</span>
                <span class="n">inference_input</span><span class="o">=</span><span class="n">image</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">inject_nested_batches_of_images_into_payload</span><span class="p">(</span>
                <span class="n">payload</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span>
                <span class="n">encoded_images</span><span class="o">=</span><span class="n">loaded_image</span><span class="p">,</span>
                <span class="n">key</span><span class="o">=</span><span class="n">image_name</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="n">inputs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">parameters</span><span class="p">)</span>
        <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;inputs&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">inputs</span>
        <span class="k">if</span> <span class="n">excluded_fields</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;excluded_fields&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">excluded_fields</span>
        <span class="k">if</span> <span class="n">specification</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;specification&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">specification</span>
        <span class="k">if</span> <span class="n">specification</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">legacy_endpoints</span><span class="p">:</span>
                <span class="n">url</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__api_url</span><span class="si">}</span><span class="s2">/infer/workflows&quot;</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">url</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__api_url</span><span class="si">}</span><span class="s2">/workflows/run&quot;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">workflow_version_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;workflow_version_id&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">workflow_version_id</span>
            <span class="k">if</span> <span class="n">legacy_endpoints</span><span class="p">:</span>
                <span class="n">url</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__api_url</span><span class="si">}</span><span class="s2">/infer/workflows/</span><span class="si">{</span><span class="n">workspace_name</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">workflow_id</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">url</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__api_url</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">workspace_name</span><span class="si">}</span><span class="s2">/workflows/</span><span class="si">{</span><span class="n">workflow_id</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="n">response</span> <span class="o">=</span> <span class="n">send_post_request</span><span class="p">(</span>
            <span class="n">url</span><span class="o">=</span><span class="n">url</span><span class="p">,</span>
            <span class="n">payload</span><span class="o">=</span><span class="n">payload</span><span class="p">,</span>
            <span class="n">headers</span><span class="o">=</span><span class="n">DEFAULT_HEADERS</span><span class="p">,</span>
            <span class="n">enable_retries</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">__inference_configuration</span><span class="o">.</span><span class="n">workflow_run_retries_enabled</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">response</span>

    <span class="nd">@wrap_errors</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">infer_from_yolo_world</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">inference_input</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">]],</span>
        <span class="n">class_names</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">model_version</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">confidence</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Run inference using YOLO-World model.</span>

<span class="sd">        Args:</span>
<span class="sd">            inference_input: Input image(s) to run inference on. Can be a single image</span>
<span class="sd">                reference or a list of image references.</span>
<span class="sd">            class_names: List of class names to detect in the image(s).</span>
<span class="sd">            model_version: Optional version of YOLO-World model to use. If not specified,</span>
<span class="sd">                uses the default version.</span>
<span class="sd">            confidence: Optional confidence threshold for detections. If not specified,</span>
<span class="sd">                uses the model&#39;s default threshold.</span>

<span class="sd">        Returns:</span>
<span class="sd">            List of dictionaries containing detection results for each input image.</span>
<span class="sd">            Each dictionary contains bounding boxes, class labels, and confidence scores</span>
<span class="sd">            for detected objects.</span>

<span class="sd">        Raises:</span>
<span class="sd">            HTTPCallErrorError: If there is an error in the HTTP call.</span>
<span class="sd">            HTTPClientError: If there is an error with the server connection.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">encoded_inference_inputs</span> <span class="o">=</span> <span class="n">load_static_inference_input</span><span class="p">(</span>
            <span class="n">inference_input</span><span class="o">=</span><span class="n">inference_input</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">payload</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__initialise_payload</span><span class="p">()</span>
        <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">class_names</span>
        <span class="k">if</span> <span class="n">model_version</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;yolo_world_version_id&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">model_version</span>
        <span class="k">if</span> <span class="n">confidence</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;confidence&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">confidence</span>
        <span class="n">url</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__wrap_url_with_api_key</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__api_url</span><span class="si">}</span><span class="s2">/yolo_world/infer&quot;</span><span class="p">)</span>
        <span class="n">requests_data</span> <span class="o">=</span> <span class="n">prepare_requests_data</span><span class="p">(</span>
            <span class="n">url</span><span class="o">=</span><span class="n">url</span><span class="p">,</span>
            <span class="n">encoded_inference_inputs</span><span class="o">=</span><span class="n">encoded_inference_inputs</span><span class="p">,</span>
            <span class="n">headers</span><span class="o">=</span><span class="n">DEFAULT_HEADERS</span><span class="p">,</span>
            <span class="n">parameters</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">payload</span><span class="o">=</span><span class="n">payload</span><span class="p">,</span>
            <span class="n">max_batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">image_placement</span><span class="o">=</span><span class="n">ImagePlacement</span><span class="o">.</span><span class="n">JSON</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">responses</span> <span class="o">=</span> <span class="n">execute_requests_packages</span><span class="p">(</span>
            <span class="n">requests_data</span><span class="o">=</span><span class="n">requests_data</span><span class="p">,</span>
            <span class="n">request_method</span><span class="o">=</span><span class="n">RequestMethod</span><span class="o">.</span><span class="n">POST</span><span class="p">,</span>
            <span class="n">max_concurrent_requests</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">__inference_configuration</span><span class="o">.</span><span class="n">max_concurrent_requests</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">r</span><span class="o">.</span><span class="n">json</span><span class="p">()</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">responses</span><span class="p">]</span>

    <span class="nd">@wrap_errors_async</span>
    <span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">infer_from_yolo_world_async</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">inference_input</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">]],</span>
        <span class="n">class_names</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">model_version</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">confidence</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Run inference using YOLO-World model asynchronously.</span>

<span class="sd">        Args:</span>
<span class="sd">            inference_input: Input image(s) to run inference on. Can be a single image</span>
<span class="sd">                reference or a list of image references.</span>
<span class="sd">            class_names: List of class names to detect in the image(s).</span>
<span class="sd">            model_version: Optional version of YOLO-World model to use. If not specified,</span>
<span class="sd">                uses the default version.</span>
<span class="sd">            confidence: Optional confidence threshold for detections. If not specified,</span>
<span class="sd">                uses the model&#39;s default threshold.</span>

<span class="sd">        Returns:</span>
<span class="sd">            List of dictionaries containing detection results for each input image.</span>
<span class="sd">            Each dictionary contains bounding boxes, class labels, and confidence scores</span>
<span class="sd">            for detected objects.</span>

<span class="sd">        Raises:</span>
<span class="sd">            HTTPCallErrorError: If there is an error in the HTTP call.</span>
<span class="sd">            HTTPClientError: If there is an error with the server connection.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">encoded_inference_inputs</span> <span class="o">=</span> <span class="k">await</span> <span class="n">load_static_inference_input_async</span><span class="p">(</span>
            <span class="n">inference_input</span><span class="o">=</span><span class="n">inference_input</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">payload</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__initialise_payload</span><span class="p">()</span>
        <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">class_names</span>
        <span class="k">if</span> <span class="n">model_version</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;yolo_world_version_id&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">model_version</span>
        <span class="k">if</span> <span class="n">confidence</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;confidence&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">confidence</span>
        <span class="n">url</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__wrap_url_with_api_key</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__api_url</span><span class="si">}</span><span class="s2">/yolo_world/infer&quot;</span><span class="p">)</span>
        <span class="n">requests_data</span> <span class="o">=</span> <span class="n">prepare_requests_data</span><span class="p">(</span>
            <span class="n">url</span><span class="o">=</span><span class="n">url</span><span class="p">,</span>
            <span class="n">encoded_inference_inputs</span><span class="o">=</span><span class="n">encoded_inference_inputs</span><span class="p">,</span>
            <span class="n">headers</span><span class="o">=</span><span class="n">DEFAULT_HEADERS</span><span class="p">,</span>
            <span class="n">parameters</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">payload</span><span class="o">=</span><span class="n">payload</span><span class="p">,</span>
            <span class="n">max_batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">image_placement</span><span class="o">=</span><span class="n">ImagePlacement</span><span class="o">.</span><span class="n">JSON</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="k">await</span> <span class="n">execute_requests_packages_async</span><span class="p">(</span>
            <span class="n">requests_data</span><span class="o">=</span><span class="n">requests_data</span><span class="p">,</span>
            <span class="n">request_method</span><span class="o">=</span><span class="n">RequestMethod</span><span class="o">.</span><span class="n">POST</span><span class="p">,</span>
            <span class="n">max_concurrent_requests</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">__inference_configuration</span><span class="o">.</span><span class="n">max_concurrent_requests</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="nd">@experimental</span><span class="p">(</span>
        <span class="n">info</span><span class="o">=</span><span class="s2">&quot;Video processing in inference server is under development. Breaking changes are possible.&quot;</span>
    <span class="p">)</span>
    <span class="nd">@wrap_errors</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">start_inference_pipeline_with_workflow</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">video_reference</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]],</span>
        <span class="n">workflow_specification</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">workspace_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">workflow_id</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">image_input_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;image&quot;</span><span class="p">,</span>
        <span class="n">workflows_parameters</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">workflows_thread_pool_workers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
        <span class="n">cancel_thread_pool_tasks_on_exit</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">video_metadata_input_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;video_metadata&quot;</span><span class="p">,</span>
        <span class="n">max_fps</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">source_buffer_filling_strategy</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">BufferFillingStrategy</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;DROP_OLDEST&quot;</span><span class="p">,</span>
        <span class="n">source_buffer_consumption_strategy</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span>
            <span class="n">BufferConsumptionStrategy</span>
        <span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;EAGER&quot;</span><span class="p">,</span>
        <span class="n">video_source_properties</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">batch_collection_timeout</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">results_buffer_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">64</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Starts an inference pipeline using a workflow specification.</span>

<span class="sd">        Args:</span>
<span class="sd">            video_reference: Path to video file, camera index, or list of video sources.</span>
<span class="sd">                Can be a string path, integer camera index, or list of either.</span>
<span class="sd">            workflow_specification: Optional workflow specification dictionary. Mutually</span>
<span class="sd">                exclusive with workspace_name/workflow_id.</span>
<span class="sd">            workspace_name: Optional name of workspace containing workflow. Must be used</span>
<span class="sd">                with workflow_id.</span>
<span class="sd">            workflow_id: Optional ID of workflow to use. Must be used with workspace_name.</span>
<span class="sd">            image_input_name: Name of the image input node in workflow. Defaults to &quot;image&quot;.</span>
<span class="sd">            workflows_parameters: Optional parameters to pass to workflow.</span>
<span class="sd">            workflows_thread_pool_workers: Number of worker threads for workflow execution.</span>
<span class="sd">                Defaults to 4.</span>
<span class="sd">            cancel_thread_pool_tasks_on_exit: Whether to cancel pending tasks when exiting.</span>
<span class="sd">                Defaults to True.</span>
<span class="sd">            video_metadata_input_name: Name of video metadata input in workflow.</span>
<span class="sd">                Defaults to &quot;video_metadata&quot;.</span>
<span class="sd">            max_fps: Optional maximum FPS to process video at.</span>
<span class="sd">            source_buffer_filling_strategy: Strategy for filling source buffer when full.</span>
<span class="sd">                One of: &quot;WAIT&quot;, &quot;DROP_OLDEST&quot;, &quot;ADAPTIVE_DROP_OLDEST&quot;, &quot;DROP_LATEST&quot;,</span>
<span class="sd">                &quot;ADAPTIVE_DROP_LATEST&quot;. Defaults to &quot;DROP_OLDEST&quot;.</span>
<span class="sd">            source_buffer_consumption_strategy: Strategy for consuming from source buffer.</span>
<span class="sd">                One of: &quot;LAZY&quot;, &quot;EAGER&quot;. Defaults to &quot;EAGER&quot;.</span>
<span class="sd">            video_source_properties: Optional dictionary of video source properties.</span>
<span class="sd">            batch_collection_timeout: Optional timeout for batch collection in seconds.</span>
<span class="sd">            results_buffer_size: Size of results buffer. Defaults to 64.</span>

<span class="sd">        Returns:</span>
<span class="sd">            dict: Response containing pipeline initialization details.</span>

<span class="sd">        Raises:</span>
<span class="sd">            InvalidParameterError: If workflow specification parameters are invalid.</span>
<span class="sd">            HTTPCallErrorError: If there is an error in the HTTP call.</span>
<span class="sd">            HTTPClientError: If there is an error with the server connection.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">named_workflow_specified</span> <span class="o">=</span> <span class="p">(</span><span class="n">workspace_name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span>
            <span class="n">workflow_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">named_workflow_specified</span> <span class="o">!=</span> <span class="p">(</span><span class="n">workflow_specification</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)):</span>
            <span class="k">raise</span> <span class="n">InvalidParameterError</span><span class="p">(</span>
                <span class="s2">&quot;Parameters (`workspace_name`, `workflow_id`) can be used mutually exclusive with &quot;</span>
                <span class="s2">&quot;`workflow_specification`, but at least one must be set.&quot;</span>
            <span class="p">)</span>
        <span class="n">payload</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;api_key&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">__api_key</span><span class="p">,</span>
            <span class="s2">&quot;video_configuration&quot;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;VideoConfiguration&quot;</span><span class="p">,</span>
                <span class="s2">&quot;video_reference&quot;</span><span class="p">:</span> <span class="n">video_reference</span><span class="p">,</span>
                <span class="s2">&quot;max_fps&quot;</span><span class="p">:</span> <span class="n">max_fps</span><span class="p">,</span>
                <span class="s2">&quot;source_buffer_filling_strategy&quot;</span><span class="p">:</span> <span class="n">source_buffer_filling_strategy</span><span class="p">,</span>
                <span class="s2">&quot;source_buffer_consumption_strategy&quot;</span><span class="p">:</span> <span class="n">source_buffer_consumption_strategy</span><span class="p">,</span>
                <span class="s2">&quot;video_source_properties&quot;</span><span class="p">:</span> <span class="n">video_source_properties</span><span class="p">,</span>
                <span class="s2">&quot;batch_collection_timeout&quot;</span><span class="p">:</span> <span class="n">batch_collection_timeout</span><span class="p">,</span>
            <span class="p">},</span>
            <span class="s2">&quot;processing_configuration&quot;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;WorkflowConfiguration&quot;</span><span class="p">,</span>
                <span class="s2">&quot;workflow_specification&quot;</span><span class="p">:</span> <span class="n">workflow_specification</span><span class="p">,</span>
                <span class="s2">&quot;workspace_name&quot;</span><span class="p">:</span> <span class="n">workspace_name</span><span class="p">,</span>
                <span class="s2">&quot;workflow_id&quot;</span><span class="p">:</span> <span class="n">workflow_id</span><span class="p">,</span>
                <span class="s2">&quot;image_input_name&quot;</span><span class="p">:</span> <span class="n">image_input_name</span><span class="p">,</span>
                <span class="s2">&quot;workflows_parameters&quot;</span><span class="p">:</span> <span class="n">workflows_parameters</span><span class="p">,</span>
                <span class="s2">&quot;workflows_thread_pool_workers&quot;</span><span class="p">:</span> <span class="n">workflows_thread_pool_workers</span><span class="p">,</span>
                <span class="s2">&quot;cancel_thread_pool_tasks_on_exit&quot;</span><span class="p">:</span> <span class="n">cancel_thread_pool_tasks_on_exit</span><span class="p">,</span>
                <span class="s2">&quot;video_metadata_input_name&quot;</span><span class="p">:</span> <span class="n">video_metadata_input_name</span><span class="p">,</span>
            <span class="p">},</span>
            <span class="s2">&quot;sink_configuration&quot;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;MemorySinkConfiguration&quot;</span><span class="p">,</span>
                <span class="s2">&quot;results_buffer_size&quot;</span><span class="p">:</span> <span class="n">results_buffer_size</span><span class="p">,</span>
            <span class="p">},</span>
        <span class="p">}</span>
        <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">post</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__api_url</span><span class="si">}</span><span class="s2">/inference_pipelines/initialise&quot;</span><span class="p">,</span>
            <span class="n">json</span><span class="o">=</span><span class="n">payload</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">response</span><span class="o">.</span><span class="n">raise_for_status</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>

    <span class="nd">@experimental</span><span class="p">(</span>
        <span class="n">info</span><span class="o">=</span><span class="s2">&quot;Video processing in inference server is under development. Breaking changes are possible.&quot;</span>
    <span class="p">)</span>
    <span class="nd">@wrap_errors</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">list_inference_pipelines</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Lists all active inference pipelines on the server.</span>

<span class="sd">        This method retrieves information about all currently running inference pipelines</span>
<span class="sd">        on the server, including their IDs and status.</span>

<span class="sd">        Returns:</span>
<span class="sd">            List[dict]: A list of dictionaries containing information about each active</span>
<span class="sd">                inference pipeline.</span>

<span class="sd">        Raises:</span>
<span class="sd">            HTTPCallErrorError: If there is an error in the HTTP call.</span>
<span class="sd">            HTTPClientError: If there is an error with the server connection.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">payload</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;api_key&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">__api_key</span><span class="p">}</span>
        <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__api_url</span><span class="si">}</span><span class="s2">/inference_pipelines/list&quot;</span><span class="p">,</span>
            <span class="n">json</span><span class="o">=</span><span class="n">payload</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">api_key_safe_raise_for_status</span><span class="p">(</span><span class="n">response</span><span class="o">=</span><span class="n">response</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>

    <span class="nd">@experimental</span><span class="p">(</span>
        <span class="n">info</span><span class="o">=</span><span class="s2">&quot;Video processing in inference server is under development. Breaking changes are possible.&quot;</span>
    <span class="p">)</span>
    <span class="nd">@wrap_errors</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">get_inference_pipeline_status</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pipeline_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Gets the current status of a specific inference pipeline.</span>

<span class="sd">        Args:</span>
<span class="sd">            pipeline_id: The unique identifier of the inference pipeline to check.</span>

<span class="sd">        Returns:</span>
<span class="sd">            dict: A dictionary containing the current status and details of the pipeline.</span>

<span class="sd">        Raises:</span>
<span class="sd">            HTTPCallErrorError: If there is an error in the HTTP call.</span>
<span class="sd">            HTTPClientError: If there is an error with the server connection.</span>
<span class="sd">            ValueError: If pipeline_id is empty or None.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_ensure_pipeline_id_not_empty</span><span class="p">(</span><span class="n">pipeline_id</span><span class="o">=</span><span class="n">pipeline_id</span><span class="p">)</span>
        <span class="n">payload</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;api_key&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">__api_key</span><span class="p">}</span>
        <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__api_url</span><span class="si">}</span><span class="s2">/inference_pipelines/</span><span class="si">{</span><span class="n">pipeline_id</span><span class="si">}</span><span class="s2">/status&quot;</span><span class="p">,</span>
            <span class="n">json</span><span class="o">=</span><span class="n">payload</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">api_key_safe_raise_for_status</span><span class="p">(</span><span class="n">response</span><span class="o">=</span><span class="n">response</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>

    <span class="nd">@experimental</span><span class="p">(</span>
        <span class="n">info</span><span class="o">=</span><span class="s2">&quot;Video processing in inference server is under development. Breaking changes are possible.&quot;</span>
    <span class="p">)</span>
    <span class="nd">@wrap_errors</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">pause_inference_pipeline</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pipeline_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Pauses a running inference pipeline.</span>

<span class="sd">        Sends a request to pause the specified inference pipeline. The pipeline must be</span>
<span class="sd">        currently running for this operation to succeed.</span>

<span class="sd">        Args:</span>
<span class="sd">            pipeline_id: The unique identifier of the inference pipeline to pause.</span>

<span class="sd">        Returns:</span>
<span class="sd">            dict: A dictionary containing the response from the server about the pause operation.</span>

<span class="sd">        Raises:</span>
<span class="sd">            HTTPCallErrorError: If there is an error in the HTTP call.</span>
<span class="sd">            HTTPClientError: If there is an error with the server connection.</span>
<span class="sd">            ValueError: If pipeline_id is empty or None.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_ensure_pipeline_id_not_empty</span><span class="p">(</span><span class="n">pipeline_id</span><span class="o">=</span><span class="n">pipeline_id</span><span class="p">)</span>
        <span class="n">payload</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;api_key&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">__api_key</span><span class="p">}</span>
        <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">post</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__api_url</span><span class="si">}</span><span class="s2">/inference_pipelines/</span><span class="si">{</span><span class="n">pipeline_id</span><span class="si">}</span><span class="s2">/pause&quot;</span><span class="p">,</span>
            <span class="n">json</span><span class="o">=</span><span class="n">payload</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">api_key_safe_raise_for_status</span><span class="p">(</span><span class="n">response</span><span class="o">=</span><span class="n">response</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>

    <span class="nd">@experimental</span><span class="p">(</span>
        <span class="n">info</span><span class="o">=</span><span class="s2">&quot;Video processing in inference server is under development. Breaking changes are possible.&quot;</span>
    <span class="p">)</span>
    <span class="nd">@wrap_errors</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">resume_inference_pipeline</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pipeline_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Resumes a paused inference pipeline.</span>

<span class="sd">        Sends a request to resume the specified inference pipeline. The pipeline must be</span>
<span class="sd">        currently paused for this operation to succeed.</span>

<span class="sd">        Args:</span>
<span class="sd">            pipeline_id: The unique identifier of the inference pipeline to resume.</span>

<span class="sd">        Returns:</span>
<span class="sd">            dict: A dictionary containing the response from the server about the resume operation.</span>

<span class="sd">        Raises:</span>
<span class="sd">            HTTPCallErrorError: If there is an error in the HTTP call.</span>
<span class="sd">            HTTPClientError: If there is an error with the server connection.</span>
<span class="sd">            ValueError: If pipeline_id is empty or None.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_ensure_pipeline_id_not_empty</span><span class="p">(</span><span class="n">pipeline_id</span><span class="o">=</span><span class="n">pipeline_id</span><span class="p">)</span>
        <span class="n">payload</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;api_key&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">__api_key</span><span class="p">}</span>
        <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">post</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__api_url</span><span class="si">}</span><span class="s2">/inference_pipelines/</span><span class="si">{</span><span class="n">pipeline_id</span><span class="si">}</span><span class="s2">/resume&quot;</span><span class="p">,</span>
            <span class="n">json</span><span class="o">=</span><span class="n">payload</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">api_key_safe_raise_for_status</span><span class="p">(</span><span class="n">response</span><span class="o">=</span><span class="n">response</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>

    <span class="nd">@experimental</span><span class="p">(</span>
        <span class="n">info</span><span class="o">=</span><span class="s2">&quot;Video processing in inference server is under development. Breaking changes are possible.&quot;</span>
    <span class="p">)</span>
    <span class="nd">@wrap_errors</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">terminate_inference_pipeline</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pipeline_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Terminates a running inference pipeline.</span>

<span class="sd">        Sends a request to terminate the specified inference pipeline. This will stop all</span>
<span class="sd">        processing and free up associated resources.</span>

<span class="sd">        Args:</span>
<span class="sd">            pipeline_id: The unique identifier of the inference pipeline to terminate.</span>

<span class="sd">        Returns:</span>
<span class="sd">            dict: A dictionary containing the response from the server about the termination operation.</span>

<span class="sd">        Raises:</span>
<span class="sd">            HTTPCallErrorError: If there is an error in the HTTP call.</span>
<span class="sd">            HTTPClientError: If there is an error with the server connection.</span>
<span class="sd">            ValueError: If pipeline_id is empty or None.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_ensure_pipeline_id_not_empty</span><span class="p">(</span><span class="n">pipeline_id</span><span class="o">=</span><span class="n">pipeline_id</span><span class="p">)</span>
        <span class="n">payload</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;api_key&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">__api_key</span><span class="p">}</span>
        <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">post</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__api_url</span><span class="si">}</span><span class="s2">/inference_pipelines/</span><span class="si">{</span><span class="n">pipeline_id</span><span class="si">}</span><span class="s2">/terminate&quot;</span><span class="p">,</span>
            <span class="n">json</span><span class="o">=</span><span class="n">payload</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">api_key_safe_raise_for_status</span><span class="p">(</span><span class="n">response</span><span class="o">=</span><span class="n">response</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>

    <span class="nd">@experimental</span><span class="p">(</span>
        <span class="n">info</span><span class="o">=</span><span class="s2">&quot;Video processing in inference server is under development. Breaking changes are possible.&quot;</span>
    <span class="p">)</span>
    <span class="nd">@wrap_errors</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">consume_inference_pipeline_result</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">pipeline_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">excluded_fields</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Consumes and returns the next available result from an inference pipeline.</span>

<span class="sd">        Args:</span>
<span class="sd">            pipeline_id: The unique identifier of the inference pipeline to consume results from.</span>
<span class="sd">            excluded_fields: Optional list of field names to exclude from the result. If None,</span>
<span class="sd">                no fields will be excluded.</span>

<span class="sd">        Returns:</span>
<span class="sd">            dict: A dictionary containing the next available result from the pipeline.</span>

<span class="sd">        Raises:</span>
<span class="sd">            HTTPCallErrorError: If there is an error in the HTTP call.</span>
<span class="sd">            HTTPClientError: If there is an error with the server connection.</span>
<span class="sd">            InvalidParameterError: If pipeline_id is empty or None.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_ensure_pipeline_id_not_empty</span><span class="p">(</span><span class="n">pipeline_id</span><span class="o">=</span><span class="n">pipeline_id</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">excluded_fields</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">excluded_fields</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">payload</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;api_key&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">__api_key</span><span class="p">,</span> <span class="s2">&quot;excluded_fields&quot;</span><span class="p">:</span> <span class="n">excluded_fields</span><span class="p">}</span>
        <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__api_url</span><span class="si">}</span><span class="s2">/inference_pipelines/</span><span class="si">{</span><span class="n">pipeline_id</span><span class="si">}</span><span class="s2">/consume&quot;</span><span class="p">,</span>
            <span class="n">json</span><span class="o">=</span><span class="n">payload</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">api_key_safe_raise_for_status</span><span class="p">(</span><span class="n">response</span><span class="o">=</span><span class="n">response</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_ensure_pipeline_id_not_empty</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pipeline_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">pipeline_id</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">InvalidParameterError</span><span class="p">(</span><span class="s2">&quot;Empty `pipeline_id` parameter detected&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_post_images</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">inference_input</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">]],</span>
        <span class="n">endpoint</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">model_id</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">extra_payload</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]]:</span>
        <span class="n">encoded_inference_inputs</span> <span class="o">=</span> <span class="n">load_static_inference_input</span><span class="p">(</span>
            <span class="n">inference_input</span><span class="o">=</span><span class="n">inference_input</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">payload</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__initialise_payload</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">model_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;model_id&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">model_id</span>
        <span class="n">url</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__wrap_url_with_api_key</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__api_url</span><span class="si">}{</span><span class="n">endpoint</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">extra_payload</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">payload</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">extra_payload</span><span class="p">)</span>
        <span class="n">requests_data</span> <span class="o">=</span> <span class="n">prepare_requests_data</span><span class="p">(</span>
            <span class="n">url</span><span class="o">=</span><span class="n">url</span><span class="p">,</span>
            <span class="n">encoded_inference_inputs</span><span class="o">=</span><span class="n">encoded_inference_inputs</span><span class="p">,</span>
            <span class="n">headers</span><span class="o">=</span><span class="n">DEFAULT_HEADERS</span><span class="p">,</span>
            <span class="n">parameters</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">payload</span><span class="o">=</span><span class="n">payload</span><span class="p">,</span>
            <span class="n">max_batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">__inference_configuration</span><span class="o">.</span><span class="n">max_batch_size</span><span class="p">,</span>
            <span class="n">image_placement</span><span class="o">=</span><span class="n">ImagePlacement</span><span class="o">.</span><span class="n">JSON</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">responses</span> <span class="o">=</span> <span class="n">execute_requests_packages</span><span class="p">(</span>
            <span class="n">requests_data</span><span class="o">=</span><span class="n">requests_data</span><span class="p">,</span>
            <span class="n">request_method</span><span class="o">=</span><span class="n">RequestMethod</span><span class="o">.</span><span class="n">POST</span><span class="p">,</span>
            <span class="n">max_concurrent_requests</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">__inference_configuration</span><span class="o">.</span><span class="n">max_concurrent_requests</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">results</span> <span class="o">=</span> <span class="p">[</span><span class="n">r</span><span class="o">.</span><span class="n">json</span><span class="p">()</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">responses</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">unwrap_single_element_list</span><span class="p">(</span><span class="n">sequence</span><span class="o">=</span><span class="n">results</span><span class="p">)</span>

    <span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">_post_images_async</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">inference_input</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">]],</span>
        <span class="n">endpoint</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">model_id</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">extra_payload</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]]:</span>
        <span class="n">encoded_inference_inputs</span> <span class="o">=</span> <span class="k">await</span> <span class="n">load_static_inference_input_async</span><span class="p">(</span>
            <span class="n">inference_input</span><span class="o">=</span><span class="n">inference_input</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">payload</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__initialise_payload</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">model_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;model_id&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">model_id</span>
        <span class="n">url</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__wrap_url_with_api_key</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__api_url</span><span class="si">}{</span><span class="n">endpoint</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">extra_payload</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">payload</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">extra_payload</span><span class="p">)</span>
        <span class="n">requests_data</span> <span class="o">=</span> <span class="n">prepare_requests_data</span><span class="p">(</span>
            <span class="n">url</span><span class="o">=</span><span class="n">url</span><span class="p">,</span>
            <span class="n">encoded_inference_inputs</span><span class="o">=</span><span class="n">encoded_inference_inputs</span><span class="p">,</span>
            <span class="n">headers</span><span class="o">=</span><span class="n">DEFAULT_HEADERS</span><span class="p">,</span>
            <span class="n">parameters</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">payload</span><span class="o">=</span><span class="n">payload</span><span class="p">,</span>
            <span class="n">max_batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">__inference_configuration</span><span class="o">.</span><span class="n">max_batch_size</span><span class="p">,</span>
            <span class="n">image_placement</span><span class="o">=</span><span class="n">ImagePlacement</span><span class="o">.</span><span class="n">JSON</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">responses</span> <span class="o">=</span> <span class="k">await</span> <span class="n">execute_requests_packages_async</span><span class="p">(</span>
            <span class="n">requests_data</span><span class="o">=</span><span class="n">requests_data</span><span class="p">,</span>
            <span class="n">request_method</span><span class="o">=</span><span class="n">RequestMethod</span><span class="o">.</span><span class="n">POST</span><span class="p">,</span>
            <span class="n">max_concurrent_requests</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">__inference_configuration</span><span class="o">.</span><span class="n">max_concurrent_requests</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">unwrap_single_element_list</span><span class="p">(</span><span class="n">sequence</span><span class="o">=</span><span class="n">responses</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">__initialise_payload</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">__client_mode</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">HTTPClientMode</span><span class="o">.</span><span class="n">V0</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;api_key&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">__api_key</span><span class="p">}</span>
        <span class="k">return</span> <span class="p">{}</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">__wrap_url_with_api_key</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">url</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">__client_mode</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">HTTPClientMode</span><span class="o">.</span><span class="n">V0</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">url</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">url</span><span class="si">}</span><span class="s2">?api_key=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__api_key</span><span class="si">}</span><span class="s2">&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">__ensure_v1_client_mode</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">__client_mode</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">HTTPClientMode</span><span class="o">.</span><span class="n">V1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">WrongClientModeError</span><span class="p">(</span><span class="s2">&quot;Use client mode `v1` to run this operation.&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



<div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h3 id="inference_sdk.http.client.InferenceHTTPClient.client_mode" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">client_mode</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#inference_sdk.http.client.InferenceHTTPClient.client_mode" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Get the current client mode.</p>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>HTTPClientMode</code></td>            <td>
                  <code><a class="autorefs autorefs-internal" href="../entities/#inference_sdk.http.entities.HTTPClientMode">HTTPClientMode</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The current API version mode (V0 or V1).</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="inference_sdk.http.client.InferenceHTTPClient.inference_configuration" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">inference_configuration</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#inference_sdk.http.client.InferenceHTTPClient.inference_configuration" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Get the current inference configuration.</p>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>InferenceConfiguration</code></td>            <td>
                  <code><a class="autorefs autorefs-internal" href="../entities/#inference_sdk.http.entities.InferenceConfiguration">InferenceConfiguration</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The current inference configuration settings.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="inference_sdk.http.client.InferenceHTTPClient.selected_model" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">selected_model</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#inference_sdk.http.client.InferenceHTTPClient.selected_model" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Get the currently selected model identifier.</p>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="str">str</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Optional[str]: The identifier of the currently selected model, if any.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="inference_sdk.http.client.InferenceHTTPClient.webrtc" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">webrtc</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#inference_sdk.http.client.InferenceHTTPClient.webrtc" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Lazy accessor for the WebRTC client namespace.</p>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>WebRTCClient</code></td>            <td>
                  <code><a class="autorefs autorefs-internal" href="../../webrtc/client/#inference_sdk.webrtc.client.WebRTCClient">WebRTCClient</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Namespaced WebRTC API bound to this HTTP client.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

    </div>

</div>




<div class="doc doc-object doc-function">


<h3 id="inference_sdk.http.client.InferenceHTTPClient.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">api_url</span><span class="p">,</span> <span class="n">api_key</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#inference_sdk.http.client.InferenceHTTPClient.__init__" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Initialize a new InferenceHTTPClient instance.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>api_url</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The base URL for the inference API.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>api_key</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="str">str</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>API key for authentication. Defaults to None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>inference_sdk/http/client.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">api_url</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">api_key</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Initialize a new InferenceHTTPClient instance.</span>

<span class="sd">    Args:</span>
<span class="sd">        api_url (str): The base URL for the inference API.</span>
<span class="sd">        api_key (Optional[str], optional): API key for authentication. Defaults to None.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">__api_url</span> <span class="o">=</span> <span class="n">api_url</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">__api_key</span> <span class="o">=</span> <span class="n">api_key</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">__inference_configuration</span> <span class="o">=</span> <span class="n">InferenceConfiguration</span><span class="o">.</span><span class="n">init_default</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">__client_mode</span> <span class="o">=</span> <span class="n">_determine_client_mode</span><span class="p">(</span><span class="n">api_url</span><span class="o">=</span><span class="n">api_url</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">__selected_model</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">__webrtc_client</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;WebRTCClient&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="inference_sdk.http.client.InferenceHTTPClient.clip_compare" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">clip_compare</span><span class="p">(</span><span class="n">subject</span><span class="p">,</span> <span class="n">prompt</span><span class="p">,</span> <span class="n">subject_type</span><span class="o">=</span><span class="s1">&#39;image&#39;</span><span class="p">,</span> <span class="n">prompt_type</span><span class="o">=</span><span class="s1">&#39;text&#39;</span><span class="p">,</span> <span class="n">clip_version</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#inference_sdk.http.client.InferenceHTTPClient.clip_compare" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Compare a subject against prompts using CLIP embeddings.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>subject</code>
            </td>
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="str">str</span>, <span title="inference_sdk.http.entities.ImagesReference">ImagesReference</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The subject to compare (image or text).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>prompt</code>
            </td>
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="str">str</span>, <span title="typing.List">List</span>[<span title="str">str</span>], <span title="inference_sdk.http.entities.ImagesReference">ImagesReference</span>, <span title="typing.List">List</span>[<span title="inference_sdk.http.entities.ImagesReference">ImagesReference</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The prompt(s) to compare against.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>subject_type</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Type of subject ('image' or 'text'). Defaults to "image".</p>
              </div>
            </td>
            <td>
                  <code>&#39;image&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>prompt_type</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Type of prompt(s) ('image' or 'text'). Defaults to "text".</p>
              </div>
            </td>
            <td>
                  <code>&#39;text&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>clip_version</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="str">str</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Version of CLIP model to use. Defaults to None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="dict">dict</span>, <span title="typing.List">List</span>[<span title="dict">dict</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Union[dict, List[dict]]: Comparison results between subject and prompt(s).</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.InvalidParameterError">InvalidParameterError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If subject_type or prompt_type is invalid.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.HTTPCallErrorError">HTTPCallErrorError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If there is an error in the HTTP call.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.HTTPClientError">HTTPClientError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If there is an error with the server connection.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>inference_sdk/http/client.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1413</span>
<span class="normal">1414</span>
<span class="normal">1415</span>
<span class="normal">1416</span>
<span class="normal">1417</span>
<span class="normal">1418</span>
<span class="normal">1419</span>
<span class="normal">1420</span>
<span class="normal">1421</span>
<span class="normal">1422</span>
<span class="normal">1423</span>
<span class="normal">1424</span>
<span class="normal">1425</span>
<span class="normal">1426</span>
<span class="normal">1427</span>
<span class="normal">1428</span>
<span class="normal">1429</span>
<span class="normal">1430</span>
<span class="normal">1431</span>
<span class="normal">1432</span>
<span class="normal">1433</span>
<span class="normal">1434</span>
<span class="normal">1435</span>
<span class="normal">1436</span>
<span class="normal">1437</span>
<span class="normal">1438</span>
<span class="normal">1439</span>
<span class="normal">1440</span>
<span class="normal">1441</span>
<span class="normal">1442</span>
<span class="normal">1443</span>
<span class="normal">1444</span>
<span class="normal">1445</span>
<span class="normal">1446</span>
<span class="normal">1447</span>
<span class="normal">1448</span>
<span class="normal">1449</span>
<span class="normal">1450</span>
<span class="normal">1451</span>
<span class="normal">1452</span>
<span class="normal">1453</span>
<span class="normal">1454</span>
<span class="normal">1455</span>
<span class="normal">1456</span>
<span class="normal">1457</span>
<span class="normal">1458</span>
<span class="normal">1459</span>
<span class="normal">1460</span>
<span class="normal">1461</span>
<span class="normal">1462</span>
<span class="normal">1463</span>
<span class="normal">1464</span>
<span class="normal">1465</span>
<span class="normal">1466</span>
<span class="normal">1467</span>
<span class="normal">1468</span>
<span class="normal">1469</span>
<span class="normal">1470</span>
<span class="normal">1471</span>
<span class="normal">1472</span>
<span class="normal">1473</span>
<span class="normal">1474</span>
<span class="normal">1475</span>
<span class="normal">1476</span>
<span class="normal">1477</span>
<span class="normal">1478</span>
<span class="normal">1479</span>
<span class="normal">1480</span>
<span class="normal">1481</span>
<span class="normal">1482</span>
<span class="normal">1483</span>
<span class="normal">1484</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@wrap_errors</span>
<span class="k">def</span><span class="w"> </span><span class="nf">clip_compare</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">subject</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">ImagesReference</span><span class="p">],</span>
    <span class="n">prompt</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">ImagesReference</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">]],</span>
    <span class="n">subject_type</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;image&quot;</span><span class="p">,</span>
    <span class="n">prompt_type</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;text&quot;</span><span class="p">,</span>
    <span class="n">clip_version</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compare a subject against prompts using CLIP embeddings.</span>

<span class="sd">    Args:</span>
<span class="sd">        subject (Union[str, ImagesReference]): The subject to compare (image or text).</span>
<span class="sd">        prompt (Union[str, List[str], ImagesReference, List[ImagesReference]]): The prompt(s) to compare against.</span>
<span class="sd">        subject_type (str, optional): Type of subject (&#39;image&#39; or &#39;text&#39;). Defaults to &quot;image&quot;.</span>
<span class="sd">        prompt_type (str, optional): Type of prompt(s) (&#39;image&#39; or &#39;text&#39;). Defaults to &quot;text&quot;.</span>
<span class="sd">        clip_version (Optional[str], optional): Version of CLIP model to use. Defaults to None.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Union[dict, List[dict]]: Comparison results between subject and prompt(s).</span>

<span class="sd">    Raises:</span>
<span class="sd">        InvalidParameterError: If subject_type or prompt_type is invalid.</span>
<span class="sd">        HTTPCallErrorError: If there is an error in the HTTP call.</span>
<span class="sd">        HTTPClientError: If there is an error with the server connection.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="p">(</span>
        <span class="n">subject_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">CLIP_ARGUMENT_TYPES</span>
        <span class="ow">or</span> <span class="n">prompt_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">CLIP_ARGUMENT_TYPES</span>
    <span class="p">):</span>
        <span class="k">raise</span> <span class="n">InvalidParameterError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Could not accept `subject_type` and `prompt_type` with values different than </span><span class="si">{</span><span class="n">CLIP_ARGUMENT_TYPES</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>
    <span class="n">payload</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__initialise_payload</span><span class="p">()</span>
    <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;subject_type&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">subject_type</span>
    <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;prompt_type&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">prompt_type</span>
    <span class="k">if</span> <span class="n">clip_version</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;clip_version_id&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">clip_version</span>
    <span class="k">if</span> <span class="n">subject_type</span> <span class="o">==</span> <span class="s2">&quot;image&quot;</span><span class="p">:</span>
        <span class="n">encoded_image</span> <span class="o">=</span> <span class="n">load_static_inference_input</span><span class="p">(</span>
            <span class="n">inference_input</span><span class="o">=</span><span class="n">subject</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">payload</span> <span class="o">=</span> <span class="n">inject_images_into_payload</span><span class="p">(</span>
            <span class="n">payload</span><span class="o">=</span><span class="n">payload</span><span class="p">,</span> <span class="n">encoded_images</span><span class="o">=</span><span class="n">encoded_image</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="s2">&quot;subject&quot;</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;subject&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">subject</span>
    <span class="k">if</span> <span class="n">prompt_type</span> <span class="o">==</span> <span class="s2">&quot;image&quot;</span><span class="p">:</span>
        <span class="n">encoded_inference_inputs</span> <span class="o">=</span> <span class="n">load_static_inference_input</span><span class="p">(</span>
            <span class="n">inference_input</span><span class="o">=</span><span class="n">prompt</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">payload</span> <span class="o">=</span> <span class="n">inject_images_into_payload</span><span class="p">(</span>
            <span class="n">payload</span><span class="o">=</span><span class="n">payload</span><span class="p">,</span> <span class="n">encoded_images</span><span class="o">=</span><span class="n">encoded_inference_inputs</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="s2">&quot;prompt&quot;</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;prompt&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">prompt</span>

    <span class="n">headers</span> <span class="o">=</span> <span class="n">DEFAULT_HEADERS</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">execution_id_value</span> <span class="o">=</span> <span class="n">execution_id</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">execution_id_value</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">headers</span><span class="p">[</span><span class="n">EXECUTION_ID_HEADER</span><span class="p">]</span> <span class="o">=</span> <span class="n">execution_id_value</span>

    <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">post</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__wrap_url_with_api_key</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__api_url</span><span class="si">}</span><span class="s2">/clip/compare&quot;</span><span class="p">),</span>
        <span class="n">json</span><span class="o">=</span><span class="n">payload</span><span class="p">,</span>
        <span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">_collect_processing_time_from_response</span><span class="p">(</span>
        <span class="n">response</span><span class="p">,</span> <span class="n">model_id</span><span class="o">=</span><span class="n">clip_version</span> <span class="ow">or</span> <span class="s2">&quot;clip&quot;</span>
    <span class="p">)</span>
    <span class="n">api_key_safe_raise_for_status</span><span class="p">(</span><span class="n">response</span><span class="o">=</span><span class="n">response</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="inference_sdk.http.client.InferenceHTTPClient.clip_compare_async" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">clip_compare_async</span><span class="p">(</span><span class="n">subject</span><span class="p">,</span> <span class="n">prompt</span><span class="p">,</span> <span class="n">subject_type</span><span class="o">=</span><span class="s1">&#39;image&#39;</span><span class="p">,</span> <span class="n">prompt_type</span><span class="o">=</span><span class="s1">&#39;text&#39;</span><span class="p">,</span> <span class="n">clip_version</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-async"><code>async</code></small>
  </span>

<a href="#inference_sdk.http.client.InferenceHTTPClient.clip_compare_async" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Compare a subject against prompts using CLIP embeddings asynchronously.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>subject</code>
            </td>
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="str">str</span>, <span title="inference_sdk.http.entities.ImagesReference">ImagesReference</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The subject to compare (image or text).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>prompt</code>
            </td>
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="str">str</span>, <span title="typing.List">List</span>[<span title="str">str</span>], <span title="inference_sdk.http.entities.ImagesReference">ImagesReference</span>, <span title="typing.List">List</span>[<span title="inference_sdk.http.entities.ImagesReference">ImagesReference</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The prompt(s) to compare against.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>subject_type</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Type of subject ('image' or 'text'). Defaults to "image".</p>
              </div>
            </td>
            <td>
                  <code>&#39;image&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>prompt_type</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Type of prompt(s) ('image' or 'text'). Defaults to "text".</p>
              </div>
            </td>
            <td>
                  <code>&#39;text&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>clip_version</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="str">str</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Version of CLIP model to use. Defaults to None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="dict">dict</span>, <span title="typing.List">List</span>[<span title="dict">dict</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Union[dict, List[dict]]: Comparison results between subject and prompt(s).</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.InvalidParameterError">InvalidParameterError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If subject_type or prompt_type is invalid.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.HTTPCallErrorError">HTTPCallErrorError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If there is an error in the HTTP call.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.HTTPClientError">HTTPClientError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If there is an error with the server connection.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>inference_sdk/http/client.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1486</span>
<span class="normal">1487</span>
<span class="normal">1488</span>
<span class="normal">1489</span>
<span class="normal">1490</span>
<span class="normal">1491</span>
<span class="normal">1492</span>
<span class="normal">1493</span>
<span class="normal">1494</span>
<span class="normal">1495</span>
<span class="normal">1496</span>
<span class="normal">1497</span>
<span class="normal">1498</span>
<span class="normal">1499</span>
<span class="normal">1500</span>
<span class="normal">1501</span>
<span class="normal">1502</span>
<span class="normal">1503</span>
<span class="normal">1504</span>
<span class="normal">1505</span>
<span class="normal">1506</span>
<span class="normal">1507</span>
<span class="normal">1508</span>
<span class="normal">1509</span>
<span class="normal">1510</span>
<span class="normal">1511</span>
<span class="normal">1512</span>
<span class="normal">1513</span>
<span class="normal">1514</span>
<span class="normal">1515</span>
<span class="normal">1516</span>
<span class="normal">1517</span>
<span class="normal">1518</span>
<span class="normal">1519</span>
<span class="normal">1520</span>
<span class="normal">1521</span>
<span class="normal">1522</span>
<span class="normal">1523</span>
<span class="normal">1524</span>
<span class="normal">1525</span>
<span class="normal">1526</span>
<span class="normal">1527</span>
<span class="normal">1528</span>
<span class="normal">1529</span>
<span class="normal">1530</span>
<span class="normal">1531</span>
<span class="normal">1532</span>
<span class="normal">1533</span>
<span class="normal">1534</span>
<span class="normal">1535</span>
<span class="normal">1536</span>
<span class="normal">1537</span>
<span class="normal">1538</span>
<span class="normal">1539</span>
<span class="normal">1540</span>
<span class="normal">1541</span>
<span class="normal">1542</span>
<span class="normal">1543</span>
<span class="normal">1544</span>
<span class="normal">1545</span>
<span class="normal">1546</span>
<span class="normal">1547</span>
<span class="normal">1548</span>
<span class="normal">1549</span>
<span class="normal">1550</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@wrap_errors_async</span>
<span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">clip_compare_async</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">subject</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">ImagesReference</span><span class="p">],</span>
    <span class="n">prompt</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">ImagesReference</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">]],</span>
    <span class="n">subject_type</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;image&quot;</span><span class="p">,</span>
    <span class="n">prompt_type</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;text&quot;</span><span class="p">,</span>
    <span class="n">clip_version</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compare a subject against prompts using CLIP embeddings asynchronously.</span>

<span class="sd">    Args:</span>
<span class="sd">        subject (Union[str, ImagesReference]): The subject to compare (image or text).</span>
<span class="sd">        prompt (Union[str, List[str], ImagesReference, List[ImagesReference]]): The prompt(s) to compare against.</span>
<span class="sd">        subject_type (str, optional): Type of subject (&#39;image&#39; or &#39;text&#39;). Defaults to &quot;image&quot;.</span>
<span class="sd">        prompt_type (str, optional): Type of prompt(s) (&#39;image&#39; or &#39;text&#39;). Defaults to &quot;text&quot;.</span>
<span class="sd">        clip_version (Optional[str], optional): Version of CLIP model to use. Defaults to None.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Union[dict, List[dict]]: Comparison results between subject and prompt(s).</span>

<span class="sd">    Raises:</span>
<span class="sd">        InvalidParameterError: If subject_type or prompt_type is invalid.</span>
<span class="sd">        HTTPCallErrorError: If there is an error in the HTTP call.</span>
<span class="sd">        HTTPClientError: If there is an error with the server connection.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="p">(</span>
        <span class="n">subject_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">CLIP_ARGUMENT_TYPES</span>
        <span class="ow">or</span> <span class="n">prompt_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">CLIP_ARGUMENT_TYPES</span>
    <span class="p">):</span>
        <span class="k">raise</span> <span class="n">InvalidParameterError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Could not accept `subject_type` and `prompt_type` with values different than </span><span class="si">{</span><span class="n">CLIP_ARGUMENT_TYPES</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>
    <span class="n">payload</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__initialise_payload</span><span class="p">()</span>
    <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;subject_type&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">subject_type</span>
    <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;prompt_type&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">prompt_type</span>
    <span class="k">if</span> <span class="n">clip_version</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;clip_version_id&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">clip_version</span>
    <span class="k">if</span> <span class="n">subject_type</span> <span class="o">==</span> <span class="s2">&quot;image&quot;</span><span class="p">:</span>
        <span class="n">encoded_image</span> <span class="o">=</span> <span class="k">await</span> <span class="n">load_static_inference_input_async</span><span class="p">(</span>
            <span class="n">inference_input</span><span class="o">=</span><span class="n">subject</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">payload</span> <span class="o">=</span> <span class="n">inject_images_into_payload</span><span class="p">(</span>
            <span class="n">payload</span><span class="o">=</span><span class="n">payload</span><span class="p">,</span> <span class="n">encoded_images</span><span class="o">=</span><span class="n">encoded_image</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="s2">&quot;subject&quot;</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;subject&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">subject</span>
    <span class="k">if</span> <span class="n">prompt_type</span> <span class="o">==</span> <span class="s2">&quot;image&quot;</span><span class="p">:</span>
        <span class="n">encoded_inference_inputs</span> <span class="o">=</span> <span class="k">await</span> <span class="n">load_static_inference_input_async</span><span class="p">(</span>
            <span class="n">inference_input</span><span class="o">=</span><span class="n">prompt</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">payload</span> <span class="o">=</span> <span class="n">inject_images_into_payload</span><span class="p">(</span>
            <span class="n">payload</span><span class="o">=</span><span class="n">payload</span><span class="p">,</span> <span class="n">encoded_images</span><span class="o">=</span><span class="n">encoded_inference_inputs</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="s2">&quot;prompt&quot;</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;prompt&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">prompt</span>

    <span class="k">async</span> <span class="k">with</span> <span class="n">aiohttp</span><span class="o">.</span><span class="n">ClientSession</span><span class="p">()</span> <span class="k">as</span> <span class="n">session</span><span class="p">:</span>
        <span class="k">async</span> <span class="k">with</span> <span class="n">session</span><span class="o">.</span><span class="n">post</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__wrap_url_with_api_key</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__api_url</span><span class="si">}</span><span class="s2">/clip/compare&quot;</span><span class="p">),</span>
            <span class="n">json</span><span class="o">=</span><span class="n">payload</span><span class="p">,</span>
            <span class="n">headers</span><span class="o">=</span><span class="n">DEFAULT_HEADERS</span><span class="p">,</span>
        <span class="p">)</span> <span class="k">as</span> <span class="n">response</span><span class="p">:</span>
            <span class="n">response</span><span class="o">.</span><span class="n">raise_for_status</span><span class="p">()</span>
            <span class="k">return</span> <span class="k">await</span> <span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="inference_sdk.http.client.InferenceHTTPClient.configure" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">configure</span><span class="p">(</span><span class="n">inference_configuration</span><span class="p">)</span></code>

<a href="#inference_sdk.http.client.InferenceHTTPClient.configure" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Configure the client with new inference settings.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>inference_configuration</code>
            </td>
            <td>
                  <code><a class="autorefs autorefs-internal" href="../entities/#inference_sdk.http.entities.InferenceConfiguration">InferenceConfiguration</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The new configuration to apply.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>InferenceHTTPClient</code></td>            <td>
                  <code><a class="autorefs autorefs-internal" href="#inference_sdk.http.client.InferenceHTTPClient">InferenceHTTPClient</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The client instance with updated configuration.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>inference_sdk/http/client.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">configure</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> <span class="n">inference_configuration</span><span class="p">:</span> <span class="n">InferenceConfiguration</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;InferenceHTTPClient&quot;</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Configure the client with new inference settings.</span>

<span class="sd">    Args:</span>
<span class="sd">        inference_configuration (InferenceConfiguration): The new configuration to apply.</span>

<span class="sd">    Returns:</span>
<span class="sd">        InferenceHTTPClient: The client instance with updated configuration.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">__inference_configuration</span> <span class="o">=</span> <span class="n">inference_configuration</span>
    <span class="k">return</span> <span class="bp">self</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="inference_sdk.http.client.InferenceHTTPClient.consume_inference_pipeline_result" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">consume_inference_pipeline_result</span><span class="p">(</span><span class="n">pipeline_id</span><span class="p">,</span> <span class="n">excluded_fields</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#inference_sdk.http.client.InferenceHTTPClient.consume_inference_pipeline_result" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Consumes and returns the next available result from an inference pipeline.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>pipeline_id</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The unique identifier of the inference pipeline to consume results from.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>excluded_fields</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="typing.List">List</span>[<span title="str">str</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Optional list of field names to exclude from the result. If None,
no fields will be excluded.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>dict</code></td>            <td>
                  <code><span title="dict">dict</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A dictionary containing the next available result from the pipeline.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.HTTPCallErrorError">HTTPCallErrorError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If there is an error in the HTTP call.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.HTTPClientError">HTTPClientError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If there is an error with the server connection.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.InvalidParameterError">InvalidParameterError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If pipeline_id is empty or None.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>inference_sdk/http/client.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">2775</span>
<span class="normal">2776</span>
<span class="normal">2777</span>
<span class="normal">2778</span>
<span class="normal">2779</span>
<span class="normal">2780</span>
<span class="normal">2781</span>
<span class="normal">2782</span>
<span class="normal">2783</span>
<span class="normal">2784</span>
<span class="normal">2785</span>
<span class="normal">2786</span>
<span class="normal">2787</span>
<span class="normal">2788</span>
<span class="normal">2789</span>
<span class="normal">2790</span>
<span class="normal">2791</span>
<span class="normal">2792</span>
<span class="normal">2793</span>
<span class="normal">2794</span>
<span class="normal">2795</span>
<span class="normal">2796</span>
<span class="normal">2797</span>
<span class="normal">2798</span>
<span class="normal">2799</span>
<span class="normal">2800</span>
<span class="normal">2801</span>
<span class="normal">2802</span>
<span class="normal">2803</span>
<span class="normal">2804</span>
<span class="normal">2805</span>
<span class="normal">2806</span>
<span class="normal">2807</span>
<span class="normal">2808</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@experimental</span><span class="p">(</span>
    <span class="n">info</span><span class="o">=</span><span class="s2">&quot;Video processing in inference server is under development. Breaking changes are possible.&quot;</span>
<span class="p">)</span>
<span class="nd">@wrap_errors</span>
<span class="k">def</span><span class="w"> </span><span class="nf">consume_inference_pipeline_result</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">pipeline_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">excluded_fields</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Consumes and returns the next available result from an inference pipeline.</span>

<span class="sd">    Args:</span>
<span class="sd">        pipeline_id: The unique identifier of the inference pipeline to consume results from.</span>
<span class="sd">        excluded_fields: Optional list of field names to exclude from the result. If None,</span>
<span class="sd">            no fields will be excluded.</span>

<span class="sd">    Returns:</span>
<span class="sd">        dict: A dictionary containing the next available result from the pipeline.</span>

<span class="sd">    Raises:</span>
<span class="sd">        HTTPCallErrorError: If there is an error in the HTTP call.</span>
<span class="sd">        HTTPClientError: If there is an error with the server connection.</span>
<span class="sd">        InvalidParameterError: If pipeline_id is empty or None.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_ensure_pipeline_id_not_empty</span><span class="p">(</span><span class="n">pipeline_id</span><span class="o">=</span><span class="n">pipeline_id</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">excluded_fields</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">excluded_fields</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">payload</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;api_key&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">__api_key</span><span class="p">,</span> <span class="s2">&quot;excluded_fields&quot;</span><span class="p">:</span> <span class="n">excluded_fields</span><span class="p">}</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__api_url</span><span class="si">}</span><span class="s2">/inference_pipelines/</span><span class="si">{</span><span class="n">pipeline_id</span><span class="si">}</span><span class="s2">/consume&quot;</span><span class="p">,</span>
        <span class="n">json</span><span class="o">=</span><span class="n">payload</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">api_key_safe_raise_for_status</span><span class="p">(</span><span class="n">response</span><span class="o">=</span><span class="n">response</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="inference_sdk.http.client.InferenceHTTPClient.depth_estimation" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">depth_estimation</span><span class="p">(</span><span class="n">inference_input</span><span class="p">,</span> <span class="n">model_id</span><span class="o">=</span><span class="s1">&#39;depth-anything-v3/small&#39;</span><span class="p">)</span></code>

<a href="#inference_sdk.http.client.InferenceHTTPClient.depth_estimation" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Run depth estimation on input image(s).</p>
<p>This method estimates depth maps from images using models like Depth Anything.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>inference_input</code>
            </td>
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="inference_sdk.http.entities.ImagesReference">ImagesReference</span>, <span title="typing.List">List</span>[<span title="inference_sdk.http.entities.ImagesReference">ImagesReference</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Input image(s)
for depth estimation. Can be file paths, URLs, base64 strings, numpy arrays,
or PIL images.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>model_id</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The depth estimation model to use. Defaults to
"depth-anything-v3/small". Supported models include:
- "depth-anything-v2/small"
- "depth-anything-v3/small"
- "depth-anything-v3/base"</p>
              </div>
            </td>
            <td>
                  <code>&#39;depth-anything-v3/small&#39;</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="dict">dict</span>, <span title="typing.List">List</span>[<span title="dict">dict</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Union[dict, List[dict]]: Depth estimation results containing:
- normalized_depth: The normalized depth map as a list
- image: Hex-encoded visualization of the depth map</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.HTTPCallErrorError">HTTPCallErrorError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If there is an error in the HTTP call.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.HTTPClientError">HTTPClientError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If there is an error with the server connection.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>inference_sdk/http/client.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1696</span>
<span class="normal">1697</span>
<span class="normal">1698</span>
<span class="normal">1699</span>
<span class="normal">1700</span>
<span class="normal">1701</span>
<span class="normal">1702</span>
<span class="normal">1703</span>
<span class="normal">1704</span>
<span class="normal">1705</span>
<span class="normal">1706</span>
<span class="normal">1707</span>
<span class="normal">1708</span>
<span class="normal">1709</span>
<span class="normal">1710</span>
<span class="normal">1711</span>
<span class="normal">1712</span>
<span class="normal">1713</span>
<span class="normal">1714</span>
<span class="normal">1715</span>
<span class="normal">1716</span>
<span class="normal">1717</span>
<span class="normal">1718</span>
<span class="normal">1719</span>
<span class="normal">1720</span>
<span class="normal">1721</span>
<span class="normal">1722</span>
<span class="normal">1723</span>
<span class="normal">1724</span>
<span class="normal">1725</span>
<span class="normal">1726</span>
<span class="normal">1727</span>
<span class="normal">1728</span>
<span class="normal">1729</span>
<span class="normal">1730</span>
<span class="normal">1731</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@wrap_errors</span>
<span class="k">def</span><span class="w"> </span><span class="nf">depth_estimation</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">inference_input</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">]],</span>
    <span class="n">model_id</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;depth-anything-v3/small&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Run depth estimation on input image(s).</span>

<span class="sd">    This method estimates depth maps from images using models like Depth Anything.</span>

<span class="sd">    Args:</span>
<span class="sd">        inference_input (Union[ImagesReference, List[ImagesReference]]): Input image(s)</span>
<span class="sd">            for depth estimation. Can be file paths, URLs, base64 strings, numpy arrays,</span>
<span class="sd">            or PIL images.</span>
<span class="sd">        model_id (str, optional): The depth estimation model to use. Defaults to</span>
<span class="sd">            &quot;depth-anything-v3/small&quot;. Supported models include:</span>
<span class="sd">            - &quot;depth-anything-v2/small&quot;</span>
<span class="sd">            - &quot;depth-anything-v3/small&quot;</span>
<span class="sd">            - &quot;depth-anything-v3/base&quot;</span>

<span class="sd">    Returns:</span>
<span class="sd">        Union[dict, List[dict]]: Depth estimation results containing:</span>
<span class="sd">            - normalized_depth: The normalized depth map as a list</span>
<span class="sd">            - image: Hex-encoded visualization of the depth map</span>

<span class="sd">    Raises:</span>
<span class="sd">        HTTPCallErrorError: If there is an error in the HTTP call.</span>
<span class="sd">        HTTPClientError: If there is an error with the server connection.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">extra_payload</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;model_id&quot;</span><span class="p">:</span> <span class="n">model_id</span><span class="p">}</span>
    <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_post_images</span><span class="p">(</span>
        <span class="n">inference_input</span><span class="o">=</span><span class="n">inference_input</span><span class="p">,</span>
        <span class="n">endpoint</span><span class="o">=</span><span class="s2">&quot;/infer/depth-estimation&quot;</span><span class="p">,</span>
        <span class="n">extra_payload</span><span class="o">=</span><span class="n">extra_payload</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">result</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="inference_sdk.http.client.InferenceHTTPClient.depth_estimation_async" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">depth_estimation_async</span><span class="p">(</span><span class="n">inference_input</span><span class="p">,</span> <span class="n">model_id</span><span class="o">=</span><span class="s1">&#39;depth-anything-v3/small&#39;</span><span class="p">)</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-async"><code>async</code></small>
  </span>

<a href="#inference_sdk.http.client.InferenceHTTPClient.depth_estimation_async" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Run depth estimation on input image(s) asynchronously.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>inference_input</code>
            </td>
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="inference_sdk.http.entities.ImagesReference">ImagesReference</span>, <span title="typing.List">List</span>[<span title="inference_sdk.http.entities.ImagesReference">ImagesReference</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Input image(s)
for depth estimation.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>model_id</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The depth estimation model to use. Defaults to
"depth-anything-v3/small".</p>
              </div>
            </td>
            <td>
                  <code>&#39;depth-anything-v3/small&#39;</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="dict">dict</span>, <span title="typing.List">List</span>[<span title="dict">dict</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Union[dict, List[dict]]: Depth estimation results.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.HTTPCallErrorError">HTTPCallErrorError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If there is an error in the HTTP call.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.HTTPClientError">HTTPClientError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If there is an error with the server connection.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>inference_sdk/http/client.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1733</span>
<span class="normal">1734</span>
<span class="normal">1735</span>
<span class="normal">1736</span>
<span class="normal">1737</span>
<span class="normal">1738</span>
<span class="normal">1739</span>
<span class="normal">1740</span>
<span class="normal">1741</span>
<span class="normal">1742</span>
<span class="normal">1743</span>
<span class="normal">1744</span>
<span class="normal">1745</span>
<span class="normal">1746</span>
<span class="normal">1747</span>
<span class="normal">1748</span>
<span class="normal">1749</span>
<span class="normal">1750</span>
<span class="normal">1751</span>
<span class="normal">1752</span>
<span class="normal">1753</span>
<span class="normal">1754</span>
<span class="normal">1755</span>
<span class="normal">1756</span>
<span class="normal">1757</span>
<span class="normal">1758</span>
<span class="normal">1759</span>
<span class="normal">1760</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@wrap_errors_async</span>
<span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">depth_estimation_async</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">inference_input</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">]],</span>
    <span class="n">model_id</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;depth-anything-v3/small&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Run depth estimation on input image(s) asynchronously.</span>

<span class="sd">    Args:</span>
<span class="sd">        inference_input (Union[ImagesReference, List[ImagesReference]]): Input image(s)</span>
<span class="sd">            for depth estimation.</span>
<span class="sd">        model_id (str, optional): The depth estimation model to use. Defaults to</span>
<span class="sd">            &quot;depth-anything-v3/small&quot;.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Union[dict, List[dict]]: Depth estimation results.</span>

<span class="sd">    Raises:</span>
<span class="sd">        HTTPCallErrorError: If there is an error in the HTTP call.</span>
<span class="sd">        HTTPClientError: If there is an error with the server connection.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">extra_payload</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;model_id&quot;</span><span class="p">:</span> <span class="n">model_id</span><span class="p">}</span>
    <span class="n">result</span> <span class="o">=</span> <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">_post_images_async</span><span class="p">(</span>
        <span class="n">inference_input</span><span class="o">=</span><span class="n">inference_input</span><span class="p">,</span>
        <span class="n">endpoint</span><span class="o">=</span><span class="s2">&quot;/infer/depth-estimation&quot;</span><span class="p">,</span>
        <span class="n">extra_payload</span><span class="o">=</span><span class="n">extra_payload</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">result</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="inference_sdk.http.client.InferenceHTTPClient.detect_gazes" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">detect_gazes</span><span class="p">(</span><span class="n">inference_input</span><span class="p">)</span></code>

<a href="#inference_sdk.http.client.InferenceHTTPClient.detect_gazes" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Detect gazes in input image(s).</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>inference_input</code>
            </td>
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="inference_sdk.http.entities.ImagesReference">ImagesReference</span>, <span title="typing.List">List</span>[<span title="inference_sdk.http.entities.ImagesReference">ImagesReference</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Input image(s) for gaze detection.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="dict">dict</span>, <span title="typing.List">List</span>[<span title="dict">dict</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Union[dict, List[dict]]: Gaze detection results for the input image(s).</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.WrongClientModeError">WrongClientModeError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If not in API v1 mode.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.HTTPCallErrorError">HTTPCallErrorError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If there is an error in the HTTP call.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.HTTPClientError">HTTPClientError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If there is an error with the server connection.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>inference_sdk/http/client.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1233</span>
<span class="normal">1234</span>
<span class="normal">1235</span>
<span class="normal">1236</span>
<span class="normal">1237</span>
<span class="normal">1238</span>
<span class="normal">1239</span>
<span class="normal">1240</span>
<span class="normal">1241</span>
<span class="normal">1242</span>
<span class="normal">1243</span>
<span class="normal">1244</span>
<span class="normal">1245</span>
<span class="normal">1246</span>
<span class="normal">1247</span>
<span class="normal">1248</span>
<span class="normal">1249</span>
<span class="normal">1250</span>
<span class="normal">1251</span>
<span class="normal">1252</span>
<span class="normal">1253</span>
<span class="normal">1254</span>
<span class="normal">1255</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@wrap_errors</span>
<span class="k">def</span><span class="w"> </span><span class="nf">detect_gazes</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">inference_input</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">]],</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Detect gazes in input image(s).</span>

<span class="sd">    Args:</span>
<span class="sd">        inference_input (Union[ImagesReference, List[ImagesReference]]): Input image(s) for gaze detection.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Union[dict, List[dict]]: Gaze detection results for the input image(s).</span>

<span class="sd">    Raises:</span>
<span class="sd">        WrongClientModeError: If not in API v1 mode.</span>
<span class="sd">        HTTPCallErrorError: If there is an error in the HTTP call.</span>
<span class="sd">        HTTPClientError: If there is an error with the server connection.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">__ensure_v1_client_mode</span><span class="p">()</span>  <span class="c1"># Lambda does not support Gaze, so we require v1 mode of client</span>
    <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_post_images</span><span class="p">(</span>
        <span class="n">inference_input</span><span class="o">=</span><span class="n">inference_input</span><span class="p">,</span> <span class="n">endpoint</span><span class="o">=</span><span class="s2">&quot;/gaze/gaze_detection&quot;</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">combine_gaze_detections</span><span class="p">(</span><span class="n">detections</span><span class="o">=</span><span class="n">result</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="inference_sdk.http.client.InferenceHTTPClient.detect_gazes_async" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">detect_gazes_async</span><span class="p">(</span><span class="n">inference_input</span><span class="p">)</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-async"><code>async</code></small>
  </span>

<a href="#inference_sdk.http.client.InferenceHTTPClient.detect_gazes_async" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Detect gazes in input image(s) asynchronously.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>inference_input</code>
            </td>
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="inference_sdk.http.entities.ImagesReference">ImagesReference</span>, <span title="typing.List">List</span>[<span title="inference_sdk.http.entities.ImagesReference">ImagesReference</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Input image(s) for gaze detection.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="dict">dict</span>, <span title="typing.List">List</span>[<span title="dict">dict</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Union[dict, List[dict]]: Gaze detection results for the input image(s).</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.WrongClientModeError">WrongClientModeError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If not in API v1 mode.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.HTTPCallErrorError">HTTPCallErrorError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If there is an error in the HTTP call.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.HTTPClientError">HTTPClientError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If there is an error with the server connection.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>inference_sdk/http/client.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1257</span>
<span class="normal">1258</span>
<span class="normal">1259</span>
<span class="normal">1260</span>
<span class="normal">1261</span>
<span class="normal">1262</span>
<span class="normal">1263</span>
<span class="normal">1264</span>
<span class="normal">1265</span>
<span class="normal">1266</span>
<span class="normal">1267</span>
<span class="normal">1268</span>
<span class="normal">1269</span>
<span class="normal">1270</span>
<span class="normal">1271</span>
<span class="normal">1272</span>
<span class="normal">1273</span>
<span class="normal">1274</span>
<span class="normal">1275</span>
<span class="normal">1276</span>
<span class="normal">1277</span>
<span class="normal">1278</span>
<span class="normal">1279</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@wrap_errors_async</span>
<span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">detect_gazes_async</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">inference_input</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">]],</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Detect gazes in input image(s) asynchronously.</span>

<span class="sd">    Args:</span>
<span class="sd">        inference_input (Union[ImagesReference, List[ImagesReference]]): Input image(s) for gaze detection.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Union[dict, List[dict]]: Gaze detection results for the input image(s).</span>

<span class="sd">    Raises:</span>
<span class="sd">        WrongClientModeError: If not in API v1 mode.</span>
<span class="sd">        HTTPCallErrorError: If there is an error in the HTTP call.</span>
<span class="sd">        HTTPClientError: If there is an error with the server connection.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">__ensure_v1_client_mode</span><span class="p">()</span>  <span class="c1"># Lambda does not support Gaze, so we require v1 mode of client</span>
    <span class="n">result</span> <span class="o">=</span> <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">_post_images_async</span><span class="p">(</span>
        <span class="n">inference_input</span><span class="o">=</span><span class="n">inference_input</span><span class="p">,</span> <span class="n">endpoint</span><span class="o">=</span><span class="s2">&quot;/gaze/gaze_detection&quot;</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">combine_gaze_detections</span><span class="p">(</span><span class="n">detections</span><span class="o">=</span><span class="n">result</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="inference_sdk.http.client.InferenceHTTPClient.get_clip_image_embeddings" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">get_clip_image_embeddings</span><span class="p">(</span><span class="n">inference_input</span><span class="p">,</span> <span class="n">clip_version</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#inference_sdk.http.client.InferenceHTTPClient.get_clip_image_embeddings" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Get CLIP embeddings for input image(s).</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>inference_input</code>
            </td>
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="inference_sdk.http.entities.ImagesReference">ImagesReference</span>, <span title="typing.List">List</span>[<span title="inference_sdk.http.entities.ImagesReference">ImagesReference</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Input image(s) to embed.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>clip_version</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="str">str</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Version of CLIP model to use. Defaults to None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="dict">dict</span>, <span title="typing.List">List</span>[<span title="dict">dict</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Union[dict, List[dict]]: CLIP embeddings for the input image(s).</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.HTTPCallErrorError">HTTPCallErrorError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If there is an error in the HTTP call.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.HTTPClientError">HTTPClientError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If there is an error with the server connection.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>inference_sdk/http/client.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1281</span>
<span class="normal">1282</span>
<span class="normal">1283</span>
<span class="normal">1284</span>
<span class="normal">1285</span>
<span class="normal">1286</span>
<span class="normal">1287</span>
<span class="normal">1288</span>
<span class="normal">1289</span>
<span class="normal">1290</span>
<span class="normal">1291</span>
<span class="normal">1292</span>
<span class="normal">1293</span>
<span class="normal">1294</span>
<span class="normal">1295</span>
<span class="normal">1296</span>
<span class="normal">1297</span>
<span class="normal">1298</span>
<span class="normal">1299</span>
<span class="normal">1300</span>
<span class="normal">1301</span>
<span class="normal">1302</span>
<span class="normal">1303</span>
<span class="normal">1304</span>
<span class="normal">1305</span>
<span class="normal">1306</span>
<span class="normal">1307</span>
<span class="normal">1308</span>
<span class="normal">1309</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@wrap_errors</span>
<span class="k">def</span><span class="w"> </span><span class="nf">get_clip_image_embeddings</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">inference_input</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">]],</span>
    <span class="n">clip_version</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Get CLIP embeddings for input image(s).</span>

<span class="sd">    Args:</span>
<span class="sd">        inference_input (Union[ImagesReference, List[ImagesReference]]): Input image(s) to embed.</span>
<span class="sd">        clip_version (Optional[str], optional): Version of CLIP model to use. Defaults to None.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Union[dict, List[dict]]: CLIP embeddings for the input image(s).</span>

<span class="sd">    Raises:</span>
<span class="sd">        HTTPCallErrorError: If there is an error in the HTTP call.</span>
<span class="sd">        HTTPClientError: If there is an error with the server connection.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">extra_payload</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">if</span> <span class="n">clip_version</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">extra_payload</span><span class="p">[</span><span class="s2">&quot;clip_version_id&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">clip_version</span>
    <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_post_images</span><span class="p">(</span>
        <span class="n">inference_input</span><span class="o">=</span><span class="n">inference_input</span><span class="p">,</span>
        <span class="n">endpoint</span><span class="o">=</span><span class="s2">&quot;/clip/embed_image&quot;</span><span class="p">,</span>
        <span class="n">extra_payload</span><span class="o">=</span><span class="n">extra_payload</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">combine_clip_embeddings</span><span class="p">(</span><span class="n">embeddings</span><span class="o">=</span><span class="n">result</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">unwrap_single_element_list</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="inference_sdk.http.client.InferenceHTTPClient.get_clip_image_embeddings_async" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">get_clip_image_embeddings_async</span><span class="p">(</span><span class="n">inference_input</span><span class="p">,</span> <span class="n">clip_version</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-async"><code>async</code></small>
  </span>

<a href="#inference_sdk.http.client.InferenceHTTPClient.get_clip_image_embeddings_async" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Get CLIP embeddings for input image(s) asynchronously.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>inference_input</code>
            </td>
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="inference_sdk.http.entities.ImagesReference">ImagesReference</span>, <span title="typing.List">List</span>[<span title="inference_sdk.http.entities.ImagesReference">ImagesReference</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Input image(s) to embed.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>clip_version</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="str">str</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Version of CLIP model to use. Defaults to None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="dict">dict</span>, <span title="typing.List">List</span>[<span title="dict">dict</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Union[dict, List[dict]]: CLIP embeddings for the input image(s).</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.HTTPCallErrorError">HTTPCallErrorError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If there is an error in the HTTP call.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.HTTPClientError">HTTPClientError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If there is an error with the server connection.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>inference_sdk/http/client.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1311</span>
<span class="normal">1312</span>
<span class="normal">1313</span>
<span class="normal">1314</span>
<span class="normal">1315</span>
<span class="normal">1316</span>
<span class="normal">1317</span>
<span class="normal">1318</span>
<span class="normal">1319</span>
<span class="normal">1320</span>
<span class="normal">1321</span>
<span class="normal">1322</span>
<span class="normal">1323</span>
<span class="normal">1324</span>
<span class="normal">1325</span>
<span class="normal">1326</span>
<span class="normal">1327</span>
<span class="normal">1328</span>
<span class="normal">1329</span>
<span class="normal">1330</span>
<span class="normal">1331</span>
<span class="normal">1332</span>
<span class="normal">1333</span>
<span class="normal">1334</span>
<span class="normal">1335</span>
<span class="normal">1336</span>
<span class="normal">1337</span>
<span class="normal">1338</span>
<span class="normal">1339</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@wrap_errors_async</span>
<span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">get_clip_image_embeddings_async</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">inference_input</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">]],</span>
    <span class="n">clip_version</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Get CLIP embeddings for input image(s) asynchronously.</span>

<span class="sd">    Args:</span>
<span class="sd">        inference_input (Union[ImagesReference, List[ImagesReference]]): Input image(s) to embed.</span>
<span class="sd">        clip_version (Optional[str], optional): Version of CLIP model to use. Defaults to None.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Union[dict, List[dict]]: CLIP embeddings for the input image(s).</span>

<span class="sd">    Raises:</span>
<span class="sd">        HTTPCallErrorError: If there is an error in the HTTP call.</span>
<span class="sd">        HTTPClientError: If there is an error with the server connection.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">extra_payload</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">if</span> <span class="n">clip_version</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">extra_payload</span><span class="p">[</span><span class="s2">&quot;clip_version_id&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">clip_version</span>
    <span class="n">result</span> <span class="o">=</span> <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">_post_images_async</span><span class="p">(</span>
        <span class="n">inference_input</span><span class="o">=</span><span class="n">inference_input</span><span class="p">,</span>
        <span class="n">endpoint</span><span class="o">=</span><span class="s2">&quot;/clip/embed_image&quot;</span><span class="p">,</span>
        <span class="n">extra_payload</span><span class="o">=</span><span class="n">extra_payload</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">combine_clip_embeddings</span><span class="p">(</span><span class="n">embeddings</span><span class="o">=</span><span class="n">result</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">unwrap_single_element_list</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="inference_sdk.http.client.InferenceHTTPClient.get_clip_text_embeddings" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">get_clip_text_embeddings</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">clip_version</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#inference_sdk.http.client.InferenceHTTPClient.get_clip_text_embeddings" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Get CLIP embeddings for input text(s).</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>text</code>
            </td>
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="str">str</span>, <span title="typing.List">List</span>[<span title="str">str</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Input text(s) to embed.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>clip_version</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="str">str</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Version of CLIP model to use. Defaults to None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="dict">dict</span>, <span title="typing.List">List</span>[<span title="dict">dict</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Union[dict, List[dict]]: CLIP embeddings for the input text(s).</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.HTTPCallErrorError">HTTPCallErrorError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If there is an error in the HTTP call.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.HTTPClientError">HTTPClientError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If there is an error with the server connection.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>inference_sdk/http/client.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1341</span>
<span class="normal">1342</span>
<span class="normal">1343</span>
<span class="normal">1344</span>
<span class="normal">1345</span>
<span class="normal">1346</span>
<span class="normal">1347</span>
<span class="normal">1348</span>
<span class="normal">1349</span>
<span class="normal">1350</span>
<span class="normal">1351</span>
<span class="normal">1352</span>
<span class="normal">1353</span>
<span class="normal">1354</span>
<span class="normal">1355</span>
<span class="normal">1356</span>
<span class="normal">1357</span>
<span class="normal">1358</span>
<span class="normal">1359</span>
<span class="normal">1360</span>
<span class="normal">1361</span>
<span class="normal">1362</span>
<span class="normal">1363</span>
<span class="normal">1364</span>
<span class="normal">1365</span>
<span class="normal">1366</span>
<span class="normal">1367</span>
<span class="normal">1368</span>
<span class="normal">1369</span>
<span class="normal">1370</span>
<span class="normal">1371</span>
<span class="normal">1372</span>
<span class="normal">1373</span>
<span class="normal">1374</span>
<span class="normal">1375</span>
<span class="normal">1376</span>
<span class="normal">1377</span>
<span class="normal">1378</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@wrap_errors</span>
<span class="k">def</span><span class="w"> </span><span class="nf">get_clip_text_embeddings</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">text</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
    <span class="n">clip_version</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Get CLIP embeddings for input text(s).</span>

<span class="sd">    Args:</span>
<span class="sd">        text (Union[str, List[str]]): Input text(s) to embed.</span>
<span class="sd">        clip_version (Optional[str], optional): Version of CLIP model to use. Defaults to None.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Union[dict, List[dict]]: CLIP embeddings for the input text(s).</span>

<span class="sd">    Raises:</span>
<span class="sd">        HTTPCallErrorError: If there is an error in the HTTP call.</span>
<span class="sd">        HTTPClientError: If there is an error with the server connection.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">payload</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__initialise_payload</span><span class="p">()</span>
    <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">text</span>
    <span class="k">if</span> <span class="n">clip_version</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;clip_version_id&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">clip_version</span>
    <span class="n">headers</span> <span class="o">=</span> <span class="n">DEFAULT_HEADERS</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">execution_id_value</span> <span class="o">=</span> <span class="n">execution_id</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">execution_id_value</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">headers</span><span class="p">[</span><span class="n">EXECUTION_ID_HEADER</span><span class="p">]</span> <span class="o">=</span> <span class="n">execution_id_value</span>

    <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">post</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__wrap_url_with_api_key</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__api_url</span><span class="si">}</span><span class="s2">/clip/embed_text&quot;</span><span class="p">),</span>
        <span class="n">json</span><span class="o">=</span><span class="n">payload</span><span class="p">,</span>
        <span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">_collect_processing_time_from_response</span><span class="p">(</span>
        <span class="n">response</span><span class="p">,</span> <span class="n">model_id</span><span class="o">=</span><span class="n">clip_version</span> <span class="ow">or</span> <span class="s2">&quot;clip&quot;</span>
    <span class="p">)</span>
    <span class="n">api_key_safe_raise_for_status</span><span class="p">(</span><span class="n">response</span><span class="o">=</span><span class="n">response</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">unwrap_single_element_list</span><span class="p">(</span><span class="n">sequence</span><span class="o">=</span><span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">())</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="inference_sdk.http.client.InferenceHTTPClient.get_clip_text_embeddings_async" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">get_clip_text_embeddings_async</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">clip_version</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-async"><code>async</code></small>
  </span>

<a href="#inference_sdk.http.client.InferenceHTTPClient.get_clip_text_embeddings_async" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Get CLIP embeddings for input text(s) asynchronously.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>text</code>
            </td>
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="str">str</span>, <span title="typing.List">List</span>[<span title="str">str</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Input text(s) to embed.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>clip_version</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="str">str</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Version of CLIP model to use. Defaults to None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="dict">dict</span>, <span title="typing.List">List</span>[<span title="dict">dict</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Union[dict, List[dict]]: CLIP embeddings for the input text(s).</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.HTTPCallErrorError">HTTPCallErrorError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If there is an error in the HTTP call.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.HTTPClientError">HTTPClientError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If there is an error with the server connection.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>inference_sdk/http/client.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1380</span>
<span class="normal">1381</span>
<span class="normal">1382</span>
<span class="normal">1383</span>
<span class="normal">1384</span>
<span class="normal">1385</span>
<span class="normal">1386</span>
<span class="normal">1387</span>
<span class="normal">1388</span>
<span class="normal">1389</span>
<span class="normal">1390</span>
<span class="normal">1391</span>
<span class="normal">1392</span>
<span class="normal">1393</span>
<span class="normal">1394</span>
<span class="normal">1395</span>
<span class="normal">1396</span>
<span class="normal">1397</span>
<span class="normal">1398</span>
<span class="normal">1399</span>
<span class="normal">1400</span>
<span class="normal">1401</span>
<span class="normal">1402</span>
<span class="normal">1403</span>
<span class="normal">1404</span>
<span class="normal">1405</span>
<span class="normal">1406</span>
<span class="normal">1407</span>
<span class="normal">1408</span>
<span class="normal">1409</span>
<span class="normal">1410</span>
<span class="normal">1411</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@wrap_errors_async</span>
<span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">get_clip_text_embeddings_async</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">text</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
    <span class="n">clip_version</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Get CLIP embeddings for input text(s) asynchronously.</span>

<span class="sd">    Args:</span>
<span class="sd">        text (Union[str, List[str]]): Input text(s) to embed.</span>
<span class="sd">        clip_version (Optional[str], optional): Version of CLIP model to use. Defaults to None.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Union[dict, List[dict]]: CLIP embeddings for the input text(s).</span>

<span class="sd">    Raises:</span>
<span class="sd">        HTTPCallErrorError: If there is an error in the HTTP call.</span>
<span class="sd">        HTTPClientError: If there is an error with the server connection.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">payload</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__initialise_payload</span><span class="p">()</span>
    <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">text</span>
    <span class="k">if</span> <span class="n">clip_version</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;clip_version_id&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">clip_version</span>
    <span class="k">async</span> <span class="k">with</span> <span class="n">aiohttp</span><span class="o">.</span><span class="n">ClientSession</span><span class="p">()</span> <span class="k">as</span> <span class="n">session</span><span class="p">:</span>
        <span class="k">async</span> <span class="k">with</span> <span class="n">session</span><span class="o">.</span><span class="n">post</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__wrap_url_with_api_key</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__api_url</span><span class="si">}</span><span class="s2">/clip/embed_text&quot;</span><span class="p">),</span>
            <span class="n">json</span><span class="o">=</span><span class="n">payload</span><span class="p">,</span>
            <span class="n">headers</span><span class="o">=</span><span class="n">DEFAULT_HEADERS</span><span class="p">,</span>
        <span class="p">)</span> <span class="k">as</span> <span class="n">response</span><span class="p">:</span>
            <span class="n">response</span><span class="o">.</span><span class="n">raise_for_status</span><span class="p">()</span>
            <span class="n">response_payload</span> <span class="o">=</span> <span class="k">await</span> <span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">unwrap_single_element_list</span><span class="p">(</span><span class="n">sequence</span><span class="o">=</span><span class="n">response_payload</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="inference_sdk.http.client.InferenceHTTPClient.get_inference_pipeline_status" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">get_inference_pipeline_status</span><span class="p">(</span><span class="n">pipeline_id</span><span class="p">)</span></code>

<a href="#inference_sdk.http.client.InferenceHTTPClient.get_inference_pipeline_status" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Gets the current status of a specific inference pipeline.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>pipeline_id</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The unique identifier of the inference pipeline to check.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>dict</code></td>            <td>
                  <code><span title="dict">dict</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A dictionary containing the current status and details of the pipeline.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.HTTPCallErrorError">HTTPCallErrorError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If there is an error in the HTTP call.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.HTTPClientError">HTTPClientError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If there is an error with the server connection.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><span title="ValueError">ValueError</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If pipeline_id is empty or None.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>inference_sdk/http/client.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">2658</span>
<span class="normal">2659</span>
<span class="normal">2660</span>
<span class="normal">2661</span>
<span class="normal">2662</span>
<span class="normal">2663</span>
<span class="normal">2664</span>
<span class="normal">2665</span>
<span class="normal">2666</span>
<span class="normal">2667</span>
<span class="normal">2668</span>
<span class="normal">2669</span>
<span class="normal">2670</span>
<span class="normal">2671</span>
<span class="normal">2672</span>
<span class="normal">2673</span>
<span class="normal">2674</span>
<span class="normal">2675</span>
<span class="normal">2676</span>
<span class="normal">2677</span>
<span class="normal">2678</span>
<span class="normal">2679</span>
<span class="normal">2680</span>
<span class="normal">2681</span>
<span class="normal">2682</span>
<span class="normal">2683</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@experimental</span><span class="p">(</span>
    <span class="n">info</span><span class="o">=</span><span class="s2">&quot;Video processing in inference server is under development. Breaking changes are possible.&quot;</span>
<span class="p">)</span>
<span class="nd">@wrap_errors</span>
<span class="k">def</span><span class="w"> </span><span class="nf">get_inference_pipeline_status</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pipeline_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Gets the current status of a specific inference pipeline.</span>

<span class="sd">    Args:</span>
<span class="sd">        pipeline_id: The unique identifier of the inference pipeline to check.</span>

<span class="sd">    Returns:</span>
<span class="sd">        dict: A dictionary containing the current status and details of the pipeline.</span>

<span class="sd">    Raises:</span>
<span class="sd">        HTTPCallErrorError: If there is an error in the HTTP call.</span>
<span class="sd">        HTTPClientError: If there is an error with the server connection.</span>
<span class="sd">        ValueError: If pipeline_id is empty or None.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_ensure_pipeline_id_not_empty</span><span class="p">(</span><span class="n">pipeline_id</span><span class="o">=</span><span class="n">pipeline_id</span><span class="p">)</span>
    <span class="n">payload</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;api_key&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">__api_key</span><span class="p">}</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__api_url</span><span class="si">}</span><span class="s2">/inference_pipelines/</span><span class="si">{</span><span class="n">pipeline_id</span><span class="si">}</span><span class="s2">/status&quot;</span><span class="p">,</span>
        <span class="n">json</span><span class="o">=</span><span class="n">payload</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">api_key_safe_raise_for_status</span><span class="p">(</span><span class="n">response</span><span class="o">=</span><span class="n">response</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="inference_sdk.http.client.InferenceHTTPClient.get_model_description" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">get_model_description</span><span class="p">(</span><span class="n">model_id</span><span class="p">,</span> <span class="n">allow_loading</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></code>

<a href="#inference_sdk.http.client.InferenceHTTPClient.get_model_description" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Get the description of a model.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>model_id</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The identifier of the model.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>allow_loading</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Whether to load the model if not already loaded. Defaults to True.</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>ModelDescription</code></td>            <td>
                  <code><a class="autorefs autorefs-internal" href="../entities/#inference_sdk.http.entities.ModelDescription">ModelDescription</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Description of the model.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.WrongClientModeError">WrongClientModeError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If not in API v1 mode.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.ModelNotInitializedError">ModelNotInitializedError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If the model is not initialized and cannot be loaded.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>inference_sdk/http/client.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">850</span>
<span class="normal">851</span>
<span class="normal">852</span>
<span class="normal">853</span>
<span class="normal">854</span>
<span class="normal">855</span>
<span class="normal">856</span>
<span class="normal">857</span>
<span class="normal">858</span>
<span class="normal">859</span>
<span class="normal">860</span>
<span class="normal">861</span>
<span class="normal">862</span>
<span class="normal">863</span>
<span class="normal">864</span>
<span class="normal">865</span>
<span class="normal">866</span>
<span class="normal">867</span>
<span class="normal">868</span>
<span class="normal">869</span>
<span class="normal">870</span>
<span class="normal">871</span>
<span class="normal">872</span>
<span class="normal">873</span>
<span class="normal">874</span>
<span class="normal">875</span>
<span class="normal">876</span>
<span class="normal">877</span>
<span class="normal">878</span>
<span class="normal">879</span>
<span class="normal">880</span>
<span class="normal">881</span>
<span class="normal">882</span>
<span class="normal">883</span>
<span class="normal">884</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">get_model_description</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> <span class="n">model_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">allow_loading</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ModelDescription</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Get the description of a model.</span>

<span class="sd">    Args:</span>
<span class="sd">        model_id (str): The identifier of the model.</span>
<span class="sd">        allow_loading (bool, optional): Whether to load the model if not already loaded. Defaults to True.</span>

<span class="sd">    Returns:</span>
<span class="sd">        ModelDescription: Description of the model.</span>

<span class="sd">    Raises:</span>
<span class="sd">        WrongClientModeError: If not in API v1 mode.</span>
<span class="sd">        ModelNotInitializedError: If the model is not initialized and cannot be loaded.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">__ensure_v1_client_mode</span><span class="p">()</span>
    <span class="n">de_aliased_model_id</span> <span class="o">=</span> <span class="n">resolve_roboflow_model_alias</span><span class="p">(</span><span class="n">model_id</span><span class="o">=</span><span class="n">model_id</span><span class="p">)</span>
    <span class="n">registered_models</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">list_loaded_models</span><span class="p">()</span>
    <span class="n">matching_model</span> <span class="o">=</span> <span class="n">filter_model_descriptions</span><span class="p">(</span>
        <span class="n">descriptions</span><span class="o">=</span><span class="n">registered_models</span><span class="o">.</span><span class="n">models</span><span class="p">,</span>
        <span class="n">model_id</span><span class="o">=</span><span class="n">de_aliased_model_id</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="n">matching_model</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">allow_loading</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
        <span class="n">registered_models</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="n">model_id</span><span class="o">=</span><span class="n">de_aliased_model_id</span><span class="p">)</span>
        <span class="n">matching_model</span> <span class="o">=</span> <span class="n">filter_model_descriptions</span><span class="p">(</span>
            <span class="n">descriptions</span><span class="o">=</span><span class="n">registered_models</span><span class="o">.</span><span class="n">models</span><span class="p">,</span>
            <span class="n">model_id</span><span class="o">=</span><span class="n">de_aliased_model_id</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">if</span> <span class="n">matching_model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">matching_model</span>
    <span class="k">raise</span> <span class="n">ModelNotInitializedError</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;Model </span><span class="si">{</span><span class="n">model_id</span><span class="si">}</span><span class="s2"> (de-aliased: </span><span class="si">{</span><span class="n">de_aliased_model_id</span><span class="si">}</span><span class="s2">) is not initialised and cannot &quot;</span>
        <span class="sa">f</span><span class="s2">&quot;retrieve its description.&quot;</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="inference_sdk.http.client.InferenceHTTPClient.get_model_description_async" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">get_model_description_async</span><span class="p">(</span><span class="n">model_id</span><span class="p">,</span> <span class="n">allow_loading</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-async"><code>async</code></small>
  </span>

<a href="#inference_sdk.http.client.InferenceHTTPClient.get_model_description_async" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Get the description of a model asynchronously.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>model_id</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The identifier of the model.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>allow_loading</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Whether to load the model if not already loaded. Defaults to True.</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>ModelDescription</code></td>            <td>
                  <code><a class="autorefs autorefs-internal" href="../entities/#inference_sdk.http.entities.ModelDescription">ModelDescription</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Description of the model.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.WrongClientModeError">WrongClientModeError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If not in API v1 mode.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.ModelNotInitializedError">ModelNotInitializedError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If the model is not initialized and cannot be loaded.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>inference_sdk/http/client.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">886</span>
<span class="normal">887</span>
<span class="normal">888</span>
<span class="normal">889</span>
<span class="normal">890</span>
<span class="normal">891</span>
<span class="normal">892</span>
<span class="normal">893</span>
<span class="normal">894</span>
<span class="normal">895</span>
<span class="normal">896</span>
<span class="normal">897</span>
<span class="normal">898</span>
<span class="normal">899</span>
<span class="normal">900</span>
<span class="normal">901</span>
<span class="normal">902</span>
<span class="normal">903</span>
<span class="normal">904</span>
<span class="normal">905</span>
<span class="normal">906</span>
<span class="normal">907</span>
<span class="normal">908</span>
<span class="normal">909</span>
<span class="normal">910</span>
<span class="normal">911</span>
<span class="normal">912</span>
<span class="normal">913</span>
<span class="normal">914</span>
<span class="normal">915</span>
<span class="normal">916</span>
<span class="normal">917</span>
<span class="normal">918</span>
<span class="normal">919</span>
<span class="normal">920</span>
<span class="normal">921</span>
<span class="normal">922</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">get_model_description_async</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> <span class="n">model_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">allow_loading</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ModelDescription</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Get the description of a model asynchronously.</span>

<span class="sd">    Args:</span>
<span class="sd">        model_id (str): The identifier of the model.</span>
<span class="sd">        allow_loading (bool, optional): Whether to load the model if not already loaded. Defaults to True.</span>

<span class="sd">    Returns:</span>
<span class="sd">        ModelDescription: Description of the model.</span>

<span class="sd">    Raises:</span>
<span class="sd">        WrongClientModeError: If not in API v1 mode.</span>
<span class="sd">        ModelNotInitializedError: If the model is not initialized and cannot be loaded.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">__ensure_v1_client_mode</span><span class="p">()</span>
    <span class="n">de_aliased_model_id</span> <span class="o">=</span> <span class="n">resolve_roboflow_model_alias</span><span class="p">(</span><span class="n">model_id</span><span class="o">=</span><span class="n">model_id</span><span class="p">)</span>
    <span class="n">registered_models</span> <span class="o">=</span> <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">list_loaded_models_async</span><span class="p">()</span>
    <span class="n">matching_model</span> <span class="o">=</span> <span class="n">filter_model_descriptions</span><span class="p">(</span>
        <span class="n">descriptions</span><span class="o">=</span><span class="n">registered_models</span><span class="o">.</span><span class="n">models</span><span class="p">,</span>
        <span class="n">model_id</span><span class="o">=</span><span class="n">de_aliased_model_id</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="n">matching_model</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">allow_loading</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
        <span class="n">registered_models</span> <span class="o">=</span> <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">load_model_async</span><span class="p">(</span>
            <span class="n">model_id</span><span class="o">=</span><span class="n">de_aliased_model_id</span>
        <span class="p">)</span>
        <span class="n">matching_model</span> <span class="o">=</span> <span class="n">filter_model_descriptions</span><span class="p">(</span>
            <span class="n">descriptions</span><span class="o">=</span><span class="n">registered_models</span><span class="o">.</span><span class="n">models</span><span class="p">,</span>
            <span class="n">model_id</span><span class="o">=</span><span class="n">de_aliased_model_id</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">if</span> <span class="n">matching_model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">matching_model</span>
    <span class="k">raise</span> <span class="n">ModelNotInitializedError</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;Model </span><span class="si">{</span><span class="n">model_id</span><span class="si">}</span><span class="s2"> (de-aliased: </span><span class="si">{</span><span class="n">de_aliased_model_id</span><span class="si">}</span><span class="s2">) is not initialised and cannot &quot;</span>
        <span class="sa">f</span><span class="s2">&quot;retrieve its description.&quot;</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="inference_sdk.http.client.InferenceHTTPClient.get_perception_encoder_image_embeddings" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">get_perception_encoder_image_embeddings</span><span class="p">(</span><span class="n">inference_input</span><span class="p">,</span> <span class="n">perception_encoder_version</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#inference_sdk.http.client.InferenceHTTPClient.get_perception_encoder_image_embeddings" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Get Perception Encoder embeddings for input image(s).</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>inference_sdk/http/client.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1552</span>
<span class="normal">1553</span>
<span class="normal">1554</span>
<span class="normal">1555</span>
<span class="normal">1556</span>
<span class="normal">1557</span>
<span class="normal">1558</span>
<span class="normal">1559</span>
<span class="normal">1560</span>
<span class="normal">1561</span>
<span class="normal">1562</span>
<span class="normal">1563</span>
<span class="normal">1564</span>
<span class="normal">1565</span>
<span class="normal">1566</span>
<span class="normal">1567</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@wrap_errors</span>
<span class="k">def</span><span class="w"> </span><span class="nf">get_perception_encoder_image_embeddings</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">inference_input</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">]],</span>
    <span class="n">perception_encoder_version</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Get Perception Encoder embeddings for input image(s).&quot;&quot;&quot;</span>
    <span class="n">extra_payload</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">if</span> <span class="n">perception_encoder_version</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">extra_payload</span><span class="p">[</span><span class="s2">&quot;perception_encoder_version_id&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">perception_encoder_version</span>
    <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_post_images</span><span class="p">(</span>
        <span class="n">inference_input</span><span class="o">=</span><span class="n">inference_input</span><span class="p">,</span>
        <span class="n">endpoint</span><span class="o">=</span><span class="s2">&quot;/perception_encoder/embed_image&quot;</span><span class="p">,</span>
        <span class="n">extra_payload</span><span class="o">=</span><span class="n">extra_payload</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">unwrap_single_element_list</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="inference_sdk.http.client.InferenceHTTPClient.get_perception_encoder_text_embeddings" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">get_perception_encoder_text_embeddings</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">perception_encoder_version</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#inference_sdk.http.client.InferenceHTTPClient.get_perception_encoder_text_embeddings" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Get Perception Encoder embeddings for input text(s).</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>inference_sdk/http/client.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1569</span>
<span class="normal">1570</span>
<span class="normal">1571</span>
<span class="normal">1572</span>
<span class="normal">1573</span>
<span class="normal">1574</span>
<span class="normal">1575</span>
<span class="normal">1576</span>
<span class="normal">1577</span>
<span class="normal">1578</span>
<span class="normal">1579</span>
<span class="normal">1580</span>
<span class="normal">1581</span>
<span class="normal">1582</span>
<span class="normal">1583</span>
<span class="normal">1584</span>
<span class="normal">1585</span>
<span class="normal">1586</span>
<span class="normal">1587</span>
<span class="normal">1588</span>
<span class="normal">1589</span>
<span class="normal">1590</span>
<span class="normal">1591</span>
<span class="normal">1592</span>
<span class="normal">1593</span>
<span class="normal">1594</span>
<span class="normal">1595</span>
<span class="normal">1596</span>
<span class="normal">1597</span>
<span class="normal">1598</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@wrap_errors</span>
<span class="k">def</span><span class="w"> </span><span class="nf">get_perception_encoder_text_embeddings</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">text</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
    <span class="n">perception_encoder_version</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Get Perception Encoder embeddings for input text(s).&quot;&quot;&quot;</span>
    <span class="n">payload</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__initialise_payload</span><span class="p">()</span>
    <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">text</span>
    <span class="k">if</span> <span class="n">perception_encoder_version</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;perception_encoder_version_id&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">perception_encoder_version</span>

    <span class="n">headers</span> <span class="o">=</span> <span class="n">DEFAULT_HEADERS</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">execution_id_value</span> <span class="o">=</span> <span class="n">execution_id</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">execution_id_value</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">headers</span><span class="p">[</span><span class="n">EXECUTION_ID_HEADER</span><span class="p">]</span> <span class="o">=</span> <span class="n">execution_id_value</span>

    <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">post</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__wrap_url_with_api_key</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__api_url</span><span class="si">}</span><span class="s2">/perception_encoder/embed_text&quot;</span>
        <span class="p">),</span>
        <span class="n">json</span><span class="o">=</span><span class="n">payload</span><span class="p">,</span>
        <span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">_collect_processing_time_from_response</span><span class="p">(</span>
        <span class="n">response</span><span class="p">,</span>
        <span class="n">model_id</span><span class="o">=</span><span class="n">perception_encoder_version</span> <span class="ow">or</span> <span class="s2">&quot;perception_encoder&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">api_key_safe_raise_for_status</span><span class="p">(</span><span class="n">response</span><span class="o">=</span><span class="n">response</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">unwrap_single_element_list</span><span class="p">(</span><span class="n">sequence</span><span class="o">=</span><span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">())</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="inference_sdk.http.client.InferenceHTTPClient.get_server_info" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">get_server_info</span><span class="p">()</span></code>

<a href="#inference_sdk.http.client.InferenceHTTPClient.get_server_info" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Get information about the inference server.</p>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>ServerInfo</code></td>            <td>
                  <code><a class="autorefs autorefs-internal" href="../entities/#inference_sdk.http.entities.ServerInfo">ServerInfo</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Information about the server configuration and status.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.HTTPCallErrorError">HTTPCallErrorError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If there is an error in the HTTP call.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.HTTPClientError">HTTPClientError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If there is an error with the server connection.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>inference_sdk/http/client.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@wrap_errors</span>
<span class="k">def</span><span class="w"> </span><span class="nf">get_server_info</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ServerInfo</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Get information about the inference server.</span>

<span class="sd">    Returns:</span>
<span class="sd">        ServerInfo: Information about the server configuration and status.</span>

<span class="sd">    Raises:</span>
<span class="sd">        HTTPCallErrorError: If there is an error in the HTTP call.</span>
<span class="sd">        HTTPClientError: If there is an error with the server connection.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__api_url</span><span class="si">}</span><span class="s2">/info&quot;</span><span class="p">)</span>
    <span class="n">response</span><span class="o">.</span><span class="n">raise_for_status</span><span class="p">()</span>
    <span class="n">response_payload</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">ServerInfo</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">response_payload</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="inference_sdk.http.client.InferenceHTTPClient.infer" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">infer</span><span class="p">(</span><span class="n">inference_input</span><span class="p">,</span> <span class="n">model_id</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#inference_sdk.http.client.InferenceHTTPClient.infer" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Run inference on one or more images.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>inference_input</code>
            </td>
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="inference_sdk.http.entities.ImagesReference">ImagesReference</span>, <span title="typing.List">List</span>[<span title="inference_sdk.http.entities.ImagesReference">ImagesReference</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Input image(s) for inference.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>model_id</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="str">str</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Model identifier to use for inference. Defaults to None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="dict">dict</span>, <span title="typing.List">List</span>[<span title="dict">dict</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Union[dict, List[dict]]: Inference results for the input image(s).</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.HTTPCallErrorError">HTTPCallErrorError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If there is an error in the HTTP call.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.HTTPClientError">HTTPClientError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If there is an error with the server connection.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>inference_sdk/http/client.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@wrap_errors</span>
<span class="k">def</span><span class="w"> </span><span class="nf">infer</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">inference_input</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">]],</span>
    <span class="n">model_id</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Run inference on one or more images.</span>

<span class="sd">    Args:</span>
<span class="sd">        inference_input (Union[ImagesReference, List[ImagesReference]]): Input image(s) for inference.</span>
<span class="sd">        model_id (Optional[str], optional): Model identifier to use for inference. Defaults to None.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Union[dict, List[dict]]: Inference results for the input image(s).</span>

<span class="sd">    Raises:</span>
<span class="sd">        HTTPCallErrorError: If there is an error in the HTTP call.</span>
<span class="sd">        HTTPClientError: If there is an error with the server connection.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">__client_mode</span> <span class="ow">is</span> <span class="n">HTTPClientMode</span><span class="o">.</span><span class="n">V0</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">infer_from_api_v0</span><span class="p">(</span>
            <span class="n">inference_input</span><span class="o">=</span><span class="n">inference_input</span><span class="p">,</span>
            <span class="n">model_id</span><span class="o">=</span><span class="n">model_id</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">infer_from_api_v1</span><span class="p">(</span>
        <span class="n">inference_input</span><span class="o">=</span><span class="n">inference_input</span><span class="p">,</span>
        <span class="n">model_id</span><span class="o">=</span><span class="n">model_id</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="inference_sdk.http.client.InferenceHTTPClient.infer_async" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">infer_async</span><span class="p">(</span><span class="n">inference_input</span><span class="p">,</span> <span class="n">model_id</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-async"><code>async</code></small>
  </span>

<a href="#inference_sdk.http.client.InferenceHTTPClient.infer_async" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Run inference asynchronously on one or more images.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>inference_input</code>
            </td>
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="inference_sdk.http.entities.ImagesReference">ImagesReference</span>, <span title="typing.List">List</span>[<span title="inference_sdk.http.entities.ImagesReference">ImagesReference</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Input image(s) for inference.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>model_id</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="str">str</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Model identifier to use for inference. Defaults to None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="dict">dict</span>, <span title="typing.List">List</span>[<span title="dict">dict</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Union[dict, List[dict]]: Inference results for the input image(s).</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.HTTPCallErrorError">HTTPCallErrorError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If there is an error in the HTTP call.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.HTTPClientError">HTTPClientError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If there is an error with the server connection.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>inference_sdk/http/client.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@wrap_errors_async</span>
<span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">infer_async</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">inference_input</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">]],</span>
    <span class="n">model_id</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Run inference asynchronously on one or more images.</span>

<span class="sd">    Args:</span>
<span class="sd">        inference_input (Union[ImagesReference, List[ImagesReference]]): Input image(s) for inference.</span>
<span class="sd">        model_id (Optional[str], optional): Model identifier to use for inference. Defaults to None.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Union[dict, List[dict]]: Inference results for the input image(s).</span>

<span class="sd">    Raises:</span>
<span class="sd">        HTTPCallErrorError: If there is an error in the HTTP call.</span>
<span class="sd">        HTTPClientError: If there is an error with the server connection.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">__client_mode</span> <span class="ow">is</span> <span class="n">HTTPClientMode</span><span class="o">.</span><span class="n">V0</span><span class="p">:</span>
        <span class="k">return</span> <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">infer_from_api_v0_async</span><span class="p">(</span>
            <span class="n">inference_input</span><span class="o">=</span><span class="n">inference_input</span><span class="p">,</span>
            <span class="n">model_id</span><span class="o">=</span><span class="n">model_id</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">return</span> <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">infer_from_api_v1_async</span><span class="p">(</span>
        <span class="n">inference_input</span><span class="o">=</span><span class="n">inference_input</span><span class="p">,</span>
        <span class="n">model_id</span><span class="o">=</span><span class="n">model_id</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="inference_sdk.http.client.InferenceHTTPClient.infer_from_api_v0" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">infer_from_api_v0</span><span class="p">(</span><span class="n">inference_input</span><span class="p">,</span> <span class="n">model_id</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#inference_sdk.http.client.InferenceHTTPClient.infer_from_api_v0" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Run inference using API v0.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>inference_input</code>
            </td>
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="inference_sdk.http.entities.ImagesReference">ImagesReference</span>, <span title="typing.List">List</span>[<span title="inference_sdk.http.entities.ImagesReference">ImagesReference</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Input image(s) for inference.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>model_id</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="str">str</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Model identifier to use for inference. Defaults to None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="dict">dict</span>, <span title="typing.List">List</span>[<span title="dict">dict</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Union[dict, List[dict]]: Inference results for the input image(s).</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.ModelNotSelectedError">ModelNotSelectedError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If no model is selected.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.APIKeyNotProvided">APIKeyNotProvided</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If API key is required but not provided.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.InvalidModelIdentifier">InvalidModelIdentifier</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If the model identifier format is invalid.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>inference_sdk/http/client.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">infer_from_api_v0</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">inference_input</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">]],</span>
    <span class="n">model_id</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Run inference using API v0.</span>

<span class="sd">    Args:</span>
<span class="sd">        inference_input (Union[ImagesReference, List[ImagesReference]]): Input image(s) for inference.</span>
<span class="sd">        model_id (Optional[str], optional): Model identifier to use for inference. Defaults to None.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Union[dict, List[dict]]: Inference results for the input image(s).</span>

<span class="sd">    Raises:</span>
<span class="sd">        ModelNotSelectedError: If no model is selected.</span>
<span class="sd">        APIKeyNotProvided: If API key is required but not provided.</span>
<span class="sd">        InvalidModelIdentifier: If the model identifier format is invalid.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">requests_data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_prepare_infer_from_api_v0_request_data</span><span class="p">(</span>
        <span class="n">inference_input</span><span class="o">=</span><span class="n">inference_input</span><span class="p">,</span>
        <span class="n">model_id</span><span class="o">=</span><span class="n">model_id</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">responses</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_execute_infer_from_api_request</span><span class="p">(</span>
        <span class="n">requests_data</span><span class="o">=</span><span class="n">requests_data</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">request_data</span><span class="p">,</span> <span class="n">response</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">requests_data</span><span class="p">,</span> <span class="n">responses</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">response_contains_jpeg_image</span><span class="p">(</span><span class="n">response</span><span class="o">=</span><span class="n">response</span><span class="p">):</span>
            <span class="n">visualisation</span> <span class="o">=</span> <span class="n">transform_visualisation_bytes</span><span class="p">(</span>
                <span class="n">visualisation</span><span class="o">=</span><span class="n">response</span><span class="o">.</span><span class="n">content</span><span class="p">,</span>
                <span class="n">expected_format</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">__inference_configuration</span><span class="o">.</span><span class="n">output_visualisation_format</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">parsed_response</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;visualization&quot;</span><span class="p">:</span> <span class="n">visualisation</span><span class="p">}</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">parsed_response</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">parsed_response</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;visualization&quot;</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">parsed_response</span><span class="p">[</span><span class="s2">&quot;visualization&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">transform_base64_visualisation</span><span class="p">(</span>
                    <span class="n">visualisation</span><span class="o">=</span><span class="n">parsed_response</span><span class="p">[</span><span class="s2">&quot;visualization&quot;</span><span class="p">],</span>
                    <span class="n">expected_format</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">__inference_configuration</span><span class="o">.</span><span class="n">output_visualisation_format</span><span class="p">,</span>
                <span class="p">)</span>
        <span class="n">parsed_response</span> <span class="o">=</span> <span class="n">adjust_prediction_to_client_scaling_factor</span><span class="p">(</span>
            <span class="n">prediction</span><span class="o">=</span><span class="n">parsed_response</span><span class="p">,</span>
            <span class="n">scaling_factor</span><span class="o">=</span><span class="n">request_data</span><span class="o">.</span><span class="n">image_scaling_factors</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
        <span class="p">)</span>
        <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">parsed_response</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">unwrap_single_element_list</span><span class="p">(</span><span class="n">sequence</span><span class="o">=</span><span class="n">results</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="inference_sdk.http.client.InferenceHTTPClient.infer_from_api_v0_async" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">infer_from_api_v0_async</span><span class="p">(</span><span class="n">inference_input</span><span class="p">,</span> <span class="n">model_id</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-async"><code>async</code></small>
  </span>

<a href="#inference_sdk.http.client.InferenceHTTPClient.infer_from_api_v0_async" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Run inference using API v0 asynchronously.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>inference_input</code>
            </td>
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="inference_sdk.http.entities.ImagesReference">ImagesReference</span>, <span title="typing.List">List</span>[<span title="inference_sdk.http.entities.ImagesReference">ImagesReference</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Input image(s) for inference.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>model_id</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="str">str</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Model identifier to use for inference. Defaults to None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="dict">dict</span>, <span title="typing.List">List</span>[<span title="dict">dict</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Union[dict, List[dict]]: Inference results for the input image(s).</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.ModelNotSelectedError">ModelNotSelectedError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If no model is selected.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.APIKeyNotProvided">APIKeyNotProvided</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If API key is required but not provided.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.InvalidModelIdentifier">InvalidModelIdentifier</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If the model identifier format is invalid.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>inference_sdk/http/client.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">613</span>
<span class="normal">614</span>
<span class="normal">615</span>
<span class="normal">616</span>
<span class="normal">617</span>
<span class="normal">618</span>
<span class="normal">619</span>
<span class="normal">620</span>
<span class="normal">621</span>
<span class="normal">622</span>
<span class="normal">623</span>
<span class="normal">624</span>
<span class="normal">625</span>
<span class="normal">626</span>
<span class="normal">627</span>
<span class="normal">628</span>
<span class="normal">629</span>
<span class="normal">630</span>
<span class="normal">631</span>
<span class="normal">632</span>
<span class="normal">633</span>
<span class="normal">634</span>
<span class="normal">635</span>
<span class="normal">636</span>
<span class="normal">637</span>
<span class="normal">638</span>
<span class="normal">639</span>
<span class="normal">640</span>
<span class="normal">641</span>
<span class="normal">642</span>
<span class="normal">643</span>
<span class="normal">644</span>
<span class="normal">645</span>
<span class="normal">646</span>
<span class="normal">647</span>
<span class="normal">648</span>
<span class="normal">649</span>
<span class="normal">650</span>
<span class="normal">651</span>
<span class="normal">652</span>
<span class="normal">653</span>
<span class="normal">654</span>
<span class="normal">655</span>
<span class="normal">656</span>
<span class="normal">657</span>
<span class="normal">658</span>
<span class="normal">659</span>
<span class="normal">660</span>
<span class="normal">661</span>
<span class="normal">662</span>
<span class="normal">663</span>
<span class="normal">664</span>
<span class="normal">665</span>
<span class="normal">666</span>
<span class="normal">667</span>
<span class="normal">668</span>
<span class="normal">669</span>
<span class="normal">670</span>
<span class="normal">671</span>
<span class="normal">672</span>
<span class="normal">673</span>
<span class="normal">674</span>
<span class="normal">675</span>
<span class="normal">676</span>
<span class="normal">677</span>
<span class="normal">678</span>
<span class="normal">679</span>
<span class="normal">680</span>
<span class="normal">681</span>
<span class="normal">682</span>
<span class="normal">683</span>
<span class="normal">684</span>
<span class="normal">685</span>
<span class="normal">686</span>
<span class="normal">687</span>
<span class="normal">688</span>
<span class="normal">689</span>
<span class="normal">690</span>
<span class="normal">691</span>
<span class="normal">692</span>
<span class="normal">693</span>
<span class="normal">694</span>
<span class="normal">695</span>
<span class="normal">696</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">infer_from_api_v0_async</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">inference_input</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">]],</span>
    <span class="n">model_id</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Run inference using API v0 asynchronously.</span>

<span class="sd">    Args:</span>
<span class="sd">        inference_input (Union[ImagesReference, List[ImagesReference]]): Input image(s) for inference.</span>
<span class="sd">        model_id (Optional[str], optional): Model identifier to use for inference. Defaults to None.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Union[dict, List[dict]]: Inference results for the input image(s).</span>

<span class="sd">    Raises:</span>
<span class="sd">        ModelNotSelectedError: If no model is selected.</span>
<span class="sd">        APIKeyNotProvided: If API key is required but not provided.</span>
<span class="sd">        InvalidModelIdentifier: If the model identifier format is invalid.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">model_id_to_be_used</span> <span class="o">=</span> <span class="n">model_id</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">__selected_model</span>
    <span class="n">_ensure_model_is_selected</span><span class="p">(</span><span class="n">model_id</span><span class="o">=</span><span class="n">model_id_to_be_used</span><span class="p">)</span>
    <span class="n">_ensure_api_key_provided</span><span class="p">(</span><span class="n">api_key</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">__api_key</span><span class="p">)</span>
    <span class="n">model_id_to_be_used</span> <span class="o">=</span> <span class="n">resolve_roboflow_model_alias</span><span class="p">(</span><span class="n">model_id</span><span class="o">=</span><span class="n">model_id_to_be_used</span><span class="p">)</span>
    <span class="n">model_id_chunks</span> <span class="o">=</span> <span class="n">model_id_to_be_used</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;/&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">model_id_chunks</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">InvalidModelIdentifier</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Invalid model id: </span><span class="si">{</span><span class="n">model_id</span><span class="si">}</span><span class="s2">. Expected format: project_id/model_version_id.&quot;</span>
        <span class="p">)</span>
    <span class="n">max_height</span><span class="p">,</span> <span class="n">max_width</span> <span class="o">=</span> <span class="n">_determine_client_downsizing_parameters</span><span class="p">(</span>
        <span class="n">client_downsizing_disabled</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">__inference_configuration</span><span class="o">.</span><span class="n">client_downsizing_disabled</span><span class="p">,</span>
        <span class="n">model_description</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">default_max_input_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">__inference_configuration</span><span class="o">.</span><span class="n">default_max_input_size</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">encoded_inference_inputs</span> <span class="o">=</span> <span class="k">await</span> <span class="n">load_static_inference_input_async</span><span class="p">(</span>
        <span class="n">inference_input</span><span class="o">=</span><span class="n">inference_input</span><span class="p">,</span>
        <span class="n">max_height</span><span class="o">=</span><span class="n">max_height</span><span class="p">,</span>
        <span class="n">max_width</span><span class="o">=</span><span class="n">max_width</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">params</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;api_key&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">__api_key</span><span class="p">,</span>
    <span class="p">}</span>
    <span class="n">params</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__inference_configuration</span><span class="o">.</span><span class="n">to_legacy_call_parameters</span><span class="p">())</span>

    <span class="n">execution_id_value</span> <span class="o">=</span> <span class="n">execution_id</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
    <span class="n">headers</span> <span class="o">=</span> <span class="n">DEFAULT_HEADERS</span>
    <span class="k">if</span> <span class="n">execution_id_value</span><span class="p">:</span>
        <span class="n">headers</span> <span class="o">=</span> <span class="n">headers</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">headers</span><span class="p">[</span><span class="n">EXECUTION_ID_HEADER</span><span class="p">]</span> <span class="o">=</span> <span class="n">execution_id_value</span>

    <span class="n">requests_data</span> <span class="o">=</span> <span class="n">prepare_requests_data</span><span class="p">(</span>
        <span class="n">url</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__api_url</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">model_id_chunks</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">model_id_chunks</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
        <span class="n">encoded_inference_inputs</span><span class="o">=</span><span class="n">encoded_inference_inputs</span><span class="p">,</span>
        <span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">,</span>
        <span class="n">parameters</span><span class="o">=</span><span class="n">params</span><span class="p">,</span>
        <span class="n">payload</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">max_batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">image_placement</span><span class="o">=</span><span class="n">ImagePlacement</span><span class="o">.</span><span class="n">DATA</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">responses</span> <span class="o">=</span> <span class="k">await</span> <span class="n">execute_requests_packages_async</span><span class="p">(</span>
        <span class="n">requests_data</span><span class="o">=</span><span class="n">requests_data</span><span class="p">,</span>
        <span class="n">request_method</span><span class="o">=</span><span class="n">RequestMethod</span><span class="o">.</span><span class="n">POST</span><span class="p">,</span>
        <span class="n">max_concurrent_requests</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">__inference_configuration</span><span class="o">.</span><span class="n">max_concurrent_requests</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">request_data</span><span class="p">,</span> <span class="n">response</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">requests_data</span><span class="p">,</span> <span class="n">responses</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">issubclass</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">response</span><span class="p">),</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="n">visualisation</span> <span class="o">=</span> <span class="n">transform_visualisation_bytes</span><span class="p">(</span>
                <span class="n">visualisation</span><span class="o">=</span><span class="n">response</span><span class="p">,</span>
                <span class="n">expected_format</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">__inference_configuration</span><span class="o">.</span><span class="n">output_visualisation_format</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">parsed_response</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;visualization&quot;</span><span class="p">:</span> <span class="n">visualisation</span><span class="p">}</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">parsed_response</span> <span class="o">=</span> <span class="n">response</span>
            <span class="k">if</span> <span class="n">parsed_response</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;visualization&quot;</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">parsed_response</span><span class="p">[</span><span class="s2">&quot;visualization&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">transform_base64_visualisation</span><span class="p">(</span>
                    <span class="n">visualisation</span><span class="o">=</span><span class="n">parsed_response</span><span class="p">[</span><span class="s2">&quot;visualization&quot;</span><span class="p">],</span>
                    <span class="n">expected_format</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">__inference_configuration</span><span class="o">.</span><span class="n">output_visualisation_format</span><span class="p">,</span>
                <span class="p">)</span>
        <span class="n">parsed_response</span> <span class="o">=</span> <span class="n">adjust_prediction_to_client_scaling_factor</span><span class="p">(</span>
            <span class="n">prediction</span><span class="o">=</span><span class="n">parsed_response</span><span class="p">,</span>
            <span class="n">scaling_factor</span><span class="o">=</span><span class="n">request_data</span><span class="o">.</span><span class="n">image_scaling_factors</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
        <span class="p">)</span>
        <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">parsed_response</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">unwrap_single_element_list</span><span class="p">(</span><span class="n">sequence</span><span class="o">=</span><span class="n">results</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="inference_sdk.http.client.InferenceHTTPClient.infer_from_workflow" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">infer_from_workflow</span><span class="p">(</span><span class="n">workspace_name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">workflow_name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">specification</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">images</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">parameters</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">excluded_fields</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">use_cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">enable_profiling</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">workflow_version_id</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#inference_sdk.http.client.InferenceHTTPClient.infer_from_workflow" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Run inference using a workflow specification.</p>
<p>Triggers inference from workflow specification at the inference HTTP
side. Either (<code>workspace_name</code> and <code>workflow_name</code>) or <code>workflow_specification</code> must be
provided. In the first case - definition of workflow will be fetched
from Roboflow API, in the latter - <code>workflow_specification</code> will be
used. <code>images</code> and <code>parameters</code> will be merged into workflow inputs,
the distinction is made to make sure the SDK can easily serialise
images and prepare a proper payload. Supported images are numpy arrays,
PIL.Image and base64 images, links to images and local paths.
<code>excluded_fields</code> will be added to request to filter out results
of workflow execution at the server side.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>workspace_name</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="str">str</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Name of the workspace containing the workflow. Defaults to None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>workflow_name</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="str">str</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Name of the workflow. Defaults to None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>specification</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="dict">dict</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Direct workflow specification. Defaults to None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>images</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="typing.Dict">Dict</span>[<span title="str">str</span>, <span title="typing.Any">Any</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Images to process. Defaults to None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>parameters</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="typing.Dict">Dict</span>[<span title="str">str</span>, <span title="typing.Any">Any</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Additional parameters for the workflow. Defaults to None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>excluded_fields</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="typing.List">List</span>[<span title="str">str</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Fields to exclude from results. Defaults to None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>use_cache</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Whether to use cached results. Defaults to True.</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>enable_profiling</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Whether to enable profiling. Defaults to False.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.List">List</span>[<span title="typing.Dict">Dict</span>[<span title="str">str</span>, <span title="typing.Any">Any</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>List[Dict[str, Any]]: Results of the workflow execution.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.InvalidParameterError">InvalidParameterError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If neither workflow identifiers nor specification is provided.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.HTTPCallErrorError">HTTPCallErrorError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If there is an error in the HTTP call.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.HTTPClientError">HTTPClientError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If there is an error with the server connection.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>inference_sdk/http/client.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">2194</span>
<span class="normal">2195</span>
<span class="normal">2196</span>
<span class="normal">2197</span>
<span class="normal">2198</span>
<span class="normal">2199</span>
<span class="normal">2200</span>
<span class="normal">2201</span>
<span class="normal">2202</span>
<span class="normal">2203</span>
<span class="normal">2204</span>
<span class="normal">2205</span>
<span class="normal">2206</span>
<span class="normal">2207</span>
<span class="normal">2208</span>
<span class="normal">2209</span>
<span class="normal">2210</span>
<span class="normal">2211</span>
<span class="normal">2212</span>
<span class="normal">2213</span>
<span class="normal">2214</span>
<span class="normal">2215</span>
<span class="normal">2216</span>
<span class="normal">2217</span>
<span class="normal">2218</span>
<span class="normal">2219</span>
<span class="normal">2220</span>
<span class="normal">2221</span>
<span class="normal">2222</span>
<span class="normal">2223</span>
<span class="normal">2224</span>
<span class="normal">2225</span>
<span class="normal">2226</span>
<span class="normal">2227</span>
<span class="normal">2228</span>
<span class="normal">2229</span>
<span class="normal">2230</span>
<span class="normal">2231</span>
<span class="normal">2232</span>
<span class="normal">2233</span>
<span class="normal">2234</span>
<span class="normal">2235</span>
<span class="normal">2236</span>
<span class="normal">2237</span>
<span class="normal">2238</span>
<span class="normal">2239</span>
<span class="normal">2240</span>
<span class="normal">2241</span>
<span class="normal">2242</span>
<span class="normal">2243</span>
<span class="normal">2244</span>
<span class="normal">2245</span>
<span class="normal">2246</span>
<span class="normal">2247</span>
<span class="normal">2248</span>
<span class="normal">2249</span>
<span class="normal">2250</span>
<span class="normal">2251</span>
<span class="normal">2252</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@deprecated</span><span class="p">(</span>
    <span class="n">reason</span><span class="o">=</span><span class="s2">&quot;Please use run_workflow(...) method. This method will be removed end of Q2 2024&quot;</span>
<span class="p">)</span>
<span class="nd">@wrap_errors</span>
<span class="k">def</span><span class="w"> </span><span class="nf">infer_from_workflow</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">workspace_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">workflow_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">specification</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">images</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">parameters</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">excluded_fields</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">use_cache</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">enable_profiling</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">workflow_version_id</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Run inference using a workflow specification.</span>

<span class="sd">    Triggers inference from workflow specification at the inference HTTP</span>
<span class="sd">    side. Either (`workspace_name` and `workflow_name`) or `workflow_specification` must be</span>
<span class="sd">    provided. In the first case - definition of workflow will be fetched</span>
<span class="sd">    from Roboflow API, in the latter - `workflow_specification` will be</span>
<span class="sd">    used. `images` and `parameters` will be merged into workflow inputs,</span>
<span class="sd">    the distinction is made to make sure the SDK can easily serialise</span>
<span class="sd">    images and prepare a proper payload. Supported images are numpy arrays,</span>
<span class="sd">    PIL.Image and base64 images, links to images and local paths.</span>
<span class="sd">    `excluded_fields` will be added to request to filter out results</span>
<span class="sd">    of workflow execution at the server side.</span>

<span class="sd">    Args:</span>
<span class="sd">        workspace_name (Optional[str], optional): Name of the workspace containing the workflow. Defaults to None.</span>
<span class="sd">        workflow_name (Optional[str], optional): Name of the workflow. Defaults to None.</span>
<span class="sd">        specification (Optional[dict], optional): Direct workflow specification. Defaults to None.</span>
<span class="sd">        images (Optional[Dict[str, Any]], optional): Images to process. Defaults to None.</span>
<span class="sd">        parameters (Optional[Dict[str, Any]], optional): Additional parameters for the workflow. Defaults to None.</span>
<span class="sd">        excluded_fields (Optional[List[str]], optional): Fields to exclude from results. Defaults to None.</span>
<span class="sd">        use_cache (bool, optional): Whether to use cached results. Defaults to True.</span>
<span class="sd">        enable_profiling (bool, optional): Whether to enable profiling. Defaults to False.</span>

<span class="sd">    Returns:</span>
<span class="sd">        List[Dict[str, Any]]: Results of the workflow execution.</span>

<span class="sd">    Raises:</span>
<span class="sd">        InvalidParameterError: If neither workflow identifiers nor specification is provided.</span>
<span class="sd">        HTTPCallErrorError: If there is an error in the HTTP call.</span>
<span class="sd">        HTTPClientError: If there is an error with the server connection.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_run_workflow</span><span class="p">(</span>
        <span class="n">workspace_name</span><span class="o">=</span><span class="n">workspace_name</span><span class="p">,</span>
        <span class="n">workflow_id</span><span class="o">=</span><span class="n">workflow_name</span><span class="p">,</span>
        <span class="n">specification</span><span class="o">=</span><span class="n">specification</span><span class="p">,</span>
        <span class="n">images</span><span class="o">=</span><span class="n">images</span><span class="p">,</span>
        <span class="n">parameters</span><span class="o">=</span><span class="n">parameters</span><span class="p">,</span>
        <span class="n">excluded_fields</span><span class="o">=</span><span class="n">excluded_fields</span><span class="p">,</span>
        <span class="n">legacy_endpoints</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">use_cache</span><span class="o">=</span><span class="n">use_cache</span><span class="p">,</span>
        <span class="n">enable_profiling</span><span class="o">=</span><span class="n">enable_profiling</span><span class="p">,</span>
        <span class="n">workflow_version_id</span><span class="o">=</span><span class="n">workflow_version_id</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="inference_sdk.http.client.InferenceHTTPClient.infer_from_yolo_world" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">infer_from_yolo_world</span><span class="p">(</span><span class="n">inference_input</span><span class="p">,</span> <span class="n">class_names</span><span class="p">,</span> <span class="n">model_version</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">confidence</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#inference_sdk.http.client.InferenceHTTPClient.infer_from_yolo_world" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Run inference using YOLO-World model.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>inference_input</code>
            </td>
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="inference_sdk.http.entities.ImagesReference">ImagesReference</span>, <span title="typing.List">List</span>[<span title="inference_sdk.http.entities.ImagesReference">ImagesReference</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Input image(s) to run inference on. Can be a single image
reference or a list of image references.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>class_names</code>
            </td>
            <td>
                  <code><span title="typing.List">List</span>[<span title="str">str</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>List of class names to detect in the image(s).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>model_version</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="str">str</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Optional version of YOLO-World model to use. If not specified,
uses the default version.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>confidence</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="float">float</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Optional confidence threshold for detections. If not specified,
uses the model's default threshold.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.List">List</span>[<span title="dict">dict</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>List of dictionaries containing detection results for each input image.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.List">List</span>[<span title="dict">dict</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Each dictionary contains bounding boxes, class labels, and confidence scores</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.List">List</span>[<span title="dict">dict</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>for detected objects.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.HTTPCallErrorError">HTTPCallErrorError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If there is an error in the HTTP call.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.HTTPClientError">HTTPClientError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If there is an error with the server connection.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>inference_sdk/http/client.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">2423</span>
<span class="normal">2424</span>
<span class="normal">2425</span>
<span class="normal">2426</span>
<span class="normal">2427</span>
<span class="normal">2428</span>
<span class="normal">2429</span>
<span class="normal">2430</span>
<span class="normal">2431</span>
<span class="normal">2432</span>
<span class="normal">2433</span>
<span class="normal">2434</span>
<span class="normal">2435</span>
<span class="normal">2436</span>
<span class="normal">2437</span>
<span class="normal">2438</span>
<span class="normal">2439</span>
<span class="normal">2440</span>
<span class="normal">2441</span>
<span class="normal">2442</span>
<span class="normal">2443</span>
<span class="normal">2444</span>
<span class="normal">2445</span>
<span class="normal">2446</span>
<span class="normal">2447</span>
<span class="normal">2448</span>
<span class="normal">2449</span>
<span class="normal">2450</span>
<span class="normal">2451</span>
<span class="normal">2452</span>
<span class="normal">2453</span>
<span class="normal">2454</span>
<span class="normal">2455</span>
<span class="normal">2456</span>
<span class="normal">2457</span>
<span class="normal">2458</span>
<span class="normal">2459</span>
<span class="normal">2460</span>
<span class="normal">2461</span>
<span class="normal">2462</span>
<span class="normal">2463</span>
<span class="normal">2464</span>
<span class="normal">2465</span>
<span class="normal">2466</span>
<span class="normal">2467</span>
<span class="normal">2468</span>
<span class="normal">2469</span>
<span class="normal">2470</span>
<span class="normal">2471</span>
<span class="normal">2472</span>
<span class="normal">2473</span>
<span class="normal">2474</span>
<span class="normal">2475</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@wrap_errors</span>
<span class="k">def</span><span class="w"> </span><span class="nf">infer_from_yolo_world</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">inference_input</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">]],</span>
    <span class="n">class_names</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">model_version</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">confidence</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Run inference using YOLO-World model.</span>

<span class="sd">    Args:</span>
<span class="sd">        inference_input: Input image(s) to run inference on. Can be a single image</span>
<span class="sd">            reference or a list of image references.</span>
<span class="sd">        class_names: List of class names to detect in the image(s).</span>
<span class="sd">        model_version: Optional version of YOLO-World model to use. If not specified,</span>
<span class="sd">            uses the default version.</span>
<span class="sd">        confidence: Optional confidence threshold for detections. If not specified,</span>
<span class="sd">            uses the model&#39;s default threshold.</span>

<span class="sd">    Returns:</span>
<span class="sd">        List of dictionaries containing detection results for each input image.</span>
<span class="sd">        Each dictionary contains bounding boxes, class labels, and confidence scores</span>
<span class="sd">        for detected objects.</span>

<span class="sd">    Raises:</span>
<span class="sd">        HTTPCallErrorError: If there is an error in the HTTP call.</span>
<span class="sd">        HTTPClientError: If there is an error with the server connection.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">encoded_inference_inputs</span> <span class="o">=</span> <span class="n">load_static_inference_input</span><span class="p">(</span>
        <span class="n">inference_input</span><span class="o">=</span><span class="n">inference_input</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">payload</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__initialise_payload</span><span class="p">()</span>
    <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">class_names</span>
    <span class="k">if</span> <span class="n">model_version</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;yolo_world_version_id&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">model_version</span>
    <span class="k">if</span> <span class="n">confidence</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;confidence&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">confidence</span>
    <span class="n">url</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__wrap_url_with_api_key</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__api_url</span><span class="si">}</span><span class="s2">/yolo_world/infer&quot;</span><span class="p">)</span>
    <span class="n">requests_data</span> <span class="o">=</span> <span class="n">prepare_requests_data</span><span class="p">(</span>
        <span class="n">url</span><span class="o">=</span><span class="n">url</span><span class="p">,</span>
        <span class="n">encoded_inference_inputs</span><span class="o">=</span><span class="n">encoded_inference_inputs</span><span class="p">,</span>
        <span class="n">headers</span><span class="o">=</span><span class="n">DEFAULT_HEADERS</span><span class="p">,</span>
        <span class="n">parameters</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">payload</span><span class="o">=</span><span class="n">payload</span><span class="p">,</span>
        <span class="n">max_batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">image_placement</span><span class="o">=</span><span class="n">ImagePlacement</span><span class="o">.</span><span class="n">JSON</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">responses</span> <span class="o">=</span> <span class="n">execute_requests_packages</span><span class="p">(</span>
        <span class="n">requests_data</span><span class="o">=</span><span class="n">requests_data</span><span class="p">,</span>
        <span class="n">request_method</span><span class="o">=</span><span class="n">RequestMethod</span><span class="o">.</span><span class="n">POST</span><span class="p">,</span>
        <span class="n">max_concurrent_requests</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">__inference_configuration</span><span class="o">.</span><span class="n">max_concurrent_requests</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">r</span><span class="o">.</span><span class="n">json</span><span class="p">()</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">responses</span><span class="p">]</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="inference_sdk.http.client.InferenceHTTPClient.infer_from_yolo_world_async" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">infer_from_yolo_world_async</span><span class="p">(</span><span class="n">inference_input</span><span class="p">,</span> <span class="n">class_names</span><span class="p">,</span> <span class="n">model_version</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">confidence</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-async"><code>async</code></small>
  </span>

<a href="#inference_sdk.http.client.InferenceHTTPClient.infer_from_yolo_world_async" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Run inference using YOLO-World model asynchronously.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>inference_input</code>
            </td>
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="inference_sdk.http.entities.ImagesReference">ImagesReference</span>, <span title="typing.List">List</span>[<span title="inference_sdk.http.entities.ImagesReference">ImagesReference</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Input image(s) to run inference on. Can be a single image
reference or a list of image references.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>class_names</code>
            </td>
            <td>
                  <code><span title="typing.List">List</span>[<span title="str">str</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>List of class names to detect in the image(s).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>model_version</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="str">str</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Optional version of YOLO-World model to use. If not specified,
uses the default version.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>confidence</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="float">float</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Optional confidence threshold for detections. If not specified,
uses the model's default threshold.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.List">List</span>[<span title="dict">dict</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>List of dictionaries containing detection results for each input image.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.List">List</span>[<span title="dict">dict</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Each dictionary contains bounding boxes, class labels, and confidence scores</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.List">List</span>[<span title="dict">dict</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>for detected objects.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.HTTPCallErrorError">HTTPCallErrorError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If there is an error in the HTTP call.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.HTTPClientError">HTTPClientError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If there is an error with the server connection.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>inference_sdk/http/client.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">2477</span>
<span class="normal">2478</span>
<span class="normal">2479</span>
<span class="normal">2480</span>
<span class="normal">2481</span>
<span class="normal">2482</span>
<span class="normal">2483</span>
<span class="normal">2484</span>
<span class="normal">2485</span>
<span class="normal">2486</span>
<span class="normal">2487</span>
<span class="normal">2488</span>
<span class="normal">2489</span>
<span class="normal">2490</span>
<span class="normal">2491</span>
<span class="normal">2492</span>
<span class="normal">2493</span>
<span class="normal">2494</span>
<span class="normal">2495</span>
<span class="normal">2496</span>
<span class="normal">2497</span>
<span class="normal">2498</span>
<span class="normal">2499</span>
<span class="normal">2500</span>
<span class="normal">2501</span>
<span class="normal">2502</span>
<span class="normal">2503</span>
<span class="normal">2504</span>
<span class="normal">2505</span>
<span class="normal">2506</span>
<span class="normal">2507</span>
<span class="normal">2508</span>
<span class="normal">2509</span>
<span class="normal">2510</span>
<span class="normal">2511</span>
<span class="normal">2512</span>
<span class="normal">2513</span>
<span class="normal">2514</span>
<span class="normal">2515</span>
<span class="normal">2516</span>
<span class="normal">2517</span>
<span class="normal">2518</span>
<span class="normal">2519</span>
<span class="normal">2520</span>
<span class="normal">2521</span>
<span class="normal">2522</span>
<span class="normal">2523</span>
<span class="normal">2524</span>
<span class="normal">2525</span>
<span class="normal">2526</span>
<span class="normal">2527</span>
<span class="normal">2528</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@wrap_errors_async</span>
<span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">infer_from_yolo_world_async</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">inference_input</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">]],</span>
    <span class="n">class_names</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">model_version</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">confidence</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Run inference using YOLO-World model asynchronously.</span>

<span class="sd">    Args:</span>
<span class="sd">        inference_input: Input image(s) to run inference on. Can be a single image</span>
<span class="sd">            reference or a list of image references.</span>
<span class="sd">        class_names: List of class names to detect in the image(s).</span>
<span class="sd">        model_version: Optional version of YOLO-World model to use. If not specified,</span>
<span class="sd">            uses the default version.</span>
<span class="sd">        confidence: Optional confidence threshold for detections. If not specified,</span>
<span class="sd">            uses the model&#39;s default threshold.</span>

<span class="sd">    Returns:</span>
<span class="sd">        List of dictionaries containing detection results for each input image.</span>
<span class="sd">        Each dictionary contains bounding boxes, class labels, and confidence scores</span>
<span class="sd">        for detected objects.</span>

<span class="sd">    Raises:</span>
<span class="sd">        HTTPCallErrorError: If there is an error in the HTTP call.</span>
<span class="sd">        HTTPClientError: If there is an error with the server connection.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">encoded_inference_inputs</span> <span class="o">=</span> <span class="k">await</span> <span class="n">load_static_inference_input_async</span><span class="p">(</span>
        <span class="n">inference_input</span><span class="o">=</span><span class="n">inference_input</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">payload</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__initialise_payload</span><span class="p">()</span>
    <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">class_names</span>
    <span class="k">if</span> <span class="n">model_version</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;yolo_world_version_id&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">model_version</span>
    <span class="k">if</span> <span class="n">confidence</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;confidence&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">confidence</span>
    <span class="n">url</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__wrap_url_with_api_key</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__api_url</span><span class="si">}</span><span class="s2">/yolo_world/infer&quot;</span><span class="p">)</span>
    <span class="n">requests_data</span> <span class="o">=</span> <span class="n">prepare_requests_data</span><span class="p">(</span>
        <span class="n">url</span><span class="o">=</span><span class="n">url</span><span class="p">,</span>
        <span class="n">encoded_inference_inputs</span><span class="o">=</span><span class="n">encoded_inference_inputs</span><span class="p">,</span>
        <span class="n">headers</span><span class="o">=</span><span class="n">DEFAULT_HEADERS</span><span class="p">,</span>
        <span class="n">parameters</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">payload</span><span class="o">=</span><span class="n">payload</span><span class="p">,</span>
        <span class="n">max_batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">image_placement</span><span class="o">=</span><span class="n">ImagePlacement</span><span class="o">.</span><span class="n">JSON</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="k">await</span> <span class="n">execute_requests_packages_async</span><span class="p">(</span>
        <span class="n">requests_data</span><span class="o">=</span><span class="n">requests_data</span><span class="p">,</span>
        <span class="n">request_method</span><span class="o">=</span><span class="n">RequestMethod</span><span class="o">.</span><span class="n">POST</span><span class="p">,</span>
        <span class="n">max_concurrent_requests</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">__inference_configuration</span><span class="o">.</span><span class="n">max_concurrent_requests</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="inference_sdk.http.client.InferenceHTTPClient.infer_lmm" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">infer_lmm</span><span class="p">(</span><span class="n">inference_input</span><span class="p">,</span> <span class="n">model_id</span><span class="p">,</span> <span class="n">prompt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">model_id_in_path</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

<a href="#inference_sdk.http.client.InferenceHTTPClient.infer_lmm" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Run inference using a Large Multimodal Model (LMM).</p>
<p>This method supports various vision-language models including Florence-2,
Moondream2, SmolVLM, Qwen2.5-VL, Qwen3-VL, and PaliGemma.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>inference_input</code>
            </td>
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="inference_sdk.http.entities.ImagesReference">ImagesReference</span>, <span title="typing.List">List</span>[<span title="inference_sdk.http.entities.ImagesReference">ImagesReference</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Input image(s)
for inference. Can be file paths, URLs, base64 strings, numpy arrays, or PIL images.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>model_id</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The identifier of the LMM model to use. Examples include:
- "florence-2-base", "florence-2-large" for Florence-2
- "moondream2/moondream2_2b_jul24" for Moondream2
- "smolvlm2/smolvlm-2.2b-instruct" for SmolVLM
- "qwen25-vl-7b" for Qwen2.5-VL
- "qwen3vl-2b-instruct" for Qwen3-VL</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>prompt</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="str">str</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Text prompt to guide the model. Defaults to None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>model_id_in_path</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, includes model_id in the URL path
(e.g., /infer/lmm/florence-2-base) which enables path-based routing.
If False (default), model_id is only sent in the request body.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="dict">dict</span>, <span title="typing.List">List</span>[<span title="dict">dict</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Union[dict, List[dict]]: Inference results containing the model response.
The structure depends on the specific model used.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.HTTPCallErrorError">HTTPCallErrorError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If there is an error in the HTTP call.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.HTTPClientError">HTTPClientError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If there is an error with the server connection.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>inference_sdk/http/client.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1600</span>
<span class="normal">1601</span>
<span class="normal">1602</span>
<span class="normal">1603</span>
<span class="normal">1604</span>
<span class="normal">1605</span>
<span class="normal">1606</span>
<span class="normal">1607</span>
<span class="normal">1608</span>
<span class="normal">1609</span>
<span class="normal">1610</span>
<span class="normal">1611</span>
<span class="normal">1612</span>
<span class="normal">1613</span>
<span class="normal">1614</span>
<span class="normal">1615</span>
<span class="normal">1616</span>
<span class="normal">1617</span>
<span class="normal">1618</span>
<span class="normal">1619</span>
<span class="normal">1620</span>
<span class="normal">1621</span>
<span class="normal">1622</span>
<span class="normal">1623</span>
<span class="normal">1624</span>
<span class="normal">1625</span>
<span class="normal">1626</span>
<span class="normal">1627</span>
<span class="normal">1628</span>
<span class="normal">1629</span>
<span class="normal">1630</span>
<span class="normal">1631</span>
<span class="normal">1632</span>
<span class="normal">1633</span>
<span class="normal">1634</span>
<span class="normal">1635</span>
<span class="normal">1636</span>
<span class="normal">1637</span>
<span class="normal">1638</span>
<span class="normal">1639</span>
<span class="normal">1640</span>
<span class="normal">1641</span>
<span class="normal">1642</span>
<span class="normal">1643</span>
<span class="normal">1644</span>
<span class="normal">1645</span>
<span class="normal">1646</span>
<span class="normal">1647</span>
<span class="normal">1648</span>
<span class="normal">1649</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@wrap_errors</span>
<span class="k">def</span><span class="w"> </span><span class="nf">infer_lmm</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">inference_input</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">]],</span>
    <span class="n">model_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">prompt</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">model_id_in_path</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Run inference using a Large Multimodal Model (LMM).</span>

<span class="sd">    This method supports various vision-language models including Florence-2,</span>
<span class="sd">    Moondream2, SmolVLM, Qwen2.5-VL, Qwen3-VL, and PaliGemma.</span>

<span class="sd">    Args:</span>
<span class="sd">        inference_input (Union[ImagesReference, List[ImagesReference]]): Input image(s)</span>
<span class="sd">            for inference. Can be file paths, URLs, base64 strings, numpy arrays, or PIL images.</span>
<span class="sd">        model_id (str): The identifier of the LMM model to use. Examples include:</span>
<span class="sd">            - &quot;florence-2-base&quot;, &quot;florence-2-large&quot; for Florence-2</span>
<span class="sd">            - &quot;moondream2/moondream2_2b_jul24&quot; for Moondream2</span>
<span class="sd">            - &quot;smolvlm2/smolvlm-2.2b-instruct&quot; for SmolVLM</span>
<span class="sd">            - &quot;qwen25-vl-7b&quot; for Qwen2.5-VL</span>
<span class="sd">            - &quot;qwen3vl-2b-instruct&quot; for Qwen3-VL</span>
<span class="sd">        prompt (Optional[str], optional): Text prompt to guide the model. Defaults to None.</span>
<span class="sd">        model_id_in_path (bool, optional): If True, includes model_id in the URL path</span>
<span class="sd">            (e.g., /infer/lmm/florence-2-base) which enables path-based routing.</span>
<span class="sd">            If False (default), model_id is only sent in the request body.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Union[dict, List[dict]]: Inference results containing the model response.</span>
<span class="sd">            The structure depends on the specific model used.</span>

<span class="sd">    Raises:</span>
<span class="sd">        HTTPCallErrorError: If there is an error in the HTTP call.</span>
<span class="sd">        HTTPClientError: If there is an error with the server connection.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">extra_payload</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;model_id&quot;</span><span class="p">:</span> <span class="n">model_id</span><span class="p">}</span>
    <span class="k">if</span> <span class="n">prompt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">extra_payload</span><span class="p">[</span><span class="s2">&quot;prompt&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">prompt</span>

    <span class="k">if</span> <span class="n">model_id_in_path</span><span class="p">:</span>
        <span class="n">endpoint</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;/infer/lmm/</span><span class="si">{</span><span class="n">model_id</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">endpoint</span> <span class="o">=</span> <span class="s2">&quot;/infer/lmm&quot;</span>

    <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_post_images</span><span class="p">(</span>
        <span class="n">inference_input</span><span class="o">=</span><span class="n">inference_input</span><span class="p">,</span>
        <span class="n">endpoint</span><span class="o">=</span><span class="n">endpoint</span><span class="p">,</span>
        <span class="n">extra_payload</span><span class="o">=</span><span class="n">extra_payload</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">result</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="inference_sdk.http.client.InferenceHTTPClient.infer_lmm_async" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">infer_lmm_async</span><span class="p">(</span><span class="n">inference_input</span><span class="p">,</span> <span class="n">model_id</span><span class="p">,</span> <span class="n">prompt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">model_id_in_path</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-async"><code>async</code></small>
  </span>

<a href="#inference_sdk.http.client.InferenceHTTPClient.infer_lmm_async" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Run inference using a Large Multimodal Model (LMM) asynchronously.</p>
<p>This method supports various vision-language models including Florence-2,
Moondream2, SmolVLM, Qwen2.5-VL, Qwen3-VL, and PaliGemma.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>inference_input</code>
            </td>
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="inference_sdk.http.entities.ImagesReference">ImagesReference</span>, <span title="typing.List">List</span>[<span title="inference_sdk.http.entities.ImagesReference">ImagesReference</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Input image(s)
for inference. Can be file paths, URLs, base64 strings, numpy arrays, or PIL images.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>model_id</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The identifier of the LMM model to use.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>prompt</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="str">str</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Text prompt to guide the model. Defaults to None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>model_id_in_path</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, includes model_id in the URL path
(e.g., /infer/lmm/florence-2-base) which enables path-based routing.
If False (default), model_id is only sent in the request body.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="dict">dict</span>, <span title="typing.List">List</span>[<span title="dict">dict</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Union[dict, List[dict]]: Inference results containing the model response.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.HTTPCallErrorError">HTTPCallErrorError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If there is an error in the HTTP call.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.HTTPClientError">HTTPClientError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If there is an error with the server connection.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>inference_sdk/http/client.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1651</span>
<span class="normal">1652</span>
<span class="normal">1653</span>
<span class="normal">1654</span>
<span class="normal">1655</span>
<span class="normal">1656</span>
<span class="normal">1657</span>
<span class="normal">1658</span>
<span class="normal">1659</span>
<span class="normal">1660</span>
<span class="normal">1661</span>
<span class="normal">1662</span>
<span class="normal">1663</span>
<span class="normal">1664</span>
<span class="normal">1665</span>
<span class="normal">1666</span>
<span class="normal">1667</span>
<span class="normal">1668</span>
<span class="normal">1669</span>
<span class="normal">1670</span>
<span class="normal">1671</span>
<span class="normal">1672</span>
<span class="normal">1673</span>
<span class="normal">1674</span>
<span class="normal">1675</span>
<span class="normal">1676</span>
<span class="normal">1677</span>
<span class="normal">1678</span>
<span class="normal">1679</span>
<span class="normal">1680</span>
<span class="normal">1681</span>
<span class="normal">1682</span>
<span class="normal">1683</span>
<span class="normal">1684</span>
<span class="normal">1685</span>
<span class="normal">1686</span>
<span class="normal">1687</span>
<span class="normal">1688</span>
<span class="normal">1689</span>
<span class="normal">1690</span>
<span class="normal">1691</span>
<span class="normal">1692</span>
<span class="normal">1693</span>
<span class="normal">1694</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@wrap_errors_async</span>
<span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">infer_lmm_async</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">inference_input</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">]],</span>
    <span class="n">model_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">prompt</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">model_id_in_path</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Run inference using a Large Multimodal Model (LMM) asynchronously.</span>

<span class="sd">    This method supports various vision-language models including Florence-2,</span>
<span class="sd">    Moondream2, SmolVLM, Qwen2.5-VL, Qwen3-VL, and PaliGemma.</span>

<span class="sd">    Args:</span>
<span class="sd">        inference_input (Union[ImagesReference, List[ImagesReference]]): Input image(s)</span>
<span class="sd">            for inference. Can be file paths, URLs, base64 strings, numpy arrays, or PIL images.</span>
<span class="sd">        model_id (str): The identifier of the LMM model to use.</span>
<span class="sd">        prompt (Optional[str], optional): Text prompt to guide the model. Defaults to None.</span>
<span class="sd">        model_id_in_path (bool, optional): If True, includes model_id in the URL path</span>
<span class="sd">            (e.g., /infer/lmm/florence-2-base) which enables path-based routing.</span>
<span class="sd">            If False (default), model_id is only sent in the request body.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Union[dict, List[dict]]: Inference results containing the model response.</span>

<span class="sd">    Raises:</span>
<span class="sd">        HTTPCallErrorError: If there is an error in the HTTP call.</span>
<span class="sd">        HTTPClientError: If there is an error with the server connection.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">extra_payload</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;model_id&quot;</span><span class="p">:</span> <span class="n">model_id</span><span class="p">}</span>
    <span class="k">if</span> <span class="n">prompt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">extra_payload</span><span class="p">[</span><span class="s2">&quot;prompt&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">prompt</span>

    <span class="k">if</span> <span class="n">model_id_in_path</span><span class="p">:</span>
        <span class="n">endpoint</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;/infer/lmm/</span><span class="si">{</span><span class="n">model_id</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">endpoint</span> <span class="o">=</span> <span class="s2">&quot;/infer/lmm&quot;</span>

    <span class="n">result</span> <span class="o">=</span> <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">_post_images_async</span><span class="p">(</span>
        <span class="n">inference_input</span><span class="o">=</span><span class="n">inference_input</span><span class="p">,</span>
        <span class="n">endpoint</span><span class="o">=</span><span class="n">endpoint</span><span class="p">,</span>
        <span class="n">extra_payload</span><span class="o">=</span><span class="n">extra_payload</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">result</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="inference_sdk.http.client.InferenceHTTPClient.infer_on_stream" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">infer_on_stream</span><span class="p">(</span><span class="n">input_uri</span><span class="p">,</span> <span class="n">model_id</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#inference_sdk.http.client.InferenceHTTPClient.infer_on_stream" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Run inference on a video stream or sequence of images.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>input_uri</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>URI of the input stream or directory.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>model_id</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="str">str</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Model identifier to use for inference. Defaults to None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Yields:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.Tuple">Tuple</span>[<span title="typing.Union">Union</span>[<span title="str">str</span>, <span title="int">int</span>], <span title="numpy.ndarray">ndarray</span>, <span title="dict">dict</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Generator[Tuple[Union[str, int], np.ndarray, dict], None, None]: Tuples of (frame reference, frame data, prediction).</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>inference_sdk/http/client.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">infer_on_stream</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">input_uri</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">model_id</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Generator</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="nb">dict</span><span class="p">],</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Run inference on a video stream or sequence of images.</span>

<span class="sd">    Args:</span>
<span class="sd">        input_uri (str): URI of the input stream or directory.</span>
<span class="sd">        model_id (Optional[str], optional): Model identifier to use for inference. Defaults to None.</span>

<span class="sd">    Yields:</span>
<span class="sd">        Generator[Tuple[Union[str, int], np.ndarray, dict], None, None]: Tuples of (frame reference, frame data, prediction).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">reference</span><span class="p">,</span> <span class="n">frame</span> <span class="ow">in</span> <span class="n">load_stream_inference_input</span><span class="p">(</span>
        <span class="n">input_uri</span><span class="o">=</span><span class="n">input_uri</span><span class="p">,</span>
        <span class="n">image_extensions</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">__inference_configuration</span><span class="o">.</span><span class="n">image_extensions_for_directory_scan</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="n">prediction</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">infer</span><span class="p">(</span>
            <span class="n">inference_input</span><span class="o">=</span><span class="n">frame</span><span class="p">,</span>
            <span class="n">model_id</span><span class="o">=</span><span class="n">model_id</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">yield</span> <span class="n">reference</span><span class="p">,</span> <span class="n">frame</span><span class="p">,</span> <span class="n">prediction</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="inference_sdk.http.client.InferenceHTTPClient.init" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">init</span><span class="p">(</span><span class="n">api_url</span><span class="p">,</span> <span class="n">api_key</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-classmethod"><code>classmethod</code></small>
  </span>

<a href="#inference_sdk.http.client.InferenceHTTPClient.init" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Initialize a new InferenceHTTPClient instance.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>api_url</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The base URL for the inference API.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>api_key</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="str">str</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>API key for authentication. Defaults to None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>InferenceHTTPClient</code></td>            <td>
                  <code><a class="autorefs autorefs-internal" href="#inference_sdk.http.client.InferenceHTTPClient">InferenceHTTPClient</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A new instance of the InferenceHTTPClient.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>inference_sdk/http/client.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@classmethod</span>
<span class="k">def</span><span class="w"> </span><span class="nf">init</span><span class="p">(</span>
    <span class="bp">cls</span><span class="p">,</span>
    <span class="n">api_url</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">api_key</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;InferenceHTTPClient&quot;</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Initialize a new InferenceHTTPClient instance.</span>

<span class="sd">    Args:</span>
<span class="sd">        api_url (str): The base URL for the inference API.</span>
<span class="sd">        api_key (Optional[str], optional): API key for authentication. Defaults to None.</span>

<span class="sd">    Returns:</span>
<span class="sd">        InferenceHTTPClient: A new instance of the InferenceHTTPClient.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span><span class="n">api_url</span><span class="o">=</span><span class="n">api_url</span><span class="p">,</span> <span class="n">api_key</span><span class="o">=</span><span class="n">api_key</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="inference_sdk.http.client.InferenceHTTPClient.list_inference_pipelines" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">list_inference_pipelines</span><span class="p">()</span></code>

<a href="#inference_sdk.http.client.InferenceHTTPClient.list_inference_pipelines" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Lists all active inference pipelines on the server.</p>
<p>This method retrieves information about all currently running inference pipelines
on the server, including their IDs and status.</p>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.List">List</span>[<span title="dict">dict</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>List[dict]: A list of dictionaries containing information about each active
inference pipeline.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.HTTPCallErrorError">HTTPCallErrorError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If there is an error in the HTTP call.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.HTTPClientError">HTTPClientError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If there is an error with the server connection.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>inference_sdk/http/client.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">2632</span>
<span class="normal">2633</span>
<span class="normal">2634</span>
<span class="normal">2635</span>
<span class="normal">2636</span>
<span class="normal">2637</span>
<span class="normal">2638</span>
<span class="normal">2639</span>
<span class="normal">2640</span>
<span class="normal">2641</span>
<span class="normal">2642</span>
<span class="normal">2643</span>
<span class="normal">2644</span>
<span class="normal">2645</span>
<span class="normal">2646</span>
<span class="normal">2647</span>
<span class="normal">2648</span>
<span class="normal">2649</span>
<span class="normal">2650</span>
<span class="normal">2651</span>
<span class="normal">2652</span>
<span class="normal">2653</span>
<span class="normal">2654</span>
<span class="normal">2655</span>
<span class="normal">2656</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@experimental</span><span class="p">(</span>
    <span class="n">info</span><span class="o">=</span><span class="s2">&quot;Video processing in inference server is under development. Breaking changes are possible.&quot;</span>
<span class="p">)</span>
<span class="nd">@wrap_errors</span>
<span class="k">def</span><span class="w"> </span><span class="nf">list_inference_pipelines</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Lists all active inference pipelines on the server.</span>

<span class="sd">    This method retrieves information about all currently running inference pipelines</span>
<span class="sd">    on the server, including their IDs and status.</span>

<span class="sd">    Returns:</span>
<span class="sd">        List[dict]: A list of dictionaries containing information about each active</span>
<span class="sd">            inference pipeline.</span>

<span class="sd">    Raises:</span>
<span class="sd">        HTTPCallErrorError: If there is an error in the HTTP call.</span>
<span class="sd">        HTTPClientError: If there is an error with the server connection.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">payload</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;api_key&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">__api_key</span><span class="p">}</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__api_url</span><span class="si">}</span><span class="s2">/inference_pipelines/list&quot;</span><span class="p">,</span>
        <span class="n">json</span><span class="o">=</span><span class="n">payload</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">api_key_safe_raise_for_status</span><span class="p">(</span><span class="n">response</span><span class="o">=</span><span class="n">response</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="inference_sdk.http.client.InferenceHTTPClient.list_loaded_models" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">list_loaded_models</span><span class="p">()</span></code>

<a href="#inference_sdk.http.client.InferenceHTTPClient.list_loaded_models" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>List all models currently loaded on the server.</p>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>RegisteredModels</code></td>            <td>
                  <code><a class="autorefs autorefs-internal" href="../entities/#inference_sdk.http.entities.RegisteredModels">RegisteredModels</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Information about registered models.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.WrongClientModeError">WrongClientModeError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If not in API v1 mode.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.HTTPCallErrorError">HTTPCallErrorError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If there is an error in the HTTP call.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.HTTPClientError">HTTPClientError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If there is an error with the server connection.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>inference_sdk/http/client.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">924</span>
<span class="normal">925</span>
<span class="normal">926</span>
<span class="normal">927</span>
<span class="normal">928</span>
<span class="normal">929</span>
<span class="normal">930</span>
<span class="normal">931</span>
<span class="normal">932</span>
<span class="normal">933</span>
<span class="normal">934</span>
<span class="normal">935</span>
<span class="normal">936</span>
<span class="normal">937</span>
<span class="normal">938</span>
<span class="normal">939</span>
<span class="normal">940</span>
<span class="normal">941</span>
<span class="normal">942</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@wrap_errors</span>
<span class="k">def</span><span class="w"> </span><span class="nf">list_loaded_models</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">RegisteredModels</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;List all models currently loaded on the server.</span>

<span class="sd">    Returns:</span>
<span class="sd">        RegisteredModels: Information about registered models.</span>

<span class="sd">    Raises:</span>
<span class="sd">        WrongClientModeError: If not in API v1 mode.</span>
<span class="sd">        HTTPCallErrorError: If there is an error in the HTTP call.</span>
<span class="sd">        HTTPClientError: If there is an error with the server connection.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">__ensure_v1_client_mode</span><span class="p">()</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__api_url</span><span class="si">}</span><span class="s2">/model/registry?api_key=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__api_key</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="p">)</span>
    <span class="n">response</span><span class="o">.</span><span class="n">raise_for_status</span><span class="p">()</span>
    <span class="n">response_payload</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">RegisteredModels</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">response_payload</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="inference_sdk.http.client.InferenceHTTPClient.list_loaded_models_async" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">list_loaded_models_async</span><span class="p">()</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-async"><code>async</code></small>
  </span>

<a href="#inference_sdk.http.client.InferenceHTTPClient.list_loaded_models_async" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>List all models currently loaded on the server asynchronously.</p>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>RegisteredModels</code></td>            <td>
                  <code><a class="autorefs autorefs-internal" href="../entities/#inference_sdk.http.entities.RegisteredModels">RegisteredModels</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Information about registered models.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.WrongClientModeError">WrongClientModeError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If not in API v1 mode.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.HTTPCallErrorError">HTTPCallErrorError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If there is an error in the HTTP call.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.HTTPClientError">HTTPClientError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If there is an error with the server connection.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>inference_sdk/http/client.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">944</span>
<span class="normal">945</span>
<span class="normal">946</span>
<span class="normal">947</span>
<span class="normal">948</span>
<span class="normal">949</span>
<span class="normal">950</span>
<span class="normal">951</span>
<span class="normal">952</span>
<span class="normal">953</span>
<span class="normal">954</span>
<span class="normal">955</span>
<span class="normal">956</span>
<span class="normal">957</span>
<span class="normal">958</span>
<span class="normal">959</span>
<span class="normal">960</span>
<span class="normal">961</span>
<span class="normal">962</span>
<span class="normal">963</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@wrap_errors_async</span>
<span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">list_loaded_models_async</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">RegisteredModels</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;List all models currently loaded on the server asynchronously.</span>

<span class="sd">    Returns:</span>
<span class="sd">        RegisteredModels: Information about registered models.</span>

<span class="sd">    Raises:</span>
<span class="sd">        WrongClientModeError: If not in API v1 mode.</span>
<span class="sd">        HTTPCallErrorError: If there is an error in the HTTP call.</span>
<span class="sd">        HTTPClientError: If there is an error with the server connection.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">__ensure_v1_client_mode</span><span class="p">()</span>
    <span class="k">async</span> <span class="k">with</span> <span class="n">aiohttp</span><span class="o">.</span><span class="n">ClientSession</span><span class="p">()</span> <span class="k">as</span> <span class="n">session</span><span class="p">:</span>
        <span class="k">async</span> <span class="k">with</span> <span class="n">session</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__api_url</span><span class="si">}</span><span class="s2">/model/registry?api_key=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__api_key</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span> <span class="k">as</span> <span class="n">response</span><span class="p">:</span>
            <span class="n">response</span><span class="o">.</span><span class="n">raise_for_status</span><span class="p">()</span>
            <span class="n">response_payload</span> <span class="o">=</span> <span class="k">await</span> <span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>
            <span class="k">return</span> <span class="n">RegisteredModels</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">response_payload</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="inference_sdk.http.client.InferenceHTTPClient.load_model" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">load_model</span><span class="p">(</span><span class="n">model_id</span><span class="p">,</span> <span class="n">set_as_default</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

<a href="#inference_sdk.http.client.InferenceHTTPClient.load_model" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Load a model onto the server.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>model_id</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The identifier of the model to load.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>set_as_default</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Whether to set this model as the default. Defaults to False.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>RegisteredModels</code></td>            <td>
                  <code><a class="autorefs autorefs-internal" href="../entities/#inference_sdk.http.entities.RegisteredModels">RegisteredModels</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Updated information about registered models.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.WrongClientModeError">WrongClientModeError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If not in API v1 mode.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.HTTPCallErrorError">HTTPCallErrorError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If there is an error in the HTTP call.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.HTTPClientError">HTTPClientError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If there is an error with the server connection.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>inference_sdk/http/client.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">965</span>
<span class="normal">966</span>
<span class="normal">967</span>
<span class="normal">968</span>
<span class="normal">969</span>
<span class="normal">970</span>
<span class="normal">971</span>
<span class="normal">972</span>
<span class="normal">973</span>
<span class="normal">974</span>
<span class="normal">975</span>
<span class="normal">976</span>
<span class="normal">977</span>
<span class="normal">978</span>
<span class="normal">979</span>
<span class="normal">980</span>
<span class="normal">981</span>
<span class="normal">982</span>
<span class="normal">983</span>
<span class="normal">984</span>
<span class="normal">985</span>
<span class="normal">986</span>
<span class="normal">987</span>
<span class="normal">988</span>
<span class="normal">989</span>
<span class="normal">990</span>
<span class="normal">991</span>
<span class="normal">992</span>
<span class="normal">993</span>
<span class="normal">994</span>
<span class="normal">995</span>
<span class="normal">996</span>
<span class="normal">997</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@wrap_errors</span>
<span class="k">def</span><span class="w"> </span><span class="nf">load_model</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> <span class="n">model_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">set_as_default</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">RegisteredModels</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Load a model onto the server.</span>

<span class="sd">    Args:</span>
<span class="sd">        model_id (str): The identifier of the model to load.</span>
<span class="sd">        set_as_default (bool, optional): Whether to set this model as the default. Defaults to False.</span>

<span class="sd">    Returns:</span>
<span class="sd">        RegisteredModels: Updated information about registered models.</span>

<span class="sd">    Raises:</span>
<span class="sd">        WrongClientModeError: If not in API v1 mode.</span>
<span class="sd">        HTTPCallErrorError: If there is an error in the HTTP call.</span>
<span class="sd">        HTTPClientError: If there is an error with the server connection.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">__ensure_v1_client_mode</span><span class="p">()</span>
    <span class="n">de_aliased_model_id</span> <span class="o">=</span> <span class="n">resolve_roboflow_model_alias</span><span class="p">(</span><span class="n">model_id</span><span class="o">=</span><span class="n">model_id</span><span class="p">)</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">post</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__api_url</span><span class="si">}</span><span class="s2">/model/add&quot;</span><span class="p">,</span>
        <span class="n">json</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;model_id&quot;</span><span class="p">:</span> <span class="n">de_aliased_model_id</span><span class="p">,</span>
            <span class="s2">&quot;api_key&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">__api_key</span><span class="p">,</span>
        <span class="p">},</span>
        <span class="n">headers</span><span class="o">=</span><span class="n">DEFAULT_HEADERS</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">response</span><span class="o">.</span><span class="n">raise_for_status</span><span class="p">()</span>
    <span class="n">response_payload</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">set_as_default</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__selected_model</span> <span class="o">=</span> <span class="n">de_aliased_model_id</span>
    <span class="k">return</span> <span class="n">RegisteredModels</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">response_payload</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="inference_sdk.http.client.InferenceHTTPClient.load_model_async" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">load_model_async</span><span class="p">(</span><span class="n">model_id</span><span class="p">,</span> <span class="n">set_as_default</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-async"><code>async</code></small>
  </span>

<a href="#inference_sdk.http.client.InferenceHTTPClient.load_model_async" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Load a model onto the server asynchronously.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>model_id</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The identifier of the model to load.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>set_as_default</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Whether to set this model as the default. Defaults to False.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>RegisteredModels</code></td>            <td>
                  <code><a class="autorefs autorefs-internal" href="../entities/#inference_sdk.http.entities.RegisteredModels">RegisteredModels</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Updated information about registered models.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.WrongClientModeError">WrongClientModeError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If not in API v1 mode.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.HTTPCallErrorError">HTTPCallErrorError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If there is an error in the HTTP call.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.HTTPClientError">HTTPClientError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If there is an error with the server connection.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>inference_sdk/http/client.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 999</span>
<span class="normal">1000</span>
<span class="normal">1001</span>
<span class="normal">1002</span>
<span class="normal">1003</span>
<span class="normal">1004</span>
<span class="normal">1005</span>
<span class="normal">1006</span>
<span class="normal">1007</span>
<span class="normal">1008</span>
<span class="normal">1009</span>
<span class="normal">1010</span>
<span class="normal">1011</span>
<span class="normal">1012</span>
<span class="normal">1013</span>
<span class="normal">1014</span>
<span class="normal">1015</span>
<span class="normal">1016</span>
<span class="normal">1017</span>
<span class="normal">1018</span>
<span class="normal">1019</span>
<span class="normal">1020</span>
<span class="normal">1021</span>
<span class="normal">1022</span>
<span class="normal">1023</span>
<span class="normal">1024</span>
<span class="normal">1025</span>
<span class="normal">1026</span>
<span class="normal">1027</span>
<span class="normal">1028</span>
<span class="normal">1029</span>
<span class="normal">1030</span>
<span class="normal">1031</span>
<span class="normal">1032</span>
<span class="normal">1033</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@wrap_errors_async</span>
<span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">load_model_async</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> <span class="n">model_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">set_as_default</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">RegisteredModels</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Load a model onto the server asynchronously.</span>

<span class="sd">    Args:</span>
<span class="sd">        model_id (str): The identifier of the model to load.</span>
<span class="sd">        set_as_default (bool, optional): Whether to set this model as the default. Defaults to False.</span>

<span class="sd">    Returns:</span>
<span class="sd">        RegisteredModels: Updated information about registered models.</span>

<span class="sd">    Raises:</span>
<span class="sd">        WrongClientModeError: If not in API v1 mode.</span>
<span class="sd">        HTTPCallErrorError: If there is an error in the HTTP call.</span>
<span class="sd">        HTTPClientError: If there is an error with the server connection.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">__ensure_v1_client_mode</span><span class="p">()</span>
    <span class="n">de_aliased_model_id</span> <span class="o">=</span> <span class="n">resolve_roboflow_model_alias</span><span class="p">(</span><span class="n">model_id</span><span class="o">=</span><span class="n">model_id</span><span class="p">)</span>
    <span class="n">payload</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;model_id&quot;</span><span class="p">:</span> <span class="n">de_aliased_model_id</span><span class="p">,</span>
        <span class="s2">&quot;api_key&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">__api_key</span><span class="p">,</span>
    <span class="p">}</span>
    <span class="k">async</span> <span class="k">with</span> <span class="n">aiohttp</span><span class="o">.</span><span class="n">ClientSession</span><span class="p">()</span> <span class="k">as</span> <span class="n">session</span><span class="p">:</span>
        <span class="k">async</span> <span class="k">with</span> <span class="n">session</span><span class="o">.</span><span class="n">post</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__api_url</span><span class="si">}</span><span class="s2">/model/add&quot;</span><span class="p">,</span>
            <span class="n">json</span><span class="o">=</span><span class="n">payload</span><span class="p">,</span>
            <span class="n">headers</span><span class="o">=</span><span class="n">DEFAULT_HEADERS</span><span class="p">,</span>
        <span class="p">)</span> <span class="k">as</span> <span class="n">response</span><span class="p">:</span>
            <span class="n">response</span><span class="o">.</span><span class="n">raise_for_status</span><span class="p">()</span>
            <span class="n">response_payload</span> <span class="o">=</span> <span class="k">await</span> <span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">set_as_default</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__selected_model</span> <span class="o">=</span> <span class="n">de_aliased_model_id</span>
    <span class="k">return</span> <span class="n">RegisteredModels</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">response_payload</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="inference_sdk.http.client.InferenceHTTPClient.ocr_image" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">ocr_image</span><span class="p">(</span><span class="n">inference_input</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="s1">&#39;doctr&#39;</span><span class="p">,</span> <span class="n">version</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">quantize</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">generate_bounding_boxes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">language_codes</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#inference_sdk.http.client.InferenceHTTPClient.ocr_image" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Run OCR on input image(s).</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>inference_input</code>
            </td>
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="inference_sdk.http.entities.ImagesReference">ImagesReference</span>, <span title="typing.List">List</span>[<span title="inference_sdk.http.entities.ImagesReference">ImagesReference</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Input image(s) for OCR.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>model</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>OCR model to use ('doctr' or 'trocr'). Defaults to "doctr".</p>
              </div>
            </td>
            <td>
                  <code>&#39;doctr&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>version</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="str">str</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Model version to use. Defaults to None.
For trocr, supported versions are: 'trocr-small-printed', 'trocr-base-printed', 'trocr-large-printed'.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>quantize</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="bool">bool</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>(Optional[bool]): flag of EasyOCR to decide which version of model to load</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>generate_bounding_boxes</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="bool">bool</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>(Optional[bool]): flag of some models (like DocTR) to decide if output variant
with sv.Detections(...) compatible bounding boxes should be returned (due to historical reasons, some
old implementations were flattening detected OCR structure into text and were only returning that as
results).</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>language_codes</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="typing.List">List</span>[<span title="str">str</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>(Optional[List[str]]): Parameter of EasyOCR that dictates the code of languages that
model should recognise (leave blank for default for given OCR model version).</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>
        <p>Returns:
    Union[dict, List[dict]]: OCR results for the input image(s).</p>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.HTTPCallErrorError">HTTPCallErrorError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If there is an error in the HTTP call.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.HTTPClientError">HTTPClientError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If there is an error with the server connection.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>inference_sdk/http/client.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1108</span>
<span class="normal">1109</span>
<span class="normal">1110</span>
<span class="normal">1111</span>
<span class="normal">1112</span>
<span class="normal">1113</span>
<span class="normal">1114</span>
<span class="normal">1115</span>
<span class="normal">1116</span>
<span class="normal">1117</span>
<span class="normal">1118</span>
<span class="normal">1119</span>
<span class="normal">1120</span>
<span class="normal">1121</span>
<span class="normal">1122</span>
<span class="normal">1123</span>
<span class="normal">1124</span>
<span class="normal">1125</span>
<span class="normal">1126</span>
<span class="normal">1127</span>
<span class="normal">1128</span>
<span class="normal">1129</span>
<span class="normal">1130</span>
<span class="normal">1131</span>
<span class="normal">1132</span>
<span class="normal">1133</span>
<span class="normal">1134</span>
<span class="normal">1135</span>
<span class="normal">1136</span>
<span class="normal">1137</span>
<span class="normal">1138</span>
<span class="normal">1139</span>
<span class="normal">1140</span>
<span class="normal">1141</span>
<span class="normal">1142</span>
<span class="normal">1143</span>
<span class="normal">1144</span>
<span class="normal">1145</span>
<span class="normal">1146</span>
<span class="normal">1147</span>
<span class="normal">1148</span>
<span class="normal">1149</span>
<span class="normal">1150</span>
<span class="normal">1151</span>
<span class="normal">1152</span>
<span class="normal">1153</span>
<span class="normal">1154</span>
<span class="normal">1155</span>
<span class="normal">1156</span>
<span class="normal">1157</span>
<span class="normal">1158</span>
<span class="normal">1159</span>
<span class="normal">1160</span>
<span class="normal">1161</span>
<span class="normal">1162</span>
<span class="normal">1163</span>
<span class="normal">1164</span>
<span class="normal">1165</span>
<span class="normal">1166</span>
<span class="normal">1167</span>
<span class="normal">1168</span>
<span class="normal">1169</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@wrap_errors</span>
<span class="k">def</span><span class="w"> </span><span class="nf">ocr_image</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">inference_input</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">]],</span>
    <span class="n">model</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;doctr&quot;</span><span class="p">,</span>
    <span class="n">version</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">quantize</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">generate_bounding_boxes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">language_codes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Run OCR on input image(s).</span>

<span class="sd">    Args:</span>
<span class="sd">        inference_input (Union[ImagesReference, List[ImagesReference]]): Input image(s) for OCR.</span>
<span class="sd">        model (str, optional): OCR model to use (&#39;doctr&#39; or &#39;trocr&#39;). Defaults to &quot;doctr&quot;.</span>
<span class="sd">        version (Optional[str], optional): Model version to use. Defaults to None.</span>
<span class="sd">            For trocr, supported versions are: &#39;trocr-small-printed&#39;, &#39;trocr-base-printed&#39;, &#39;trocr-large-printed&#39;.</span>
<span class="sd">        quantize: (Optional[bool]): flag of EasyOCR to decide which version of model to load</span>
<span class="sd">        generate_bounding_boxes: (Optional[bool]): flag of some models (like DocTR) to decide if output variant</span>
<span class="sd">            with sv.Detections(...) compatible bounding boxes should be returned (due to historical reasons, some</span>
<span class="sd">            old implementations were flattening detected OCR structure into text and were only returning that as</span>
<span class="sd">            results).</span>
<span class="sd">        language_codes: (Optional[List[str]]): Parameter of EasyOCR that dictates the code of languages that</span>
<span class="sd">            model should recognise (leave blank for default for given OCR model version).</span>
<span class="sd">    Returns:</span>
<span class="sd">        Union[dict, List[dict]]: OCR results for the input image(s).</span>

<span class="sd">    Raises:</span>
<span class="sd">        HTTPCallErrorError: If there is an error in the HTTP call.</span>
<span class="sd">        HTTPClientError: If there is an error with the server connection.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">encoded_inference_inputs</span> <span class="o">=</span> <span class="n">load_static_inference_input</span><span class="p">(</span>
        <span class="n">inference_input</span><span class="o">=</span><span class="n">inference_input</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">payload</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__initialise_payload</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">version</span><span class="p">:</span>
        <span class="n">key</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="si">}</span><span class="s2">_version_id&quot;</span>
        <span class="n">payload</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">version</span>
    <span class="k">if</span> <span class="n">quantize</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;quantize&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">quantize</span>
    <span class="k">if</span> <span class="n">generate_bounding_boxes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;generate_bounding_boxes&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">generate_bounding_boxes</span>
    <span class="k">if</span> <span class="n">language_codes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;language_codes&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">language_codes</span>
    <span class="n">model_path</span> <span class="o">=</span> <span class="n">resolve_ocr_path</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="n">model</span><span class="p">)</span>
    <span class="n">url</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__wrap_url_with_api_key</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__api_url</span><span class="si">}{</span><span class="n">model_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">requests_data</span> <span class="o">=</span> <span class="n">prepare_requests_data</span><span class="p">(</span>
        <span class="n">url</span><span class="o">=</span><span class="n">url</span><span class="p">,</span>
        <span class="n">encoded_inference_inputs</span><span class="o">=</span><span class="n">encoded_inference_inputs</span><span class="p">,</span>
        <span class="n">headers</span><span class="o">=</span><span class="n">DEFAULT_HEADERS</span><span class="p">,</span>
        <span class="n">parameters</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">payload</span><span class="o">=</span><span class="n">payload</span><span class="p">,</span>
        <span class="n">max_batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">image_placement</span><span class="o">=</span><span class="n">ImagePlacement</span><span class="o">.</span><span class="n">JSON</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">responses</span> <span class="o">=</span> <span class="n">execute_requests_packages</span><span class="p">(</span>
        <span class="n">requests_data</span><span class="o">=</span><span class="n">requests_data</span><span class="p">,</span>
        <span class="n">request_method</span><span class="o">=</span><span class="n">RequestMethod</span><span class="o">.</span><span class="n">POST</span><span class="p">,</span>
        <span class="n">max_concurrent_requests</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">__inference_configuration</span><span class="o">.</span><span class="n">max_concurrent_requests</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">results</span> <span class="o">=</span> <span class="p">[</span><span class="n">r</span><span class="o">.</span><span class="n">json</span><span class="p">()</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">responses</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">unwrap_single_element_list</span><span class="p">(</span><span class="n">sequence</span><span class="o">=</span><span class="n">results</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="inference_sdk.http.client.InferenceHTTPClient.ocr_image_async" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">ocr_image_async</span><span class="p">(</span><span class="n">inference_input</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="s1">&#39;doctr&#39;</span><span class="p">,</span> <span class="n">version</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">quantize</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">generate_bounding_boxes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">language_codes</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-async"><code>async</code></small>
  </span>

<a href="#inference_sdk.http.client.InferenceHTTPClient.ocr_image_async" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Run OCR on input image(s) asynchronously.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>inference_input</code>
            </td>
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="inference_sdk.http.entities.ImagesReference">ImagesReference</span>, <span title="typing.List">List</span>[<span title="inference_sdk.http.entities.ImagesReference">ImagesReference</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Input image(s) for OCR.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>model</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>OCR model to use ('doctr' or 'trocr'). Defaults to "doctr".</p>
              </div>
            </td>
            <td>
                  <code>&#39;doctr&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>version</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="str">str</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Model version to use. Defaults to None.
For trocr, supported versions are: 'trocr-small-printed', 'trocr-base-printed', 'trocr-large-printed'.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>quantize</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="bool">bool</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>(Optional[bool]): flag of EasyOCR to decide which version of model to load</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>generate_bounding_boxes</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="bool">bool</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>(Optional[bool]): flag of some models (like DocTR) to decide if output variant
with sv.Detections(...) compatible bounding boxes should be returned (due to historical reasons, some
old implementations were flattening detected OCR structure into text and were only returning that as
results).</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>language_codes</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="typing.List">List</span>[<span title="str">str</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>(Optional[List[str]]): Parameter of EasyOCR that dictates the code of languages that
model should recognise (leave blank for default for given OCR model version).</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>
        <p>Returns:
    Union[dict, List[dict]]: OCR results for the input image(s).</p>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.HTTPCallErrorError">HTTPCallErrorError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If there is an error in the HTTP call.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.HTTPClientError">HTTPClientError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If there is an error with the server connection.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>inference_sdk/http/client.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1171</span>
<span class="normal">1172</span>
<span class="normal">1173</span>
<span class="normal">1174</span>
<span class="normal">1175</span>
<span class="normal">1176</span>
<span class="normal">1177</span>
<span class="normal">1178</span>
<span class="normal">1179</span>
<span class="normal">1180</span>
<span class="normal">1181</span>
<span class="normal">1182</span>
<span class="normal">1183</span>
<span class="normal">1184</span>
<span class="normal">1185</span>
<span class="normal">1186</span>
<span class="normal">1187</span>
<span class="normal">1188</span>
<span class="normal">1189</span>
<span class="normal">1190</span>
<span class="normal">1191</span>
<span class="normal">1192</span>
<span class="normal">1193</span>
<span class="normal">1194</span>
<span class="normal">1195</span>
<span class="normal">1196</span>
<span class="normal">1197</span>
<span class="normal">1198</span>
<span class="normal">1199</span>
<span class="normal">1200</span>
<span class="normal">1201</span>
<span class="normal">1202</span>
<span class="normal">1203</span>
<span class="normal">1204</span>
<span class="normal">1205</span>
<span class="normal">1206</span>
<span class="normal">1207</span>
<span class="normal">1208</span>
<span class="normal">1209</span>
<span class="normal">1210</span>
<span class="normal">1211</span>
<span class="normal">1212</span>
<span class="normal">1213</span>
<span class="normal">1214</span>
<span class="normal">1215</span>
<span class="normal">1216</span>
<span class="normal">1217</span>
<span class="normal">1218</span>
<span class="normal">1219</span>
<span class="normal">1220</span>
<span class="normal">1221</span>
<span class="normal">1222</span>
<span class="normal">1223</span>
<span class="normal">1224</span>
<span class="normal">1225</span>
<span class="normal">1226</span>
<span class="normal">1227</span>
<span class="normal">1228</span>
<span class="normal">1229</span>
<span class="normal">1230</span>
<span class="normal">1231</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@wrap_errors_async</span>
<span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">ocr_image_async</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">inference_input</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">]],</span>
    <span class="n">model</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;doctr&quot;</span><span class="p">,</span>
    <span class="n">version</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">quantize</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">generate_bounding_boxes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">language_codes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Run OCR on input image(s) asynchronously.</span>

<span class="sd">    Args:</span>
<span class="sd">        inference_input (Union[ImagesReference, List[ImagesReference]]): Input image(s) for OCR.</span>
<span class="sd">        model (str, optional): OCR model to use (&#39;doctr&#39; or &#39;trocr&#39;). Defaults to &quot;doctr&quot;.</span>
<span class="sd">        version (Optional[str], optional): Model version to use. Defaults to None.</span>
<span class="sd">            For trocr, supported versions are: &#39;trocr-small-printed&#39;, &#39;trocr-base-printed&#39;, &#39;trocr-large-printed&#39;.</span>
<span class="sd">        quantize: (Optional[bool]): flag of EasyOCR to decide which version of model to load</span>
<span class="sd">        generate_bounding_boxes: (Optional[bool]): flag of some models (like DocTR) to decide if output variant</span>
<span class="sd">            with sv.Detections(...) compatible bounding boxes should be returned (due to historical reasons, some</span>
<span class="sd">            old implementations were flattening detected OCR structure into text and were only returning that as</span>
<span class="sd">            results).</span>
<span class="sd">        language_codes: (Optional[List[str]]): Parameter of EasyOCR that dictates the code of languages that</span>
<span class="sd">            model should recognise (leave blank for default for given OCR model version).</span>
<span class="sd">    Returns:</span>
<span class="sd">        Union[dict, List[dict]]: OCR results for the input image(s).</span>

<span class="sd">    Raises:</span>
<span class="sd">        HTTPCallErrorError: If there is an error in the HTTP call.</span>
<span class="sd">        HTTPClientError: If there is an error with the server connection.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">encoded_inference_inputs</span> <span class="o">=</span> <span class="k">await</span> <span class="n">load_static_inference_input_async</span><span class="p">(</span>
        <span class="n">inference_input</span><span class="o">=</span><span class="n">inference_input</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">payload</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__initialise_payload</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">version</span><span class="p">:</span>
        <span class="n">key</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="si">}</span><span class="s2">_version_id&quot;</span>
        <span class="n">payload</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">version</span>
    <span class="k">if</span> <span class="n">quantize</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;quantize&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">quantize</span>
    <span class="k">if</span> <span class="n">generate_bounding_boxes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;generate_bounding_boxes&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">generate_bounding_boxes</span>
    <span class="k">if</span> <span class="n">language_codes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;language_codes&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">language_codes</span>
    <span class="n">model_path</span> <span class="o">=</span> <span class="n">resolve_ocr_path</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="n">model</span><span class="p">)</span>
    <span class="n">url</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__wrap_url_with_api_key</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__api_url</span><span class="si">}{</span><span class="n">model_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">requests_data</span> <span class="o">=</span> <span class="n">prepare_requests_data</span><span class="p">(</span>
        <span class="n">url</span><span class="o">=</span><span class="n">url</span><span class="p">,</span>
        <span class="n">encoded_inference_inputs</span><span class="o">=</span><span class="n">encoded_inference_inputs</span><span class="p">,</span>
        <span class="n">headers</span><span class="o">=</span><span class="n">DEFAULT_HEADERS</span><span class="p">,</span>
        <span class="n">parameters</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">payload</span><span class="o">=</span><span class="n">payload</span><span class="p">,</span>
        <span class="n">max_batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">image_placement</span><span class="o">=</span><span class="n">ImagePlacement</span><span class="o">.</span><span class="n">JSON</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">responses</span> <span class="o">=</span> <span class="k">await</span> <span class="n">execute_requests_packages_async</span><span class="p">(</span>
        <span class="n">requests_data</span><span class="o">=</span><span class="n">requests_data</span><span class="p">,</span>
        <span class="n">request_method</span><span class="o">=</span><span class="n">RequestMethod</span><span class="o">.</span><span class="n">POST</span><span class="p">,</span>
        <span class="n">max_concurrent_requests</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">__inference_configuration</span><span class="o">.</span><span class="n">max_concurrent_requests</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">unwrap_single_element_list</span><span class="p">(</span><span class="n">sequence</span><span class="o">=</span><span class="n">responses</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="inference_sdk.http.client.InferenceHTTPClient.pause_inference_pipeline" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">pause_inference_pipeline</span><span class="p">(</span><span class="n">pipeline_id</span><span class="p">)</span></code>

<a href="#inference_sdk.http.client.InferenceHTTPClient.pause_inference_pipeline" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Pauses a running inference pipeline.</p>
<p>Sends a request to pause the specified inference pipeline. The pipeline must be
currently running for this operation to succeed.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>pipeline_id</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The unique identifier of the inference pipeline to pause.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>dict</code></td>            <td>
                  <code><span title="dict">dict</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A dictionary containing the response from the server about the pause operation.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.HTTPCallErrorError">HTTPCallErrorError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If there is an error in the HTTP call.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.HTTPClientError">HTTPClientError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If there is an error with the server connection.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><span title="ValueError">ValueError</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If pipeline_id is empty or None.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>inference_sdk/http/client.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">2685</span>
<span class="normal">2686</span>
<span class="normal">2687</span>
<span class="normal">2688</span>
<span class="normal">2689</span>
<span class="normal">2690</span>
<span class="normal">2691</span>
<span class="normal">2692</span>
<span class="normal">2693</span>
<span class="normal">2694</span>
<span class="normal">2695</span>
<span class="normal">2696</span>
<span class="normal">2697</span>
<span class="normal">2698</span>
<span class="normal">2699</span>
<span class="normal">2700</span>
<span class="normal">2701</span>
<span class="normal">2702</span>
<span class="normal">2703</span>
<span class="normal">2704</span>
<span class="normal">2705</span>
<span class="normal">2706</span>
<span class="normal">2707</span>
<span class="normal">2708</span>
<span class="normal">2709</span>
<span class="normal">2710</span>
<span class="normal">2711</span>
<span class="normal">2712</span>
<span class="normal">2713</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@experimental</span><span class="p">(</span>
    <span class="n">info</span><span class="o">=</span><span class="s2">&quot;Video processing in inference server is under development. Breaking changes are possible.&quot;</span>
<span class="p">)</span>
<span class="nd">@wrap_errors</span>
<span class="k">def</span><span class="w"> </span><span class="nf">pause_inference_pipeline</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pipeline_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Pauses a running inference pipeline.</span>

<span class="sd">    Sends a request to pause the specified inference pipeline. The pipeline must be</span>
<span class="sd">    currently running for this operation to succeed.</span>

<span class="sd">    Args:</span>
<span class="sd">        pipeline_id: The unique identifier of the inference pipeline to pause.</span>

<span class="sd">    Returns:</span>
<span class="sd">        dict: A dictionary containing the response from the server about the pause operation.</span>

<span class="sd">    Raises:</span>
<span class="sd">        HTTPCallErrorError: If there is an error in the HTTP call.</span>
<span class="sd">        HTTPClientError: If there is an error with the server connection.</span>
<span class="sd">        ValueError: If pipeline_id is empty or None.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_ensure_pipeline_id_not_empty</span><span class="p">(</span><span class="n">pipeline_id</span><span class="o">=</span><span class="n">pipeline_id</span><span class="p">)</span>
    <span class="n">payload</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;api_key&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">__api_key</span><span class="p">}</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">post</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__api_url</span><span class="si">}</span><span class="s2">/inference_pipelines/</span><span class="si">{</span><span class="n">pipeline_id</span><span class="si">}</span><span class="s2">/pause&quot;</span><span class="p">,</span>
        <span class="n">json</span><span class="o">=</span><span class="n">payload</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">api_key_safe_raise_for_status</span><span class="p">(</span><span class="n">response</span><span class="o">=</span><span class="n">response</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="inference_sdk.http.client.InferenceHTTPClient.resume_inference_pipeline" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">resume_inference_pipeline</span><span class="p">(</span><span class="n">pipeline_id</span><span class="p">)</span></code>

<a href="#inference_sdk.http.client.InferenceHTTPClient.resume_inference_pipeline" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Resumes a paused inference pipeline.</p>
<p>Sends a request to resume the specified inference pipeline. The pipeline must be
currently paused for this operation to succeed.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>pipeline_id</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The unique identifier of the inference pipeline to resume.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>dict</code></td>            <td>
                  <code><span title="dict">dict</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A dictionary containing the response from the server about the resume operation.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.HTTPCallErrorError">HTTPCallErrorError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If there is an error in the HTTP call.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.HTTPClientError">HTTPClientError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If there is an error with the server connection.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><span title="ValueError">ValueError</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If pipeline_id is empty or None.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>inference_sdk/http/client.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">2715</span>
<span class="normal">2716</span>
<span class="normal">2717</span>
<span class="normal">2718</span>
<span class="normal">2719</span>
<span class="normal">2720</span>
<span class="normal">2721</span>
<span class="normal">2722</span>
<span class="normal">2723</span>
<span class="normal">2724</span>
<span class="normal">2725</span>
<span class="normal">2726</span>
<span class="normal">2727</span>
<span class="normal">2728</span>
<span class="normal">2729</span>
<span class="normal">2730</span>
<span class="normal">2731</span>
<span class="normal">2732</span>
<span class="normal">2733</span>
<span class="normal">2734</span>
<span class="normal">2735</span>
<span class="normal">2736</span>
<span class="normal">2737</span>
<span class="normal">2738</span>
<span class="normal">2739</span>
<span class="normal">2740</span>
<span class="normal">2741</span>
<span class="normal">2742</span>
<span class="normal">2743</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@experimental</span><span class="p">(</span>
    <span class="n">info</span><span class="o">=</span><span class="s2">&quot;Video processing in inference server is under development. Breaking changes are possible.&quot;</span>
<span class="p">)</span>
<span class="nd">@wrap_errors</span>
<span class="k">def</span><span class="w"> </span><span class="nf">resume_inference_pipeline</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pipeline_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Resumes a paused inference pipeline.</span>

<span class="sd">    Sends a request to resume the specified inference pipeline. The pipeline must be</span>
<span class="sd">    currently paused for this operation to succeed.</span>

<span class="sd">    Args:</span>
<span class="sd">        pipeline_id: The unique identifier of the inference pipeline to resume.</span>

<span class="sd">    Returns:</span>
<span class="sd">        dict: A dictionary containing the response from the server about the resume operation.</span>

<span class="sd">    Raises:</span>
<span class="sd">        HTTPCallErrorError: If there is an error in the HTTP call.</span>
<span class="sd">        HTTPClientError: If there is an error with the server connection.</span>
<span class="sd">        ValueError: If pipeline_id is empty or None.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_ensure_pipeline_id_not_empty</span><span class="p">(</span><span class="n">pipeline_id</span><span class="o">=</span><span class="n">pipeline_id</span><span class="p">)</span>
    <span class="n">payload</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;api_key&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">__api_key</span><span class="p">}</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">post</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__api_url</span><span class="si">}</span><span class="s2">/inference_pipelines/</span><span class="si">{</span><span class="n">pipeline_id</span><span class="si">}</span><span class="s2">/resume&quot;</span><span class="p">,</span>
        <span class="n">json</span><span class="o">=</span><span class="n">payload</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">api_key_safe_raise_for_status</span><span class="p">(</span><span class="n">response</span><span class="o">=</span><span class="n">response</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="inference_sdk.http.client.InferenceHTTPClient.run_workflow" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">run_workflow</span><span class="p">(</span><span class="n">workspace_name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">workflow_id</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">specification</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">images</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">parameters</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">excluded_fields</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">use_cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">enable_profiling</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">workflow_version_id</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#inference_sdk.http.client.InferenceHTTPClient.run_workflow" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Run inference using a workflow specification.</p>
<p>Triggers inference from workflow specification at the inference HTTP
side. Either (<code>workspace_name</code> and <code>workflow_id</code>) or <code>workflow_specification</code> must be
provided. In the first case - definition of workflow will be fetched
from Roboflow API, in the latter - <code>workflow_specification</code> will be
used. <code>images</code> and <code>parameters</code> will be merged into workflow inputs,
the distinction is made to make sure the SDK can easily serialise
images and prepare a proper payload. Supported images are numpy arrays,
PIL.Image and base64 images, links to images and local paths.
<code>excluded_fields</code> will be added to request to filter out results
of workflow execution at the server side.</p>
<p><strong>Important!</strong>
Method is not compatible with inference server &lt;=0.9.18. Please migrate to newer version of
the server before end of Q2 2024. Until that is done - use old method: infer_from_workflow(...).</p>


<details class="note" open>
  <summary>Note</summary>
  <p>Method is not compatible with inference server &lt;=0.9.18. Please migrate to newer version of
the server before end of Q2 2024. Until that is done - use old method: infer_from_workflow(...).</p>
</details>

<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>workspace_name</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="str">str</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Name of the workspace containing the workflow. Defaults to None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>workflow_id</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="str">str</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>ID of the workflow. Defaults to None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>specification</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="dict">dict</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Direct workflow specification. Defaults to None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>images</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="typing.Dict">Dict</span>[<span title="str">str</span>, <span title="typing.Any">Any</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Images to process. Defaults to None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>parameters</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="typing.Dict">Dict</span>[<span title="str">str</span>, <span title="typing.Any">Any</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Additional parameters for the workflow. Defaults to None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>excluded_fields</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="typing.List">List</span>[<span title="str">str</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Fields to exclude from results. Defaults to None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>use_cache</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Whether to use cached results. Defaults to True.</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>enable_profiling</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Whether to enable profiling. Defaults to False.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.List">List</span>[<span title="typing.Dict">Dict</span>[<span title="str">str</span>, <span title="typing.Any">Any</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>List[Dict[str, Any]]: Results of the workflow execution.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.InvalidParameterError">InvalidParameterError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If neither workflow identifiers nor specification is provided.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.HTTPCallErrorError">HTTPCallErrorError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If there is an error in the HTTP call.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.HTTPClientError">HTTPClientError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If there is an error with the server connection.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>inference_sdk/http/client.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">2254</span>
<span class="normal">2255</span>
<span class="normal">2256</span>
<span class="normal">2257</span>
<span class="normal">2258</span>
<span class="normal">2259</span>
<span class="normal">2260</span>
<span class="normal">2261</span>
<span class="normal">2262</span>
<span class="normal">2263</span>
<span class="normal">2264</span>
<span class="normal">2265</span>
<span class="normal">2266</span>
<span class="normal">2267</span>
<span class="normal">2268</span>
<span class="normal">2269</span>
<span class="normal">2270</span>
<span class="normal">2271</span>
<span class="normal">2272</span>
<span class="normal">2273</span>
<span class="normal">2274</span>
<span class="normal">2275</span>
<span class="normal">2276</span>
<span class="normal">2277</span>
<span class="normal">2278</span>
<span class="normal">2279</span>
<span class="normal">2280</span>
<span class="normal">2281</span>
<span class="normal">2282</span>
<span class="normal">2283</span>
<span class="normal">2284</span>
<span class="normal">2285</span>
<span class="normal">2286</span>
<span class="normal">2287</span>
<span class="normal">2288</span>
<span class="normal">2289</span>
<span class="normal">2290</span>
<span class="normal">2291</span>
<span class="normal">2292</span>
<span class="normal">2293</span>
<span class="normal">2294</span>
<span class="normal">2295</span>
<span class="normal">2296</span>
<span class="normal">2297</span>
<span class="normal">2298</span>
<span class="normal">2299</span>
<span class="normal">2300</span>
<span class="normal">2301</span>
<span class="normal">2302</span>
<span class="normal">2303</span>
<span class="normal">2304</span>
<span class="normal">2305</span>
<span class="normal">2306</span>
<span class="normal">2307</span>
<span class="normal">2308</span>
<span class="normal">2309</span>
<span class="normal">2310</span>
<span class="normal">2311</span>
<span class="normal">2312</span>
<span class="normal">2313</span>
<span class="normal">2314</span>
<span class="normal">2315</span>
<span class="normal">2316</span>
<span class="normal">2317</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@wrap_errors</span>
<span class="k">def</span><span class="w"> </span><span class="nf">run_workflow</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">workspace_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">workflow_id</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">specification</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">images</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">parameters</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">excluded_fields</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">use_cache</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">enable_profiling</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">workflow_version_id</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Run inference using a workflow specification.</span>

<span class="sd">    Triggers inference from workflow specification at the inference HTTP</span>
<span class="sd">    side. Either (`workspace_name` and `workflow_id`) or `workflow_specification` must be</span>
<span class="sd">    provided. In the first case - definition of workflow will be fetched</span>
<span class="sd">    from Roboflow API, in the latter - `workflow_specification` will be</span>
<span class="sd">    used. `images` and `parameters` will be merged into workflow inputs,</span>
<span class="sd">    the distinction is made to make sure the SDK can easily serialise</span>
<span class="sd">    images and prepare a proper payload. Supported images are numpy arrays,</span>
<span class="sd">    PIL.Image and base64 images, links to images and local paths.</span>
<span class="sd">    `excluded_fields` will be added to request to filter out results</span>
<span class="sd">    of workflow execution at the server side.</span>

<span class="sd">    **Important!**</span>
<span class="sd">    Method is not compatible with inference server &lt;=0.9.18. Please migrate to newer version of</span>
<span class="sd">    the server before end of Q2 2024. Until that is done - use old method: infer_from_workflow(...).</span>

<span class="sd">    Note:</span>
<span class="sd">        Method is not compatible with inference server &lt;=0.9.18. Please migrate to newer version of</span>
<span class="sd">        the server before end of Q2 2024. Until that is done - use old method: infer_from_workflow(...).</span>

<span class="sd">    Args:</span>
<span class="sd">        workspace_name (Optional[str], optional): Name of the workspace containing the workflow. Defaults to None.</span>
<span class="sd">        workflow_id (Optional[str], optional): ID of the workflow. Defaults to None.</span>
<span class="sd">        specification (Optional[dict], optional): Direct workflow specification. Defaults to None.</span>
<span class="sd">        images (Optional[Dict[str, Any]], optional): Images to process. Defaults to None.</span>
<span class="sd">        parameters (Optional[Dict[str, Any]], optional): Additional parameters for the workflow. Defaults to None.</span>
<span class="sd">        excluded_fields (Optional[List[str]], optional): Fields to exclude from results. Defaults to None.</span>
<span class="sd">        use_cache (bool, optional): Whether to use cached results. Defaults to True.</span>
<span class="sd">        enable_profiling (bool, optional): Whether to enable profiling. Defaults to False.</span>

<span class="sd">    Returns:</span>
<span class="sd">        List[Dict[str, Any]]: Results of the workflow execution.</span>

<span class="sd">    Raises:</span>
<span class="sd">        InvalidParameterError: If neither workflow identifiers nor specification is provided.</span>
<span class="sd">        HTTPCallErrorError: If there is an error in the HTTP call.</span>
<span class="sd">        HTTPClientError: If there is an error with the server connection.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_run_workflow</span><span class="p">(</span>
        <span class="n">workspace_name</span><span class="o">=</span><span class="n">workspace_name</span><span class="p">,</span>
        <span class="n">workflow_id</span><span class="o">=</span><span class="n">workflow_id</span><span class="p">,</span>
        <span class="n">specification</span><span class="o">=</span><span class="n">specification</span><span class="p">,</span>
        <span class="n">images</span><span class="o">=</span><span class="n">images</span><span class="p">,</span>
        <span class="n">parameters</span><span class="o">=</span><span class="n">parameters</span><span class="p">,</span>
        <span class="n">excluded_fields</span><span class="o">=</span><span class="n">excluded_fields</span><span class="p">,</span>
        <span class="n">legacy_endpoints</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">use_cache</span><span class="o">=</span><span class="n">use_cache</span><span class="p">,</span>
        <span class="n">enable_profiling</span><span class="o">=</span><span class="n">enable_profiling</span><span class="p">,</span>
        <span class="n">workflow_version_id</span><span class="o">=</span><span class="n">workflow_version_id</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="inference_sdk.http.client.InferenceHTTPClient.sam2_segment_image" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">sam2_segment_image</span><span class="p">(</span><span class="n">inference_input</span><span class="p">,</span> <span class="n">prompts</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">sam2_version_id</span><span class="o">=</span><span class="s1">&#39;hiera_tiny&#39;</span><span class="p">,</span> <span class="n">multimask_output</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">mask_input_format</span><span class="o">=</span><span class="s1">&#39;json&#39;</span><span class="p">)</span></code>

<a href="#inference_sdk.http.client.InferenceHTTPClient.sam2_segment_image" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Run Segment Anything 2 (SAM2) segmentation on input image(s).</p>
<p>This method performs instance segmentation using SAM2, which can segment
objects based on point or box prompts.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>inference_input</code>
            </td>
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="inference_sdk.http.entities.ImagesReference">ImagesReference</span>, <span title="typing.List">List</span>[<span title="inference_sdk.http.entities.ImagesReference">ImagesReference</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Input image(s)
for segmentation. Can be file paths, URLs, base64 strings, numpy arrays,
or PIL images.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>prompts</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="typing.List">List</span>[<span title="dict">dict</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>List of prompt dictionaries. Each prompt
can contain:
- "box": {"x": float, "y": float, "width": float, "height": float}
- "points": [{"x": float, "y": float, "positive": bool}, ...]
Defaults to None (automatic segmentation).</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>sam2_version_id</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Version of SAM2 model to use. Options are
"hiera_large", "hiera_small", "hiera_tiny", "hiera_b_plus".
Defaults to "hiera_tiny".</p>
              </div>
            </td>
            <td>
                  <code>&#39;hiera_tiny&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>multimask_output</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Whether to output multiple masks per prompt.
Defaults to True.</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>mask_input_format</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Format for mask output. Defaults to "json".</p>
              </div>
            </td>
            <td>
                  <code>&#39;json&#39;</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="dict">dict</span>, <span title="typing.List">List</span>[<span title="dict">dict</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Union[dict, List[dict]]: Segmentation results containing predictions with masks,
confidence scores, and bounding boxes.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.HTTPCallErrorError">HTTPCallErrorError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If there is an error in the HTTP call.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.HTTPClientError">HTTPClientError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If there is an error with the server connection.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>inference_sdk/http/client.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1762</span>
<span class="normal">1763</span>
<span class="normal">1764</span>
<span class="normal">1765</span>
<span class="normal">1766</span>
<span class="normal">1767</span>
<span class="normal">1768</span>
<span class="normal">1769</span>
<span class="normal">1770</span>
<span class="normal">1771</span>
<span class="normal">1772</span>
<span class="normal">1773</span>
<span class="normal">1774</span>
<span class="normal">1775</span>
<span class="normal">1776</span>
<span class="normal">1777</span>
<span class="normal">1778</span>
<span class="normal">1779</span>
<span class="normal">1780</span>
<span class="normal">1781</span>
<span class="normal">1782</span>
<span class="normal">1783</span>
<span class="normal">1784</span>
<span class="normal">1785</span>
<span class="normal">1786</span>
<span class="normal">1787</span>
<span class="normal">1788</span>
<span class="normal">1789</span>
<span class="normal">1790</span>
<span class="normal">1791</span>
<span class="normal">1792</span>
<span class="normal">1793</span>
<span class="normal">1794</span>
<span class="normal">1795</span>
<span class="normal">1796</span>
<span class="normal">1797</span>
<span class="normal">1798</span>
<span class="normal">1799</span>
<span class="normal">1800</span>
<span class="normal">1801</span>
<span class="normal">1802</span>
<span class="normal">1803</span>
<span class="normal">1804</span>
<span class="normal">1805</span>
<span class="normal">1806</span>
<span class="normal">1807</span>
<span class="normal">1808</span>
<span class="normal">1809</span>
<span class="normal">1810</span>
<span class="normal">1811</span>
<span class="normal">1812</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@wrap_errors</span>
<span class="k">def</span><span class="w"> </span><span class="nf">sam2_segment_image</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">inference_input</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">]],</span>
    <span class="n">prompts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">sam2_version_id</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;hiera_tiny&quot;</span><span class="p">,</span>
    <span class="n">multimask_output</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">mask_input_format</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;json&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Run Segment Anything 2 (SAM2) segmentation on input image(s).</span>

<span class="sd">    This method performs instance segmentation using SAM2, which can segment</span>
<span class="sd">    objects based on point or box prompts.</span>

<span class="sd">    Args:</span>
<span class="sd">        inference_input (Union[ImagesReference, List[ImagesReference]]): Input image(s)</span>
<span class="sd">            for segmentation. Can be file paths, URLs, base64 strings, numpy arrays,</span>
<span class="sd">            or PIL images.</span>
<span class="sd">        prompts (Optional[List[dict]], optional): List of prompt dictionaries. Each prompt</span>
<span class="sd">            can contain:</span>
<span class="sd">            - &quot;box&quot;: {&quot;x&quot;: float, &quot;y&quot;: float, &quot;width&quot;: float, &quot;height&quot;: float}</span>
<span class="sd">            - &quot;points&quot;: [{&quot;x&quot;: float, &quot;y&quot;: float, &quot;positive&quot;: bool}, ...]</span>
<span class="sd">            Defaults to None (automatic segmentation).</span>
<span class="sd">        sam2_version_id (str, optional): Version of SAM2 model to use. Options are</span>
<span class="sd">            &quot;hiera_large&quot;, &quot;hiera_small&quot;, &quot;hiera_tiny&quot;, &quot;hiera_b_plus&quot;.</span>
<span class="sd">            Defaults to &quot;hiera_tiny&quot;.</span>
<span class="sd">        multimask_output (bool, optional): Whether to output multiple masks per prompt.</span>
<span class="sd">            Defaults to True.</span>
<span class="sd">        mask_input_format (str, optional): Format for mask output. Defaults to &quot;json&quot;.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Union[dict, List[dict]]: Segmentation results containing predictions with masks,</span>
<span class="sd">            confidence scores, and bounding boxes.</span>

<span class="sd">    Raises:</span>
<span class="sd">        HTTPCallErrorError: If there is an error in the HTTP call.</span>
<span class="sd">        HTTPClientError: If there is an error with the server connection.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">extra_payload</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;sam2_version_id&quot;</span><span class="p">:</span> <span class="n">sam2_version_id</span><span class="p">,</span>
        <span class="s2">&quot;multimask_output&quot;</span><span class="p">:</span> <span class="n">multimask_output</span><span class="p">,</span>
        <span class="s2">&quot;format&quot;</span><span class="p">:</span> <span class="n">mask_input_format</span><span class="p">,</span>
    <span class="p">}</span>
    <span class="k">if</span> <span class="n">prompts</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">extra_payload</span><span class="p">[</span><span class="s2">&quot;prompts&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;prompts&quot;</span><span class="p">:</span> <span class="n">prompts</span><span class="p">}</span>
    <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_post_images</span><span class="p">(</span>
        <span class="n">inference_input</span><span class="o">=</span><span class="n">inference_input</span><span class="p">,</span>
        <span class="n">endpoint</span><span class="o">=</span><span class="s2">&quot;/sam2/segment_image&quot;</span><span class="p">,</span>
        <span class="n">extra_payload</span><span class="o">=</span><span class="n">extra_payload</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">result</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="inference_sdk.http.client.InferenceHTTPClient.sam2_segment_image_async" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">sam2_segment_image_async</span><span class="p">(</span><span class="n">inference_input</span><span class="p">,</span> <span class="n">prompts</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">sam2_version_id</span><span class="o">=</span><span class="s1">&#39;hiera_tiny&#39;</span><span class="p">,</span> <span class="n">multimask_output</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">mask_input_format</span><span class="o">=</span><span class="s1">&#39;json&#39;</span><span class="p">)</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-async"><code>async</code></small>
  </span>

<a href="#inference_sdk.http.client.InferenceHTTPClient.sam2_segment_image_async" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Run Segment Anything 2 (SAM2) segmentation on input image(s) asynchronously.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>inference_input</code>
            </td>
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="inference_sdk.http.entities.ImagesReference">ImagesReference</span>, <span title="typing.List">List</span>[<span title="inference_sdk.http.entities.ImagesReference">ImagesReference</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Input image(s)
for segmentation.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>prompts</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="typing.List">List</span>[<span title="dict">dict</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>List of prompt dictionaries.
Defaults to None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>sam2_version_id</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Version of SAM2 model. Defaults to "hiera_tiny".</p>
              </div>
            </td>
            <td>
                  <code>&#39;hiera_tiny&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>multimask_output</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Whether to output multiple masks. Defaults to True.</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>mask_input_format</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Format for mask output. Defaults to "json".</p>
              </div>
            </td>
            <td>
                  <code>&#39;json&#39;</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="dict">dict</span>, <span title="typing.List">List</span>[<span title="dict">dict</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Union[dict, List[dict]]: Segmentation results.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.HTTPCallErrorError">HTTPCallErrorError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If there is an error in the HTTP call.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.HTTPClientError">HTTPClientError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If there is an error with the server connection.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>inference_sdk/http/client.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1814</span>
<span class="normal">1815</span>
<span class="normal">1816</span>
<span class="normal">1817</span>
<span class="normal">1818</span>
<span class="normal">1819</span>
<span class="normal">1820</span>
<span class="normal">1821</span>
<span class="normal">1822</span>
<span class="normal">1823</span>
<span class="normal">1824</span>
<span class="normal">1825</span>
<span class="normal">1826</span>
<span class="normal">1827</span>
<span class="normal">1828</span>
<span class="normal">1829</span>
<span class="normal">1830</span>
<span class="normal">1831</span>
<span class="normal">1832</span>
<span class="normal">1833</span>
<span class="normal">1834</span>
<span class="normal">1835</span>
<span class="normal">1836</span>
<span class="normal">1837</span>
<span class="normal">1838</span>
<span class="normal">1839</span>
<span class="normal">1840</span>
<span class="normal">1841</span>
<span class="normal">1842</span>
<span class="normal">1843</span>
<span class="normal">1844</span>
<span class="normal">1845</span>
<span class="normal">1846</span>
<span class="normal">1847</span>
<span class="normal">1848</span>
<span class="normal">1849</span>
<span class="normal">1850</span>
<span class="normal">1851</span>
<span class="normal">1852</span>
<span class="normal">1853</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@wrap_errors_async</span>
<span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">sam2_segment_image_async</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">inference_input</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">]],</span>
    <span class="n">prompts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">sam2_version_id</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;hiera_tiny&quot;</span><span class="p">,</span>
    <span class="n">multimask_output</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">mask_input_format</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;json&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Run Segment Anything 2 (SAM2) segmentation on input image(s) asynchronously.</span>

<span class="sd">    Args:</span>
<span class="sd">        inference_input (Union[ImagesReference, List[ImagesReference]]): Input image(s)</span>
<span class="sd">            for segmentation.</span>
<span class="sd">        prompts (Optional[List[dict]], optional): List of prompt dictionaries.</span>
<span class="sd">            Defaults to None.</span>
<span class="sd">        sam2_version_id (str, optional): Version of SAM2 model. Defaults to &quot;hiera_tiny&quot;.</span>
<span class="sd">        multimask_output (bool, optional): Whether to output multiple masks. Defaults to True.</span>
<span class="sd">        mask_input_format (str, optional): Format for mask output. Defaults to &quot;json&quot;.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Union[dict, List[dict]]: Segmentation results.</span>

<span class="sd">    Raises:</span>
<span class="sd">        HTTPCallErrorError: If there is an error in the HTTP call.</span>
<span class="sd">        HTTPClientError: If there is an error with the server connection.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">extra_payload</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;sam2_version_id&quot;</span><span class="p">:</span> <span class="n">sam2_version_id</span><span class="p">,</span>
        <span class="s2">&quot;multimask_output&quot;</span><span class="p">:</span> <span class="n">multimask_output</span><span class="p">,</span>
        <span class="s2">&quot;format&quot;</span><span class="p">:</span> <span class="n">mask_input_format</span><span class="p">,</span>
    <span class="p">}</span>
    <span class="k">if</span> <span class="n">prompts</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">extra_payload</span><span class="p">[</span><span class="s2">&quot;prompts&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;prompts&quot;</span><span class="p">:</span> <span class="n">prompts</span><span class="p">}</span>
    <span class="n">result</span> <span class="o">=</span> <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">_post_images_async</span><span class="p">(</span>
        <span class="n">inference_input</span><span class="o">=</span><span class="n">inference_input</span><span class="p">,</span>
        <span class="n">endpoint</span><span class="o">=</span><span class="s2">&quot;/sam2/segment_image&quot;</span><span class="p">,</span>
        <span class="n">extra_payload</span><span class="o">=</span><span class="n">extra_payload</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">result</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="inference_sdk.http.client.InferenceHTTPClient.sam3_3d_infer" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">sam3_3d_infer</span><span class="p">(</span><span class="n">inference_input</span><span class="p">,</span> <span class="n">mask_input</span><span class="p">,</span> <span class="n">model_id</span><span class="o">=</span><span class="s1">&#39;sam3-3d-objects&#39;</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">output_meshes</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">output_scene</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">with_mesh_postprocess</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">with_texture_baking</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">use_distillations</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

<a href="#inference_sdk.http.client.InferenceHTTPClient.sam3_3d_infer" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Generate 3D meshes and Gaussian splatting from a 2D image with mask prompts.</p>
<p>This method uses SAM3 3D to generate 3D representations from 2D images
with mask prompts.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>inference_input</code>
            </td>
            <td>
                  <code><span title="inference_sdk.http.entities.ImagesReference">ImagesReference</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Input image for 3D generation.
Can be a file path, URL, base64 string, numpy array, or PIL image.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>mask_input</code>
            </td>
            <td>
                  <code><span title="typing.Any">Any</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Mask input in any supported format:
- Polygon coordinates: [x1, y1, x2, y2, ...]
- Binary mask (as numpy array or base64)
- RLE dictionary
- List of any of the above for multiple masks</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>model_id</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The SAM3 3D model to use. Defaults to "sam3-3d-objects".</p>
              </div>
            </td>
            <td>
                  <code>&#39;sam3-3d-objects&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>output_meshes</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>SAM3 3D always outputs object gaussians, and can
optionally output object meshes if output_meshes is True. Defaults to True.</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>output_scene</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Output the combined scene reconstruction in
addition to individual object reconstructions. Defaults to True.</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>with_mesh_postprocess</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Enable mesh postprocessing. Defaults to True.</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>with_texture_baking</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Enable texture baking for meshes. Defaults to True.</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>use_distillations</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Use the distilled versions of the model components.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>dict</code></td>            <td>
                  <code><span title="dict">dict</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Response containing base64-encoded 3D outputs:
- mesh_glb: Scene mesh in GLB format (base64 encoded) if output_meshes=True, otherwise None.
- gaussian_ply: Combined Gaussian splatting in PLY format (base64 encoded)
- objects: List of individual objects, each containing:
    - mesh_glb: Object mesh (base64) if output_scene=True and output_meshes=True, otherwise None.
    - gaussian_ply: Object Gaussian (base64) if output_scene=True, otherwise None.
    - metadata: {"rotation": [...], "translation": [...], "scale": [...]}
- time: Inference time in seconds</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.HTTPCallErrorError">HTTPCallErrorError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If there is an error in the HTTP call.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.HTTPClientError">HTTPClientError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If there is an error with the server connection.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>inference_sdk/http/client.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1855</span>
<span class="normal">1856</span>
<span class="normal">1857</span>
<span class="normal">1858</span>
<span class="normal">1859</span>
<span class="normal">1860</span>
<span class="normal">1861</span>
<span class="normal">1862</span>
<span class="normal">1863</span>
<span class="normal">1864</span>
<span class="normal">1865</span>
<span class="normal">1866</span>
<span class="normal">1867</span>
<span class="normal">1868</span>
<span class="normal">1869</span>
<span class="normal">1870</span>
<span class="normal">1871</span>
<span class="normal">1872</span>
<span class="normal">1873</span>
<span class="normal">1874</span>
<span class="normal">1875</span>
<span class="normal">1876</span>
<span class="normal">1877</span>
<span class="normal">1878</span>
<span class="normal">1879</span>
<span class="normal">1880</span>
<span class="normal">1881</span>
<span class="normal">1882</span>
<span class="normal">1883</span>
<span class="normal">1884</span>
<span class="normal">1885</span>
<span class="normal">1886</span>
<span class="normal">1887</span>
<span class="normal">1888</span>
<span class="normal">1889</span>
<span class="normal">1890</span>
<span class="normal">1891</span>
<span class="normal">1892</span>
<span class="normal">1893</span>
<span class="normal">1894</span>
<span class="normal">1895</span>
<span class="normal">1896</span>
<span class="normal">1897</span>
<span class="normal">1898</span>
<span class="normal">1899</span>
<span class="normal">1900</span>
<span class="normal">1901</span>
<span class="normal">1902</span>
<span class="normal">1903</span>
<span class="normal">1904</span>
<span class="normal">1905</span>
<span class="normal">1906</span>
<span class="normal">1907</span>
<span class="normal">1908</span>
<span class="normal">1909</span>
<span class="normal">1910</span>
<span class="normal">1911</span>
<span class="normal">1912</span>
<span class="normal">1913</span>
<span class="normal">1914</span>
<span class="normal">1915</span>
<span class="normal">1916</span>
<span class="normal">1917</span>
<span class="normal">1918</span>
<span class="normal">1919</span>
<span class="normal">1920</span>
<span class="normal">1921</span>
<span class="normal">1922</span>
<span class="normal">1923</span>
<span class="normal">1924</span>
<span class="normal">1925</span>
<span class="normal">1926</span>
<span class="normal">1927</span>
<span class="normal">1928</span>
<span class="normal">1929</span>
<span class="normal">1930</span>
<span class="normal">1931</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@wrap_errors</span>
<span class="k">def</span><span class="w"> </span><span class="nf">sam3_3d_infer</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">inference_input</span><span class="p">:</span> <span class="n">ImagesReference</span><span class="p">,</span>
    <span class="n">mask_input</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="n">model_id</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;sam3-3d-objects&quot;</span><span class="p">,</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">output_meshes</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">output_scene</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">with_mesh_postprocess</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">with_texture_baking</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">use_distillations</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Generate 3D meshes and Gaussian splatting from a 2D image with mask prompts.</span>

<span class="sd">    This method uses SAM3 3D to generate 3D representations from 2D images</span>
<span class="sd">    with mask prompts.</span>

<span class="sd">    Args:</span>
<span class="sd">        inference_input (ImagesReference): Input image for 3D generation.</span>
<span class="sd">            Can be a file path, URL, base64 string, numpy array, or PIL image.</span>
<span class="sd">        mask_input (Any): Mask input in any supported format:</span>
<span class="sd">            - Polygon coordinates: [x1, y1, x2, y2, ...]</span>
<span class="sd">            - Binary mask (as numpy array or base64)</span>
<span class="sd">            - RLE dictionary</span>
<span class="sd">            - List of any of the above for multiple masks</span>
<span class="sd">        model_id (str, optional): The SAM3 3D model to use. Defaults to &quot;sam3-3d-objects&quot;.</span>
<span class="sd">        output_meshes (bool, optional): SAM3 3D always outputs object gaussians, and can</span>
<span class="sd">            optionally output object meshes if output_meshes is True. Defaults to True.</span>
<span class="sd">        output_scene (bool, optional): Output the combined scene reconstruction in</span>
<span class="sd">            addition to individual object reconstructions. Defaults to True.</span>
<span class="sd">        with_mesh_postprocess (bool, optional): Enable mesh postprocessing. Defaults to True.</span>
<span class="sd">        with_texture_baking (bool, optional): Enable texture baking for meshes. Defaults to True.</span>
<span class="sd">        use_distillations (bool, optional): Use the distilled versions of the model components.</span>

<span class="sd">    Returns:</span>
<span class="sd">        dict: Response containing base64-encoded 3D outputs:</span>
<span class="sd">            - mesh_glb: Scene mesh in GLB format (base64 encoded) if output_meshes=True, otherwise None.</span>
<span class="sd">            - gaussian_ply: Combined Gaussian splatting in PLY format (base64 encoded)</span>
<span class="sd">            - objects: List of individual objects, each containing:</span>
<span class="sd">                - mesh_glb: Object mesh (base64) if output_scene=True and output_meshes=True, otherwise None.</span>
<span class="sd">                - gaussian_ply: Object Gaussian (base64) if output_scene=True, otherwise None.</span>
<span class="sd">                - metadata: {&quot;rotation&quot;: [...], &quot;translation&quot;: [...], &quot;scale&quot;: [...]}</span>
<span class="sd">            - time: Inference time in seconds</span>

<span class="sd">    Raises:</span>
<span class="sd">        HTTPCallErrorError: If there is an error in the HTTP call.</span>
<span class="sd">        HTTPClientError: If there is an error with the server connection.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">encoded_inference_inputs</span> <span class="o">=</span> <span class="n">load_static_inference_input</span><span class="p">(</span>
        <span class="n">inference_input</span><span class="o">=</span><span class="n">inference_input</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">payload</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__initialise_payload</span><span class="p">()</span>
    <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;model_id&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">model_id</span>
    <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;mask_input&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">mask_input</span>
    <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;output_meshes&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">output_meshes</span>
    <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;output_scene&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">output_scene</span>
    <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;with_mesh_postprocess&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">with_mesh_postprocess</span>
    <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;with_texture_baking&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">with_texture_baking</span>
    <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;use_distillations&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">use_distillations</span>

    <span class="n">url</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__wrap_url_with_api_key</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__api_url</span><span class="si">}</span><span class="s2">/sam3_3d/infer&quot;</span><span class="p">)</span>
    <span class="n">requests_data</span> <span class="o">=</span> <span class="n">prepare_requests_data</span><span class="p">(</span>
        <span class="n">url</span><span class="o">=</span><span class="n">url</span><span class="p">,</span>
        <span class="n">encoded_inference_inputs</span><span class="o">=</span><span class="n">encoded_inference_inputs</span><span class="p">,</span>
        <span class="n">headers</span><span class="o">=</span><span class="n">DEFAULT_HEADERS</span><span class="p">,</span>
        <span class="n">parameters</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">payload</span><span class="o">=</span><span class="n">payload</span><span class="p">,</span>
        <span class="n">max_batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">image_placement</span><span class="o">=</span><span class="n">ImagePlacement</span><span class="o">.</span><span class="n">JSON</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">responses</span> <span class="o">=</span> <span class="n">execute_requests_packages</span><span class="p">(</span>
        <span class="n">requests_data</span><span class="o">=</span><span class="n">requests_data</span><span class="p">,</span>
        <span class="n">request_method</span><span class="o">=</span><span class="n">RequestMethod</span><span class="o">.</span><span class="n">POST</span><span class="p">,</span>
        <span class="n">max_concurrent_requests</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">__inference_configuration</span><span class="o">.</span><span class="n">max_concurrent_requests</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">responses</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="inference_sdk.http.client.InferenceHTTPClient.sam3_3d_infer_async" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">sam3_3d_infer_async</span><span class="p">(</span><span class="n">inference_input</span><span class="p">,</span> <span class="n">mask_input</span><span class="p">,</span> <span class="n">model_id</span><span class="o">=</span><span class="s1">&#39;sam3-3d-objects&#39;</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">output_meshes</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">output_scene</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">with_mesh_postprocess</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">with_texture_baking</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">use_distillations</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-async"><code>async</code></small>
  </span>

<a href="#inference_sdk.http.client.InferenceHTTPClient.sam3_3d_infer_async" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Generate 3D meshes and Gaussian splatting from a 2D image asynchronously.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>inference_input</code>
            </td>
            <td>
                  <code><span title="inference_sdk.http.entities.ImagesReference">ImagesReference</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Input image for 3D generation.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>mask_input</code>
            </td>
            <td>
                  <code><span title="typing.Any">Any</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Mask input in any supported format.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>model_id</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The SAM3 3D model to use. Defaults to "sam3-3d-objects".</p>
              </div>
            </td>
            <td>
                  <code>&#39;sam3-3d-objects&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>output_meshes</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>SAM3 3D always outputs object gaussians, and can
optionally output object meshes if output_meshes is True. Defaults to True.</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>output_scene</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Output the combined scene reconstruction in
addition to individual object reconstructions. Defaults to True.</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>with_mesh_postprocess</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Enable mesh postprocessing. Defaults to True.</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>with_texture_baking</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Enable texture baking for meshes. Defaults to True.</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>use_distillations</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Use the distilled versions of the model components.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>dict</code></td>            <td>
                  <code><span title="dict">dict</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Response containing base64-encoded 3D outputs:
- mesh_glb: Scene mesh in GLB format (base64 encoded) if output_meshes=True, otherwise None.
- gaussian_ply: Combined Gaussian splatting in PLY format (base64 encoded)
- objects: List of individual objects, each containing:
    - mesh_glb: Object mesh (base64) if output_scene=True and output_meshes=True, otherwise None.
    - gaussian_ply: Object Gaussian (base64) if output_scene=True, otherwise None.
    - metadata: {"rotation": [...], "translation": [...], "scale": [...]}
- time: Inference time in seconds</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.HTTPCallErrorError">HTTPCallErrorError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If there is an error in the HTTP call.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.HTTPClientError">HTTPClientError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If there is an error with the server connection.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>inference_sdk/http/client.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1933</span>
<span class="normal">1934</span>
<span class="normal">1935</span>
<span class="normal">1936</span>
<span class="normal">1937</span>
<span class="normal">1938</span>
<span class="normal">1939</span>
<span class="normal">1940</span>
<span class="normal">1941</span>
<span class="normal">1942</span>
<span class="normal">1943</span>
<span class="normal">1944</span>
<span class="normal">1945</span>
<span class="normal">1946</span>
<span class="normal">1947</span>
<span class="normal">1948</span>
<span class="normal">1949</span>
<span class="normal">1950</span>
<span class="normal">1951</span>
<span class="normal">1952</span>
<span class="normal">1953</span>
<span class="normal">1954</span>
<span class="normal">1955</span>
<span class="normal">1956</span>
<span class="normal">1957</span>
<span class="normal">1958</span>
<span class="normal">1959</span>
<span class="normal">1960</span>
<span class="normal">1961</span>
<span class="normal">1962</span>
<span class="normal">1963</span>
<span class="normal">1964</span>
<span class="normal">1965</span>
<span class="normal">1966</span>
<span class="normal">1967</span>
<span class="normal">1968</span>
<span class="normal">1969</span>
<span class="normal">1970</span>
<span class="normal">1971</span>
<span class="normal">1972</span>
<span class="normal">1973</span>
<span class="normal">1974</span>
<span class="normal">1975</span>
<span class="normal">1976</span>
<span class="normal">1977</span>
<span class="normal">1978</span>
<span class="normal">1979</span>
<span class="normal">1980</span>
<span class="normal">1981</span>
<span class="normal">1982</span>
<span class="normal">1983</span>
<span class="normal">1984</span>
<span class="normal">1985</span>
<span class="normal">1986</span>
<span class="normal">1987</span>
<span class="normal">1988</span>
<span class="normal">1989</span>
<span class="normal">1990</span>
<span class="normal">1991</span>
<span class="normal">1992</span>
<span class="normal">1993</span>
<span class="normal">1994</span>
<span class="normal">1995</span>
<span class="normal">1996</span>
<span class="normal">1997</span>
<span class="normal">1998</span>
<span class="normal">1999</span>
<span class="normal">2000</span>
<span class="normal">2001</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@wrap_errors_async</span>
<span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">sam3_3d_infer_async</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">inference_input</span><span class="p">:</span> <span class="n">ImagesReference</span><span class="p">,</span>
    <span class="n">mask_input</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="n">model_id</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;sam3-3d-objects&quot;</span><span class="p">,</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">output_meshes</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">output_scene</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">with_mesh_postprocess</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">with_texture_baking</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">use_distillations</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Generate 3D meshes and Gaussian splatting from a 2D image asynchronously.</span>

<span class="sd">    Args:</span>
<span class="sd">        inference_input (ImagesReference): Input image for 3D generation.</span>
<span class="sd">        mask_input (Any): Mask input in any supported format.</span>
<span class="sd">        model_id (str, optional): The SAM3 3D model to use. Defaults to &quot;sam3-3d-objects&quot;.</span>
<span class="sd">        output_meshes (bool, optional): SAM3 3D always outputs object gaussians, and can</span>
<span class="sd">            optionally output object meshes if output_meshes is True. Defaults to True.</span>
<span class="sd">        output_scene (bool, optional): Output the combined scene reconstruction in</span>
<span class="sd">            addition to individual object reconstructions. Defaults to True.</span>
<span class="sd">        with_mesh_postprocess (bool, optional): Enable mesh postprocessing. Defaults to True.</span>
<span class="sd">        with_texture_baking (bool, optional): Enable texture baking for meshes. Defaults to True.</span>
<span class="sd">        use_distillations (bool, optional): Use the distilled versions of the model components.</span>

<span class="sd">    Returns:</span>
<span class="sd">        dict: Response containing base64-encoded 3D outputs:</span>
<span class="sd">            - mesh_glb: Scene mesh in GLB format (base64 encoded) if output_meshes=True, otherwise None.</span>
<span class="sd">            - gaussian_ply: Combined Gaussian splatting in PLY format (base64 encoded)</span>
<span class="sd">            - objects: List of individual objects, each containing:</span>
<span class="sd">                - mesh_glb: Object mesh (base64) if output_scene=True and output_meshes=True, otherwise None.</span>
<span class="sd">                - gaussian_ply: Object Gaussian (base64) if output_scene=True, otherwise None.</span>
<span class="sd">                - metadata: {&quot;rotation&quot;: [...], &quot;translation&quot;: [...], &quot;scale&quot;: [...]}</span>
<span class="sd">            - time: Inference time in seconds</span>

<span class="sd">    Raises:</span>
<span class="sd">        HTTPCallErrorError: If there is an error in the HTTP call.</span>
<span class="sd">        HTTPClientError: If there is an error with the server connection.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">encoded_inference_inputs</span> <span class="o">=</span> <span class="k">await</span> <span class="n">load_static_inference_input_async</span><span class="p">(</span>
        <span class="n">inference_input</span><span class="o">=</span><span class="n">inference_input</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">payload</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__initialise_payload</span><span class="p">()</span>
    <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;model_id&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">model_id</span>
    <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;mask_input&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">mask_input</span>
    <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;output_meshes&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">output_meshes</span>
    <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;output_scene&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">output_scene</span>
    <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;with_mesh_postprocess&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">with_mesh_postprocess</span>
    <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;with_texture_baking&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">with_texture_baking</span>
    <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;use_distillations&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">use_distillations</span>

    <span class="n">url</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__wrap_url_with_api_key</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__api_url</span><span class="si">}</span><span class="s2">/sam3_3d/infer&quot;</span><span class="p">)</span>
    <span class="n">requests_data</span> <span class="o">=</span> <span class="n">prepare_requests_data</span><span class="p">(</span>
        <span class="n">url</span><span class="o">=</span><span class="n">url</span><span class="p">,</span>
        <span class="n">encoded_inference_inputs</span><span class="o">=</span><span class="n">encoded_inference_inputs</span><span class="p">,</span>
        <span class="n">headers</span><span class="o">=</span><span class="n">DEFAULT_HEADERS</span><span class="p">,</span>
        <span class="n">parameters</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">payload</span><span class="o">=</span><span class="n">payload</span><span class="p">,</span>
        <span class="n">max_batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">image_placement</span><span class="o">=</span><span class="n">ImagePlacement</span><span class="o">.</span><span class="n">JSON</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">responses</span> <span class="o">=</span> <span class="k">await</span> <span class="n">execute_requests_packages_async</span><span class="p">(</span>
        <span class="n">requests_data</span><span class="o">=</span><span class="n">requests_data</span><span class="p">,</span>
        <span class="n">request_method</span><span class="o">=</span><span class="n">RequestMethod</span><span class="o">.</span><span class="n">POST</span><span class="p">,</span>
        <span class="n">max_concurrent_requests</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">__inference_configuration</span><span class="o">.</span><span class="n">max_concurrent_requests</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">responses</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="inference_sdk.http.client.InferenceHTTPClient.sam3_concept_segment" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">sam3_concept_segment</span><span class="p">(</span><span class="n">inference_input</span><span class="p">,</span> <span class="n">prompts</span><span class="p">,</span> <span class="n">model_id</span><span class="o">=</span><span class="s1">&#39;sam3/sam3_final&#39;</span><span class="p">,</span> <span class="n">output_prob_thresh</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">nms_iou_threshold</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s1">&#39;polygon&#39;</span><span class="p">)</span></code>

<a href="#inference_sdk.http.client.InferenceHTTPClient.sam3_concept_segment" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Run SAM3 promptable concept segmentation (PCS) on input image(s).</p>
<p>Performs zero-shot instance segmentation using text or visual prompts.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>inference_input</code>
            </td>
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="inference_sdk.http.entities.ImagesReference">ImagesReference</span>, <span title="typing.List">List</span>[<span title="inference_sdk.http.entities.ImagesReference">ImagesReference</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Input image(s) for segmentation.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>prompts</code>
            </td>
            <td>
                  <code><span title="typing.List">List</span>[<span title="dict">dict</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>List of prompt dicts, each with keys like "type", "text",
"output_prob_thresh", "boxes", "box_labels".</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>model_id</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>SAM3 model to use. Defaults to "sam3/sam3_final".</p>
              </div>
            </td>
            <td>
                  <code>&#39;sam3/sam3_final&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>output_prob_thresh</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Global confidence threshold. Defaults to 0.5.</p>
              </div>
            </td>
            <td>
                  <code>0.5</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>nms_iou_threshold</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="float">float</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>IoU threshold for cross-prompt NMS. None disables NMS.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>format</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Output mask format, "polygon" or "rle". Defaults to "polygon".</p>
              </div>
            </td>
            <td>
                  <code>&#39;polygon&#39;</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="dict">dict</span>, <span title="typing.List">List</span>[<span title="dict">dict</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Segmentation results with prompt_results containing predictions.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>inference_sdk/http/client.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">2003</span>
<span class="normal">2004</span>
<span class="normal">2005</span>
<span class="normal">2006</span>
<span class="normal">2007</span>
<span class="normal">2008</span>
<span class="normal">2009</span>
<span class="normal">2010</span>
<span class="normal">2011</span>
<span class="normal">2012</span>
<span class="normal">2013</span>
<span class="normal">2014</span>
<span class="normal">2015</span>
<span class="normal">2016</span>
<span class="normal">2017</span>
<span class="normal">2018</span>
<span class="normal">2019</span>
<span class="normal">2020</span>
<span class="normal">2021</span>
<span class="normal">2022</span>
<span class="normal">2023</span>
<span class="normal">2024</span>
<span class="normal">2025</span>
<span class="normal">2026</span>
<span class="normal">2027</span>
<span class="normal">2028</span>
<span class="normal">2029</span>
<span class="normal">2030</span>
<span class="normal">2031</span>
<span class="normal">2032</span>
<span class="normal">2033</span>
<span class="normal">2034</span>
<span class="normal">2035</span>
<span class="normal">2036</span>
<span class="normal">2037</span>
<span class="normal">2038</span>
<span class="normal">2039</span>
<span class="normal">2040</span>
<span class="normal">2041</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@wrap_errors</span>
<span class="k">def</span><span class="w"> </span><span class="nf">sam3_concept_segment</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">inference_input</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">]],</span>
    <span class="n">prompts</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">],</span>
    <span class="n">model_id</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;sam3/sam3_final&quot;</span><span class="p">,</span>
    <span class="n">output_prob_thresh</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
    <span class="n">nms_iou_threshold</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="nb">format</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;polygon&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Run SAM3 promptable concept segmentation (PCS) on input image(s).</span>

<span class="sd">    Performs zero-shot instance segmentation using text or visual prompts.</span>

<span class="sd">    Args:</span>
<span class="sd">        inference_input: Input image(s) for segmentation.</span>
<span class="sd">        prompts: List of prompt dicts, each with keys like &quot;type&quot;, &quot;text&quot;,</span>
<span class="sd">            &quot;output_prob_thresh&quot;, &quot;boxes&quot;, &quot;box_labels&quot;.</span>
<span class="sd">        model_id: SAM3 model to use. Defaults to &quot;sam3/sam3_final&quot;.</span>
<span class="sd">        output_prob_thresh: Global confidence threshold. Defaults to 0.5.</span>
<span class="sd">        nms_iou_threshold: IoU threshold for cross-prompt NMS. None disables NMS.</span>
<span class="sd">        format: Output mask format, &quot;polygon&quot; or &quot;rle&quot;. Defaults to &quot;polygon&quot;.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Segmentation results with prompt_results containing predictions.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">extra_payload</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;model_id&quot;</span><span class="p">:</span> <span class="n">model_id</span><span class="p">,</span>
        <span class="s2">&quot;prompts&quot;</span><span class="p">:</span> <span class="n">prompts</span><span class="p">,</span>
        <span class="s2">&quot;output_prob_thresh&quot;</span><span class="p">:</span> <span class="n">output_prob_thresh</span><span class="p">,</span>
        <span class="s2">&quot;format&quot;</span><span class="p">:</span> <span class="nb">format</span><span class="p">,</span>
    <span class="p">}</span>
    <span class="k">if</span> <span class="n">nms_iou_threshold</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">extra_payload</span><span class="p">[</span><span class="s2">&quot;nms_iou_threshold&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">nms_iou_threshold</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_post_images</span><span class="p">(</span>
        <span class="n">inference_input</span><span class="o">=</span><span class="n">inference_input</span><span class="p">,</span>
        <span class="n">endpoint</span><span class="o">=</span><span class="s2">&quot;/sam3/concept_segment&quot;</span><span class="p">,</span>
        <span class="n">extra_payload</span><span class="o">=</span><span class="n">extra_payload</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="inference_sdk.http.client.InferenceHTTPClient.sam3_concept_segment_async" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">sam3_concept_segment_async</span><span class="p">(</span><span class="n">inference_input</span><span class="p">,</span> <span class="n">prompts</span><span class="p">,</span> <span class="n">model_id</span><span class="o">=</span><span class="s1">&#39;sam3/sam3_final&#39;</span><span class="p">,</span> <span class="n">output_prob_thresh</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">nms_iou_threshold</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s1">&#39;polygon&#39;</span><span class="p">)</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-async"><code>async</code></small>
  </span>

<a href="#inference_sdk.http.client.InferenceHTTPClient.sam3_concept_segment_async" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Run SAM3 promptable concept segmentation (PCS) asynchronously.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>inference_input</code>
            </td>
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="inference_sdk.http.entities.ImagesReference">ImagesReference</span>, <span title="typing.List">List</span>[<span title="inference_sdk.http.entities.ImagesReference">ImagesReference</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Input image(s) for segmentation.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>prompts</code>
            </td>
            <td>
                  <code><span title="typing.List">List</span>[<span title="dict">dict</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>List of prompt dicts.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>model_id</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>SAM3 model to use. Defaults to "sam3/sam3_final".</p>
              </div>
            </td>
            <td>
                  <code>&#39;sam3/sam3_final&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>output_prob_thresh</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Global confidence threshold. Defaults to 0.5.</p>
              </div>
            </td>
            <td>
                  <code>0.5</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>nms_iou_threshold</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="float">float</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>IoU threshold for cross-prompt NMS. None disables NMS.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>format</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Output mask format, "polygon" or "rle". Defaults to "polygon".</p>
              </div>
            </td>
            <td>
                  <code>&#39;polygon&#39;</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="dict">dict</span>, <span title="typing.List">List</span>[<span title="dict">dict</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Segmentation results with prompt_results containing predictions.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>inference_sdk/http/client.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">2043</span>
<span class="normal">2044</span>
<span class="normal">2045</span>
<span class="normal">2046</span>
<span class="normal">2047</span>
<span class="normal">2048</span>
<span class="normal">2049</span>
<span class="normal">2050</span>
<span class="normal">2051</span>
<span class="normal">2052</span>
<span class="normal">2053</span>
<span class="normal">2054</span>
<span class="normal">2055</span>
<span class="normal">2056</span>
<span class="normal">2057</span>
<span class="normal">2058</span>
<span class="normal">2059</span>
<span class="normal">2060</span>
<span class="normal">2061</span>
<span class="normal">2062</span>
<span class="normal">2063</span>
<span class="normal">2064</span>
<span class="normal">2065</span>
<span class="normal">2066</span>
<span class="normal">2067</span>
<span class="normal">2068</span>
<span class="normal">2069</span>
<span class="normal">2070</span>
<span class="normal">2071</span>
<span class="normal">2072</span>
<span class="normal">2073</span>
<span class="normal">2074</span>
<span class="normal">2075</span>
<span class="normal">2076</span>
<span class="normal">2077</span>
<span class="normal">2078</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@wrap_errors_async</span>
<span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">sam3_concept_segment_async</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">inference_input</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">]],</span>
    <span class="n">prompts</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">],</span>
    <span class="n">model_id</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;sam3/sam3_final&quot;</span><span class="p">,</span>
    <span class="n">output_prob_thresh</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
    <span class="n">nms_iou_threshold</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="nb">format</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;polygon&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Run SAM3 promptable concept segmentation (PCS) asynchronously.</span>

<span class="sd">    Args:</span>
<span class="sd">        inference_input: Input image(s) for segmentation.</span>
<span class="sd">        prompts: List of prompt dicts.</span>
<span class="sd">        model_id: SAM3 model to use. Defaults to &quot;sam3/sam3_final&quot;.</span>
<span class="sd">        output_prob_thresh: Global confidence threshold. Defaults to 0.5.</span>
<span class="sd">        nms_iou_threshold: IoU threshold for cross-prompt NMS. None disables NMS.</span>
<span class="sd">        format: Output mask format, &quot;polygon&quot; or &quot;rle&quot;. Defaults to &quot;polygon&quot;.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Segmentation results with prompt_results containing predictions.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">extra_payload</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;model_id&quot;</span><span class="p">:</span> <span class="n">model_id</span><span class="p">,</span>
        <span class="s2">&quot;prompts&quot;</span><span class="p">:</span> <span class="n">prompts</span><span class="p">,</span>
        <span class="s2">&quot;output_prob_thresh&quot;</span><span class="p">:</span> <span class="n">output_prob_thresh</span><span class="p">,</span>
        <span class="s2">&quot;format&quot;</span><span class="p">:</span> <span class="nb">format</span><span class="p">,</span>
    <span class="p">}</span>
    <span class="k">if</span> <span class="n">nms_iou_threshold</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">extra_payload</span><span class="p">[</span><span class="s2">&quot;nms_iou_threshold&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">nms_iou_threshold</span>
    <span class="k">return</span> <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">_post_images_async</span><span class="p">(</span>
        <span class="n">inference_input</span><span class="o">=</span><span class="n">inference_input</span><span class="p">,</span>
        <span class="n">endpoint</span><span class="o">=</span><span class="s2">&quot;/sam3/concept_segment&quot;</span><span class="p">,</span>
        <span class="n">extra_payload</span><span class="o">=</span><span class="n">extra_payload</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="inference_sdk.http.client.InferenceHTTPClient.sam3_embed_image" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">sam3_embed_image</span><span class="p">(</span><span class="n">inference_input</span><span class="p">,</span> <span class="n">image_id</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#inference_sdk.http.client.InferenceHTTPClient.sam3_embed_image" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Generate SAM3 image embeddings.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>inference_input</code>
            </td>
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="inference_sdk.http.entities.ImagesReference">ImagesReference</span>, <span title="typing.List">List</span>[<span title="inference_sdk.http.entities.ImagesReference">ImagesReference</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Input image(s) to embed.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>image_id</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="str">str</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Optional cache ID for embeddings. Defaults to None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="dict">dict</span>, <span title="typing.List">List</span>[<span title="dict">dict</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Embedding results with image_id and processing time.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>inference_sdk/http/client.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">2146</span>
<span class="normal">2147</span>
<span class="normal">2148</span>
<span class="normal">2149</span>
<span class="normal">2150</span>
<span class="normal">2151</span>
<span class="normal">2152</span>
<span class="normal">2153</span>
<span class="normal">2154</span>
<span class="normal">2155</span>
<span class="normal">2156</span>
<span class="normal">2157</span>
<span class="normal">2158</span>
<span class="normal">2159</span>
<span class="normal">2160</span>
<span class="normal">2161</span>
<span class="normal">2162</span>
<span class="normal">2163</span>
<span class="normal">2164</span>
<span class="normal">2165</span>
<span class="normal">2166</span>
<span class="normal">2167</span>
<span class="normal">2168</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@wrap_errors</span>
<span class="k">def</span><span class="w"> </span><span class="nf">sam3_embed_image</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">inference_input</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">]],</span>
    <span class="n">image_id</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Generate SAM3 image embeddings.</span>

<span class="sd">    Args:</span>
<span class="sd">        inference_input: Input image(s) to embed.</span>
<span class="sd">        image_id: Optional cache ID for embeddings. Defaults to None.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Embedding results with image_id and processing time.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">extra_payload</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">if</span> <span class="n">image_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">extra_payload</span><span class="p">[</span><span class="s2">&quot;image_id&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">image_id</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_post_images</span><span class="p">(</span>
        <span class="n">inference_input</span><span class="o">=</span><span class="n">inference_input</span><span class="p">,</span>
        <span class="n">endpoint</span><span class="o">=</span><span class="s2">&quot;/sam3/embed_image&quot;</span><span class="p">,</span>
        <span class="n">extra_payload</span><span class="o">=</span><span class="n">extra_payload</span> <span class="k">if</span> <span class="n">extra_payload</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="inference_sdk.http.client.InferenceHTTPClient.sam3_embed_image_async" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">sam3_embed_image_async</span><span class="p">(</span><span class="n">inference_input</span><span class="p">,</span> <span class="n">image_id</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-async"><code>async</code></small>
  </span>

<a href="#inference_sdk.http.client.InferenceHTTPClient.sam3_embed_image_async" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Generate SAM3 image embeddings asynchronously.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>inference_input</code>
            </td>
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="inference_sdk.http.entities.ImagesReference">ImagesReference</span>, <span title="typing.List">List</span>[<span title="inference_sdk.http.entities.ImagesReference">ImagesReference</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Input image(s) to embed.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>image_id</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="str">str</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Optional cache ID for embeddings. Defaults to None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="dict">dict</span>, <span title="typing.List">List</span>[<span title="dict">dict</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Embedding results with image_id and processing time.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>inference_sdk/http/client.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">2170</span>
<span class="normal">2171</span>
<span class="normal">2172</span>
<span class="normal">2173</span>
<span class="normal">2174</span>
<span class="normal">2175</span>
<span class="normal">2176</span>
<span class="normal">2177</span>
<span class="normal">2178</span>
<span class="normal">2179</span>
<span class="normal">2180</span>
<span class="normal">2181</span>
<span class="normal">2182</span>
<span class="normal">2183</span>
<span class="normal">2184</span>
<span class="normal">2185</span>
<span class="normal">2186</span>
<span class="normal">2187</span>
<span class="normal">2188</span>
<span class="normal">2189</span>
<span class="normal">2190</span>
<span class="normal">2191</span>
<span class="normal">2192</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@wrap_errors_async</span>
<span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">sam3_embed_image_async</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">inference_input</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">]],</span>
    <span class="n">image_id</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Generate SAM3 image embeddings asynchronously.</span>

<span class="sd">    Args:</span>
<span class="sd">        inference_input: Input image(s) to embed.</span>
<span class="sd">        image_id: Optional cache ID for embeddings. Defaults to None.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Embedding results with image_id and processing time.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">extra_payload</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">if</span> <span class="n">image_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">extra_payload</span><span class="p">[</span><span class="s2">&quot;image_id&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">image_id</span>
    <span class="k">return</span> <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">_post_images_async</span><span class="p">(</span>
        <span class="n">inference_input</span><span class="o">=</span><span class="n">inference_input</span><span class="p">,</span>
        <span class="n">endpoint</span><span class="o">=</span><span class="s2">&quot;/sam3/embed_image&quot;</span><span class="p">,</span>
        <span class="n">extra_payload</span><span class="o">=</span><span class="n">extra_payload</span> <span class="k">if</span> <span class="n">extra_payload</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="inference_sdk.http.client.InferenceHTTPClient.sam3_visual_segment" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">sam3_visual_segment</span><span class="p">(</span><span class="n">inference_input</span><span class="p">,</span> <span class="n">prompts</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">multimask_output</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">mask_input_format</span><span class="o">=</span><span class="s1">&#39;json&#39;</span><span class="p">)</span></code>

<a href="#inference_sdk.http.client.InferenceHTTPClient.sam3_visual_segment" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Run SAM3 promptable visual segmentation (PVS) on input image(s).</p>
<p>Performs instance segmentation using point or box prompts.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>inference_input</code>
            </td>
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="inference_sdk.http.entities.ImagesReference">ImagesReference</span>, <span title="typing.List">List</span>[<span title="inference_sdk.http.entities.ImagesReference">ImagesReference</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Input image(s) for segmentation.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>prompts</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="typing.List">List</span>[<span title="dict">dict</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>List of prompt dicts with "box" and/or "points" keys.
Defaults to None (automatic segmentation).</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>multimask_output</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Whether to output multiple masks per prompt.
Defaults to True.</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>mask_input_format</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Format for mask output. Defaults to "json".</p>
              </div>
            </td>
            <td>
                  <code>&#39;json&#39;</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="dict">dict</span>, <span title="typing.List">List</span>[<span title="dict">dict</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Segmentation results containing predictions with masks.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>inference_sdk/http/client.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">2080</span>
<span class="normal">2081</span>
<span class="normal">2082</span>
<span class="normal">2083</span>
<span class="normal">2084</span>
<span class="normal">2085</span>
<span class="normal">2086</span>
<span class="normal">2087</span>
<span class="normal">2088</span>
<span class="normal">2089</span>
<span class="normal">2090</span>
<span class="normal">2091</span>
<span class="normal">2092</span>
<span class="normal">2093</span>
<span class="normal">2094</span>
<span class="normal">2095</span>
<span class="normal">2096</span>
<span class="normal">2097</span>
<span class="normal">2098</span>
<span class="normal">2099</span>
<span class="normal">2100</span>
<span class="normal">2101</span>
<span class="normal">2102</span>
<span class="normal">2103</span>
<span class="normal">2104</span>
<span class="normal">2105</span>
<span class="normal">2106</span>
<span class="normal">2107</span>
<span class="normal">2108</span>
<span class="normal">2109</span>
<span class="normal">2110</span>
<span class="normal">2111</span>
<span class="normal">2112</span>
<span class="normal">2113</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@wrap_errors</span>
<span class="k">def</span><span class="w"> </span><span class="nf">sam3_visual_segment</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">inference_input</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">]],</span>
    <span class="n">prompts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">multimask_output</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">mask_input_format</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;json&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Run SAM3 promptable visual segmentation (PVS) on input image(s).</span>

<span class="sd">    Performs instance segmentation using point or box prompts.</span>

<span class="sd">    Args:</span>
<span class="sd">        inference_input: Input image(s) for segmentation.</span>
<span class="sd">        prompts: List of prompt dicts with &quot;box&quot; and/or &quot;points&quot; keys.</span>
<span class="sd">            Defaults to None (automatic segmentation).</span>
<span class="sd">        multimask_output: Whether to output multiple masks per prompt.</span>
<span class="sd">            Defaults to True.</span>
<span class="sd">        mask_input_format: Format for mask output. Defaults to &quot;json&quot;.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Segmentation results containing predictions with masks.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">extra_payload</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;multimask_output&quot;</span><span class="p">:</span> <span class="n">multimask_output</span><span class="p">,</span>
        <span class="s2">&quot;format&quot;</span><span class="p">:</span> <span class="n">mask_input_format</span><span class="p">,</span>
    <span class="p">}</span>
    <span class="k">if</span> <span class="n">prompts</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">extra_payload</span><span class="p">[</span><span class="s2">&quot;prompts&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;prompts&quot;</span><span class="p">:</span> <span class="n">prompts</span><span class="p">}</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_post_images</span><span class="p">(</span>
        <span class="n">inference_input</span><span class="o">=</span><span class="n">inference_input</span><span class="p">,</span>
        <span class="n">endpoint</span><span class="o">=</span><span class="s2">&quot;/sam3/visual_segment&quot;</span><span class="p">,</span>
        <span class="n">extra_payload</span><span class="o">=</span><span class="n">extra_payload</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="inference_sdk.http.client.InferenceHTTPClient.sam3_visual_segment_async" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">sam3_visual_segment_async</span><span class="p">(</span><span class="n">inference_input</span><span class="p">,</span> <span class="n">prompts</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">multimask_output</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">mask_input_format</span><span class="o">=</span><span class="s1">&#39;json&#39;</span><span class="p">)</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-async"><code>async</code></small>
  </span>

<a href="#inference_sdk.http.client.InferenceHTTPClient.sam3_visual_segment_async" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Run SAM3 promptable visual segmentation (PVS) asynchronously.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>inference_input</code>
            </td>
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="inference_sdk.http.entities.ImagesReference">ImagesReference</span>, <span title="typing.List">List</span>[<span title="inference_sdk.http.entities.ImagesReference">ImagesReference</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Input image(s) for segmentation.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>prompts</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="typing.List">List</span>[<span title="dict">dict</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>List of prompt dicts. Defaults to None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>multimask_output</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Whether to output multiple masks. Defaults to True.</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>mask_input_format</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Format for mask output. Defaults to "json".</p>
              </div>
            </td>
            <td>
                  <code>&#39;json&#39;</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="dict">dict</span>, <span title="typing.List">List</span>[<span title="dict">dict</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Segmentation results containing predictions with masks.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>inference_sdk/http/client.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">2115</span>
<span class="normal">2116</span>
<span class="normal">2117</span>
<span class="normal">2118</span>
<span class="normal">2119</span>
<span class="normal">2120</span>
<span class="normal">2121</span>
<span class="normal">2122</span>
<span class="normal">2123</span>
<span class="normal">2124</span>
<span class="normal">2125</span>
<span class="normal">2126</span>
<span class="normal">2127</span>
<span class="normal">2128</span>
<span class="normal">2129</span>
<span class="normal">2130</span>
<span class="normal">2131</span>
<span class="normal">2132</span>
<span class="normal">2133</span>
<span class="normal">2134</span>
<span class="normal">2135</span>
<span class="normal">2136</span>
<span class="normal">2137</span>
<span class="normal">2138</span>
<span class="normal">2139</span>
<span class="normal">2140</span>
<span class="normal">2141</span>
<span class="normal">2142</span>
<span class="normal">2143</span>
<span class="normal">2144</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@wrap_errors_async</span>
<span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">sam3_visual_segment_async</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">inference_input</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">ImagesReference</span><span class="p">]],</span>
    <span class="n">prompts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">multimask_output</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">mask_input_format</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;json&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Run SAM3 promptable visual segmentation (PVS) asynchronously.</span>

<span class="sd">    Args:</span>
<span class="sd">        inference_input: Input image(s) for segmentation.</span>
<span class="sd">        prompts: List of prompt dicts. Defaults to None.</span>
<span class="sd">        multimask_output: Whether to output multiple masks. Defaults to True.</span>
<span class="sd">        mask_input_format: Format for mask output. Defaults to &quot;json&quot;.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Segmentation results containing predictions with masks.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">extra_payload</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;multimask_output&quot;</span><span class="p">:</span> <span class="n">multimask_output</span><span class="p">,</span>
        <span class="s2">&quot;format&quot;</span><span class="p">:</span> <span class="n">mask_input_format</span><span class="p">,</span>
    <span class="p">}</span>
    <span class="k">if</span> <span class="n">prompts</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">extra_payload</span><span class="p">[</span><span class="s2">&quot;prompts&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;prompts&quot;</span><span class="p">:</span> <span class="n">prompts</span><span class="p">}</span>
    <span class="k">return</span> <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">_post_images_async</span><span class="p">(</span>
        <span class="n">inference_input</span><span class="o">=</span><span class="n">inference_input</span><span class="p">,</span>
        <span class="n">endpoint</span><span class="o">=</span><span class="s2">&quot;/sam3/visual_segment&quot;</span><span class="p">,</span>
        <span class="n">extra_payload</span><span class="o">=</span><span class="n">extra_payload</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="inference_sdk.http.client.InferenceHTTPClient.select_api_v0" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">select_api_v0</span><span class="p">()</span></code>

<a href="#inference_sdk.http.client.InferenceHTTPClient.select_api_v0" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Select API version 0 for client operations.</p>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>InferenceHTTPClient</code></td>            <td>
                  <code><a class="autorefs autorefs-internal" href="#inference_sdk.http.client.InferenceHTTPClient">InferenceHTTPClient</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The client instance with API v0 selected.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>inference_sdk/http/client.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">select_api_v0</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;InferenceHTTPClient&quot;</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Select API version 0 for client operations.</span>

<span class="sd">    Returns:</span>
<span class="sd">        InferenceHTTPClient: The client instance with API v0 selected.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">__client_mode</span> <span class="o">=</span> <span class="n">HTTPClientMode</span><span class="o">.</span><span class="n">V0</span>
    <span class="k">return</span> <span class="bp">self</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="inference_sdk.http.client.InferenceHTTPClient.select_api_v1" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">select_api_v1</span><span class="p">()</span></code>

<a href="#inference_sdk.http.client.InferenceHTTPClient.select_api_v1" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Select API version 1 for client operations.</p>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>InferenceHTTPClient</code></td>            <td>
                  <code><a class="autorefs autorefs-internal" href="#inference_sdk.http.client.InferenceHTTPClient">InferenceHTTPClient</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The client instance with API v1 selected.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>inference_sdk/http/client.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">select_api_v1</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;InferenceHTTPClient&quot;</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Select API version 1 for client operations.</span>

<span class="sd">    Returns:</span>
<span class="sd">        InferenceHTTPClient: The client instance with API v1 selected.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">__client_mode</span> <span class="o">=</span> <span class="n">HTTPClientMode</span><span class="o">.</span><span class="n">V1</span>
    <span class="k">return</span> <span class="bp">self</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="inference_sdk.http.client.InferenceHTTPClient.select_model" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">select_model</span><span class="p">(</span><span class="n">model_id</span><span class="p">)</span></code>

<a href="#inference_sdk.http.client.InferenceHTTPClient.select_model" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Select a model for inference operations.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>model_id</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The identifier of the model to select.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>InferenceHTTPClient</code></td>            <td>
                  <code><a class="autorefs autorefs-internal" href="#inference_sdk.http.client.InferenceHTTPClient">InferenceHTTPClient</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The client instance with the selected model.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>inference_sdk/http/client.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">select_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;InferenceHTTPClient&quot;</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Select a model for inference operations.</span>

<span class="sd">    Args:</span>
<span class="sd">        model_id (str): The identifier of the model to select.</span>

<span class="sd">    Returns:</span>
<span class="sd">        InferenceHTTPClient: The client instance with the selected model.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">__selected_model</span> <span class="o">=</span> <span class="n">model_id</span>
    <span class="k">return</span> <span class="bp">self</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="inference_sdk.http.client.InferenceHTTPClient.start_inference_pipeline_with_workflow" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">start_inference_pipeline_with_workflow</span><span class="p">(</span><span class="n">video_reference</span><span class="p">,</span> <span class="n">workflow_specification</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">workspace_name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">workflow_id</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">image_input_name</span><span class="o">=</span><span class="s1">&#39;image&#39;</span><span class="p">,</span> <span class="n">workflows_parameters</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">workflows_thread_pool_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">cancel_thread_pool_tasks_on_exit</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">video_metadata_input_name</span><span class="o">=</span><span class="s1">&#39;video_metadata&#39;</span><span class="p">,</span> <span class="n">max_fps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">source_buffer_filling_strategy</span><span class="o">=</span><span class="s1">&#39;DROP_OLDEST&#39;</span><span class="p">,</span> <span class="n">source_buffer_consumption_strategy</span><span class="o">=</span><span class="s1">&#39;EAGER&#39;</span><span class="p">,</span> <span class="n">video_source_properties</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">batch_collection_timeout</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">results_buffer_size</span><span class="o">=</span><span class="mi">64</span><span class="p">)</span></code>

<a href="#inference_sdk.http.client.InferenceHTTPClient.start_inference_pipeline_with_workflow" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Starts an inference pipeline using a workflow specification.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>video_reference</code>
            </td>
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="str">str</span>, <span title="int">int</span>, <span title="typing.List">List</span>[<span title="typing.Union">Union</span>[<span title="str">str</span>, <span title="int">int</span>]]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Path to video file, camera index, or list of video sources.
Can be a string path, integer camera index, or list of either.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>workflow_specification</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="dict">dict</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Optional workflow specification dictionary. Mutually
exclusive with workspace_name/workflow_id.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>workspace_name</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="str">str</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Optional name of workspace containing workflow. Must be used
with workflow_id.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>workflow_id</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="str">str</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Optional ID of workflow to use. Must be used with workspace_name.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>image_input_name</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Name of the image input node in workflow. Defaults to "image".</p>
              </div>
            </td>
            <td>
                  <code>&#39;image&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>workflows_parameters</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="typing.Dict">Dict</span>[<span title="str">str</span>, <span title="typing.Any">Any</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Optional parameters to pass to workflow.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>workflows_thread_pool_workers</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of worker threads for workflow execution.
Defaults to 4.</p>
              </div>
            </td>
            <td>
                  <code>4</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>cancel_thread_pool_tasks_on_exit</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Whether to cancel pending tasks when exiting.
Defaults to True.</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>video_metadata_input_name</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Name of video metadata input in workflow.
Defaults to "video_metadata".</p>
              </div>
            </td>
            <td>
                  <code>&#39;video_metadata&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>max_fps</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="typing.Union">Union</span>[<span title="float">float</span>, <span title="int">int</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Optional maximum FPS to process video at.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>source_buffer_filling_strategy</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="inference_sdk.http.client.BufferFillingStrategy">BufferFillingStrategy</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Strategy for filling source buffer when full.
One of: "WAIT", "DROP_OLDEST", "ADAPTIVE_DROP_OLDEST", "DROP_LATEST",
"ADAPTIVE_DROP_LATEST". Defaults to "DROP_OLDEST".</p>
              </div>
            </td>
            <td>
                  <code>&#39;DROP_OLDEST&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>source_buffer_consumption_strategy</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="inference_sdk.http.client.BufferConsumptionStrategy">BufferConsumptionStrategy</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Strategy for consuming from source buffer.
One of: "LAZY", "EAGER". Defaults to "EAGER".</p>
              </div>
            </td>
            <td>
                  <code>&#39;EAGER&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>video_source_properties</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="typing.Dict">Dict</span>[<span title="str">str</span>, <span title="float">float</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Optional dictionary of video source properties.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>batch_collection_timeout</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="float">float</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Optional timeout for batch collection in seconds.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>results_buffer_size</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Size of results buffer. Defaults to 64.</p>
              </div>
            </td>
            <td>
                  <code>64</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>dict</code></td>            <td>
                  <code><span title="dict">dict</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Response containing pipeline initialization details.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.InvalidParameterError">InvalidParameterError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If workflow specification parameters are invalid.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.HTTPCallErrorError">HTTPCallErrorError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If there is an error in the HTTP call.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.HTTPClientError">HTTPClientError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If there is an error with the server connection.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>inference_sdk/http/client.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">2530</span>
<span class="normal">2531</span>
<span class="normal">2532</span>
<span class="normal">2533</span>
<span class="normal">2534</span>
<span class="normal">2535</span>
<span class="normal">2536</span>
<span class="normal">2537</span>
<span class="normal">2538</span>
<span class="normal">2539</span>
<span class="normal">2540</span>
<span class="normal">2541</span>
<span class="normal">2542</span>
<span class="normal">2543</span>
<span class="normal">2544</span>
<span class="normal">2545</span>
<span class="normal">2546</span>
<span class="normal">2547</span>
<span class="normal">2548</span>
<span class="normal">2549</span>
<span class="normal">2550</span>
<span class="normal">2551</span>
<span class="normal">2552</span>
<span class="normal">2553</span>
<span class="normal">2554</span>
<span class="normal">2555</span>
<span class="normal">2556</span>
<span class="normal">2557</span>
<span class="normal">2558</span>
<span class="normal">2559</span>
<span class="normal">2560</span>
<span class="normal">2561</span>
<span class="normal">2562</span>
<span class="normal">2563</span>
<span class="normal">2564</span>
<span class="normal">2565</span>
<span class="normal">2566</span>
<span class="normal">2567</span>
<span class="normal">2568</span>
<span class="normal">2569</span>
<span class="normal">2570</span>
<span class="normal">2571</span>
<span class="normal">2572</span>
<span class="normal">2573</span>
<span class="normal">2574</span>
<span class="normal">2575</span>
<span class="normal">2576</span>
<span class="normal">2577</span>
<span class="normal">2578</span>
<span class="normal">2579</span>
<span class="normal">2580</span>
<span class="normal">2581</span>
<span class="normal">2582</span>
<span class="normal">2583</span>
<span class="normal">2584</span>
<span class="normal">2585</span>
<span class="normal">2586</span>
<span class="normal">2587</span>
<span class="normal">2588</span>
<span class="normal">2589</span>
<span class="normal">2590</span>
<span class="normal">2591</span>
<span class="normal">2592</span>
<span class="normal">2593</span>
<span class="normal">2594</span>
<span class="normal">2595</span>
<span class="normal">2596</span>
<span class="normal">2597</span>
<span class="normal">2598</span>
<span class="normal">2599</span>
<span class="normal">2600</span>
<span class="normal">2601</span>
<span class="normal">2602</span>
<span class="normal">2603</span>
<span class="normal">2604</span>
<span class="normal">2605</span>
<span class="normal">2606</span>
<span class="normal">2607</span>
<span class="normal">2608</span>
<span class="normal">2609</span>
<span class="normal">2610</span>
<span class="normal">2611</span>
<span class="normal">2612</span>
<span class="normal">2613</span>
<span class="normal">2614</span>
<span class="normal">2615</span>
<span class="normal">2616</span>
<span class="normal">2617</span>
<span class="normal">2618</span>
<span class="normal">2619</span>
<span class="normal">2620</span>
<span class="normal">2621</span>
<span class="normal">2622</span>
<span class="normal">2623</span>
<span class="normal">2624</span>
<span class="normal">2625</span>
<span class="normal">2626</span>
<span class="normal">2627</span>
<span class="normal">2628</span>
<span class="normal">2629</span>
<span class="normal">2630</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@experimental</span><span class="p">(</span>
    <span class="n">info</span><span class="o">=</span><span class="s2">&quot;Video processing in inference server is under development. Breaking changes are possible.&quot;</span>
<span class="p">)</span>
<span class="nd">@wrap_errors</span>
<span class="k">def</span><span class="w"> </span><span class="nf">start_inference_pipeline_with_workflow</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">video_reference</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]],</span>
    <span class="n">workflow_specification</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">workspace_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">workflow_id</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">image_input_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;image&quot;</span><span class="p">,</span>
    <span class="n">workflows_parameters</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">workflows_thread_pool_workers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
    <span class="n">cancel_thread_pool_tasks_on_exit</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">video_metadata_input_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;video_metadata&quot;</span><span class="p">,</span>
    <span class="n">max_fps</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">source_buffer_filling_strategy</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">BufferFillingStrategy</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;DROP_OLDEST&quot;</span><span class="p">,</span>
    <span class="n">source_buffer_consumption_strategy</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span>
        <span class="n">BufferConsumptionStrategy</span>
    <span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;EAGER&quot;</span><span class="p">,</span>
    <span class="n">video_source_properties</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">batch_collection_timeout</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">results_buffer_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">64</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Starts an inference pipeline using a workflow specification.</span>

<span class="sd">    Args:</span>
<span class="sd">        video_reference: Path to video file, camera index, or list of video sources.</span>
<span class="sd">            Can be a string path, integer camera index, or list of either.</span>
<span class="sd">        workflow_specification: Optional workflow specification dictionary. Mutually</span>
<span class="sd">            exclusive with workspace_name/workflow_id.</span>
<span class="sd">        workspace_name: Optional name of workspace containing workflow. Must be used</span>
<span class="sd">            with workflow_id.</span>
<span class="sd">        workflow_id: Optional ID of workflow to use. Must be used with workspace_name.</span>
<span class="sd">        image_input_name: Name of the image input node in workflow. Defaults to &quot;image&quot;.</span>
<span class="sd">        workflows_parameters: Optional parameters to pass to workflow.</span>
<span class="sd">        workflows_thread_pool_workers: Number of worker threads for workflow execution.</span>
<span class="sd">            Defaults to 4.</span>
<span class="sd">        cancel_thread_pool_tasks_on_exit: Whether to cancel pending tasks when exiting.</span>
<span class="sd">            Defaults to True.</span>
<span class="sd">        video_metadata_input_name: Name of video metadata input in workflow.</span>
<span class="sd">            Defaults to &quot;video_metadata&quot;.</span>
<span class="sd">        max_fps: Optional maximum FPS to process video at.</span>
<span class="sd">        source_buffer_filling_strategy: Strategy for filling source buffer when full.</span>
<span class="sd">            One of: &quot;WAIT&quot;, &quot;DROP_OLDEST&quot;, &quot;ADAPTIVE_DROP_OLDEST&quot;, &quot;DROP_LATEST&quot;,</span>
<span class="sd">            &quot;ADAPTIVE_DROP_LATEST&quot;. Defaults to &quot;DROP_OLDEST&quot;.</span>
<span class="sd">        source_buffer_consumption_strategy: Strategy for consuming from source buffer.</span>
<span class="sd">            One of: &quot;LAZY&quot;, &quot;EAGER&quot;. Defaults to &quot;EAGER&quot;.</span>
<span class="sd">        video_source_properties: Optional dictionary of video source properties.</span>
<span class="sd">        batch_collection_timeout: Optional timeout for batch collection in seconds.</span>
<span class="sd">        results_buffer_size: Size of results buffer. Defaults to 64.</span>

<span class="sd">    Returns:</span>
<span class="sd">        dict: Response containing pipeline initialization details.</span>

<span class="sd">    Raises:</span>
<span class="sd">        InvalidParameterError: If workflow specification parameters are invalid.</span>
<span class="sd">        HTTPCallErrorError: If there is an error in the HTTP call.</span>
<span class="sd">        HTTPClientError: If there is an error with the server connection.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">named_workflow_specified</span> <span class="o">=</span> <span class="p">(</span><span class="n">workspace_name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span>
        <span class="n">workflow_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">named_workflow_specified</span> <span class="o">!=</span> <span class="p">(</span><span class="n">workflow_specification</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)):</span>
        <span class="k">raise</span> <span class="n">InvalidParameterError</span><span class="p">(</span>
            <span class="s2">&quot;Parameters (`workspace_name`, `workflow_id`) can be used mutually exclusive with &quot;</span>
            <span class="s2">&quot;`workflow_specification`, but at least one must be set.&quot;</span>
        <span class="p">)</span>
    <span class="n">payload</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;api_key&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">__api_key</span><span class="p">,</span>
        <span class="s2">&quot;video_configuration&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;VideoConfiguration&quot;</span><span class="p">,</span>
            <span class="s2">&quot;video_reference&quot;</span><span class="p">:</span> <span class="n">video_reference</span><span class="p">,</span>
            <span class="s2">&quot;max_fps&quot;</span><span class="p">:</span> <span class="n">max_fps</span><span class="p">,</span>
            <span class="s2">&quot;source_buffer_filling_strategy&quot;</span><span class="p">:</span> <span class="n">source_buffer_filling_strategy</span><span class="p">,</span>
            <span class="s2">&quot;source_buffer_consumption_strategy&quot;</span><span class="p">:</span> <span class="n">source_buffer_consumption_strategy</span><span class="p">,</span>
            <span class="s2">&quot;video_source_properties&quot;</span><span class="p">:</span> <span class="n">video_source_properties</span><span class="p">,</span>
            <span class="s2">&quot;batch_collection_timeout&quot;</span><span class="p">:</span> <span class="n">batch_collection_timeout</span><span class="p">,</span>
        <span class="p">},</span>
        <span class="s2">&quot;processing_configuration&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;WorkflowConfiguration&quot;</span><span class="p">,</span>
            <span class="s2">&quot;workflow_specification&quot;</span><span class="p">:</span> <span class="n">workflow_specification</span><span class="p">,</span>
            <span class="s2">&quot;workspace_name&quot;</span><span class="p">:</span> <span class="n">workspace_name</span><span class="p">,</span>
            <span class="s2">&quot;workflow_id&quot;</span><span class="p">:</span> <span class="n">workflow_id</span><span class="p">,</span>
            <span class="s2">&quot;image_input_name&quot;</span><span class="p">:</span> <span class="n">image_input_name</span><span class="p">,</span>
            <span class="s2">&quot;workflows_parameters&quot;</span><span class="p">:</span> <span class="n">workflows_parameters</span><span class="p">,</span>
            <span class="s2">&quot;workflows_thread_pool_workers&quot;</span><span class="p">:</span> <span class="n">workflows_thread_pool_workers</span><span class="p">,</span>
            <span class="s2">&quot;cancel_thread_pool_tasks_on_exit&quot;</span><span class="p">:</span> <span class="n">cancel_thread_pool_tasks_on_exit</span><span class="p">,</span>
            <span class="s2">&quot;video_metadata_input_name&quot;</span><span class="p">:</span> <span class="n">video_metadata_input_name</span><span class="p">,</span>
        <span class="p">},</span>
        <span class="s2">&quot;sink_configuration&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;MemorySinkConfiguration&quot;</span><span class="p">,</span>
            <span class="s2">&quot;results_buffer_size&quot;</span><span class="p">:</span> <span class="n">results_buffer_size</span><span class="p">,</span>
        <span class="p">},</span>
    <span class="p">}</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">post</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__api_url</span><span class="si">}</span><span class="s2">/inference_pipelines/initialise&quot;</span><span class="p">,</span>
        <span class="n">json</span><span class="o">=</span><span class="n">payload</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">response</span><span class="o">.</span><span class="n">raise_for_status</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="inference_sdk.http.client.InferenceHTTPClient.terminate_inference_pipeline" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">terminate_inference_pipeline</span><span class="p">(</span><span class="n">pipeline_id</span><span class="p">)</span></code>

<a href="#inference_sdk.http.client.InferenceHTTPClient.terminate_inference_pipeline" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Terminates a running inference pipeline.</p>
<p>Sends a request to terminate the specified inference pipeline. This will stop all
processing and free up associated resources.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>pipeline_id</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The unique identifier of the inference pipeline to terminate.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>dict</code></td>            <td>
                  <code><span title="dict">dict</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A dictionary containing the response from the server about the termination operation.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.HTTPCallErrorError">HTTPCallErrorError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If there is an error in the HTTP call.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.HTTPClientError">HTTPClientError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If there is an error with the server connection.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><span title="ValueError">ValueError</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If pipeline_id is empty or None.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>inference_sdk/http/client.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">2745</span>
<span class="normal">2746</span>
<span class="normal">2747</span>
<span class="normal">2748</span>
<span class="normal">2749</span>
<span class="normal">2750</span>
<span class="normal">2751</span>
<span class="normal">2752</span>
<span class="normal">2753</span>
<span class="normal">2754</span>
<span class="normal">2755</span>
<span class="normal">2756</span>
<span class="normal">2757</span>
<span class="normal">2758</span>
<span class="normal">2759</span>
<span class="normal">2760</span>
<span class="normal">2761</span>
<span class="normal">2762</span>
<span class="normal">2763</span>
<span class="normal">2764</span>
<span class="normal">2765</span>
<span class="normal">2766</span>
<span class="normal">2767</span>
<span class="normal">2768</span>
<span class="normal">2769</span>
<span class="normal">2770</span>
<span class="normal">2771</span>
<span class="normal">2772</span>
<span class="normal">2773</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@experimental</span><span class="p">(</span>
    <span class="n">info</span><span class="o">=</span><span class="s2">&quot;Video processing in inference server is under development. Breaking changes are possible.&quot;</span>
<span class="p">)</span>
<span class="nd">@wrap_errors</span>
<span class="k">def</span><span class="w"> </span><span class="nf">terminate_inference_pipeline</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pipeline_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Terminates a running inference pipeline.</span>

<span class="sd">    Sends a request to terminate the specified inference pipeline. This will stop all</span>
<span class="sd">    processing and free up associated resources.</span>

<span class="sd">    Args:</span>
<span class="sd">        pipeline_id: The unique identifier of the inference pipeline to terminate.</span>

<span class="sd">    Returns:</span>
<span class="sd">        dict: A dictionary containing the response from the server about the termination operation.</span>

<span class="sd">    Raises:</span>
<span class="sd">        HTTPCallErrorError: If there is an error in the HTTP call.</span>
<span class="sd">        HTTPClientError: If there is an error with the server connection.</span>
<span class="sd">        ValueError: If pipeline_id is empty or None.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_ensure_pipeline_id_not_empty</span><span class="p">(</span><span class="n">pipeline_id</span><span class="o">=</span><span class="n">pipeline_id</span><span class="p">)</span>
    <span class="n">payload</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;api_key&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">__api_key</span><span class="p">}</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">post</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__api_url</span><span class="si">}</span><span class="s2">/inference_pipelines/</span><span class="si">{</span><span class="n">pipeline_id</span><span class="si">}</span><span class="s2">/terminate&quot;</span><span class="p">,</span>
        <span class="n">json</span><span class="o">=</span><span class="n">payload</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">api_key_safe_raise_for_status</span><span class="p">(</span><span class="n">response</span><span class="o">=</span><span class="n">response</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="inference_sdk.http.client.InferenceHTTPClient.unload_model" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">unload_model</span><span class="p">(</span><span class="n">model_id</span><span class="p">)</span></code>

<a href="#inference_sdk.http.client.InferenceHTTPClient.unload_model" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Unload a model from the server.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>model_id</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The identifier of the model to unload.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>RegisteredModels</code></td>            <td>
                  <code><a class="autorefs autorefs-internal" href="../entities/#inference_sdk.http.entities.RegisteredModels">RegisteredModels</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Updated information about registered models.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.WrongClientModeError">WrongClientModeError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If not in API v1 mode.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.HTTPCallErrorError">HTTPCallErrorError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If there is an error in the HTTP call.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="../errors/#inference_sdk.http.errors.HTTPClientError">HTTPClientError</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If there is an error with the server connection.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>inference_sdk/http/client.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1035</span>
<span class="normal">1036</span>
<span class="normal">1037</span>
<span class="normal">1038</span>
<span class="normal">1039</span>
<span class="normal">1040</span>
<span class="normal">1041</span>
<span class="normal">1042</span>
<span class="normal">1043</span>
<span class="normal">1044</span>
<span class="normal">1045</span>
<span class="normal">1046</span>
<span class="normal">1047</span>
<span class="normal">1048</span>
<span class="normal">1049</span>
<span class="normal">1050</span>
<span class="normal">1051</span>
<span class="normal">1052</span>
<span class="normal">1053</span>
<span class="normal">1054</span>
<span class="normal">1055</span>
<span class="normal">1056</span>
<span class="normal">1057</span>
<span class="normal">1058</span>
<span class="normal">1059</span>
<span class="normal">1060</span>
<span class="normal">1061</span>
<span class="normal">1062</span>
<span class="normal">1063</span>
<span class="normal">1064</span>
<span class="normal">1065</span>
<span class="normal">1066</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@wrap_errors</span>
<span class="k">def</span><span class="w"> </span><span class="nf">unload_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">RegisteredModels</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Unload a model from the server.</span>

<span class="sd">    Args:</span>
<span class="sd">        model_id (str): The identifier of the model to unload.</span>

<span class="sd">    Returns:</span>
<span class="sd">        RegisteredModels: Updated information about registered models.</span>

<span class="sd">    Raises:</span>
<span class="sd">        WrongClientModeError: If not in API v1 mode.</span>
<span class="sd">        HTTPCallErrorError: If there is an error in the HTTP call.</span>
<span class="sd">        HTTPClientError: If there is an error with the server connection.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">__ensure_v1_client_mode</span><span class="p">()</span>
    <span class="n">de_aliased_model_id</span> <span class="o">=</span> <span class="n">resolve_roboflow_model_alias</span><span class="p">(</span><span class="n">model_id</span><span class="o">=</span><span class="n">model_id</span><span class="p">)</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">post</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__api_url</span><span class="si">}</span><span class="s2">/model/remove&quot;</span><span class="p">,</span>
        <span class="n">json</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;model_id&quot;</span><span class="p">:</span> <span class="n">de_aliased_model_id</span><span class="p">,</span>
        <span class="p">},</span>
        <span class="n">headers</span><span class="o">=</span><span class="n">DEFAULT_HEADERS</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">response</span><span class="o">.</span><span class="n">raise_for_status</span><span class="p">()</span>
    <span class="n">response_payload</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>
    <span class="k">if</span> <span class="p">(</span>
        <span class="n">de_aliased_model_id</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">__selected_model</span>
        <span class="ow">or</span> <span class="n">model_id</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">__selected_model</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__selected_model</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">return</span> <span class="n">RegisteredModels</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">response_payload</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="inference_sdk.http.client.InferenceHTTPClient.use_api_v0" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">use_api_v0</span><span class="p">()</span></code>

<a href="#inference_sdk.http.client.InferenceHTTPClient.use_api_v0" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Temporarily use API version 0 for client operations.</p>


    <p><span class="doc-section-title">Yields:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="#inference_sdk.http.client.InferenceHTTPClient">InferenceHTTPClient</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Generator[InferenceHTTPClient, None, None]: The client instance temporarily using API v0.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>inference_sdk/http/client.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@contextmanager</span>
<span class="k">def</span><span class="w"> </span><span class="nf">use_api_v0</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Generator</span><span class="p">[</span><span class="s2">&quot;InferenceHTTPClient&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Temporarily use API version 0 for client operations.</span>

<span class="sd">    Yields:</span>
<span class="sd">        Generator[InferenceHTTPClient, None, None]: The client instance temporarily using API v0.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">previous_client_mode</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__client_mode</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">__client_mode</span> <span class="o">=</span> <span class="n">HTTPClientMode</span><span class="o">.</span><span class="n">V0</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">yield</span> <span class="bp">self</span>
    <span class="k">finally</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__client_mode</span> <span class="o">=</span> <span class="n">previous_client_mode</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="inference_sdk.http.client.InferenceHTTPClient.use_api_v1" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">use_api_v1</span><span class="p">()</span></code>

<a href="#inference_sdk.http.client.InferenceHTTPClient.use_api_v1" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Temporarily use API version 1 for client operations.</p>


    <p><span class="doc-section-title">Yields:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="#inference_sdk.http.client.InferenceHTTPClient">InferenceHTTPClient</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Generator[InferenceHTTPClient, None, None]: The client instance temporarily using API v1.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>inference_sdk/http/client.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@contextmanager</span>
<span class="k">def</span><span class="w"> </span><span class="nf">use_api_v1</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Generator</span><span class="p">[</span><span class="s2">&quot;InferenceHTTPClient&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Temporarily use API version 1 for client operations.</span>

<span class="sd">    Yields:</span>
<span class="sd">        Generator[InferenceHTTPClient, None, None]: The client instance temporarily using API v1.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">previous_client_mode</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__client_mode</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">__client_mode</span> <span class="o">=</span> <span class="n">HTTPClientMode</span><span class="o">.</span><span class="n">V1</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">yield</span> <span class="bp">self</span>
    <span class="k">finally</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__client_mode</span> <span class="o">=</span> <span class="n">previous_client_mode</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="inference_sdk.http.client.InferenceHTTPClient.use_configuration" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">use_configuration</span><span class="p">(</span><span class="n">inference_configuration</span><span class="p">)</span></code>

<a href="#inference_sdk.http.client.InferenceHTTPClient.use_configuration" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Temporarily use a different inference configuration.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>inference_configuration</code>
            </td>
            <td>
                  <code><a class="autorefs autorefs-internal" href="../entities/#inference_sdk.http.entities.InferenceConfiguration">InferenceConfiguration</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The temporary configuration to use.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Yields:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="#inference_sdk.http.client.InferenceHTTPClient">InferenceHTTPClient</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Generator[InferenceHTTPClient, None, None]: The client instance with temporary configuration.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>inference_sdk/http/client.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@contextmanager</span>
<span class="k">def</span><span class="w"> </span><span class="nf">use_configuration</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> <span class="n">inference_configuration</span><span class="p">:</span> <span class="n">InferenceConfiguration</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Generator</span><span class="p">[</span><span class="s2">&quot;InferenceHTTPClient&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Temporarily use a different inference configuration.</span>

<span class="sd">    Args:</span>
<span class="sd">        inference_configuration (InferenceConfiguration): The temporary configuration to use.</span>

<span class="sd">    Yields:</span>
<span class="sd">        Generator[InferenceHTTPClient, None, None]: The client instance with temporary configuration.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">previous_configuration</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__inference_configuration</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">__inference_configuration</span> <span class="o">=</span> <span class="n">inference_configuration</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">yield</span> <span class="bp">self</span>
    <span class="k">finally</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__inference_configuration</span> <span class="o">=</span> <span class="n">previous_configuration</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="inference_sdk.http.client.InferenceHTTPClient.use_model" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">use_model</span><span class="p">(</span><span class="n">model_id</span><span class="p">)</span></code>

<a href="#inference_sdk.http.client.InferenceHTTPClient.use_model" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Temporarily use a specific model for inference operations.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>model_id</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The identifier of the model to use.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Yields:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" href="#inference_sdk.http.client.InferenceHTTPClient">InferenceHTTPClient</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Generator[InferenceHTTPClient, None, None]: The client instance temporarily using the specified model.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>inference_sdk/http/client.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@contextmanager</span>
<span class="k">def</span><span class="w"> </span><span class="nf">use_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Generator</span><span class="p">[</span><span class="s2">&quot;InferenceHTTPClient&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Temporarily use a specific model for inference operations.</span>

<span class="sd">    Args:</span>
<span class="sd">        model_id (str): The identifier of the model to use.</span>

<span class="sd">    Yields:</span>
<span class="sd">        Generator[InferenceHTTPClient, None, None]: The client instance temporarily using the specified model.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">previous_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__selected_model</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">__selected_model</span> <span class="o">=</span> <span class="n">model_id</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">yield</span> <span class="bp">self</span>
    <span class="k">finally</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__selected_model</span> <span class="o">=</span> <span class="n">previous_model</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div>









  




                
              </article>
            </div>
          
  

          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Footer" >
        
          
          <a href="../../config/" class="md-footer__link md-footer__link--prev" aria-label="Previous: Config">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Previous
              </span>
              <div class="md-ellipsis">
                Config
              </div>
            </div>
          </a>
        
        
          
          <a href="../entities/" class="md-footer__link md-footer__link--next" aria-label="Next: Entities">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Next
              </span>
              <div class="md-ellipsis">
                Entities
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Roboflow 2025. All rights reserved.
    </div>
  
  
</div>
      
        <div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://github.com/roboflow" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://www.youtube.com/roboflow" target="_blank" rel="noopener" title="www.youtube.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78 0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305m-317.51 213.508V175.185l142.739 81.205z"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://www.linkedin.com/company/roboflow-ai/mycompany/" target="_blank" rel="noopener" title="www.linkedin.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3M135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5m282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9z"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://twitter.com/roboflow" target="_blank" rel="noopener" title="twitter.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
      <div class="md-progress" data-md-component="progress" role="progressbar"></div>
    
    
    <script id="__config" type="application/json">{"base": "../../../..", "features": ["announce.dismiss", "content.action.edit", "content.code.copy", "content.tabs.link", "navigation.footer", "navigation.indexes", "navigation.instant", "navigation.instant.prefetch", "navigation.instant.preview", "navigation.instant.progress", "navigation.prune", "navigation.tabs", "navigation.tabs.sticky", "navigation.top", "navigation.tracking", "optimize", "search.share", "search.suggest", "toc.follow"], "search": "../../../../assets/javascripts/workers/search.c7c1ca2c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": {"default": 1.0}}</script>
    
    
      <script src="../../../../assets/javascripts/bundle.5a789024.min.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/dompurify/3.0.8/purify.min.js"></script>
      
        <script src="../../../../javascript/init_kapa_widget.js"></script>
      
        <script src="../../../../javascript/cookbooks.js"></script>
      
        <script src="../../../../javascript/workflows.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/gsap/3.12.5/gsap.min.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/gsap/3.12.5/ScrollTrigger.min.js"></script>
      
        <script src="https://unpkg.com/@rive-app/canvas"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/swiper@11/swiper-bundle.min.js"></script>
      
        <script src="../../../../assets/home.js"></script>
      
        <script src="../../../../js/segment.js"></script>
      
    
  </body>
</html>