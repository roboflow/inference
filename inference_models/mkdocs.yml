site_name: Inference Models
site_url: https://roboflow.github.io/inference-models/
site_author: Roboflow
site_description: Next-generation computer vision inference library with multi-backend support
repo_name: roboflow/inference
repo_url: https://github.com/roboflow/inference
edit_uri: https://github.com/roboflow/inference/tree/main/inference_models/docs
copyright: Roboflow 2026. All rights reserved.

extra:
  version:
    provider: mike
    default: latest
  generator: false
  social:
    - icon: fontawesome/brands/github
      link: https://github.com/roboflow
    - icon: fontawesome/brands/youtube
      link: https://www.youtube.com/roboflow
    - icon: fontawesome/brands/linkedin
      link: https://www.linkedin.com/company/roboflow-ai/mycompany/
    - icon: fontawesome/brands/twitter
      link: https://twitter.com/roboflow

extra_css:
  - stylesheets/extra.css

nav:
  - Home: index.md
  - Getting Started:
      - Installation: getting-started/installation.md
      - Quick Overview: getting-started/overview.md
      - Hardware Compatibility: getting-started/hardware-compatibility.md
      - Docker Environments: getting-started/docker.md
      - TensorRT Compilation: getting-started/trt-compilation.md
  - Models:
      - Overview: models/index.md
      - Object Detection:
          - RF-DETR: models/rfdetr-object-detection.md
          - YOLOv5: models/yolov5-object-detection.md
          - YOLOv8: models/yolov8-object-detection.md
          - YOLOv9: models/yolov9-object-detection.md
          - YOLOv10: models/yolov10-object-detection.md
          - YOLOv11: models/yolov11-object-detection.md
          - YOLOv12: models/yolov12-object-detection.md
          - YOLO26: models/yolo26-object-detection.md
          - YOLO-NAS: models/yolonas-object-detection.md
          - Roboflow Instant: models/roboflow-instant-object-detection.md
      - Instance Segmentation:
          - RF-DETR: models/rfdetr-instance-segmentation.md
          - YOLOv5: models/yolov5-instance-segmentation.md
          - YOLOv7: models/yolov7-instance-segmentation.md
          - YOLOv8: models/yolov8-instance-segmentation.md
          - YOLOv11: models/yolov11-instance-segmentation.md
          - YOLO26: models/yolo26-instance-segmentation.md
          - YOLACT: models/yolact-instance-segmentation.md
      - Classification:
          - YOLOv8: models/yolov8-classification.md
          - YOLOv11: models/yolov11-classification.md
          - ResNet: models/resnet-classification.md
          - ViT: models/vit-classification.md
          - DINOv3: models/dinov3-classification.md
      - OCR:
          - DocTR: models/doctr.md
          - EasyOCR: models/easyocr.md
          - TrOCR: models/trocr.md
      - Keypoint Detection:
          - YOLOv8: models/yolov8-keypoint-detection.md
          - YOLOv11: models/yolov11-keypoint-detection.md
          - YOLO26: models/yolo26-keypoint-detection.md
          - MediaPipe Face Detection: models/mediapipe-face.md
      - Interactive Segmentation:
          - SAM: models/sam-interactive-segmentation.md
          - SAM2: models/sam2-interactive-segmentation.md
          - SAM2 RT: models/sam2-rt-video-tracking.md
      - Vision-Language Models:
          - Florence-2: models/florence2.md
          - PaliGemma: models/paligemma.md
          - Qwen2.5-VL: models/qwen25vl.md
          - Qwen3-VL: models/qwen3vl.md
          - SmolVLM: models/smolvlm.md
          - Moondream2: models/moondream2.md
      - Embeddings:
          - CLIP: models/clip.md
          - Perception Encoder: models/perception-encoder.md
      - Semantic Segmentation:
          - DeepLabV3+: models/deeplabv3plus.md
      - Open-Vocabulary Object Detection:
          - Grounding DINO: models/grounding-dino.md
          - OWLv2: models/owlv2.md
      - Depth Estimation:
          - Depth Anything V2: models/depth-anything-v2.md
          - Depth Anything V3: models/depth-anything-v3.md
      - Gaze Detection:
          - L2CS-Net: models/l2cs.md
  - How-To:
      - Understand Core Concepts: how-to/understand-core-concepts.md
      - Choose the Right Backend: how-to/choose-backend.md
      - Work with Model Predictions: how-to/work-with-predictions.md
      - Understand Prediction Parameters: how-to/prediction-parameters.md
      - Debug Model Loading Issues: how-to/debug-model-loading.md
      - Configure Environment Variables: how-to/environment-variables.md
      - Load Models Locally: how-to/local-packages.md
      - Understand Roboflow Model Packages: how-to/roboflow-model-packages.md
      - Manage Cache: how-to/cache-management.md
  - Contributors:
      - Development Environment: contributors/dev-environment.md
      - Core Architecture: contributors/core-architecture.md
      - Dependencies and Backends: contributors/dependencies-and-backends.md
      - Adding a Model: contributors/adding-model.md
      - Writing Tests: contributors/writing-tests.md
  - API Reference:
      - Overview: api-reference/index.md
      - Core Classes:
          - AutoModel: api-reference/auto-model.md
          - AutoModelPipeline: api-reference/auto-model-pipeline.md
      - Prediction Types:
          - Detections: api-reference/detections.md
          - InstanceDetections: api-reference/instance-detections.md
          - KeyPoints: api-reference/keypoints.md
          - ClassificationPrediction: api-reference/classification-prediction.md
          - MultiLabelClassificationPrediction: api-reference/multi-label-classification-prediction.md
      - Enums and Types:
          - BackendType: api-reference/backend-type.md
          - ColorFormat: api-reference/color-format.md
          - Quantization: api-reference/quantization.md
      - Developer Tools:
          - Overview: api-reference/developer-tools/index.md
          - Base Functions:
              - get_model_package_contents: api-reference/developer-tools/get-model-package-contents.md
              - x_ray_runtime_environment: api-reference/developer-tools/x-ray-runtime-environment.md
              - download_files_to_directory: api-reference/developer-tools/download-files-to-directory.md
              - get_selected_onnx_execution_providers: api-reference/developer-tools/get-selected-onnx-execution-providers.md
              - get_model_from_provider: api-reference/developer-tools/get-model-from-provider.md
              - register_model_provider: api-reference/developer-tools/register-model-provider.md
          - Backend-Specific Utilities:
              - CUDA:
                  - use_primary_cuda_context: api-reference/developer-tools/cuda/use-primary-cuda-context.md
                  - use_cuda_context: api-reference/developer-tools/cuda/use-cuda-context.md
              - ONNX:
                  - set_onnx_execution_provider_defaults: api-reference/developer-tools/onnx/set-onnx-execution-provider-defaults.md
                  - run_onnx_session_with_batch_size_limit: api-reference/developer-tools/onnx/run-onnx-session-with-batch-size-limit.md
                  - run_onnx_session_via_iobinding: api-reference/developer-tools/onnx/run-onnx-session-via-iobinding.md
              - PyTorch:
                  - generate_batch_chunks: api-reference/developer-tools/torch/generate-batch-chunks.md
              - TensorRT:
                  - get_trt_engine_inputs_and_outputs: api-reference/developer-tools/trt/get-trt-engine-inputs-and-outputs.md
                  - infer_from_trt_engine: api-reference/developer-tools/trt/infer-from-trt-engine.md
                  - load_trt_model: api-reference/developer-tools/trt/load-trt-model.md
          - Entities:
              - RuntimeXRayResult: api-reference/developer-tools/runtime-xray-result.md
              - ModelMetadata: api-reference/developer-tools/model-metadata.md
              - ModelDependency: api-reference/developer-tools/model-dependency.md
              - ModelPackageMetadata: api-reference/developer-tools/model-package-metadata.md
              - TorchScriptPackageDetails: api-reference/developer-tools/torchscript-package-details.md
              - ONNXPackageDetails: api-reference/developer-tools/onnx-package-details.md
              - TRTPackageDetails: api-reference/developer-tools/trt-package-details.md
              - JetsonEnvironmentRequirements: api-reference/developer-tools/jetson-environment-requirements.md
              - ServerEnvironmentRequirements: api-reference/developer-tools/server-environment-requirements.md
              - FileDownloadSpecs: api-reference/developer-tools/file-download-specs.md
  - Errors:
      - Overview: errors/index.md
      - Model Loading: errors/model-loading.md
      - Package Negotiation: errors/package-negotiation.md
      - Model Retrieval: errors/model-retrieval.md
      - File & Download: errors/file-download.md
      - Runtime & Environment: errors/runtime-environment.md
      - Input & Validation: errors/input-validation.md
      - Models Runtime: errors/models-runtime.md
  - Changelog: changelog.md

theme:
  name: 'material'
  favicon: favicon.png
  logo: favicon.png
  font:
    text: Inter
    code: ui-monospace
  features:
    - navigation.tracking
    - content.code.copy
    - content.action.edit
    - content.tooltips
    - content.code.annotate
    - navigation.tabs
    - navigation.tabs.sticky
  icon:
    repo: fontawesome/brands/github
  palette:
    - scheme: default
      primary: 'custom'
plugins:
  - search
  - mkdocstrings:
      default_handler: python
      handlers:
        python:
          options:
            separate_signature: true
            line_length: 88
            parameter_headings: true
            paths: [ inference_models ]
            load_external_modules: true
            allow_inspection: true
            show_bases: true
            group_by_category: true
            docstring_style: google
            show_symbol_type_heading: true
            show_root_heading: True
            show_symbol_type_toc: true
            show_category_heading: true
            docstring_section_style: list
          inventories:
            - url: https://docs.python-requests.org/en/master/objects.inv
              domains: [ std, py ]
  - gen-files:
      scripts:
        - docs/scripts/gen_ref_pages.py
  - literate-nav:
      nav_file: SUMMARY.md
      implicit_index: True

markdown_extensions:
  - admonition
  - attr_list
  - md_in_html
  - pymdownx.details
  - pymdownx.emoji:
      emoji_index: !!python/name:material.extensions.emoji.twemoji
      emoji_generator: !!python/name:material.extensions.emoji.to_svg
  - pymdownx.highlight:
      anchor_linenums: true
  - pymdownx.inlinehilite
  - pymdownx.snippets
  - pymdownx.superfences
  - pymdownx.tabbed:
      alternate_style: true
  - toc:
      permalink: true

